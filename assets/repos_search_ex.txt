{"tutorials-2017-09-26-ncs1002-configuration-automation-with-ydk": {"content": "This tutorial is the next one in our series of documents, devoted to automation of configuration of Cisco optical products. We will give here exact examples and explanations of how to use OpenConfig models and YDK infrastructure to configure a slice on NCS1002 (terminal device). You can refer to the previous tutorial to refresh information about different modes of NCS1002 slices and corresponding OpenConfig models.There are many ways to configure a device using OpenConfig models. This document describes how you can automate configuration with help of YDK. YANG Development Kit (YDK) is a powerful, open-source tool that generates APIs using YANG models. YDK supports different programming languages and has several built-in components that isolate you from the protocol, transport and encoding specifics. There is no need to code protocol specifics (e.g. NETCONF, RESTCONF) or manipulate serialized data (e.g. XML or JSON) directly, as YDK has this integrated. With YDK you can focus your attention on the data structures and automation logic. YDK supports Python and C++ today with more languages coming soon (e.g., Go Lang, Ruby, etc.). YDK performs local validation of your code based on information embedded in the YANG model. The tool checks types, values, semantics, deviations, etc to make sure that some possible errors are found locally, before applying configuration on a device.Slice configuration overviewIn our introduction tutorial, we talked about five different slice modes (three modes for 100G client ports and two modes for 10G clients). Let\u2019s have a look on a configuration procedure for the simplest case, a 2x100GE-2x100G mode. Full YDK configuration examples for all modes can be found on GitHub.As you remember, in \u201c2x100GE2x100G\u201d mode, the speed of each line port equals to the speed of any client port and this allows to have direct 1-to-1 mappings between client ports and line (trunk) ports. The code provided below is very basic by the intention to make it easier. Slice number, wavelengths and power levels are predefined in the code, but nothing prevents you from modifying this code according to your needs.There are three major OpenConfig models needed to configure a slice#  openconfig-interfaces  openconfig-terminal-device  openconfig-platformThey are complementary to each other (or, in other words, there are interdependences). That means that you need to commit configurations from all of them at the same time.Let\u2019s start with the first model listed, \u201copenconfig-interfaces\u201d. The task of this model is to make sure that line ports (trunks) are \u201cUP\u201d. This operation should be done on each port you have in the slice (if you like to follow schemes, you can see that these ports correspond to \u201cTransceivers on Line Ports\u201d)   \tinterface = oc_interface.Interface()interface.name = 'Optics0/0/0/5' if_config = interface.Config()if_config.name = 'Optics0/0/0/5'if_config.type = iana_if_type.OpticalchannelIdentity()if_config.enabled = True  ## \u201dTrue\u201d means \u201cno shut\u201dinterface.config = if_configoc_interface.interface.append(interface)(the code, that you will see on GitHub) will have several enhancements to remove repetitive configuration, but the overall logic stays the same as in this document)In the second model (\u201copenconfig-terminal-device\u201d) you need to define#  Logical Ethernet Channels and map them to the client ports.  Mappings between Ethernet Logical Channels and OTN Logical Channels.  Mappings between OTN Logical Channels and Optical Channels.Our final goal is to map the first client port to the first line port, and the last client port should be mapped to the second line port. You can find all the configurations for the first client/line ports pair below. Code will be similar for the second pair, and full configuration is available on GitHuba) At this step, you need to define Ethernet Logical Channels and make proper mapping between them and Transceivers. You also need to specify the speed, status, and Ethernet mode of the channel#  channel = oc_logical_channel.logical_channels.Channel()channel.index = 1 ## indexing can be any, except 0channel_config = channel.Config()  channel_config.rate_class = oc_tr_types.Trib_Rate_100GIdentity()channel_config.admin_state = oc_tr_types.AdminStateTypeEnum.ENABLEDchannel_config.trib_protocol = oc_tr_types.Prot_100G_MlgIdentity()channel_config.logical_channel_type = oc_tr_types.Prot_EthernetIdentity()channel.config = channel_configchannel_ingress = channel.Ingress()channel_ingress_tr = channel_ingress.Config()channel_ingress_tr.transceiver = '0/0-Optics0/0/0/0'channel_ingress.config = channel_ingress_trchannel.ingress = channel_ingressb) After you created Ethernet Logical Channels, you need to map them to OTN Logical Channels (will be created in the next step). At this step, you need to define the speed of the mapped Ethernet Logical Channel inside the OTN channel (things are easy for this mode, but with 5x100GE-2x250G mode you will need to split middle Ethernet Logical Channel into two different OTN Logical Channels in a 50/50 ratio) channel_assignment = channel.logical_channel_assignments.Assignment()channel_assignment.index = 1  channel_assignment_config = channel_assignment.Config()channel_assignment_config.allocation = Decimal64('100') channel_assignment_config.assignment_type = channel_assignment.config.AssignmentTypeEnum. LOGICAL_CHANNELchannel_assignment_config.logical_channel = 51 channel_assignment.config = channel_assignment_configchannel.logical_channel_assignments.assignment.append(channel_assignment)oc_logical_channel.logical_channels.channel.append(channel)c) At this step, you need to define OTN logical channels, their speed and map them to Optical Channels (that are defined in the final step using \u201copenconfig-platform\u201d model)# channel = oc_logical_channel.logical_channels.Channel()channel.index = 51channel_config = channel.Config()channel_config.admin_state = oc_tr_types.AdminStateTypeEnum.ENABLEDchannel_config.logical_channel_type = oc_tr_types.Prot_OtnIdentity()channel.config = channel_configchannel_assignment = channel.logical_channel_assignments.Assignment()channel_assignment.index = 1channel_assignment_config = channel_assignment.Config()channel_assignment_config.allocation = Decimal64('100')channel_assignment_config.assignment_type = channel_assignment.config. AssignmentTypeEnum.OPTICAL_CHANNELchannel_assignment_config.optical_channel = '0/0-OpticalChannel0/0/0/5\u2019channel_assignment.config = channel_assignment_configchannel.logical_channel_assignments.assignment.append(channel_assignment)oc_logical_channel.logical_channels.channel.append(channel)Finally, in the \u201copenconfig-platform\u201d model you need to create Optical Channels and map them with real line ports on the slice. You also define power level, wavelength and FEC mode (mode1 = 7% or mode2 = 20%) for each trunk. Please consider, that in the \u201copenconfig-platform\u201d model power levels are defined in \u201c0.01dM\u201d and frequency is expressed in \u201cMHz\u201d. component = oc_component.Component()component.name = '0/0-OpticalChannel0/0/0/5'optical_channel_config = component.optical_channel.Config()optical_channel_config.line_port = '0/0-Optics0/0/0/5' optical_channel_config.operational_mode = 2 optical_channel_config.target_output_power = 0 optical_channel_config.frequency = 191300000component.optical_channel.config = optical_channel_configoc_component.component.append(component)At this step, we configured the main logic of our code, let\u2019s have a look at other parts of the YDK code.Connecting to NCS1002For a successful connection of your YDK code to a NCS1002, you need to have this configured on your device# xml agent tty!netconf agent tty session timeout 500!netconf-yang agent ssh!ssh server v2   ## requires key generationYDK code uses built-in NCCLIENT client module to handle the NETCONF connection establishment#from ydk.services import NetconfServicefrom ydk.providers import NetconfServiceProviderprovider = NetconfServiceProvider(address=device.hostname,                                   port=device.port,                                   username=device.username,                                   password=device.password,                                   protocol=device.scheme)YDK will wrap-up the configuration based on OpenConfig models to XML format before sending to a NCS1002. Here is an example of such an output for 2x100GE2x100G mode that was explained in this document#VOSIPCHU-M-C1GV#vosipchu$ python nc-create-oc-ncs1002-40-ydk.py ssh#//root#lab@172.20.168.83 -v2017-09-11 19#02#57,687 - ydk.providers.netconf_provider - INFO - NetconfServiceProvider connected to 172.20.168.83#None using ssh2017-09-11 19#02#57,687 - ydk.services.netconf_service - INFO - Executing edit-config RPC2017-09-11 19#02#57,704 - ydk.services.executor_service - INFO - Executor operation initiated2017-09-11 19#02#57,712 - ydk.providers._provider_plugin - DEBUG - &lt;rpc xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~ message-id=~urn#uuid#aded4537-5078-403c-a0ef-f205bdc10bf9~&gt;  &lt;edit-config&gt;    &lt;target&gt;      &lt;candidate&gt;&lt;/candidate&gt;    &lt;/target&gt;    &lt;config&gt;      &lt;interfaces xmlns=~http#//openconfig.net/yang/interfaces~&gt;        &lt;interface&gt;          &lt;name&gt;Optics0/0/0/5&lt;/name&gt;          &lt;config&gt;            &lt;enabled&gt;true&lt;/enabled&gt;            &lt;name&gt;Optics0/0/0/5&lt;/name&gt;            &lt;type xmlns#idx=~urn#ietf#params#xml#ns#yang#iana-if-type~&gt;idx#opticalChannel&lt;/type&gt;          &lt;/config&gt;        &lt;/interface&gt;        &lt;interface&gt;          &lt;name&gt;Optics0/0/0/6&lt;/name&gt;          &lt;config&gt;            &lt;enabled&gt;true&lt;/enabled&gt;            &lt;name&gt;Optics0/0/0/6&lt;/name&gt;            &lt;type xmlns#idx=~urn#ietf#params#xml#ns#yang#iana-if-type~&gt;idx#opticalChannel&lt;/type&gt;          &lt;/config&gt;        &lt;/interface&gt;      &lt;/interfaces&gt;    &lt;/config&gt;  &lt;/edit-config&gt;&lt;/rpc&gt;2017-09-11 19#02#58,000 - ydk.providers._provider_plugin - DEBUG - &lt;rpc-reply xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~ message-id=~urn#uuid#aded4537-5078-403c-a0ef-f205bdc10bf9~&gt;  &lt;ok/&gt;&lt;/rpc-reply&gt;2017-09-11 19#02#58,001 - ydk.services.executor_service - INFO - Executor operation completed2017-09-11 19#02#58,001 - ydk.services.netconf_service - INFO - Executing edit-config RPC2017-09-11 19#02#58,016 - ydk.services.executor_service - INFO - Executor operation initiated2017-09-11 19#02#58,020 - ydk.providers._provider_plugin - DEBUG - &lt;rpc xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~ message-id=~urn#uuid#cbb88133-ef42-4eb1-b3ca-c8ef6472e52e~&gt;  &lt;edit-config&gt;    &lt;target&gt;      &lt;candidate&gt;&lt;/candidate&gt;    &lt;/target&gt;    &lt;config&gt;      &lt;terminal-device xmlns=~http#//openconfig.net/yang/terminal-device~&gt;        &lt;logical-channels&gt;          &lt;channel&gt;            &lt;index&gt;100&lt;/index&gt;            &lt;config&gt;              &lt;admin-state&gt;ENABLED&lt;/admin-state&gt;              &lt;logical-channel-type xmlns#idx=~http#//openconfig.net/yang/transport-types~&gt;idx#PROT_ETHERNET&lt;/logical-channel-type&gt;              &lt;rate-class xmlns#idx=~http#//openconfig.net/yang/transport-types~&gt;idx#TRIB_RATE_100G&lt;/rate-class&gt;              &lt;trib-protocol xmlns#idx=~http#//openconfig.net/yang/transport-types~&gt;idx#PROT_100G_MLG&lt;/trib-protocol&gt;            &lt;/config&gt;            &lt;ingress&gt;              &lt;config&gt;                &lt;transceiver&gt;0/0-Optics0/0/0/0&lt;/transceiver&gt;              &lt;/config&gt;            &lt;/ingress&gt;            &lt;logical-channel-assignments&gt;              &lt;assignment&gt;                &lt;index&gt;1&lt;/index&gt;                &lt;config&gt;                  &lt;allocation&gt;100&lt;/allocation&gt;                  &lt;assignment-type&gt;LOGICAL_CHANNEL&lt;/assignment-type&gt;                  &lt;logical-channel&gt;200&lt;/logical-channel&gt;                &lt;/config&gt;              &lt;/assignment&gt;            &lt;/logical-channel-assignments&gt;          &lt;/channel&gt;          &lt;channel&gt;            &lt;index&gt;101&lt;/index&gt;            &lt;config&gt;              &lt;admin-state&gt;ENABLED&lt;/admin-state&gt;              &lt;logical-channel-type xmlns#idx=~http#//openconfig.net/yang/transport-types~&gt;idx#PROT_ETHERNET&lt;/logical-channel-type&gt;              &lt;rate-class xmlns#idx=~http#//openconfig.net/yang/transport-types~&gt;idx#TRIB_RATE_100G&lt;/rate-class&gt;              &lt;trib-protocol xmlns#idx=~http#//openconfig.net/yang/transport-types~&gt;idx#PROT_100G_MLG&lt;/trib-protocol&gt;            &lt;/config&gt;            &lt;ingress&gt;              &lt;config&gt;                &lt;transceiver&gt;0/0-Optics0/0/0/4&lt;/transceiver&gt;              &lt;/config&gt;            &lt;/ingress&gt;            &lt;logical-channel-assignments&gt;              &lt;assignment&gt;                &lt;index&gt;1&lt;/index&gt;                &lt;config&gt;                  &lt;allocation&gt;100&lt;/allocation&gt;                  &lt;assignment-type&gt;LOGICAL_CHANNEL&lt;/assignment-type&gt;                  &lt;logical-channel&gt;201&lt;/logical-channel&gt;                &lt;/config&gt;              &lt;/assignment&gt;            &lt;/logical-channel-assignments&gt;          &lt;/channel&gt;          &lt;channel&gt;            &lt;index&gt;200&lt;/index&gt;            &lt;config&gt;              &lt;admin-state&gt;ENABLED&lt;/admin-state&gt;              &lt;logical-channel-type xmlns#idx=~http#//openconfig.net/yang/transport-types~&gt;idx#PROT_OTN&lt;/logical-channel-type&gt;            &lt;/config&gt;            &lt;logical-channel-assignments&gt;              &lt;assignment&gt;                &lt;index&gt;1&lt;/index&gt;                &lt;config&gt;                  &lt;allocation&gt;100&lt;/allocation&gt;                  &lt;assignment-type&gt;OPTICAL_CHANNEL&lt;/assignment-type&gt;                  &lt;optical-channel&gt;0/0-OpticalChannel0/0/0/5&lt;/optical-channel&gt;                &lt;/config&gt;              &lt;/assignment&gt;            &lt;/logical-channel-assignments&gt;          &lt;/channel&gt;          &lt;channel&gt;            &lt;index&gt;201&lt;/index&gt;            &lt;config&gt;              &lt;admin-state&gt;ENABLED&lt;/admin-state&gt;              &lt;logical-channel-type xmlns#idx=~http#//openconfig.net/yang/transport-types~&gt;idx#PROT_OTN&lt;/logical-channel-type&gt;            &lt;/config&gt;            &lt;logical-channel-assignments&gt;              &lt;assignment&gt;                &lt;index&gt;1&lt;/index&gt;                &lt;config&gt;                  &lt;allocation&gt;100&lt;/allocation&gt;                  &lt;assignment-type&gt;OPTICAL_CHANNEL&lt;/assignment-type&gt;                  &lt;optical-channel&gt;0/0-OpticalChannel0/0/0/6&lt;/optical-channel&gt;                &lt;/config&gt;              &lt;/assignment&gt;            &lt;/logical-channel-assignments&gt;          &lt;/channel&gt;        &lt;/logical-channels&gt;      &lt;/terminal-device&gt;    &lt;/config&gt;  &lt;/edit-config&gt;&lt;/rpc&gt;2017-09-11 19#02#58,309 - ydk.providers._provider_plugin - DEBUG - &lt;rpc-reply xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~ message-id=~urn#uuid#cbb88133-ef42-4eb1-b3ca-c8ef6472e52e~&gt;  &lt;ok/&gt;&lt;/rpc-reply&gt;2017-09-11 19#02#58,309 - ydk.services.executor_service - INFO - Executor operation completed2017-09-11 19#02#58,309 - ydk.services.netconf_service - INFO - Executing edit-config RPC2017-09-11 19#02#58,320 - ydk.services.executor_service - INFO - Executor operation initiated2017-09-11 19#02#58,321 - ydk.providers._provider_plugin - DEBUG - &lt;rpc xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~ message-id=~urn#uuid#0358444c-6097-4a80-8062-3232b3a87550~&gt;  &lt;edit-config&gt;    &lt;target&gt;      &lt;candidate&gt;&lt;/candidate&gt;    &lt;/target&gt;    &lt;config&gt;      &lt;components xmlns=~http#//openconfig.net/yang/platform~&gt;        &lt;component&gt;          &lt;name&gt;0/0-OpticalChannel0/0/0/5&lt;/name&gt;          &lt;optical-channel xmlns=~http#//openconfig.net/yang/terminal-device~&gt;            &lt;config&gt;              &lt;frequency&gt;191300000&lt;/frequency&gt;              &lt;line-port&gt;0/0-Optics0/0/0/5&lt;/line-port&gt;              &lt;operational-mode&gt;2&lt;/operational-mode&gt;              &lt;target-output-power&gt;0&lt;/target-output-power&gt;            &lt;/config&gt;          &lt;/optical-channel&gt;        &lt;/component&gt;        &lt;component&gt;          &lt;name&gt;0/0-OpticalChannel0/0/0/6&lt;/name&gt;          &lt;optical-channel xmlns=~http#//openconfig.net/yang/terminal-device~&gt;            &lt;config&gt;              &lt;frequency&gt;196100000&lt;/frequency&gt;              &lt;line-port&gt;0/0-Optics0/0/0/6&lt;/line-port&gt;              &lt;operational-mode&gt;2&lt;/operational-mode&gt;              &lt;target-output-power&gt;0&lt;/target-output-power&gt;            &lt;/config&gt;          &lt;/optical-channel&gt;        &lt;/component&gt;      &lt;/components&gt;    &lt;/config&gt;  &lt;/edit-config&gt;&lt;/rpc&gt;2017-09-11 19#02#58,610 - ydk.providers._provider_plugin - DEBUG - &lt;rpc-reply xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~ message-id=~urn#uuid#0358444c-6097-4a80-8062-3232b3a87550~&gt;  &lt;ok/&gt;&lt;/rpc-reply&gt;2017-09-11 19#02#58,610 - ydk.services.executor_service - INFO - Executor operation completed2017-09-11 19#02#58,610 - ydk.services.netconf_service - INFO - Executing commit RPC2017-09-11 19#02#58,612 - ydk.services.executor_service - INFO - Executor operation initiated2017-09-11 19#02#58,613 - ydk.providers._provider_plugin - DEBUG - &lt;rpc xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~ message-id=~urn#uuid#dad37f83-ee8d-4049-be33-f7b4dbc595ac~&gt;  &lt;commit/&gt;&lt;/rpc&gt;2017-09-11 19#03#00,353 - ydk.providers._provider_plugin - DEBUG - &lt;rpc-reply xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~ message-id=~urn#uuid#dad37f83-ee8d-4049-be33-f7b4dbc595ac~&gt;  &lt;ok/&gt;&lt;/rpc-reply&gt;2017-09-11 19#03#00,353 - ydk.services.executor_service - INFO - Executor operation completed2017-09-11 19#03#00,817 - ydk.providers.netconf_provider - INFO - NetconfServiceProvider disconnected from 172.20.168.83 using sshAs you can see, YDK connects to the device, does its job, commits, and exits. You can also use non-verbose version (without \u201c-v\u201d in the command line) with less output to the console.You can also check the updated configuration on a NCS1002 using \u201cshow\u201d commands. New lines of config will be seen after your code successfully commits intended configuration. When you configure a slice using OpenConfig models, show output in CLI will be different, comparing to the output you have after configuration of a slice through CLI. That change was done to reflect OpenConfig logic. Proper protection mechanisms are implemented on NCS1002 to make sure that a slice configured through CLI cannot be configured again using OpenConfig models and vice versa (mutual exclusion).CLI view from a NCS1002Here is an output of Slice #0 configuration using OpenConfig models on a NCS1002# !controller Optics0/0/0/5 transmit-power 0 dwdm-carrier 100MHz-grid frequency 1913000!controller Optics0/0/0/6 transmit-power 0 dwdm-carrier 100MHz-grid frequency 1961000!terminal-device logical-channel 100  rate-class 100G  admin-state enable  ingress-client-port Optics0/0/0/0  trib-protocol 100G-MLG  logical-channel-type Ethernet  assignment-id 1   allocation 100   assignment-type logical   assigned-logical-channel 200  ! ! logical-channel 101  rate-class 100G  admin-state enable  ingress-client-port Optics0/0/0/4  trib-protocol 100G-MLG  logical-channel-type Ethernet  assignment-id 1   allocation 100   assignment-type logical   assigned-logical-channel 201  ! ! logical-channel 200  admin-state enable  logical-channel-type Otn  assignment-id 1   allocation 100   assignment-type optical   assigned-optical-channel 0_0-OpticalChannel0_0_0_5  ! ! logical-channel 201  admin-state enable  logical-channel-type Otn  assignment-id 1   allocation 100   assignment-type optical   assigned-optical-channel 0_0-OpticalChannel0_0_0_6  ! ! optical-channel 0_0-OpticalChannel0_0_0_5  line-port Optics0/0/0/5  operational-mode 2 ! optical-channel 0_0-OpticalChannel0_0_0_6  line-port Optics0/0/0/6  operational-mode 2!Several helpful CLI \u201cshow\u201d commands are listed here to check the configuration status using OC models#a) A command to display accepted configuration layout with logical channels and their mappings# RP/0/RP0/CPU0#ios#show terminal-device layoutThu Sep  12 09#36#28.139 UTCSlice Id#                      0Status#                        Config AcceptedClient Bitrate#                100GLine Bitrate#                  100GClient [Lane]     Logical Channel Logical Channel Optical Channel     Line                    (Ethernet)      (Coherent)Optics0/0/0/0 [0]     100             200 0_0-OpticalChannel0_0_0_5         Optics0/0/0/5Optics0/0/0/4 [0]     101             201 0_0-OpticalChannel0_0_0_6         Optics0/0/0/6b) A command to display configuration details either for all logical channels or for a specific one#RP/0/RP0/CPU0#ios#show terminal-device logical-channel number 100Thu Sep  12 09#36#28.139 UTCLogical Channel Index#      100Name#                       HundredGigECtrlr0/0/0/0Admin-State#                EnableLoopback-Mode#              NoneType of Logical Channel#    Logical Level 1Trib-Rate#                  100G tributary signal rateTrib-Protocol#              100G MLG protocolProtocol-Type#              Ethernet protocol framingIngress Client Port#        Optics0/0/0/0Ingress Physical Channel#   0Logical Assignment Index#   1Logical Assignment Name#    NALogical Channel#            200Optical Channel#            NAAllocation#                 100GAssignment Type#            Logicalc) A command to display supported operational modes#RP/0/RP0/CPU0#ios#show terminal-device operational-modesThu Sep  12 09#36#28.139 UTCOperational Mode#       1Description#            FEC Mode 7Vendor#                 Cisco Systems, Inc.Operational Mode#       2Description#            FEC Mode 20Vendor#                 Cisco Systems, Inc.Openconfig models for slice configuration came with IOS XR 6.2.1 release. Python 2.7 and YDK version 0.5.4 were used for scripts.ConclusionYDK is a great tool that helps you to make configuration easier. In our example, we configured a full NCS1002 slice using OpenConfig models with a basic YDK script. You don\u2019t need to deal with XML encoding, you don\u2019t need to be an YANG expert to check semantics of your code, as YDK does it all for you. Try all example codes, modify them as you need and stay tuned for our next updates!", "url": "https://xrdocs.github.io/programmability/tutorials/2017-09-26-ncs1002-configuration-automation-with-ydk/", "tags": "iosxr, automation, YDK, programmability, NCS1002, NCS1k", "title": "NCS1002 Configuration Automation with YDK", "author": "Viktor Osipchuk"}, "blogs-2018-05-07-ncs-5500-buffering-architecture": {"content": "     NCS 5500 Buffering Architecture  Executive Summary  Router Buffering Architectures          Off-chip vs. On-chip buffering      Motivation for a New Design      An Innovative Approach \u2013 Hybrid Buffering      Jericho ASIC Architecture      Deep Buffering      Future ASIC Architecture Direction        Summary  The NCS 5500 uses an innovative design to provide deep buffering while maintaining high performance and power efficiency. This paper explores this design and shows its strengths over traditional forwarding architectures. It also will address criticism of these optimizations coming from other vendors.Executive SummaryBuffers are the shock absorbers in networks. Their primary role is to manage temporary congestion in a manner that controls loss and latency while allowing end nodes to adapt to available bandwidth or complete short transfers without loss. Note that this does not mean preventing all packet loss and that buffers cannot solve persistent or artificial congestion that does not respond to signals from the network.Router Buffering ArchitecturesOff-chip vs. On-chip bufferingOne of the tradeoffs a router architect needs to make is where to buffer packets. Traditionally, there have been two options# on-chip or off-chip.On-chip buffering minimizes power and board space but doesn\u2019t allow for buffering beyond 10s or 100s of microseconds. It is well suited to data centers where round trip times allow end nodes to adjust their speed very quickly and where bandwidth can be overprovisioned via inexpensive fiber runs. In some cases, it may still have limitations due to TCP Incast traffic flows. On-chip SRAM buffers are a 10,000th the size of off-chip buffers so it\u2019s not a small difference. On-chip buffering allows for higher-bandwidth devices as it allows more of the ASIC\u2019s resources to be used for physical ports rather than connecting to off-chip memories. On-chip vs. off-chip buffering is one of the key factors underlying the wide range of port counts and power consumption between routers with the two models. As of 2018, fabric-capable forwarding chips with off-chip buffers currently range from 200 to 900 Gbps while System on Chip models shipping range up to 3.2 Tbps.With off-chip buffering, two key requirements must be met. First, the memory must be large enough to buffer the required packets. This is a separate topic, but note that the NCS 5500 ha very large buffers. Second, it must be fast enough to maintain the forwarding rate. The bandwidth component of memory performance is a key challenge for buffering. This paper discusses how the NCS 5500 balances the bandwidth constraint with other design goals such as performance, power, and cost.For deep buffers, a router architect must currently choose between high-speed custom memories or large banks of commodity memories. While not as difficult as FIB memory requirements (which require high operations per second), memory bandwidth can be a challenge as commodity memories are not designed for the operations needed for networking. Traditionally, deep-buffered routers pass every packet through the off-chip memory. Note that these memories are also used for forwarding tables, which may or may not be stored in the same memory bank.High-performance memories can be made to a wide range of specifications, including bandwidth, operations per second, capacity, cost, and physical size. They save board space but are significantly more expensive and consume more power as performance increases.Off-chip buffering with commodity memory is less expensive but often requires more board space than custom memories due to the need to overprovision the capacity in order to get sufficient aggregate memory bandwidth.Using a mid-performance commodity memory such as graphics memory (e.g., GDDR5) helps, but still doesn\u2019t meet the performance of high-end memory devices.Cisco uses custom high-performance memories on the CRS and NCS 6000. Commodity memory is used for buffering on the ASR 9000 and NCS 5500. The NCS 5000 has on-chip buffers only.Motivation for a New DesignThere are two key drivers for rethinking the traditional approach to off-chip buffers when designing new chips. First, valuable bandwidth (and thus power) is used to perform an off-chip write/read for packets that don\u2019t require moderate or deep buffers. Second, in the near future even high-performance memories will no longer be able to keep up with the requirements of ASICs as silicon logic and on-chip memory will continue to outpace off-chip memory performance.An Innovative Approach \u2013 Hybrid BufferingNew chip designs must address the memory bandwidth challenge while still acheiving the overall system goals to balance price, performance, power, and functionality. Commodity memory bandwidth currently maxes out at approximately 900G half duplex. High-performance memories are available supporting 400G &amp; 500G ASICs at line rate (some are ~500G full duplex, others are ~1T half duplex). Future generations of custom memory (notably HBM which is discussed later) will increase performance but still not be able to keep up with highest-bandwidth processors.A solution to this challenge to implement both on-chip and off-chip buffers and only use off-chip buffers as needed. This is the design of the NCS 5500. Packets in congested queues are buffered off-chip while packets in empty and lightly congested queues (less than approximately 5000 packets) remain on-chip. This is called an evict / readmit model in which queues can transition on and off chip as they fill or empty. It uses memory bandwidth more efficiently and allows the chip to run faster than the off-chip memory. This approach has an additional benefit of reduced power consumption relative to buffering all packets off-chip.This design is based on the same principle that underlies much of network and server design \u2013 statistical multiplexing. Not all clients (of the network or of memory) need to use the full bandwidth at the same time. This oversubscription is small for the worst-case and negligible in practice in Jericho and Jericho+. Oversubscription will increase in the future as the gap between memory technologies and forwarding logic continues to grow so this design will become even more critical in the future.The next section explains how hybrid buffering is implemented in NCS 5500. Later, the conditions needed to see corner cases in the lab are explained.Jericho ASIC ArchitectureThe diagram below shows a high-level view of the Jericho &amp; Jericho+ ASICs used in NCS 5500. There are two packet cores. The cores share on-chip buffers with separate pools for ingress and egress (OTM in the graphic). The on-chip buffers are approximately 16MB each. The egress buffer supports reassembling packets but doesn\u2019t provide externally visible QoS. In addition, it doesn\u2019t drop packets due to the VoQ scheduling, which only allows packets to be sent to egress once they can be transmitted. The configured QoS is implemented by the ingress traffic manager. The ingress on-chip buffer contains VoQs for every output queue in the system. A vast majority of packets pass only through these on-chip buffers.If a queue becomes moderately congested, the queue is \u201cevicted\u201d and additional packets for that queue only will be stored in an off-chip GDDR5 memory. Eviction occurs on a per-queue basis so all other traffic to the destination physical port and all other ports remains in the on-chip buffers.Figure 1# Jericho ASIC Logical DiagramThe aggregate half-duplex bandwidth between the forwarding cores and the off-chip memory is approximately 900 Gbps. With GDDR5, this bandwidth can be used for read or write, which is an important component of the design as, in theory, even line rate bursts on all interfaces on 900G Jericho+ can be absorbed before shifting the bandwidth allocation back to read the packets out. In Jericho, at very high levels of memory bandwidth usage, writes are given a higher priority in order to absorb large bursts into deep queues. With sustained high rates near the maximum memory bandwidth, the allocation will return to 50/50 to allow the off-chip buffers to drain. At that point, packet loss is inevitable in any router so managing the drops becomes very important. If the allocated write bandwidth is exceeded, packets for the specific queues that are tail dropping in the off-chip memory will temporarily be dropped on-chip. This preserves memory bandwidth for packets that may not need to be dropped. Packets to other queues utilizing the deep buffers will receive priority for storage in off-chip memory. Meanwhile, the configured QoS policies are being implemented, which may further reduce the memory bandwidth required.Some other memory technologies do not have the flexibility of half duplex bandwidth that can be shared between read and write. In practice, that is not an issue today, but may be a challenge in the future.This condition is clearly an extreme and contrived corner case. It will only be seen in a lab test with a traffic generator and almost every packet forced to heavily congested queues.Deep BufferingThe NCS 5500 can provide extremely deep buffers when required. This is enabled by the size of the off-chip memory as well as the distributed VoQ architecture. The off-chip memory on each chip is 4 GB and can store up to 3 million packets (1.5M packet descriptors on each core). After buffer carving, the effective capacity is approximately 3GB.There are also system-level factors that are key to the buffering architecture in multi-ASIC systems (the 2 RU NCS 5502, the line card based NCS 5504/5508/5516, and the newer 1 RU systems with multiple Jericho+ ASICs). When significant congestion of a VoQ is occurring, it is likely to enter the router on more than one NPU. This means that the aggregate memory available for buffering to a single egress queue comprises the memory on all ingress ASICs receiving traffic destined to that queue. When this is occurring, each ASIC individually moves queues on and off-chip as needed. With this model, the total buffering for a queue is larger than any router with two-stage queuing.When all the ingress traffic enters a single ASIC (such as the single-chip NCS 5501) the system can buffer up to approximately 30 msec on all ports at the same time when all traffic is going to congested output queues. If fewer queues are congested, more memory is available to the congested queues, up to 1 GB and 390k packets per queue.The default queue depths on NCS 5500 are set to 10 msec per NPU, but they can be increased significantly if required by the network designer. Care should be taken as too much buffering can cause just as many problems as not enough.For a practical analysis of memory capacity and bandwidth, it is important to understand that all the queues will not be highly congested at the same time.Future ASIC Architecture DirectionIncreases in ASIC logic and on-chip memory performance will continue to outpace off-chip memory. This gap will grow significantly over time. In the near future, many routers with high-end custom memories will need to embrace this model. The only other option is to use an increasing number of relatively small ASICs, still with high- performance memories.In 2018 or 2019, networking ASICs will begin shipping with a new technology called High Bandwidth Memory (HBM). HBM is a high-end commodity component that must be tightly integrated with the on-die logic by placing it into the ASIC package. This new option will deliver a significant increase in memory bandwidth as well as a decrease in power.SummaryThis paper has shown the benefits of the hybrid buffering architecture and how it is implemented on Cisco\u2019s NCS 5500 routers. It has also addressed the criticism of this design. While it should be clear that hybrid buffering is an optimal design in many cases, Cisco will still be implementing the traditional off-chip approach, especially in extensions to existing platforms.", "url": "https://xrdocs.github.io/cloud-scale-networking/blogs/2018-05-07-ncs-5500-buffering-architecture/", "tags": "iosxr, cisco", "title": "NCS 5500 Buffering Architecture", "author": "Lane Wigley"}, "tutorials-2016-07-21-configuring-model-driven-telemetry-mdt": {"content": "     Configuring Model-Driven Telemetry (MDT)  Important Background (aka TL;DR)  Using TCP Dial-Out          TCP Dial-Out Router Config        Using gRPC Dial-Out          gRPC Dial-Out Router Config        Using gRPC Dial-In          gRPC Dial-In Router Config        Important Background (aka TL;DR)Before configuring Model-Driven Telemetry, you should understand the different options that are available for transport, session initation and encoding and pick the combination that works for you.  Here\u2019s a quick summary#  Transport# The router can deliver telemetry data either across using TCP or gRPC over HTTP/2.  Some people will prefer the simplicity of a raw TCP socket, others will appreciate the optional TLS encyption that gRPC brings.  Session Initiation# There are two options for initiating a telemetry session.  The router can \u201cdial-out\u201d to the collector or the collector can \u201cdial-in\u201d to the router.  Regardless of which side initiates the session, the router always streams the data to the collector at the requested intervals. TCP supports \u201cdial-out\u201d while gRPC supports both \u201cdial-in\u201d and \u201cdial-out.\u201d  Encoding# The router can deliver telemetry data in two different flavors of Google Protocol Buffers# Compact and Self-Describing GPB.  Compact GPB is the most efficient encoding but requires a unique .proto for each YANG model that is streamed.  Self-describing GPB is less efficient but it uses a single .proto file to decode all YANG models because the keys are passed as strings in the .proto.This tutorial covers the detailed configuration steps for three combinations# TCP Dial-Out, gRPC Dial-Out and gRPC Dial-In, all using the self-describing GPB encoding.Using TCP Dial-OutWith the TCP Dial-Out method, the router initiates a TCP session to the collector and sends whatever data is specified by the sensor-group in the subscription.TCP Dial-Out Router ConfigThere are three steps to configuring the router for telemetry with TCP dial-out# create a destination-group, create a sensor-group, create a subscription.Step 1# Create a destination-groupThe destination-group specifies the destination address, port, encoding and transport that the router should use to send out telemetry data.  In this case, we configure the router to send telemetry via tcp, encoding as self-describing gpb, to 172.30.8.4 port 5432.RP/0/RP0/CPU0#SunC(config)# telemetry model-drivenRP/0/RP0/CPU0#SunC(config-model-driven)# destination-group DGroup1RP/0/RP0/CPU0#SunC(config-model-driven-dest)#  address family ipv4 172.30.8.4 port 5432  RP/0/RP0/CPU0#SunC(config-model-driven-dest-addr)#   encoding self-describing-gpb  RP/0/RP0/CPU0#SunC(config-model-driven-dest-addr)#   protocol tcp  RP/0/RP0/CPU0#SunC(config-model-driven-dest-addr)# commit   Step 2# Create a sensor-groupThe sensor-group specifies a list of YANG models which are to be streamed.  The sensor path below represents the XR YANG model for interfaces statistics#RP/0/RP0/CPU0#SunC(config)#telemetry model-drivenRP/0/RP0/CPU0#SunC(config-model-driven)#sensor-group SGroup1RP/0/RP0/CPU0#SunC(config-model-driven-snsr-grp)# sensor-path Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-countersRP/0/RP0/CPU0#SunC(config-model-driven-snsr-grp)# commitStep 3# Create a subscriptionThe subscription associates a destination-group with a sensor-group and sets the streaming interval.  The following configuration associates the sensor-group and destination created above with a streaming interval of 30 seconds.RP/0/RP0/CPU0#SunC(config)telemetry model-driven  RP/0/RP0/CPU0#SunC(config-model-driven)#subscription Sub1  RP/0/RP0/CPU0#SunC(config-model-driven-subs)#sensor-group-id SGroup1 sample-interval 30000  RP/0/RP0/CPU0#SunC(config-model-driven-subs)#destination-id DGroup1  RP/0/RP0/CPU0#SunC(config-mdt-subscription)# commit  All Together NowHere\u2019s the entire configuration for TCP dial-out with GPB encoding in one shot#telemetry model-driven   destination-group DGroup1     address family ipv4 172.30.8.4 port 5432     encoding self-describing-gpb     protocol tcp  ! ! sensor-group SGroup1  sensor-path Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters !   subscription Sub1    sensor-group-id SGroup1 sample-interval 30000    destination-id DGroup1   ValidationUse the following command to verify that you have correctly configured the router for TCP dial-out.RP/0/RP0/CPU0#SunC#show telemetry model-driven subscriptionThu Jul 21 15#42#27.751 UTCSubscription#  Sub1                     State# ACTIVE-------------  Sensor groups#  Id                Interval(ms)        State  SGroup1           30000               Resolved  Destination Groups#  Id                Encoding            Transport   State   Port    IP  DGroup1           self-describing-gpb tcp         Active  5432    172.30.8.4Using gRPC Dial-OutWith the gRPC Dial-Out method, the router initiates a gRPC session to the collector and sends whatever data is specified by the sensor-group in the subscription.gRPC Dial-Out Router ConfigThe steps to configure gRPC dial-out are the same as TCP dial-out# create a destination-group, create a sensor-group, create a subscription.Step 1# Create a destination-groupThe destination-group specifies the destination address, port, encoding and transport that the router should use to send out telemetry data.  In this case, we configure the router to send telemetry via gRPC, encoding as self-describing gpb, to 172.30.8.4 port 57500.RP/0/RP0/CPU0#SunC(config)#telemetry model-driven  RP/0/RP0/CPU0#SunC(config-model-driven)# destination-group DGroup2  RP/0/RP0/CPU0#SunC(config-model-driven-dest)#  address family ipv4 172.30.8.4 port 57500  RP/0/RP0/CPU0#SunC(config-model-driven-dest-addr)#   encoding self-describing-gpb  RP/0/RP0/CPU0#SunC(config-model-driven-dest-addr)#   protocol grpc  RP/0/RP0/CPU0#SunC(config-model-driven-dest-addr)# commit  Step 2# Create a sensor-groupThe sensor-group specifies a list of YANG models which are to be streamed.  The sensor path below represents the XR YANG model for summarized memory statistics#RP/0/RP0/CPU0#SunC(config)#telemetry model-driven   RP/0/RP0/CPU0#SunC(config-model-driven)#sensor-group SGroup2  RP/0/RP0/CPU0#SunC(config-model-driven-snsr-grp)# sensor-path Cisco-IOS-XR-nto-misc-oper#memory-summary/nodes/node/summary  RP/0/RP0/CPU0#SunC(config-model-driven-snsr-grp)# commit  Step 3# Create a subscriptionThe subscription associates a destination-group with a sensor-group and sets the streaming interval.  The following configuration associates the sensor-group and destination created above with a streaming interval of 30 seconds.RP/0/RP0/CPU0#SunC(config)telemetry model-driven  RP/0/RP0/CPU0#SunC(config-model-driven)#subscription Sub2  RP/0/RP0/CPU0#SunC(config-model-driven-subs)#sensor-group-id SGroup2 sample-interval 30000  RP/0/RP0/CPU0#SunC(config-model-driven-subs)#destination-id DGroup2  RP/0/RP0/CPU0#SunC(config-mdt-subscription)# commit  All Together NowHere\u2019s the entire configuration for gRPC dial-out with GPB encoding in one shot#telemetry model-driven destination-group DGroup2  address family ipv4 172.30.8.4 port 57500   encoding self-describing-gpb   protocol grpc  ! ! sensor-group SGroup2  sensor-path Cisco-IOS-XR-nto-misc-oper#memory-summary/nodes/node/summary ! subscription Sub2  sensor-group-id SGroup2 sample-interval 30000  destination-id DGroup2ValidationUse the following command to verify that you have correctly configured the router for gRPC dial-out.RP/0/RP0/CPU0#SunC#show telemetry model-driven subscriptionThu Jul 21 21#14#08.636 UTCSubscription#  Sub2                     State# ACTIVE-------------  Sensor groups#  Id                Interval(ms)        State  SGroup2           30000               Resolved  Destination Groups#  Id                Encoding            Transport   State   Port    IP  DGroup2           self-describing-gpb grpc        NA      57500   172.30.8.4Using gRPC Dial-InWith the gRPC Dial-In method, the collector initiates a gRPC session to the router and specifies a subscription.  The router sends whatever data is specified by the sensor-group in the subscription requested by the collector.gRPC Dial-In Router ConfigThere are three steps to configure a router to accept a gRPC dial-in from a collector# enable gRPC, create a sensor-group, create a subscription.Step 1# Enable gRPCThe following configuration enables the router\u2019s gRPC server to accept incoming connections from the collector.RP/0/RP0/CPU0#SunC(config)#grpc  RP/0/RP0/CPU0#SunC(config-grpc)#port 57500  RP/0/RP0/CPU0#SunC(config-grpc)#commit  Step 2# Create a sensor-groupThe sensor-group specifies a list of YANG models which are to be streamed.  The sensor path below represents the OpenConfig YANG model for interfaces#RP/0/RP0/CPU0#SunC(config)#telemetry model-driven   RP/0/RP0/CPU0#SunC(config-model-driven)#sensor-group SGroup3  RP/0/RP0/CPU0#SunC(config-model-driven-snsr-grp)# sensor-path openconfig-interfaces#interfaces/interface  RP/0/RP0/CPU0#SunC(config-model-driven-snsr-grp)# commit  Step 3# Create a subscriptionThe subscription associates a sensor-group with the streaming interval.  No destination group is required because the collector will be dialing in.  The collector will need to request subscription \u201cSub3\u201d when it connects.RP/0/RP0/CPU0#SunC(config)telemetry model-driven  RP/0/RP0/CPU0#SunC(config-model-driven)#subscription Sub3  RP/0/RP0/CPU0#SunC(config-model-driven-subs)#sensor-group-id SGroup3 sample-interval 30000  RP/0/RP0/CPU0#SunC(config-mdt-subscription)# commit  All Together NowHere\u2019s the entire configuration for gRPC dial-in in one shot#grpc port 57500!telemetry model-driven sensor-group SGroup3  sensor-path openconfig-interfaces#interfaces/interface ! subscription Sub3  sensor-group-id SGroup3 sample-interval 30000ValidationUse the following command to verify that you have correctly configured the router for gRPC dial-in.RP/0/RP0/CPU0#SunC#show telemetry model-driven subscription Sub3Thu Jul 21 21#32#45.365 UTCSubscription#  Sub3-------------  State#       ACTIVE  Sensor groups#  Id# SGroup3    Sample Interval#      30000 ms    Sensor Path#          openconfig-interfaces#interfaces/interface    Sensor Path State#    Resolved  Destination Groups#  Group Id# DialIn_1002    Destination IP#       172.30.8.4    Destination Port#     44841    Encoding#             self-describing-gpb    Transport#            dialin    State#                Active    Total bytes sent#     13909    Total packets sent#   14    Last Sent time#       2016-07-21 21#32#25.231964501 +0000  Collection Groups#  ------------------    Id# 2    Sample Interval#      30000 ms    Encoding#             self-describing-gpb    Num of collection#    7    Collection time#      Min#    32 ms Max#    39 ms    Total time#           Min#    34 ms Avg#    37 ms Max#    40 ms    Total Deferred#       0    Total Send Errors#    0    Total Send Drops#     0    Total Other Errors#   0    Last Collection Start#2016-07-21 21#32#25.231930501 +0000    Last Collection End#  2016-07-21 21#32#25.231969501 +0000    Sensor Path#          openconfig-interfaces#interfaces/interface", "url": "https://xrdocs.github.io/telemetry/tutorials/2016-07-21-configuring-model-driven-telemetry-mdt/", "tags": "iosxr, Telemetry, MDT", "title": "Configuring Model-Driven Telemetry (MDT)", "author": "Shelly Cadora"}, "tutorials-2017-08-07-understanding-ncs5500-resources-s01e03": {"content": "     Understanding NCS5500 Resources  S01E03 IPv6 Prefixes          Previously on \u201cUnderstanding NCS5500 Resources\u201d      IPv6 routes and FIB Profiles      Lab verification        S01E03 IPv6 PrefixesPreviously on \u201cUnderstanding NCS5500 Resources\u201dIn the previous posts, we introduced the different routers and line cards in NCS5500 portfolio and we explained how IPv4 prefixes are sorted in LEM, LPM and eTCAM.All the principles described below and the examples used to illustrate them were validated in August 2017 with Jericho-based systems, using scale (with eTCAM) and base (without eTCAM) line cards and running the two IOS XR releases available# 6.1.4 and 6.2.2.IPv6 routes and FIB ProfilesPlease take a few minutes to read the S01E02 to understand the different databases used to store routes in NCS5500#  LPM# Longest Prefix Match Database (or KAPS) is an SRAM used to store IPv4 and IPv6 prefixes.  LEM# Large Exact Match Database also used to store specific IPv4 and IPv6 routes, plus MAC addresses and MPLS labels.  eTCAM# external TCAMs, only present in the -SE \u201cscale\u201d line cards and systems. As the name implies, they are not a resource inside the Forwarding ASIC, it\u2019s an additional memory used to extend unicast route and ACL / classifiers scale.We explained how the different profiles influenced the prefixes storing in different databases for base and scale systems or line cards. The principles for IPv6 are similar but things are actually simpler# the order of operation will be exactly the same, regardless of the FIB profile activated and regardless of the type of line card (base or scale).The logic behind this decision# IPv6/48 prefixes are by far the largest population of the public table.(From BGPv6 table on Twitter)To avoid any misunderstanding, let\u2019s review the IPv6 resource allocation / distribution for each profile and line card type quickly, starting with the Base systems with Host-optimized FIB profile#Base systems with Internet-optimized FIB profile#Scale systems regardless of FIB profile#See ? Pretty easy. By default, IPv6/48 are moved into LEM and the all other IPv6 prefixes are pushed into LPM.Lab verificationLPM is an algorithmic memory. That means, the capacity will depend on the prefix distribution and how many have been programmed at a given moment. We will use a couple of examples below to illustrate below how the routes are moved but you should not rely on the \u201cestimated capacity\u201d to based your capacity planning. Only a real internet table will give you a reliable idea of the available space.In slot 0/0, we have a base line card (18H18F) using an Internet-optimized profile. In slot 0/6, we use a scale line card (24H12F-SE).Also, keep in mind we are announcing ordered prefixes which are fine in a lab context to verify where the system will store the routes but it\u2019s not a realistic scenario (compared to a real internet table for instance).IPv6/48 RoutesIPv6/48 prefixes are stored in LEM#First we advertise 20,000 IPv6/48 routes and check the different databases.On Base line cards#RP/0/RP0/CPU0#NCS5508-1-614#sh route ipv6 bgp | i /48 | utility wc -l20000RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lem location 0/0/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 20107    (3 %)        iproute                     # 5        (0 %)        ip6route                    # 20000    (3 %)        mplslabel                   # 102      (0 %)RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/0/CPU0HW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 117926        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 172      (0 %)        iproute                     # 29       (0 %)        ip6route                    # 117      (0 %)        ipmcroute                   # 50       (0 %)RP/0/RP0/CPU0#NCS5508-1-614#Note# for readability, we will only display NPU-0 information. In the full output of the show command, we will have from NPU-0 to NPU-0 on 18H18F and from NPU-0 to NPU-3 on the 24H12F-SE.On Scale line cards#RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lem location 0/6/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 20127    (3 %)        iproute                     # 24       (0 %)        ip6route                    # 20000    (3 %)        mplslabel                   # 102      (0 %)RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/6/CPU0HW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 118638        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 144      (0 %)        iproute                     # 0        (0 %)        ip6route                    # 117      (0 %)        ipmcroute                   # 50       (0 %)RP/0/RP0/CPU0#NCS5508-1-614#With 20,000 IPv6/48 prefixes, as expected, it\u2019s only 3% of the 786,432 entries of LEM.Just for verification, we will advertise 200,000 then 400,000 IPv6/48 routes. And of course the LEM estimated max entries will stay constant. LEM is very different than LPM from this perspective.RP/0/RP0/CPU0#NCS5508-1-614#sh route ipv6 bgp | i /48 | utility wc -l200000RP/0/RP0/CPU0#NCS5508-1-614#RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lem location 0/0/CPU0  | i ~(Estim|In-Use)~        Estimated Max Entries       # 786432        Total In-Use                # 200107   (25 %)RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/0/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 117926        Total In-Use                # 172      (0 %)RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lem location 0/6/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 786432        Total In-Use                # 200127   (25 %)RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/6/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 118638        Total In-Use                # 144      (0 %)RP/0/RP0/CPU0#NCS5508-1-614#RP/0/RP0/CPU0#NCS5508-1-614#sh route ipv6 bgp | i /48 | utility wc -l400000RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lem location 0/0/CPU0  | i ~(Estim|In-Use)~        Estimated Max Entries       # 786432        Total In-Use                # 400107   (51 %)RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/0/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 117926        Total In-Use                # 172      (0 %)RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lem location 0/6/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 786432        Total In-Use                # 400127   (51 %)RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/6/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 118638        Total In-Use                # 144      (0 %)RP/0/RP0/CPU0#NCS5508-1-614#Non IPv6/48 Routes ?From IPv6/1 to IPv6/47 and from IPv6/49 to IPv6/128, all these prefixes will be stored in LPM.The estimated max prefixes will be very different for each test and will also differ depending on the number of routes we advertise.IPv6/32 RoutesLet\u2019s see is the occupation for 20,000 / 40,000 and 60,000 IPv6/32 prefixes.On base line cards with 20,000 IPv6/32#RP/0/RP0/CPU0#NCS5508-1-614#sh route ipv6 bgp | i /32 | utility wc -l20000RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/0/CPU0HW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 493046        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 20172    (4 %)        iproute                     # 29       (0 %)        ip6route                    # 20117    (4 %)        ipmcroute                   # 50       (0 %)RP/0/RP0/CPU0#NCS5508-1-614#On scale line cards with IPv6/32#RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/6/CPU0HW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 492362        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 20144    (4 %)        iproute                     # 0        (0 %)        ip6route                    # 20117    (4 %)        ipmcroute                   # 50       (0 %)RP/0/RP0/CPU0#NCS5508-1-614#40,000 IPv6/32 prefixes#RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/0/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 477274        Total In-Use                # 40172    (8 %)RP/0/RP0/CPU0#NCS5508-1-614#RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/6/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 478572        Total In-Use                # 40144    (8 %)RP/0/RP0/CPU0#NCS5508-1-614#60,000 IPv6/32 prefixes#RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/0/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 459800        Total In-Use                # 60172    (13 %)RP/0/RP0/CPU0#NCS5508-1-614#RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/6/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 460686        Total In-Use                # 60144    (13 %)RP/0/RP0/CPU0#NCS5508-1-614#IPv6/56 Routes20,000 IPv6/56 prefixes#RP/0/RP0/CPU0#NCS5508-1-614#sh route ipv6 bgp | i /56 | utility wc -l20000RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/0/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 239664        Total In-Use                # 20172    (8 %)RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/6/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 489198        Total In-Use                # 20144    (4 %)RP/0/RP0/CPU0#NCS5508-1-614#40,000 IPv6/56 prefixes#RP/0/RP0/CPU0#NCS5508-1-614#sh route ipv6 bgp | i /56 | utility wc -l40000RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/0/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 220600        Total In-Use                # 40172    (18 %)RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/6/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 475320        Total In-Use                # 40144    (8 %)RP/0/RP0/CPU0#NCS5508-1-614#60,000 IPv6/56 prefixes#RP/0/RP0/CPU0#NCS5508-1-614#sh route ipv6 bgp | i /56 | utility wc -l60000RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/0/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 201192        Total In-Use                # 60172    (30 %)RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/6/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 458492        Total In-Use                # 60144    (13 %)RP/0/RP0/CPU0#NCS5508-1-614#IPv6/64 Routes20,000 IPv6/64 prefixes#RP/0/RP0/CPU0#NCS5508-1-614#sh route ipv6 bgp | i /64 | utility wc -l20000RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/0/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 239664        Total In-Use                # 20172    (8 %)RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/6/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 489198        Total In-Use                # 20144    (4 %)RP/0/RP0/CPU0#NCS5508-1-614#        40,000 IPv6/64 prefixes#RP/0/RP0/CPU0#NCS5508-1-614#sh route ipv6 bgp | i /64 | utility wc -l40000RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/0/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 220600        Total In-Use                # 40172    (18 %)RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/6/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 475320        Total In-Use                # 40144    (8 %)RP/0/RP0/CPU0#NCS5508-1-614#60,000 IPv6/64 prefixes#RP/0/RP0/CPU0#NCS5508-1-614#sh route ipv6 bgp | i /64 | utility wc -l60000RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/0/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 201192        Total In-Use                # 60172    (30 %)RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/6/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 458492        Total In-Use                # 60144    (13 %)RP/0/RP0/CPU0#NCS5508-1-614#IPv6/128 Routes20,000 IPv6/128 prefixes#RP/0/RP0/CPU0#NCS5508-1-614#sh route ipv6 bgp | i /128 | utility wc -l20000RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/0/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 238848        Total In-Use                # 20172    (8 %)RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/6/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 239330        Total In-Use                # 20144    (8 %)RP/0/RP0/CPU0#NCS5508-1-614#40,000 IPv6/128 prefixes#RP/0/RP0/CPU0#NCS5508-1-614#sh route ipv6 bgp | i /128 | utility wc -l40000RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/0/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 220186        Total In-Use                # 40172    (18 %)RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/6/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 220446        Total In-Use                # 40144    (18 %)RP/0/RP0/CPU0#NCS5508-1-614#60,000 IPv6/128 prefixes#RP/0/RP0/CPU0#NCS5508-1-614#sh route ipv6 bgp | i /128 | utility wc -l60000RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/0/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 200914        Total In-Use                # 60172    (30 %)RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/6/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 201098        Total In-Use                # 60144    (30 %)RP/0/RP0/CPU0#NCS5508-1-614#80,000 IPv6/128 prefixes#RP/0/RP0/CPU0#NCS5508-1-614#sh route ipv6 bgp | i /128 | utility wc -l60000RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/0/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 181075        Total In-Use                # 80173    (44 %)RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/6/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 181219        Total In-Use                # 80145    (44 %)RP/0/RP0/CPU0#NCS5508-1-614#100,000 IPv6/128 prefixes#RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/0/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 161334        Total In-Use                # 100172   (62 %)RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/6/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 161456        Total In-Use                # 100144   (62 %)RP/0/RP0/CPU0#NCS5508-1-614#120,000 IPv6/128 prefixes#RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/0/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 141370        Total In-Use                # 120172   (85 %)RP/0/RP0/CPU0#NCS5508-1-614#sh contr npu resources lpm location 0/6/CPU0 | i ~(Estim|In-Use)~        Estimated Max Entries       # 141476        Total In-Use                # 120144   (85 %)RP/0/RP0/CPU0#NCS5508-1-614#            Pfx      Base Max Pfx      Scale Max Pfx                  20k IPv6/32      LPM# 489,903      LPM# 492,387              40k IPv6/32      LPM# 475,663      LPM# 478,583              60k IPv6/32      LPM# 458,713      LPM# 460,693              80k IPv6/32      LPM# 440,257      LPM# 440,929              100k IPv6/32      LPM# 421,187      LPM# 421,733              200k IPv6/32      LPM# 322,395      LPM# 323,017              250k IPv6/32      LPM# 272,903      LPM# 273,141              20k IPv6/48      LEM# 786,432      LEM# 786,432              40k IPv6/48      LEM# 786,432      LEM# 786,432              60k IPv6/48      LEM# 786,432      LEM# 786,432              80k IPv6/48      LEM# 786,432      LEM# 786,432              100k IPv6/48      LEM# 786,432      LEM# 786,432              200k IPv6/48      LEM# 786,432      LEM# 786,432              20k IPv6/56      LPM# 486,773      LPM# 489,223              40k IPv6/56      LPM# 474,051      LPM# 475,331              60k IPv6/56      LPM# 457,623      LPM# 458,501              80k IPv6/56      LPM# 439,433      LPM# 440,103              100k IPv6/56      LPM# 420,525      LPM# 421,069              200k IPv6/56      LPM# 322,061      LPM# 322,349              250k IPv6/56      LPM# 272,637      LPM# 272,873              20k IPv6/64      LPM# 239,675      LPM# 489,223              40k IPv6/64      LPM# 220,605      LPM# 475,331              60k IPv6/64      LPM# 201,195      LPM# 458,501              80k IPv6/64      LPM# 181,283      LPM# 440,103              100k IPv6/64      LPM# 161,503      LPM# 421,069              120k IPv6/64      LPM# 141,511      LPM# 401,163              20k IPv6/128      LPM# 238,848      LPM# 239,330              40k IPv6/128      LPM# 220,186      LPM# 220,446              60k IPv6/128      LPM# 200,914      LPM# 201,098              80k IPv6/128      LPM# 181,075      LPM# 181,219              100k IPv6/128      LPM# 161,334      LPM# 161,456              120k IPv6/128      LPM# 141,370      LPM# 141,476      Again this chart is just provided for information with \u201caligned\u201d/\u201dsorted\u201d routes, not really representing a real internet distribution. Take a look at the former post for a production router with public view IPv4+IPv6.In next posts, we will cover Encapsulation database, FEC and ECMP FEC database, MPLS use-cases and the classifiers/ACLs. Stay tuned.", "url": "https://xrdocs.github.io/cloud-scale-networking/tutorials/2017-08-07-understanding-ncs5500-resources-s01e03/", "tags": "ncs5500, ncs 5500, lpm, lem, routes, prefixes, eTCAM", "title": "Understanding NCS5500 Resources (S01E03)", "author": "Nicolas Fevrier"}, "blogs-2018-02-16-xr-s-journey-to-the-we-b-st-open-r-integration-with-ios-xr": {"content": "     On This Page  Prelude  IOS-XR\u2019s Journey to the West (Web)  What is Open/R?          Where does one start?      Open/R on Linux#Vagrant      Capturing Open/R Hellos and Peering messages      Open/R breeze CLI        Integrating Open/R with IOS-XR          Does XR meet the Requirements?      Gaps and workaround      Current Solution and implementation details      Pre-Built Open/R Docker image      Deploying Open/R Docker image on NCS5500      Testing FIB Programming Rate      Check IOS-XR RIB State        Coexistence with Other Protocols on IOS-XR  What else can we do?  PreludeIn December 2017, within a month of Facebook\u2019s open-source announcement of Open/R, we released an integration of Open/R with IOS-XR. With the model-driven Service Layer APIs and application hosting capabilities, IOS-XR provided a pretty easy ride. The code for this integration is on Github (https#//github.com/akshshar/openr-xr) and is going through iterations and reviews before a pull request is sent out to the core code at https#//github.com/facebook/openr/.To see the demo of Open/R on XR in action, take a look at the following NFD17 presentation focused on IOS-XR\u2019s interplay with community tools#\u00a0\u00a0If you\u2019d like to see this demo live and have a chat, then catch us at the Cisco Booth at Beer\u2019n\u2019Gear at Nanog72 in Atlanta on Tuesday,20th Feb,2018 from 6pm to 8pm.This blog will dive deeper into the demo as well as the integration points in code, so hopefully it is useful for folks starting off with open/R.IOS-XR\u2019s Journey to the West (Web)As part of this blog series titled \u201cXR\u2019s journey to the Web\u201d, I intend to candidly present the journey we have undertaken with the IOS-XR software stack since 2014. In line with the ethos of xrdocs, expect this series to be highly technical and heavily focused on showcasing how IOS-XR integrates with community tools and open-source software innovations - where does it excel? where can it get better? and what needs to be done to help it get better?As an allegory, I often refer back to the famous Chinese folklore# \u201cJourney to the west\u201d - a 16th Century Chinese novel by Wu Cheng-en.Through an extended account, it chronicles the story of Xuanzang in the 6th Century AD and his journey to India (the \u201cwest\u201d) to seek out and bring back the teachings of Buddhism to a primarily Confucian China. As Buddhism began to spread through the east, a new movement began in China that sought to marry the practical Confucian core with the new intellectual and spiritual expectations arising out of Buddhism. This movement came to be known as neo-confucianism.I liken the changes that have happened to IOS-XR over the last few years to a similar creative reinterpretation of the core concepts of traditional networking. As the \u201cWeb\u201d players (Google, Facebook, Apple, Amazon etc.) began to showcase how better efficiencies may be achieved in network operations through automation at every stage of deployment, and through the ability to \u201crun with scissors\u201d - it became clear that the traditional core of network stacks would have to evolve to meet the operational demands of these highly automated networks.The evolution was comprised of some very interesting developments#      Linux-ization of the Stack# IOS-XR moved from 32-bit QNX to 64-bit Linux to enable an environment for scripting, hosting applications and integration with tools in the DevOps space such as Ansible, Puppet, Docker, etc.        Streaming Telemetry# Real-time push-based Streaming Telemetry for monitoring, alerts and remediation triggers/events, outperforming SNMP in every department - scale, ease-of-use, cadence etc.        Model Driven APIs at every layer of the stack# This includes Yang Models at the Manageability layer and tools to generate bindings in various languages. Further,in September 2017, we took it a step further - we introduced model driven APIs over gRPC called the Service Layer APIs that provide programmatic access to the IOS-XR RIB, label switch database and notifications for interface and BFD events.  This blog series will focus on how a combination of the above enhancements should allow us to integrate with a wide variety of tools and software stacks in the networking community and let our users run with scissors when needed.In this blog in particular, we shall explore how IOS-XR\u2019s service layer APIs and application hosting capabilities can be leveraged to host and integrate Open/R as an IGP on IOS-XR. We will also touch upon further enhancements to Open/R that may be possible with Service Layer APIs serving as the platform hooks to IOS-XR.What is Open/R?In November 2017, Facebook open sourced Open/R.As the Github description suggests, it is, and I quote, a \u201cDistributed platform for building autonomic network functions\u201d. Pretty heavy description, so let\u2019s distill it a bit.Much of the documentation for open/R can be found in the docs directory in the git repo#  https#//github.com/facebook/openr/tree/master/openr/docsIt is laid out rather well and describes all the components of the code individually - their purpose, internal interactions, et al.At a higher level, the components look something like this#At the outset, the architecture is reminiscent of traditional link state routing protocols like IS-IS - what with the initial Hellos used to identify neighbors (similar to IS-IS Hello Packets), establishment of adjacencies using 0MQ messages (similar to Link State PDUs (LSPs) in IS-IS) and the use of Djikstra\u2019s algorithm for SPF computations. It also borrows ideas from other protocols like BGP (the concept of originatorIDs for loop prevention, \u00e0 la AS-PATH handling) and spanning tree for flood optimization of messages.So is it really just an alternative to traditional IGPs ? Not quite. There are some design decisions taken to enable the architecture to be pluggable from the get-go#      KV-Store#  A Key-Value store that serves as a common database for the entire stack. Peering Messages to other routers are sent out over 0MQ channels. The internal  communication with other components such as the Prefix Manager, Decision module or the link monitor module are handled by sending and receiving thrift objects on sockets through an abstracted KvStoreClient.        Thrift based modeled APIs between all the modules# for example, the FIB module implements a thrift client and the platform module implements a thrift server to receive route batches from the FIB before programming the underlying platform. These interaction RPCs and the data structures such as the route updates are modeled in thrift IDL files (See https#//github.com/facebook/openr/tree/master/openr/if)  Consequently, integrations with existing stacks and platforms can cleanly occur at the lower platform layer abstracted through the modeled thrift interface. Newer functionalities that leverage the underlying platform\u2019s capabilities (like MPLS, BFD, SR etc.) can extend an existing or implement a new thrift model and leverage the KVstore to store data locally and share information with other routers easily.Where does one start?I believe the best place to start is of course the documentation on Github I refer to above. However, not enough importance can be placed on the need to read through the structure of the code to understand the important touch points in each module. The developers at Facebook graciously released a netlink platform integration for Open/R to enable the community to take a look at how things tie in internally.This netlink platform integration enables Open/R to run as a routing stack on top of a Linux kernel as the network stack. You can check out the relevant pieces of code here#  The \u201cPlatform\u201d module code runs a thrift Server and receives route batches from the Fib module that runs a thrift clienthttps#//github.com/facebook/openr/tree/master/openr/platformThis consists of two important abstractions#  NetlinkFibhandler#  implements the FibService interface described in the thrift IDL here# https#//github.com/facebook/openr/blob/master/openr/if/Platform.thrift to handle the incoming route batches from the Fib module  NetlinkSystemHandler# implements the SystemService interface again described in the thrift IDL here# https#//github.com/facebook/openr/blob/master/openr/if/Platform.thrift to detect interfaces and IPv6 neighbors in the kernel that may be used to send hellos and peering messages to neighbors.  The \u201cNetlink(nl)\u201d abstraction  handles actual interaction with the kernel through netlink using the libnl library. The Netlink platform handlers described above utilize this abstraction to program and fetch routes and get a list of ipv6 neighbors or links or associated events from the kernel.https#//github.com/facebook/openr/tree/master/openr/nlWell, this is good to know. But the question still lingers -  How can one power through the all the concepts and get Open/R running?The Open/R Github repo gives a nod to an emulator that might become available soon (https#//github.com/facebook/openr/blob/master/openr/docs/Emulator.md). However, that doesn\u2019t prevent us from using standard techniques such as Vagrant to bring up an environment to play with, right away.Open/R on Linux#VagrantIf you\u2019d like to try a back-to-back setup with two linux instances on your laptop, I\u2019ve published a vagrant setup with two ubuntu 16.04 instances (rtr1 and rtr2) connected through an ubuntu switch#  https#//github.com/akshshar/openr-vagrantThe switch in the middle is a nice-to-have. It allows you to capture packets as the two nodes rtr1 and rtr2 exchange hellos and peering messages.The relevant Vagrantfiles in the repository are divided into two buckets#      Pre-Built# A pre-built ubuntu-16.04 vagrant box with open/R already built and installed has been published on vagrantcloud here. The box is built using the hash# a14e09abc0fcbe5835b45f549d48c09935d17f87 of https#//github.com/akshshar/openr-xr as of April 5, 2018. This box is referenced in the Vagrantfile at the root of the git repo.        Latest Build# If you\u2019d like to build the boxes from scratch, drop into the vagrant_build_latest/ folder before issuing a vagrant up.  Clone the above git repo and issue a vagrant up inside the directory#If you\u2019re behind a proxy, just populate the &lt;git repo directory&gt;/scripts/http_proxy &lt;git repo directory&gt;/scripts/https_proxy files before issuing a vagrant up.cisco@host#~$  git clone https#//github.com/akshshar/openr-vagrant Cloning into 'openr-vagrant'...remote# Counting objects# 31, done.remote# Compressing objects# 100% (17/17), done.remote# Total 31 (delta 14), reused 26 (delta 12), pack-reused 0Unpacking objects# 100% (31/31), done.Checking connectivity... done.cisco@host#~$ cd openr-vagrant/cisco@host#~$ vagrant upBringing machine 'rtr1' up with 'virtualbox' provider...Bringing machine 'switch' up with 'virtualbox' provider...Bringing machine 'rtr2' up with 'virtualbox' provider...The provisioning scripts set up the ip addresses on the connecting ports of rtr1 and rtr2. The Vagrantfile uses a pre-built Vagrant box located hereOnce the devices are up, issue a vagrant ssh rtr1 and vagrant ssh rtr2 in separate terminals and start open/R (The run scripts added to each node will automatically detect the interfaces and start discovering each other).Further, for rtr2, I\u2019ve added a simple route-scaling python script that allows you to add up to 8000 routes by manipulating the batch_size and batch_num values in &lt;git repo directory&gt;/scripts/increment_ipv4_prefix.py before running /usr/sbin/run_openr.shvagrant@rtr1#~$ /usr/sbin/run_openr.sh /usr/sbin/run_openr.sh# line 98# /etc/sysconfig/openr# No such file or directoryConfiguration not found at /etc/sysconfig/openr. Using default configurationopenr[10562]# Starting OpenR daemon.......vagrant@rtr2#~$ /usr/sbin/run_openr.sh /usr/sbin/run_openr.sh# line 98# /etc/sysconfig/openr# No such file or directoryConfiguration not found at /etc/sysconfig/openr. Using default configurationopenr[10562]# Starting OpenR daemon.......Capturing Open/R Hellos and Peering messagesStart a tcpdump capture on one or more of the bridges on the switch in the middle#AKSHSHAR-M-K0DS#openr-two-nodes akshshar$ vagrant ssh switch #######################  snip #############################Last login# Thu Feb 15 11#04#25 2018 from 10.0.2.2vagrant@vagrant-ubuntu-trusty-64#~$ sudo tcpdump -i br0 -w /vagrant/openr.pcap tcpdump# listening on br0, link-type EN10MB (Ethernet), capture size 262144 bytesOpen up the pcap file in wireshark and you should see the following messages show up#      Hello Messages# The hello messages are sent to UDP port 6666 to the All-Nodes IPv6 Multicast address ff02##1 and source IP = Link local IPv6 address of node. These messages are used to discover neighbors and learn their link local IPv6 addresses.            Peering Messages# Once the link local IPv6 address of neighbor is known, 0MQ TCP messages are sent out to create an adjacency with the neighbor on an interface. One such message is shown below#      Open/R breeze CLIOnce the peering messages go through, adjacencies should get established with the neighbors on all connected interfaces. These adjacencies can be verified using the \u201cbreeze\u201d cli#Note# Keep the run_openr_rtrx.sh scripts running and open up a new terminal to ssh into rtr1 before invoking the breeze cli.vagrant@rtr1#~$ breeze kvstore adj&gt; rtr1's adjacencies, version# 26, Node Label# 13277, Overloaded?# FalseNeighbor    Local Interface    Remote Interface      Metric    Weight    Adj Label  NextHop-v4    NextHop-v6                Uptimertr2        eth1               eth1                       6         1        50003  10.1.1.20     fe80##a00#27ff#fe7e#496   8m52srtr2        eth2               eth2                       4         1        50004  11.1.1.20     fe80##a00#27ff#fe93#99dd  8m52sLet\u2019s look at the fib state in Open/R using the breeze cli#vagrant@rtr1#~$ breeze fib list== rtr1's FIB routes by client 786  ==&gt; 100.1.1.0/24via 11.1.1.20@eth2via 10.1.1.20@eth1&gt; 100.1.10.0/24via 11.1.1.20@eth2via 10.1.1.20@eth1&gt; 100.1.100.0/24via 11.1.1.20@eth2via 10.1.1.20@eth1&gt; 100.1.101.0/24via 11.1.1.20@eth2via 10.1.1.20@eth1&gt; 100.1.102.0/24via 11.1.1.20@eth2via 10.1.1.20@eth1&gt; 100.1.103.0/24via 11.1.1.20@eth2via 10.1.1.20@eth1&gt; 100.1.104.0/24via 11.1.1.20@eth2via 10.1.1.20@eth1&gt; 100.1.105.0/24via 11.1.1.20@eth2via 10.1.1.20@eth1......If you used the default route-scaling script on rtr2, then rtr1 should now have about 1000 routes in its fib#vagrant@rtr1#~$ breeze fib counters== rtr1's Fib counters  ==fibagent.num_of_routes # 1004vagrant@rtr1#~$ In this case Open/R is launched using the NetlinkFibHandler (Open up /usr/sbin/run_openr.sh on either rtr1 and take a look at ENABLE_NETLINK_FIB_HANDLER=true directive). As a result, the FIB on rtr1 gets downloaded to the Linux kernel and we can view the routes using ip route#vagrant@rtr1#~$ ip routedefault via 10.0.2.2 dev eth0 10.0.2.0/24 dev eth0  proto kernel  scope link  src 10.0.2.15 10.1.1.0/24 dev eth1  proto kernel  scope link  src 10.1.1.10 11.1.1.0/24 dev eth2  proto kernel  scope link  src 11.1.1.10 60.1.1.1  proto 99 \tnexthop via 10.1.1.20  dev eth1 weight 1\tnexthop via 11.1.1.20  dev eth2 weight 1100.1.1.0/24  proto 99 \tnexthop via 10.1.1.20  dev eth1 weight 1\tnexthop via 11.1.1.20  dev eth2 weight 1100.1.2.0/24  proto 99 \tnexthop via 10.1.1.20  dev eth1 weight 1\tnexthop via 11.1.1.20  dev eth2 weight 1100.1.3.0/24  proto 99 \tnexthop via 10.1.1.20  dev eth1 weight 1\tnexthop via 11.1.1.20  dev eth2 weight 1100.1.4.0/24  proto 99 \tnexthop via 10.1.1.20  dev eth1 weight 1\tnexthop via 11.1.1.20  dev eth2 weight 1.....Great! These outputs should give you a fair gist of how Open/R works as a link state routing protocol.Note# The route updates are exchanged by the routers frequently over the established adjacencies. So subsequent updates may modify the next hop entries (10.1.1.20 or 11.1.1.20 seen in the outputs above) based on the content of the latest update. The outputs above were captured when the latest route updates were received for both the discovered next hop interfaces.Integrating Open/R with IOS-XRDoes XR meet the Requirements?Now that we understand how Open/R operates, let\u2019s codify the requirements for it to work on a platform running Linux#      API to get and set Routes# On Linux, this API is Netlink, but it can be replaced with any viable API that the networking stack on the platform offers.    In September 2017, we introduced Service Layer APIs - a highly performant and model driven   API into the network infrastructure layer (RIB, label switch database, interface and BFD   events) over gRPC. This API is ideal for platform integration with Open/R and as we\u2019ll see        later,achieves great performance due to its route batching capability. This   API is available on IOS-XR releases post 6.1.2.        Ability to host applications# The Network OS must have the capability to host Linux applications either natively or as a container (docker/lxc).    With IOS-XR 6.1.2+, the capability to host linux applications on the box with docker was   introduced. In addition, applications can be hosted within LXC containers or even natively   (if compiled for WRL7). Further, use of network namespaces mapped to IOS-XR vrfs was   introduced in release 6.2.2+, allowing isolation of traffic in the kernel based on vrf   configuration.        Ability to exchange Hellos and Peering Messages# Open/R should be able to run unmodified on a platform and send its UDP hellos to port 6666 and ff02##1 and send/receive TCP peering messages using link local IPv6 addresses of neighbors.    Packet/IO capabilities have existed in IOS-XR since 6.0.0+, allowing applications to bind   to XR interfaces in the kernel, open up the TCP/UDP ports, transmit/receive TCP/UDP traffic   along with exception traffic such as icmp, icmpv6, IPv6 multicast etc.  Gaps and workaround      Pending Issue# While the primary requirements were met right away, I did find an issue with dynamic IPv6  neighbor discovery in the kernel. Neighbor Solicitation messages generated in the kernel were  unable to exit the box. This issue is being looked at as part of the packet/IO plumbing code  that connects the linux kernel with the XR networking stack on the box.    Workaround# However, since XR itself has no issues in handling the IPv6 neighbors, we utilize two  capabilities in XR as a workaround#                  Enable \u201cipv6 nd ra-unicast\u201d under the XR interfaces using XR CLI or Yang model. This enables neighbors to be reachable without explicit traffic being originated in XR.                    Set up a client (currently separate from the Open/R binary, running as a parallel process) that receives IPv6 neighbor table from XR periodically using Streaming Telemetry over gRPC and programs the kernel using Netlink. Open/R then works with the programmed neighbors in the kernel without any issues. By reacting to Streaming Telemetry data for IPv6 neighbors, the entries in the kernel are kept dynamic and in sync with network events like link flap or disabling IPv6 on interface.                  Resolved Issue# Patch Ready#    As part of the initial design of the packet/IO architecture, the presence of a default route through an interface (that connects the kernel to the XR networking stack) called \u201cfwdintf\u201d and consequently, an fe80##/64 route through fwdintf alone, solved most use cases where an application needed to send traffic through data ports over the internal fabric.    However, as soon as we realized that Open/R utilizes TCP messages with link local IPv6 addresses of neighbors as the destination to establish adjacencies, it became obvious that we needed to allow fe80##/64 routes through all the exposed interfaces (Gig, TenGig, HundredGig etc.) in the kernel. This was a simple fix and an internal bug was filed,resolved and the patch is utilized in the integration that you see below. This patch will be released for public consumption as a SMU on top of IOS-XR release 6.2.25 and will be integrated into 6.3.2.  Current Solution and implementation detailsThe current solution is shown below#The code for this implementation can be found here#  https#//github.com/akshshar/openr-xrThe touch points are described below#      CMakelists.txt was extended to include grpc,protobuf and iosxrsl (IOS-XR Service Layer APIs compiled into a library) as target linklibraries.        Platform module was extended to include IosxrslFibHandler that implements the FibService interface described in the thrift IDL here#https#//github.com/facebook/openr/blob/master/openr/if/Platform.thrift to handleincoming route batches from the Fib module.    It may be noted that the NetlinkSystemHandler code remains untouched and continues to register and react to link and neighbor information from the kernel in IOS-XR for now. In the future, as the above figure indicates, I will experiment by replacing the netlink hooks for link information with the IOS-XR Service Layer RPC for Interface events and by replacing the netlink hooks for IPv6 neighbor information with IOS-XR Telemetry stream for IPv6 neighbors. The goal will be to remove dependencies on libnl and determine if any efficiencies are gained as a result. For now, there is no immediate need to replace the NetlinkSystemHandler functionality.        IOS-XR Service Layer (iosxrsl) abstraction# The iosxrsl directory in the git repo implements all the necessary initialization techniques to connect to IOS-XR Service-layer over gRPC, handles async thread for the init channel used by service layer and creates the necessary abstractions for Route batch handling for IOS-XR RIB (Routing information Base), making it easy to implement the IosxrslFibHandler.cpp code explained above. Eventually, the IOS-XR Service Layer Interface API abstraction will also go here.        Main.cpp# Extended to accept new parameters for IOS-XR Service Layer IP address and port (reachable IP address in IOS-XR and configured gRPC port for service-layer). Further, it starts a Fibthrift thread that intializes the gRPC connection to IOS-XR and registers against a set of VRFs (New) for IPv4 and IPv6 operations.        Docker Build# As shown in the figure above, Open/R is spun up on IOS-XR as an application running inside a docker container. The Dockerfile is used to build Open/R with all its dependencies, along with the grpc, protobuf, and IOS-XR Service-Layer library inside an ubuntu 16.04 rootfs. The Dockerfile used is also shown below#        FROM ubuntu#16.04   RUN apt-get update &amp;&amp; apt-get install -y autoconf automake libtool curl make g++ unzip git  python-pip python-dev &amp;&amp; git clone https#//github.com/google/protobuf.git ~/protobuf &amp;&amp; \\            cd ~/protobuf &amp;&amp; \\            git checkout 2761122b810fe8861004ae785cc3ab39f384d342 &amp;&amp; \\            ./autogen.sh &amp;&amp; \\            ./configure &amp;&amp; \\            make &amp;&amp; \\            make install &amp;&amp;\\            ldconfig &amp;&amp; make clean &amp;&amp; cd ~/ &amp;&amp; rm -r ~/protobuf   RUN git clone https#//github.com/grpc/grpc.git ~/grpc &amp;&amp; cd ~/grpc &amp;&amp; \\            git checkout 80893242c1ee929d19e6bec5dc19a1515cd8dd81 &amp;&amp; \\            git submodule update --init &amp;&amp; \\            make &amp;&amp; \\            make install &amp;&amp; make clean &amp;&amp; cd ~/ &amp;&amp; rm -r ~/grpc  RUN apt-get install -y pkg-config &amp;&amp; git clone https#//wwwin-github.cisco.com/akshshar/service-layer-objmodel ~/service-layer-objmodel &amp;&amp; \\           cd ~/service-layer-objmodel/grpc/cpp &amp;&amp; \\           ./build_libiosxrsl.sh &amp;&amp;  \\           cd ~/ &amp;&amp; rm -r ~/service-layer-objmodel  RUN git clone https#//github.com/akshshar/openr.git /root/openr &amp;&amp; cd /root/openr/ &amp;&amp; git   checkout openr20171212 &amp;&amp; cd /root/openr/build &amp;&amp; ./build_openr_dependencies.sh  RUN cd /root/openr/build &amp;&amp; ./build_openr.sh &amp;&amp; ./remake_glog.sh &amp;&amp; cd /root/ &amp;&amp; rm -r /root/openr  COPY run_openr.sh /usr/sbin/run_openr.sh  CMD /usr/sbin/run_openr.sh &gt;/var/log/openr.log 2&gt;&amp;1            Tip# When issuing the docker build command with this Dockerfile, make sure to use the \u2013squash flag# docker build --squash -it openr .   This is required to prevent the size of the docker image from spiraling out of control.Pre-Built Open/R Docker imageThe Dockerfile as described in the previous section is published in the openr-xr git repo here#  https#//github.com/akshshar/openr-xr/blob/openr20171212/docker/DockerfileTo speed up the process, I have published a pre-built docker image using the current hash# a14e09abc0fcbe5835b45f549d48c09935d17f87 of https#//github.com/akshshar/openr-xr as of April 5, 2018 to dockerhub here#  https#//hub.docker.com/r/akshshar/openr-slapi-xr/\u00a0Deploying Open/R Docker image on NCS5500IOS-XR utilizes a consistent approach towards the application hosting infrastructure across all XR platforms. This implies that all hardware platforms# 1RU, 2RU, Modular or even Virtual platforms would follow the same deployment technique for Open/R as described below#In the demo, I will utilize two NCS5501s connected to each other over a HundredGig interface.The basic configuration on the router is shown below#XR Configuration#interface HundredGigE0/0/1/0 ipv4 address 10.1.1.10 255.255.255.0 ipv6 nd unicast-ra ipv6 enable!!!grpc port 57777 service-layer!!telemetry model-driven sensor-group IPV6Neighbor  sensor-path Cisco-IOS-XR-ipv6-nd-oper#ipv6-node-discovery/nodes/node/neighbor-interfaces/neighbor-interface/host-addresses/host-address ! subscription IPV6  sensor-group-id IPV6Neighbor sample-interval 15000 !!endAs explained in an earlier section, ipv6 nd unicast-ra is required to keep neighbors alive in XR while Open/R initiates traffic in the linux kernel. The grpc configuration starts the gRPC server on XR and can be used to subscribe to Telemetry data (subscription IPv6 as shown in the configuration above) and service-layer configuration allows Service-Layer clients to connect over the same gRPC port.Once the Docker image is ready#  Either built from scratch using this Dockerfile  or pulled from Dockerhub# akshshar/openr-slapi-xr,set up a private docker registry that is reachable from the NCS5500 router in question and push the docker image to that registry.Setting up a private docker registry and pulling a docker image onto NCS5500 is explained in detail in the \u201cDocker on XR\u201d tutorial here#  https#//xrdocs.github.io/application-hosting/tutorials/2017-02-26-running-docker-containers-on-ios-xr-6-1-2/#private-insecure-registryOnce the docker image is pulled successfully, you should see#RP/0/RP0/CPU0#rtr1#bashFri Feb 16 22#46#52.944 UTC[rtr1#~]$ [rtr1#~]$ [rtr1#~]$ docker imagesREPOSITORY              TAG                 IMAGE ID            CREATED             SIZE11.11.11.2#5000/openr   latest              fdddb43d9600        33 seconds ago        1.829 GB[rtr1#~]$ [rtr1#~]$ Now, simply spin up the docker image using the parameters shown below#RP/0/RP0/CPU0#rtr1#RP/0/RP0/CPU0#rtr1#bashFri Feb 16 22#46#52.944 UTC[rtr1#~]$ [rtr1#~]$ docker run -itd  --name openr --cap-add=SYS_ADMIN --cap-add=NET_ADMIN  -v /var/run/netns#/var/run/netns -v /misc/app_host#/root -v /misc/app_host/hosts_rtr1#/etc/hosts --hostname rtr1 11.11.11.2#5000/openr bash684ad446ccef5b0f3d04bfa4705cab2117fc60f266cf0536476eb9506eb3050a[rtr1#~]$ [rtr1#~]$ [rtr1#~]$ docker psCONTAINER ID        IMAGE                   COMMAND             CREATED             STATUS              PORTS               NAMESb71b65238fe2        11.11.11.2#5000/openr   ~bash -l~           24 secondss ago        Up 24 seconds                             openrInstead of bash as the entrypoint command for the docker instance, one can directly start openr using /root/run_openr_rtr1.sh &gt; /root/openr_logs 2&gt;&amp;1. I\u2019m using bash here for demonstration purposes.Note the capabilities# --cap-add=SYS_ADMIN and --cap-add=NET_ADMIN. Both of these are necessary to ensure changing into a mounted network namespace(vrf) is possible inside the container.Once the docker instance is up on rtr1, we do the same thing on rtr2#RP/0/RP0/CPU0#rtr2#bashFri Feb 16 23#12#53.828 UTC[rtr2#~]$ docker psCONTAINER ID        IMAGE                   COMMAND             CREATED             STATUS              PORTS               NAMES684ad446ccef        11.11.11.2#5000/openr   ~bash -l~           8 minutes ago       Up 8 minutes                            openr[rtr2#~]$ On rtr2, the file /root/run_openr_rtr2.sh is slightly different. It leverages increment_ipv4_prefix.py as a route-scaling script to increase the number of routes advertized by rtr2 to rtr1. Here I\u2019ll push a 1000 routes from rtr2 to rtr1 to test the amount of time Open/R on rtr1 takes to program XR RIB.Testing FIB Programming RateOn rtr2, exec into the docker instance and start Open/R#RP/0/RP0/CPU0#rtr2#bashFri Feb 16 23#12#53.828 UTC[rtr2#~]$ [rtr2#~]$ docker exec -it openr bashroot@rtr2#/# /root/run_openr_rtr2.sh/root/run_openr_rtr2.sh# line 106# /etc/sysconfig/openr# No such file or directoryConfiguration not found at /etc/sysconfig/openr. Using default configurationopenr[13]# Starting OpenR daemon.openr....Now, hop over to rtr1 and do the same#RP/0/RP0/CPU0#rtr1#bashFri Feb 16 23#12#53.828 UTC[rtr1#~]$ [rtr1#~]$ docker exec -it openr bashroot@rtr2#/# /root/run_openr_rtr1.sh/root/run_openr_rtr1.sh# line 106# /etc/sysconfig/openr# No such file or directoryConfiguration not found at /etc/sysconfig/openr. Using default configurationopenr[13]# Starting OpenR daemon.openrI0216 23#50#28.058964   134 Fib.cpp#144] Fib# publication received ...I0216 23#50#28.063819   134 Fib.cpp#218] Processing route database ... 1002 entriesI0216 23#50#28.065533   134 Fib.cpp#371] Syncing latest routeDb with fib-agent ... I0216 23#50#28.081434   126 IosxrslFibHandler.cpp#185] Syncing FIB with provided routes. Client# OPENRI0216 23#50#28.105329    95 ServiceLayerRoute.cpp#197] ###########################I0216 23#50#28.105350    95 ServiceLayerRoute.cpp#198] Transmitted message# IOSXR-SL Routev4 Oper# SL_OBJOP_UPDATEVrfName# ~default~Routes {  Prefix# 1006698753  PrefixLen# 32  RouteCommon {    AdminDistance# 99  }  PathList {    NexthopAddress {      V4Address# 167837972    }    NexthopInterface {      Name# ~HundredGigE0/0/1/0~    }  }}Routes {.....Routes {  Prefix# 1677976064  PrefixLen# 24  RouteCommon {    AdminDistance# 99  }  PathList {    NexthopAddress {      V4Address# 167837972    }    NexthopInterface {      Name# ~HundredGigE0/0I0216 23#49#00.923399    95 ServiceLayerRoute.cpp#199] ###########################I0216 23#49#00.943408    95 ServiceLayerRoute.cpp#211] RPC call was successful, checking response...I0216 23#49#00.943434    95 ServiceLayerRoute.cpp#217] IPv4 Route Operation#2 SuccessfulI0216 23#49#00.944533    95 ServiceLayerRoute.cpp#777] ###########################I0216 23#49#00.944545    95 ServiceLayerRoute.cpp#778] Transmitted message# IOSXR-SL RouteV6 Oper# SL_OBJOP_UPDATEVrfName# ~default~I0216 23#49#00.944550    95 ServiceLayerRoute.cpp#779] ###########################I0216 23#49#00.945046    95 ServiceLayerRoute.cpp#793] RPC call was successful, checking response...I0216 23#49#00.945063    95 ServiceLayerRoute.cpp#799] IPv6 Route Operation#2 SuccessfulI0216 23#27#01.021437    52 Fib.cpp#534] OpenR convergence performance. Duration=3816I0216 23#27#01.021456    52 Fib.cpp#537]   node# rtr1, event# ADJ_DB_UPDATED, duration# 0ms, unix-timestamp# 1518823617205I0216 23#27#01.021464    52 Fib.cpp#537]   node# rtr1, event# DECISION_RECEIVED, duration# 1ms, unix-timestamp# 1518823617206I0216 23#27#01.021471    52 Fib.cpp#537]   node# rtr1, event# DECISION_DEBOUNCE, duration# 9ms, unix-timestamp# 1518823617215I0216 23#27#01.021476    52 Fib.cpp#537]   node# rtr1, event# DECISION_SPF, duration# 22ms, unix-timestamp# 1518823617237I0216 23#27#01.021479    52 Fib.cpp#537]   node# rtr1, event# FIB_ROUTE_DB_RECVD, duration# 12ms, unix-timestamp# 1518823617249I0216 23#27#01.021484    52 Fib.cpp#537]   node# rtr1, event# FIB_DEBOUNCE, duration# 3709ms, unix-timestamp# 1518823620958I0216 23#27#01.021488    52 Fib.cpp#537]   node# rtr1, event# OPENR_FIB_ROUTES_PROGRAMMED, duration# 63ms, unix-timestamp# 1518823621021As seen in the highlighted outputs, the total time taken to program 1002 route entries was about 63ms, giving us a route programming rate of about 16000 routes/second!Having said that, the FIB_DEBOUNCE rate is something to be looked at as I work through the code a bit more.It goes without saying that the adjacencies were correctly established, but for the sake of public record, here are breeze outputs on rtr1 and rtr2#rtr1 breeze adj#RP/0/RP0/CPU0#rtr1#bashSat Feb 17 00#18#07.974 UTC[rtr1#~]$ [rtr1#~]$ docker exec -it openr bashroot@rtr1#/# root@rtr1#/# ip netns exec global-vrf bashroot@rtr1#/# root@rtr1#/# root@rtr1#/# breeze kvstore adj&gt; rtr1's adjacencies, version# 2, Node Label# 36247, Overloaded?# FalseNeighbor    Local Interface    Remote Interface      Metric    Weight    Adj Label  NextHop-v4    NextHop-v6                Uptimertr2        Hg0_0_1_0          Hg0_0_1_0                 10         1        50066  10.1.1.20     fe80##28a#96ff#fec0#bcc0  1m36sroot@rtr1#/# rtr2 breeze adj#RP/0/RP0/CPU0#rtr2#RP/0/RP0/CPU0#rtr2#bashSat Feb 17 00#24#11.960 UTC[rtr2#~]$ [rtr2#~]$ docker exec -it openr bashroot@rtr2#/# root@rtr2#/# ip netns exec global-vrf bashroot@rtr2#/# breeze kvstore adj&gt; rtr2's adjacencies, version# 3, Node Label# 1, Overloaded?# FalseNeighbor    Local Interface    Remote Interface      Metric    Weight    Adj Label  NextHop-v4    NextHop-v6                Uptimertr1        Hg0_0_1_0          Hg0_0_1_0                  9         1        50066  10.1.1.10     fe80##28a#96ff#fed3#18c0  1m38sCheck IOS-XR RIB StateWell, this is the moment of truth. Open/R  instances were able to run inside docker containers on two back-to-back NCS5501 devices, connected over a HundredGig port. Now, let\u2019s see what happened to rtr1\u2019s RIB since we injected 1000 routes into this open/R instance#RP/0/RP0/CPU0#rtr1#show routeSat Feb 17 00#28#36.838 UTCCodes# C - connected, S - static, R - RIP, B - BGP, (&gt;) - Diversion path       D - EIGRP, EX - EIGRP external, O - OSPF, IA - OSPF inter area       N1 - OSPF NSSA external type 1, N2 - OSPF NSSA external type 2       E1 - OSPF external type 1, E2 - OSPF external type 2, E - EGP       i - ISIS, L1 - IS-IS level-1, L2 - IS-IS level-2       ia - IS-IS inter area, su - IS-IS summary null, * - candidate default       U - per-user static route, o - ODR, L - local, G  - DAGR, l - LISP       A - access/subscriber, a - Application route       M - mobile route, r - RPL, (!) - FRR Backup pathGateway of last resort is 10.1.1.20 to network 0.0.0.0S*   0.0.0.0/0 [1/0] via 10.1.1.20, 1d02h               [1/0] via 11.11.11.2, 1d02hC    10.1.1.0/24 is directly connected, 3w0d, HundredGigE0/0/1/0L    10.1.1.10/32 is directly connected, 3w0d, HundredGigE0/0/1/0L    10.10.10.10/32 is directly connected, 3w0d, Loopback1C    11.11.11.0/24 is directly connected, 1d02h, MgmtEth0/RP0/CPU0/0L    11.11.11.23/32 is directly connected, 1d02h, MgmtEth0/RP0/CPU0/0L    50.1.1.1/32 is directly connected, 3w0d, Loopback0a    60.1.1.1/32 [99/0] via 10.1.1.20, 00#03#14, HundredGigE0/0/1/0a    100.1.1.0/24 [99/0] via 10.1.1.20, 00#03#14, HundredGigE0/0/1/0a    100.1.2.0/24 [99/0] via 10.1.1.20, 00#03#14, HundredGigE0/0/1/0a    100.1.3.0/24 [99/0] via 10.1.1.20, 00#03#14, HundredGigE0/0/1/0a    100.1.4.0/24 [99/0] via 10.1.1.20, 00#03#14, HundredGigE0/0/1/0a    100.1.5.0/24 [99/0] via 10.1.1.20, 00#03#14, HundredGigE0/0/1/0a    100.1.6.0/24 [99/0] via 10.1.1.20, 00#03#14, HundredGigE0/0/1/0a    100.1.7.0/24 [99/0] via 10.1.1.20, 00#03#14, HundredGigE0/0/1/0a    100.1.8.0/24 [99/0] via 10.1.1.20, 00#03#14, HundredGigE0/0/1/0a    100.1.9.0/24 [99/0] via 10.1.1.20, 00#03#14, HundredGigE0/0/1/0a    100.1.10.0/24 [99/0] via 10.1.1.20, 00#03#14, HundredGigE0/0/1/0a    100.1.11.0/24 [99/0] via 10.1.1.20, 00#03#14, HundredGigE0/0/1/0a    100.1.12.0/24 [99/0] via 10.1.1.20, 00#03#14, HundredGigE0/0/1/0a    100.1.13.0/24 [99/0] via 10.1.1.20, 00#03#14, HundredGigE0/0/1/0a    100.1.14.0/24 [99/0] via 10.1.1.20, 00#03#14, HundredGigE0/0/1/0....RP/0/RP0/CPU0#rtr1#show route summarySat Feb 17 00#29#47.961 UTCRoute Source                     Routes     Backup     Deleted     Memory(bytes)local                            4          0          0           960          connected                        2          2          0           960          dagr                             0          0          0           0            static                           1          0          0           352          bgp 65000                        0          0          0           0            application Service-layer        1002       0          0           240480       Total                            1009       2          0           242752       RP/0/RP0/CPU0#rtr1#Again, if we dump the fib counters in open/R inside the docker container, we see the counters match up to the summary above#RP/0/RP0/CPU0#rtr1#bashMon Feb 19 23#12#51.407 UTC[rtr1#~]$ [rtr1#~]$ docker exec -it openr bashroot@rtr1#/# ip netns exec global-vrf bashroot@rtr1#/# root@rtr1#/# breeze fib  counters== rtr1's Fib counters  ==fibagent.num_of_routes # 1002root@rtr1#/# So, there you go! There are 1002 service layer routes in the RIB, all thanks to Open/R acting as an IGP, learning routes from its neighbor and programming the IOS-XR RIB on the local box over gRPC.Coexistence with Other Protocols on IOS-XRThe two outputs in the previous section showcase an interesting juxtaposition# Open/R internally is designed to program a \u201cFIB\u201d on a given platform (such as the Linux Kernel using Netlink), but in the integration with IOS-XR described above, the integration point is shifted up to the \u201cRIB\u201d.At this level, notionally, Open/R is no longer the only network protocol stack on the system. It can instead co-exist with other stacks (This is precisely what I demonstrated in the demo at NFD17 where iBGP is configured using Loopback addresses that are advertised through Open/R running as an IGP). In this case, Open/R and XR-BGP coexist and the conflict resolution is handled at the RIB level using, you guessed it, Administrative Distance. By default, I have selected 99 as the Admin Distance for Open/R (in line with protocol ID used for Netlink integration by Facebook).What else can we do?Integration of Open/R with IOS-XR Service Layer APIs opens up a whole host of possibilities.This particular integration was centered around Route handling and hence the RIB API was sufficient.The Service Layer API however offers access to the Label Switch Database on IOS-XR so that a client may program label blocks and label-prefix mappings based on some application logic.This may be leveraged to provide label handling (MPLS) capabilities to Open/R.Further, Open/R currently hooks into interface events and IPv6 neighbor events. With the Service Layer API it is also possible to get a stream of BFD notifications, allowing faster response to link-down event of the neighbor, if the neighbor is connected through a LAN/switch.As Service Layer APIs evolve further and get SR-TE (label stack) capabilities and L2 capabilities, there is a stream of new possibilities for Open/R in the near future.", "url": "https://xrdocs.github.io/cisco-service-layer/blogs/2018-02-16-xr-s-journey-to-the-we-b-st-open-r-integration-with-ios-xr/", "tags": "iosxr, cisco, linux, servicelayer, service-layer, application, igp, gRPC, openr, open/r, open-r, rib", "title": "XR's journey to the web:  Open/R integration with XR", "author": "Akshat Sharma"}, "blogs-2017-08-01-internet-edge-peering-current-practice": {"content": "     On This Page  Introduction  Peering Background          Peering History      IXP Fabric vs. Private Network Interconnect      Localized Peering      B2B IP Peering        Peering Hardware  Peering Network Design          Traditional SP IXP Network Design      Distributed SP Peering Fabric      Regional Core Bypass / Express Peering      Peering Network Resiliency        Management, Control-Plane, and Security          Peering Telemetry                  Flow Information          Peer Statistics and Operational Data          Model-Driven Telemetry          BGP Monitoring Protocol          TE Traffic Matrix Information          BGP Policy Accounting                      Peering Engineering          Ingress and Egress Peer Engineering      Peer Selection via Analytics      Segment Routing Egress Peer Engineering      Flexible Routing Policies via RPL        Peering Security          BCP Implementation      BGP Attribute and CoS Scrubbing      Per-Peer Control Plane Policers      BGP Prefix Security                  RPKI Origin Validation          BGPSEC                    BGP Flowspec        Summary  IntroductionThe Internet was created to provide transparent data services across interconnected packet switched networks. The interconnection and exchange of Internet routing data between two networks is known as Peering. Peering is the glue holding together the Internet, without it the flow of data across the Internet would not be possible. Peering represents an important administrative, operational, and security boundary between networks. Peering is a subject of great interest in many areas, from analytics to politics. This paper will focus on the technical aspects of peering covering peering history and current peering architecture in the areas of network, security, and telemetry.Peering BackgroundPeering HistoryThe Internet became ubiquitous across the globe in the early 1990s largely due to the construction of Internet connection points known as IXPs or Internet Exchange Points. The IXP provided a place for networks to connect and exchange traffic. The initial IXPs constructed were slightly different than the exchange points of today, but by the middle of the 1990s they began to look markedly similar to today\u2019s IXPs. The initial four major North American IXPs, known as NAPs or Network Access Points were operated by traditional telephone companies. As the Internet grew the steep rise in traffic necessitated the creation of more IXPs and private enterprises created a number of carrier-neutral IXPs across the globe. These facilities also provide physical cross-connect services to allow networks to peer directly with each other, bypassing the IXP fabric. Hundreds of IXPs exist today across the world, along with thousands of private interconnections between organizations.IXP Fabric vs. Private Network InterconnectThe easiest way to interconnect the large number of networks joining the Internet was for the IXP itself to create a peering \u201cfabric\u201d facilitating connectivity from one network to many other networks via a single physical connection to each member network. Multiplexing technology such as ATM VCs were used initially, replaced with Ethernet VLANs or flat Ethernet broadcast domains as Ethernet became the dominant medium.In the earlier days of the Internet, producers and consumers were more widely distributed as regional residential and business providers provided services to both along with major telephony carriers. As broadband connectivity has become ubiquitous across the world, service and content providers have evolved to meet user\u2019s needs. In North America for example, Internet connectivity to residential consumers has been consolidated to a small number of providers. There are also relatively few mobile providers, an area seeing tremendous traffic growth. In addition, the content being consumed is produced by a much smaller number of content providers, most of whom have created their own peering presence. This has led the \u201ceyeball\u201d consumer networks to peer directly with content provider networks over PNI (Private Network Interconnection) instead of utilizing IXP fabrics. The reduction in pricing of Internet transit has also lead to more use of transit for low bandwidth peers, also negating the need for IXP fabric connections.Outside North America broadband consolidation has not occurred at the same rate and the decoupling of physical infrastructure from network service has led to many more network providers who interconnect with each other and content providers. IXP fabrics are still widely used across the world today in regional IXPs and large IXPs outside North America. In North America peering fabrics have largely been replaced by the use of Private Network Interconnection.Localized PeeringWhile the bulk of Internet peering still occurs in a relatively small number of IXPs in the US, there has been an effort in the last several years to interconnect closer to consumers. The main driver is the cost to carry traffic across long-haul networks from the traditional peering locations to the consumers they serve in larger markets across a large geographic distance. Building and maintaining equipment in a more distributed peering fabric has become more feasible vs increasing capacity on long-haul fiber networks. In addition, it improves the quality of experience for end users since content is served closer to the consumer.B2B IP PeeringAn often-overlooked form of peering is B2B peering between different networks. There are many examples of B2B peering, the most visible today are those connecting datacenter colocation providers to cloud service providers. Additionally, B2B peering is used for linear video content providers to send video to end providers, carry voice services over IP instead of PSTN, and interconnect various service owners to consumers.Peering HardwareThe main requirements when looking at peering network hardware are      Physical, power, and cooling footprint        10G/100G interface density        Software support for necessary peering features  The Cisco Visual Networking Index has shown a 1270% rise in Internet traffic over the last 12 years and projects a threefold increase over the next five years. Peering routers require flexible high-density hardware supporting the required software feature sets needed for Internet peering. The Cisco NCS 5500 platform powered by IOS-XR satisfies today\u2019s peering needs along with capacity for future traffic growth. Most peering locations are third party facilities where space and power can add considerable cost. Across the entire NCS 5500 series density is greater than 24x100GE per RU, with the NCS 5504, 5508, and 5516 chassis systems providing 36x100GE per RU, all at power consumption of approximately .3/Gbps. In addition to high density 100GE, every NCS 5500 QSFP+ port supports 4x10GE breakout options to connect to 10GE peers as well as downstream caching devices in the case of content provider edge peering.More information on the Network Convergence System 5500 series can be found at http#//www.cisco.com/c/en/us/products/routers/network-convergence-system-5500-series/index.htmlPeering Network DesignTraditional SP IXP Network DesignTraditional SP peering is distributed to one or more geographic locations driven by the convenience of having peers in the same IXP location. There is a need to maintain those locations today as not everyone has the capability of interconnecting everywhere. Peering center network design has typically been done with two or more larger edge peering routers with either direct connections to an optical backbone or connections to another stage of backbone routers as seen in left hand side of Figure 1. In recent years, there has been a trend to more modular network design within the peering center using smaller fixed or chassis systems, allowing the use of best of breed hardware and flexibility to add capacity more granularly. The topology mimics the folded CLOS networks, scaling horizontally across peer connections and minimizing impact during failures. Also, datacenter space in traditional IXP facilities has become more limited in recent years, leading the carrier neutral facility providers to expand to multiple facilities within a metropolitan area. Placing smaller high-density systems to multiplex peer connections onto higher speed links is more cost effective than paying the MRC of inter-facility cross-connects per peer connection.Figure 1 - IXP Network Design EvolutionDistributed SP Peering FabricWhile traditional IXP facilities are still important, reducing the distance and network hops between where packets enter your network and exit to the consumer is a high priority for service providers. Each pass through an optical transponder or router interface adds additional cost to the transit path. The rise in video traffic over the next several years demands Internet peering at the edges of the network to serve wireline broadband subscribers along with high-bandwidth 5G mobile users. Content providers have invested heavily in their own networks as well as distributed caches serving content from any network location with Internet access. Third party colocation providers have begun building more regional locations supporting PNI between content distributors and the end subscribers on the SP network. This leads to a localized peering option for SPs and content providers, greatly reducing the distance and hops across the network. The right-hand diagram of Figure 1 is an example of how more distributed peering is changing the landscape of peering.An initial step may be to create a single localized peering facility within a region but as traffic demands increase or more resiliency is needed it can drive the addition of multiple facilities within a region.Reduced footprint high capacity routers are ideal for serving the needs of a distributed peering network. The NCS 5501, 5502, and 5504 are ideal, providing high density peer termination in a compact, efficient package while not sacrificing features or protocol scale.Figure 2 - Localized PeeringRegional Core Bypass / Express PeeringRegional SP networks serving residential subscribers are typically deployed in an aggregation/access hierarchy using logical Ethernet connections over a metro optical transport network. The aggregation nodes serve as an aggregation point for connections to regional sites along with acting as the ingress point for traffic coming from the SP backbone. If a distributed peering fabric is implemented, SPs can drive even greater efficiency by selecting specific high bandwidth regional sites for core bypass. This is simply connecting the regional hub routers directly to a localized peering facility, bypassing the regional core aggregation nodes which are simply acting as a pass through for the traffic. Due to the growth in Internet video traffic, this secondary express peering network in time will likely be higher capacity than the original SP converged network. The same express peering network can also be used to serve content originated by the SP, leaving the converged regional network to serve other higher priority traffic needs.Figure 3 - Express Peering FabricPeering Network ResiliencyPeering resiliency refers to the ability for the network to cope with the loss of a peer, peering router, or peering facility. Apart from B2B peering instances, almost all traffic coming over a peering link is considered best-effort low priority traffic. Even though most traffic is BE, it is recommended for SPs to dual-home to high bandwidth sources of inbound traffic within the same facility or region. Since most larger SPs peer with the same providers in diverse geographic locations, it is more cost-effective to maintain multiple connections in a facility or region than to have traffic fail-over to a path originating in another geographic region. The traffic may result in congestion on backbone links or building excess capacity on expensive long-haul optical networks. The same holds true for localized peering facilities, dual-homing a peer to multiple routers is more cost effective than relying on backup paths across longer distances.Management, Control-Plane, and SecurityRobust and feature-rich software is required in all three of these areas to build a successful peering network. IOS-XR has been a critical part of many peering networks across the world, and continued innovation in the areas of telemetry, programmability, and security is enhancing service provider peering edge networks.Peering TelemetryPeering exists to drive greater efficiency in the network by reducing network transit path length. The insight to determine when to peer with another network and if the peering is resulting in savings is paramount. The streaming data capabilities of IOS-XR using Netflow/IPFIX, Model-Driven Telemetry, and BGP Monitoring Protocol give unprecedented visibility into the peering edge of the network.Flow InformationNetflow was invented by Cisco due to requirements for traffic visibility and accounting. Netflow in its simplest form exports 5-tuple data for each flow traversing a Netflow-enabled interface. Netflow data was further enhanced with the inclusion of BGP information in the exported Netflow data, namely AS_PATH and destination prefix. It was now possible to see where traffic originated by ASN and derive the destination for the traffic per BGP prefix, aiding in peering analysis and planning. The latest iteration of Cisco Netflow is Netflow v9, with the next-generation IETF standardized version called IPFIX (IP Flow Information Export). Netflow continues to be an important source of information for discovering traffic patterns, detecting traffic anomalies, and for detecting security issues such as DDoS attacks. IPFIX has expanded on Netflow\u2019s capabilities by introducing hundreds of entities Netflow is a mandatory component for SPs at the peering edge and Cisco continues to lead in support and development of Netflow and IPFIX on all platforms.Peer Statistics and Operational DataThe most basic information needed on a per-peering connection basis is interface traffic statistics. Collected via SNMP or newer methods like Model-Driven Streaming Telemetry, having insight into both real-time traffic statistics and historical trends is a necessary component for operating and planning peering networks. In addition to statistics data, it\u2019s important to monitor the state of the peer such as current operational state, max prefix limits, andModel-Driven TelemetryModel-driven streaming telemetry is a foundational element to a modern peering network architecture. Apart from insights gained from the higher frequency of data like interface statistics, MDT also supports operational data such as BGP session state and BGP prefix counts. In addition to periodic streaming data, event driven streaming telemetry can also enhance peering monitoring and automation capabilities. In the case of a RSVP-TE or SR-TE enabled peering router, traffic matrix data can also be streamed and when combined with Netflow data provides powerful insight into the traffic entering or leaving your network. Cisco IOS-XR coupled with the capabilities of the NCS and ASR hardware platforms deliver a wide range of streaming telemetry data. http#//www.cisco.com/c/en/us/td/docs/iosxr/ncs5500/telemetry/b-telemetry-cg-ncs5500-62x.html is a resource for configuring both policy and model driven telemetry on IOS-XR based platforms.BGP Monitoring ProtocolBGP Monitoring Protocol, standardized in RFC 7854, streaming data regarding received BGP prefixes from peers both pre and post routing policy. Since all prefix changes from peers are streamed you gain instant visibility into why outbound traffic shifts are occurring on the network. SNAS, Streaming Network Analytics System, implements a BMP collector and a number of BGP monitoring applications focused on deriving greater meaning from BGP updates. Protocol analytics and security are two main focus areas. The SNAS project can be found at http#//snas.io. IOS-XR was the first vendor to support BMP and continues to be enhanced to support additional NLRI.TE Traffic Matrix InformationTE enabled networks with full or partial mesh configurations can easily determine traffic between peering facilities and origin/destination facilities by looking at TE tunnel statistics. Netflow data can show similar statistics, but requires collection and aggregation, which is not a realtime operation. IOS-XR supports near realtime monitoring of TE tunnel statistics via streaming telemetry, enhancing the capability to catch anomalies and dynamically react to traffic changes. In addition to traditional RSVP-TE tunnel statistics, IOS-XR has been enhanced to gather persistent traffic matrix statistics for Segment Routing enabled networks. The Demand Matrix feature measures traffic from external interfaces destined for Prefix SIDs, making it ideal for peering edge applications.BGP Policy AccountingUnique to IOS-XR is the BGP Policy Accounting feature. BGP PA allows providers to use criteria defined in RPL such as matching a single or set of origin ASNs via regex to create traffic counters when the route is installed in the FIB. This is done through the application of RIB to FIB table policies via the table-policy command. BGP PA can add to the data acquired via other means or be used to quickly isolate operational issues. [pointer to BGP PA?]Peering EngineeringIngress and Egress Peer EngineeringIngress peer engineering is influencing the point traffic is coming into your network. Since you are peering with a network you do not own, the options for ingress peer engineering are limited. The use of selective advertisement, deaggregation of shorter prefixes into longer ones, and AS_PATH prepending are the standard options available that guarantee IPE. Other mechanisms like MED may be available if agreements with the peer are negotiated for them to adhere to those attributes.Egress peer engineering is much easier since you are controlling the path on your own network. There are standard mechanisms to influence best path selection such as LOCALPREF and MED and also more advanced options for per-peer selection such as SR EPE.Peer Selection via AnalyticsUsing the data provided by the peering edge devices and telemetry collectors, traffic analysis can reveal who to peer with and where to peer with them. Analyzing transit connections is key to determining good candidates for peering. Netflow exported data will contain the source ASN of traffic flows, and when aggregated over a time period by source ASN gives a clear picture of how much traffic you can expect via direct peering with the ASN. The aggregate traffic to a destination prefix can help determine where to peer, helping minimize the transit hops from source to destination.Segment Routing Egress Peer EngineeringEgress Peering Engineering or EPE using SR is a newer method of directing traffic to a specific peer based on a unique label, in the case of SR the peer is addressed via a specific prefix SID. It allows a TE path decision from deeper in the network to not only specify an egress node but a specific egress peer or set of peers. Through the use of Anycast SIDs, traffic can be load balanced between several peer nodes as well, simplifying the process of balancing egress traffic.Flexible Routing Policies via RPLBGP routing policies are used to filter inbound or outbound advertised prefixes and apply modifications to BGP attributes. These mechanisms are used to steer traffic towards egress points, or steer traffic into networks via the application of MED and AS_PATH or prefix suppression.IOS-XR from its inception has supported flexible routing policy definitions via its Routing Policy Language. RPL supports advanced functionality such as hierarchical policies, global parameters, and passing parameters to policies. Replacing common policy components with variables passed as parameters when the policy is applied allows abstraction and eliminates duplication. More information about RPL including many examples of its functionality can be found at http#//www.cisco.com/c/en/us/td/docs/iosxr/ncs5500/routing/62x/b-routing-cg-ncs5500-62x/b-routing-cg-ncs5500-62x_chapter_0101.htmlPeering SecurityPeering by definition is at the edge of the network, where security is mandatory. While not exclusive to peering, there are a number of best practices and software features when implemented will protect your own network as well as others from malicious sources within your network.BCP ImplementationBest Current Practices are informational documents published by the IETF to give guidelines on operational practices. This document will not outline the contents of the recommended BCPs, but two in particular are of interest to Internet peering. BCP38 explains the need to filter unused address space at the edges of the network, minimizing the chances of spoofed traffic from DDoS sources reaching their intended target. BCP38 is applicable for ingress traffic and especially egress traffic, as it stops spoofed traffic before it reaches outside your network. BCP84 proposes automated ways to verify ingress traffic is valid via the use of Unicast Reverse Path Check or uRPF, a mechanism dropping traffic if the source address does not match a valid route. BCP194, BGP Operations and Security, covers a number of BGP operational practices, many of which are used in Internet peering. IOS-XR supports all of the mechanisms recommended in BCP38, BCP84, and BCP194, including software features such as GTTL, BGP dampening, and prefix limits.BGP Attribute and CoS ScrubbingScrubbing of data on ingress and egress of your network is an important security measure. Scrubbing falls into two categories, control-plane and dataplane. The control-plane for Internet peering is BGP and there are a few BGP transitive attributes one should take care to normalize. Your internal BGP communities should be deleted from outbound BGP NLRI via egress policy. Most often you are setting communities on inbound prefixes, make sure you are replacing existing communities from the peer and not adding communities. Unless you have an agreement with the peer, normalize the MED attribute to zero or another standard value on all inbound prefixes.In the dataplane, it\u2019s important to treat the peering edge as untrusted and clear any CoS markings on inbound packets, assuming a prior agreement hasn\u2019t been reached with the peer to carry them across the network boundary. It\u2019s an overlooked aspect which could lead to peer traffic being prioritized on your network, leading to unexpected network behavior.Per-Peer Control Plane PolicersBGP protocol packets are handled at the RP level, meaning each packet is handled by the router CPU with limited bandwidth and processing resources. In the case of a malicious or misconfigured peer this could exhaust the processing power of the CPU impacting other important tasks. Most vendors implement policers to prohibit impact to other processes, but at a per-protocol level, meaning even with a policer in place sessions to other BGP peers could be disrupted. IOS-XR\u2019s powerful control plane policing feature implements separate dynamic policers for each peer, meaning no impact outside of that peer.BGP Prefix SecurityRPKI Origin ValidationPrefix hijacking has been prevalent throughout the last decade as the Internet became more integrated into our lives. This led to the creation of RPKI origin validation, a mechanism to validate a prefix was being originated by its rightful owner by checking the originating ASN vs. a secure database. IOS-XR fully supports RPKI for origin validation. Complete details of IOS-XR\u2019s Flowspec implementation plus configuration examples can be found athttp#//www.cisco.com/c/en/us/td/docs/routers/asr9000/software/asr9k-r6-2/routing/configuration/guide/b-routing-cg-asr9000-62x/b-routing-cg-asr9000-62x_chapter_011.htmlBGPSECRPKI origin validation works to validate the source of a prefix, but does not validate the entire path of the prefix. Origin validation also does not use cryptographic signatures to ensure the originator is who they say they are, so spoofing the ASN as well does not stop someone form hijacking a prefix. BGPSEC is an evolution where a BGP prefix is cryptographically signed with the key of its valid originator, and each BGP router receiving the path checks to ensure the prefix originated from the valid owner. BGPSEC standards are being worked on in the SIDR working group.BGP FlowspecBGP Flowspec was standardized in RFC 5575 and defines additional BGP NLRI to inject traffic manipulation policy information to be dynamically implemented by a receiving router. BGP acts as the control-plane for disseminating the policy information while it is up to the BGP Flowspec receiver to implement the dataplane rules specified in the NLRI. At the Internet peering edge, DDoS protection has become extremely important, and automating the remediation of an incoming DDoS attack has become very important. IOS-XR on the ASR9000 and ASR9900 implements most functionality defined in RFC 5575 and the RFCs and drafts extending BGP Flowspec\u2019s capabilities. IOS-XR supports many of the optionsSummaryCisco routers have powered the Internet for decades now, including playing a critical role in peering between Internet networks. Through continued innovation Cisco platforms such as the NCS 5500 powered by IOS-XR enable providers to unlock efficiency today in their peering edge driving Capex and Opex savings.Stay tuned for the next paper in the series covering Next-Generation peering, where we introduce Intelligent Peering through rich analytics, router programmability, and more flexible path selection.", "url": "https://xrdocs.github.io/design/blogs/2017-08-01-internet-edge-peering-current-practice/", "tags": "iosxr, Peering, Design", "title": "Internet Edge Peering - Current Practice", "author": "Phil Bedard"}, "tutorials-2018-02-15-port-assignments-on-ncs5500-platforms": {"content": "     Port Assignments on NCS5500  Introduction  Port allocation          NCS5501(-SE) (Base and Scale version)      NCS5502(-SE) (Base and Scale version)      NCS55A1-24H      NCS55A1-36H(-SE)      NCS55-36X100G and NC55-36X100G-S      NCS55-24X100G-SE      NCS55-18H18F      NCS55-24H12F-SE      NCS55A2-MOD(-SE)-S      NCS55-36X100G-A-SE        IntroductionThis short post will help understanding how the ports are allocated to NPU for each line card and systems.It will be useful for future post(s) and particularly on topics like Netflow/IPFIX.For example, it\u2019s important to understand the way our ports are distributed among forwarding ASICs when considering the amount of sample traffic from an NPU to the LC CPU is shaped 133Mbps or 200Mbps.Let\u2019s review platform by platform and line card by line card, how we do this allocation.The following CLI is used to identify the port assignment, looking at the \u201clocal\u201d VOQ port type.RP/0/RP0/CPU0#Router#show contr npu voq-usage interface all instance 1 location 0/7/CPU0-------------------------------------------------------------------Node ID# 0/7/CPU0Intf         Intf     NPU NPU  PP   Sys   VOQ   Flow   VOQ    Portname         handle    #  core Port Port  base  base   port   speed             (hex)                                     type   (Gbps)----------------------------------------------------------------------Hu0/7/0/9    3800278   1   0    9  1833  12104  25928 local   100Hu0/7/0/8    3800280   1   1   17  1841  12168  25992 local   100Hu0/7/0/7    3800288   1   1   13  1837  12136  25960 local   100Hu0/7/0/6    3800290   1   1   21  1845  12200  26024 local   100Hu0/7/0/10   38001a8   1   0    5  1829  12072  25896 local   100Hu0/7/0/11   38001b0   1   0    1  1825  12040  25864 local   100...RP/0/RP0/CPU0#Router#Port allocationNCS5501(-SE) (Base and Scale version)NCS5501 and NCS5501-SE are using a single Qumran-MX ASIC and all the SFP ports are connected to core 0 while all QSFP ports are connected to core 1. NCS5502(-SE) (Base and Scale version)NCS5502s are made of 8 Jericho ASICs interconnected with 2x fabric engine (FE3600)             Interface      NPU/Core      Interface      NPU/Core      Interface      NPU/Core      Interface      NPU/Core                  Hu0/0/0/0      0 / 1      Hu0/0/0/12      2 / 1      Hu0/0/0/24      4 / 1      Hu0/0/0/36      6 / 1              Hu0/0/0/1      0 / 1      Hu0/0/0/13      2 / 1      Hu0/0/0/25      4 / 1      Hu0/0/0/37      6 / 1              Hu0/0/0/2      0 / 1      Hu0/0/0/14      2 / 0      Hu0/0/0/26      4 / 1      Hu0/0/0/38      6 / 1              Hu0/0/0/3      0 / 0      Hu0/0/0/15      2 / 0      Hu0/0/0/27      4 / 0      Hu0/0/0/39      6 / 0              Hu0/0/0/4      0 / 0      Hu0/0/0/16      2 / 0      Hu0/0/0/28      4 / 0      Hu0/0/0/40      6 / 0              Hu0/0/0/5      0 / 0      Hu0/0/0/17      2 / 0      Hu0/0/0/29      4 / 0      Hu0/0/0/41      6 / 0              Hu0/0/0/6      1 / 1      Hu0/0/0/18      3 / 1      Hu0/0/0/30      5 / 1      Hu0/0/0/42      7 / 1              Hu0/0/0/7      1 / 1      Hu0/0/0/19      3 / 1      Hu0/0/0/31      5 / 1      Hu0/0/0/43      7 / 1              Hu0/0/0/8      1 / 1      Hu0/0/0/20      3 / 1      Hu0/0/0/32      5 / 1      Hu0/0/0/44      7 / 1              Hu0/0/0/9      1 / 0      Hu0/0/0/21      3 / 0      Hu0/0/0/33      5 / 0      Hu0/0/0/45      7 / 0              Hu0/0/0/10      1 / 0      Hu0/0/0/22      3 / 0      Hu0/0/0/34      5 / 0      Hu0/0/0/46      7 / 0              Hu0/0/0/11      1 / 0      Hu0/0/0/23      3 / 0      Hu0/0/0/35      5 / 0      Hu0/0/0/47      7 / 0      NCS55A1-24HNCS55A1-24H is made of two Jericho+ connected back-to-back (no fabric engine)            Interface      NPU/Core      Interface      NPU/Core      Interface      NPU/Core                  Hu0/0/0/0      0 / 1      Hu0/0/0/9      0 / 0      Hu0/0/0/18      1 / 1              Hu0/0/0/1      0 / 0      Hu0/0/0/10      0 / 1      Hu0/0/0/19      1 / 0              Hu0/0/0/2      0 / 1      Hu0/0/0/11      0 / 0      Hu0/0/0/20      1 / 1              Hu0/0/0/3      0 / 0      Hu0/0/0/12      1 / 1      Hu0/0/0/21      1 / 0              Hu0/0/0/4      0 / 1      Hu0/0/0/13      1 / 0      Hu0/0/0/22      1 / 1              Hu0/0/0/5      0 / 0      Hu0/0/0/14      1 / 1      Hu0/0/0/23      1 / 0              Hu0/0/0/6      0 / 1      Hu0/0/0/15      1 / 0      \u00a0      \u00a0              Hu0/0/0/7      0 / 0      Hu0/0/0/16      1 / 1      \u00a0      \u00a0              Hu0/0/0/8      0 / 1      Hu0/0/0/17      1 / 0      \u00a0      \u00a0      NCS55A1-36H(-SE)NCSA1-36Hs are made of 4 Jericho+ ASICs interconnected through a FE3600 ASIC.            Interface      NPU/Core      Interface      NPU/Core      Interface      NPU/Core      Interface      NPU/Core                  Hu0/0/0/1      0 / 0      Hu0/0/0/9      1 / 0      Hu0/0/0/18      2 / 0      Hu0/0/0/27      3 / 0              Hu0/0/0/1      0 / 0      Hu0/0/0/10      1 / 0      Hu0/0/0/19      2 / 0      Hu0/0/0/28      3 / 0              Hu0/0/0/2      0 / 0      Hu0/0/0/11      1 / 0      Hu0/0/0/20      2 / 0      Hu0/0/0/29      3 / 0              Hu0/0/0/3      0 / 0      Hu0/0/0/12      1 / 0      Hu0/0/0/21      2 / 0      Hu0/0/0/30      3 / 0              Hu0/0/0/4      0 / 1      Hu0/0/0/13      1 / 1      Hu0/0/0/22      2 / 1      Hu0/0/0/31      3 / 1              Hu0/0/0/5      0 / 1      Hu0/0/0/14      1 / 1      Hu0/0/0/23      2 / 1      Hu0/0/0/32      3 / 1              Hu0/0/0/6      0 / 1      Hu0/0/0/15      1 / 1      Hu0/0/0/24      2 / 1      Hu0/0/0/33      3 / 1              Hu0/0/0/7      0 / 1      Hu0/0/0/16      1 / 1      Hu0/0/0/25      2 / 1      Hu0/0/0/34      3 / 1              Hu0/0/0/8      0 / 1      Hu0/0/0/17      1 / 1      Hu0/0/0/26      2 / 1      Hu0/0/0/35      3 / 1      NCS55-36X100G and NC55-36X100G-SIn these cards we have 6 Jericho ASICs.            Interface      NPU/Core      Interface      NPU/Core      Interface      NPU/Core      Interface      NPU/Core                  Hu0/x/0/0      0 / 1      Hu0/x/0/9      1 / 0      Hu0/x/0/18      3 / 1      Hu0/x/0/27      4 / 0              Hu0/x/0/1      0 / 1      Hu0/x/0/10      1 / 0      Hu0/x/0/19      3 / 1      Hu0/x/0/28      4 / 0              Hu0/x/0/2      0 / 1      Hu0/x/0/11      1 / 0      Hu0/x/0/20      3 / 1      Hu0/x/0/29      4 / 0              Hu0/x/0/3      0 / 0      Hu0/x/0/12      2 / 1      Hu0/x/0/21      3 / 0      Hu0/x/0/30      5 / 1              Hu0/x/0/4      0 / 0      Hu0/x/0/13      2 / 1      Hu0/x/0/22      3 / 0      Hu0/x/0/31      5 / 1              Hu0/x/0/5      0 / 0      Hu0/x/0/14      2 / 1      Hu0/x/0/23      3 / 0      Hu0/x/0/32      5 / 1              Hu0/x/0/6      1 / 1      Hu0/x/0/15      2 / 0      Hu0/x/0/24      4 / 1      Hu0/x/0/33      5 / 0              Hu0/x/0/7      1 / 1      Hu0/x/0/16      2 / 0      Hu0/x/0/25      4 / 1      Hu0/x/0/34      5 / 0              Hu0/x/0/8      1 / 1      Hu0/x/0/17      2 / 0      Hu0/x/0/26      4 / 1      Hu0/x/0/35      5 / 0      NCS55-24X100G-SEThe scale 24x100G are made of 4 Jericho ASICs.            Interface      NPU/Core      Interface      NPU/Core      Interface      NPU/Core      Interface      NPU/Core                  Hu0/x/0/0      0 / 1      Hu0/x/0/6      1 / 1      Hu0/x/0/12      2 / 1      Hu0/x/0/18      3 / 1              Hu0/x/0/1      0 / 1      Hu0/x/0/7      1 / 1      Hu0/x/0/13      2 / 1      Hu0/x/0/19      3 / 1              Hu0/x/0/2      0 / 1      Hu0/x/0/8      1 / 1      Hu0/x/0/14      2 / 1      Hu0/x/0/20      3 / 1              Hu0/x/0/3      0 / 0      Hu0/x/0/9      1 / 0      Hu0/x/0/15      2 / 0      Hu0/x/0/21      3 / 0              Hu0/x/0/4      0 / 0      Hu0/x/0/10      1 / 0      Hu0/x/0/16      2 / 0      Hu0/x/0/22      3 / 0              Hu0/x/0/5      0 / 0      Hu0/x/0/11      1 / 0      Hu0/x/0/17      2 / 0      Hu0/x/0/23      3 / 0      NCS55-18H18FBy default, the base combo card offers 36 ports 40G, and it\u2019s possible to upgrade half of them to 100G.This line card is made of 3 Jericho ASICs.            Interface      NPU/Core      Interface      NPU/Core      Interface      NPU/Core      Interface      NPU/Core                  Fo0/x/0/0      0 / 0      Hu0/x/0/9      0 / 0      Hu0/x/0/18      1 / 1      Fo0/x/0/27      2 / 1              Fo0/x/0/1      0 / 0      Hu0/x/0/10      0 / 0      Hu0/x/0/19      1 / 1      Fo0/x/0/28      2 / 0              Fo0/x/0/2      0 / 1      Hu0/x/0/11      0 / 0      Hu0/x/0/20      1 / 1      Fo0/x/0/29      2 / 1              Fo0/x/0/3      0 / 1      Fo0/x/0/12      1 / 0      Hu0/x/0/21      1 / 0      Hu0/x/0/30      2 / 1              Fo0/x/0/4      0 / 0      Fo0/x/0/13      1 / 0      Hu0/x/0/22      1 / 0      Hu0/x/0/31      2 / 1              Fo0/x/0/5      0 / 1      Fo0/x/0/14      1 / 1      Hu0/x/0/23      1 / 0      Hu0/x/0/32      2 / 1              Hu0/x/0/6      0 / 1      Fo0/x/0/15      1 / 1      Fo0/x/0/24      2 / 0      Hu0/x/0/33      2 / 0              Hu0/x/0/7      0 / 1      Fo0/x/0/16      1 / 0      Fo0/x/0/25      2 / 0      Hu0/x/0/34      2 / 0              Hu0/x/0/8      0 / 1      Fo0/x/0/17      1 / 1      Fo0/x/0/26      2 / 1      Hu0/x/0/35      2 / 0      NCS55-24H12F-SEBy default, the scale combo card offers 36 ports 40G, and it\u2019s possible to upgrade two third of them to 100G.This line card is made of 4 Jericho ASICs with eTCAM.            Interface      NPU/Core      Interface      NPU/Core      Interface      NPU/Core      Interface      NPU/Core                  Fo0/x/0/0      0 / 0      Fo0/x/0/9      1 / 1      Fo0/x/0/18      2 / 0      Fo0/x/0/27      3 / 0              Fo0/x/0/1      0 / 0      Fo0/x/0/10      1 / 0      Fo0/x/0/19      2 / 0      Fo0/x/0/28      3 / 0              Hu0/x/0/2      0 / 1      Fo0/x/0/11      1 / 0      Hu0/x/0/20      2 / 1      Fo0/x/0/29      3 / 1              Hu0/x/0/3      0 / 1      Hu0/x/0/12      1 / 1      Hu0/x/0/21      2 / 1      Hu0/x/0/30      3 / 1              Hu0/x/0/4      0 / 1      Hu0/x/0/13      1 / 1      Hu0/x/0/22      2 / 1      Hu0/x/0/31      3 / 1              Hu0/x/0/5      0 / 0      Hu0/x/0/14      1 / 1      Hu0/x/0/23      2 / 0      Hu0/x/0/32      3 / 1              Hu0/x/0/6      0 / 0      Hu0/x/0/15      1 / 0      Hu0/x/0/24      2 / 0      Hu0/x/0/33      3 / 0              Hu0/x/0/7      0 / 0      Hu0/x/0/16      1 / 0      Hu0/x/0/25      2 / 0      Hu0/x/0/34      3 / 0              Fo0/x/0/8      0 / 1      Hu0/x/0/17      1 / 0      Fo0/x/0/26      2 / 1      Hu0/x/0/35      3 / 0      NCS55A2-MOD(-SE)-S2RU chassis made of a single Jericho+ ASIC.            Interface      NPU/Core      Interface      NPU/Core      Interface      NPU/Core      Interface      NPU/Core                  Te0/x/0/0      0 / 0      Te0/x/0/14      0 / 1      TF0/x/0/28      0 / 0      Hu0/x/1/2/0      0 / 1              Te0/x/0/1      0 / 0      Te0/x/0/15      0 / 1      TF0/x/0/29      0 / 0      Te0/x/2/0      0 / 1              Te0/x/0/2      0 / 0      Te0/x/0/16      0 / 0      TF0/x/0/30      0 / 0      Te0/x/2/1      0 / 0              Te0/x/0/3      0 / 0      Te0/x/0/17      0 / 0      TF0/x/0/31      0 / 0      Te0/x/2/2      0 / 1              Te0/x/0/4      0 / 0      Te0/x/0/18      0 / 0      TF0/x/0/32      0 / 1      Te0/x/2/3      0 / 0              Te0/x/0/5      0 / 0      Te0/x/0/19      0 / 0      TF0/x/0/33      0 / 1      Te0/x/2/4      0 / 1              Te0/x/0/6      0 / 0      Te0/x/0/20      0 / 1      TF0/x/0/34      0 / 1      Te0/x/2/5      0 / 0              Te0/x/0/7      0 / 0      Te0/x/0/21      0 / 1      TF0/x/0/35      0 / 1      Te0/x/2/6      0 / 1              Te0/x/0/8      0 / 1      Te0/x/0/22      0 / 1      TF0/x/0/36      0 / 0      Te0/x/2/7      0 / 0              Te0/x/0/9      0 / 1      Te0/x/0/23      0 / 1      TF0/x/0/37      0 / 0      Te0/x/2/8      0 / 0              Te0/x/0/10      0 / 1      TF0/x/0/24      0 / 1      TF0/x/0/38      0 / 0      Te0/x/2/9      0 / 1              Te0/x/0/11      0 / 1      TF0/x/0/25      0 / 1      TF0/x/0/39      0 / 0      Te0/x/2/10      0 / 0              Te0/x/0/12      0 / 1      TF0/x/0/26      0 / 1      Hu0/x/1/0      0 / 0      Te0/x/2/11      0 / 1              Te0/x/0/13      0 / 1      TF0/x/0/27      0 / 1      Hu0/x/1/1      0 / 1      -      -      NCS55-36X100G-A-SEFinally, this line card is using 4 Jericho+ with new generation eTCAM.            Interface      NPU/Core      Interface      NPU/Core      Interface      NPU/Core      Interface      NPU/Core                  Hu0/x/0/0      0 / 1      Hu0/x/0/9      1 / 1      Hu0/x/0/18      2 / 1      Hu0/x/0/27      3 / 1              Hu0/x/0/1      0 / 1      Hu0/x/0/10      1 / 1      Hu0/x/0/19      2 / 1      Hu0/x/0/28      3 / 1              Hu0/x/0/2      0 / 1      Hu0/x/0/11      1 / 1      Hu0/x/0/20      2 / 1      Hu0/x/0/29      3 / 1              Hu0/x/0/3      0 / 0      Hu0/x/0/12      1 / 0      Hu0/x/0/21      2 / 0      Hu0/x/0/30      3 / 0              Hu0/x/0/4      0 / 0      Hu0/x/0/13      1 / 0      Hu0/x/0/22      2 / 0      Hu0/x/0/31      3 / 0              Hu0/x/0/5      0 / 0      Hu0/x/0/14      1 / 0      Hu0/x/0/23      2 / 0      Hu0/x/0/32      3 / 0              Hu0/x/0/6      0 / 0      Hu0/x/0/15      1 / 0      Hu0/x/0/24      2 / 0      Hu0/x/0/33      3 / 0              Hu0/x/0/7      0 / 1      Hu0/x/0/16      1 / 1      Hu0/x/0/25      2 / 1      Hu0/x/0/34      3 / 1              Hu0/x/0/8      0 / 0      Hu0/x/0/17      1 / 0      Hu0/x/0/26      2 / 0      Hu0/x/0/35      3 / 0      ", "url": "https://xrdocs.github.io/cloud-scale-networking/tutorials/2018-02-15-port-assignments-on-ncs5500-platforms/", "tags": "NCS5500, ncs 5500, Port", "title": "Port Assignments on NCS5500 Platforms", "author": "Nicolas Fevrier"}, "blogs-2018-03-08-introduction-to-p4-and-p4runtime": {"content": "     On This Page  Introduction to P4          A Brief History of Programmable NPUs      What is P4?      Some observations about P4      P4 Usage Models                  Running P4 compiled code on the NPU engines          P4 as a behavioral specification language                      P4Runtime  Introduction to P4A Brief History of Programmable NPUsProgrammable NPUs have existed in routing products for a long time. Almost all the routers developed for the Service Provide and Enterprise market segments have been built with Network Processor Units (NPU) that are highly programmable, so as to keep up with the pace of new feature and functional requirements that are a norm in this market segment.  On the other hand, Cloud Provider market has traditionally used fixed function ASICs to build the networks, driven primarily by high bandwidth, low to medium functional requirements.Environments for programming these NPUs historically fall into one of the following two categories#1) Low level programming language, with target specific instruction set and tools. While this environment allows for writing most optimal forwarding plane code, it is tied to a  specific NPU architecture and not readily portable to others. This is analogous to writing assembly language code specific to X86 or ARM processor families which is not portable from one to the other.2) High level programming language, such as C or C++, with target specific compilers and tools. This allows for writing code that is easy to port across multiple NPUs, or at-least provides a common environment for developing packet processing functions across multiple NPU architectures. While compilers have come a long way to optimize high level language code to target architectures, lack of native language constructs will result in sub-optimal performance in several cases.What is P4?P4 is a domain specific programming language for writing packet forwarding functions. It has several native language constructs such as IPv4 addresses, Interfaces, VLANs that allows for writing highly optimal code which is portable (subject to some constraints as discussed below) across different NPU architectures.To illustrate this with an example, the following is a very simple packet forwarding flow. IP destination address of the incoming packet is looked up in a longest prefix match table. If there is a match, packet is forwarded to the outgoing interface from the result of the lookup. If there is no match, the packet is dropped.A program written in a high level language such as C or Python would involve defining data structures for the IPv4 header, LPM table, results of the lookup and actions performed.A sample P4 program that achieves the same functionality is shown below.As seen, the language provides native constructs for objects such as IPv4 header (ipv4), table type (LPM), actions (drop, route), making it simpler to program.table routing {key = { ipv4.dstAddr # lpm; }actions = { drop; route; }size # 2048;}control ingress() {apply {routing.apply();}}    P4 compilers generate two sets of outputs for a P4 program, as shown in the figure below.\t* A set of APIs that can be used by the control plane functions to program the table entries in the NPU\t* Target specific executable that can be loaded onto the packet processing NPU engines.Some observations about P4The fundamental premise of P4 is that it allows the packet forwarding behavior of a NPU to be fully programmable using a domain specific language and the associated tools that makes it highly performant, yet portable across a set of NPUs, thus striking the balance between performance and portability.There is however, a subtlety that is often easy to miss when discussing programmable NPUs; and that is the underlying architecture of the NPU itself. While most programmable NPUs look the same and provide similar levels of flexibility in terms of their programmability, the design of the packet processing engines within these NPUs - the blocks that deal with processing the incoming and outgoing packets - can vary significantly. This is attributed to factors such as the number and type of pipeline stages, level of programmability of different pipeline stages, connectivity and access rates to various memories from each of these stages, packet recycling and queuing architectures , etc., - driven by the design trade-offs made by NPU designers.These architectural differences among the NPUs lead to an interesting observation about the P4 programs that are written to run on these NPUs - that, while most of the programs written can be compiled to run on most programmable NPUs, the same program may not yield the most optimal outcome in terms of performance, scale and convergence on all the NPUs, despite the fact that the backend compiler can map the P4 program to a target architecture.Secondly, analysis of the NPUs  on the market shows there are aspects of the packet forwarding functionality that need to be implemented outside of the core P4 functionality, using platform specific extensions and SDK driven configurations. This leads to an observation that not all parts of a common P4 program may be compiled to run on a target NPU.Thirdly, as the adoption for P4 as the packet forwarding programming language of choice, there is a desire to expand the scope of P4 to include not only the programmable NPUs that can run a compiled P4 program, but also fixed function or semi-programmable/configurable ASICs.P4 Usage ModelsThe adoption of P4, and the desire to use it across fully programmable, semi-programmable and fixed function ASICs, is driving the industry towards two distinct, yet related usage models.Running P4 compiled code on the NPU enginesAs per for original intent of P4, developers program the packet forwarding functionality using P4 language constructs. A front-end compiler processes the program and generates a set of APIs for managing the tables and counters that the program operates on. These APIs are then used by the control plane application interfacing with the NPU. A back-end compiler then generates the target specific machine code for the P4 program, which is loaded onto the NPU engine as an executable that processes the packets. This model applies to programmable NPUs.P4 as a behavioral specification languageA second use case is the use of P4 as a behavioral specification for packet forwarding behavior. Vendors and customers write P4 programs in a generic way - not necessarily optimized for a specific NPU architecture - to represent the desired behavior they expect out of the packet forwarding function on the router or switch. A front-end compiler processes this program, as in the above case, and generates the set of APIs to manage the tables and counters accessed by the program.The P4 program may or may not be compiled to run on the target NPU. When it is not compiled to run on the target NPU, it is either because the NPU is not programmable, or because the P4 program, as written, cannot be compiled to optimally run on the NPU. Instead, the control plane application invokes to the generated APIs, and a manual adaptation of these APIs to the SDK/driver for the target NPU is provided by the NPU vendor.Some in the industry are looking to use P4 in this model. This helps for an unambiguous documentation of requirements between the customers and vendors, and also allows an effective way of validating how well a customer implementation matches (or not) with these requirements.  ONF has recently announced project Stratumthat proposes use of P4Runtime, along with gNMI and gNOI as a way to manage an SDN switch.P4RuntimeP4Runtime, a project under P4.org\u2019s API working group, is an effort towards developing an infrastructure for applications to interface with APIs generated from a P4 program in a seamless fashion. It uses GRPC with GPB encoding between a P4Runtime Controller (running locally on the switch or remotely) and P4Runtime Agent (running locally on the switch). NPU specific adaptation of the P4Runtime Agent APIs provides the required glue layer to interface with the SDK or the NPU driver.As seen in the figure above, there are several ways that a P4Runtime Agent API gets mapped to the underlying hardware#1) Direct mapping of the P4Runtime API to the program running on the NPU. This is the model what is applicable when the P4 program is compiled to run on the NPU without any modifications.2) Adaptation of P4Runtime API to a NPU SDK that manages a NPU programmed using a target specific P4 or non-P4 program.3) Adaptation of P4Runtime API to a NPU SDK managing a fixed function or semi-programmable NPU.By abstracting the communication between the Controller (which the application interfaces with), and the Agent (which interfaces with the packet processing engine) using well define, version controlled APIs,  P4Runtime provides a consistent environment for applications to interface with switches and routers that have packet processing engines ranging from fully programmable NPUs to fixed function ASICs.In summary, P4 is evolving as a programming language and environment of choice for vendors and customer alike, for behavioral specification and implementation of packet forwarding functionality on routers and switches.  Cisco is making investments in P4, both as a data plane programming environment and integrating the P4Runtime environment with IOS-XR.", "url": "https://xrdocs.github.io/cloud-scale-networking/blogs/2018-03-08-introduction-to-p4-and-p4runtime/", "tags": "IOS-XR, Cisco, OCP, P4, P4runtime, OFA, API", "title": "Introduction to P4 and P4Runtime", "author": "Praveen Bhagwatula"}, "blogs-2017-06-21-building-a-ciscolive-demo-with-telemetry-and-kafka": {"content": "     Enhancing Demos with Telemetry  Behind the Scenes of Continuous Automation  The Easy Part# Data Model and Router Config  The Other Easy Part# Pipeline and Kafka  The Easiest Part  A Quick Python Script  In Sum  Behind the Scenes of Continuous AutomationEvery year at Cisco Live, my team helps put together the demos that go into the World of Solutions. Geeks that we are, we get a thrill out of showing off the art of the possible. But the real purpose of a demo is to start a conversation with the folks who stop by our booth.This year, a colleague asked me to help integrate model-driven telemetry (MDT) into a Service Provider demo called \u201cContinuous Automation.\u201d The goal of the demo is to illustrate how MDT can be used with model-driven APIs to automate a simple provisioning and validation task (it\u2019s loosely based on a real customer use case that he\u2019s actively working on).Pieces of the demo were already in place# a small Python app that utilized the YDK Python APIs to configure a BGP neighbor and execute a connectivity test from the router when the neighbor came up.  The problem was that the app had no way to know when the neighbor came up.  Enter MDT!The Easy Part# Data Model and Router ConfigThe operational data that we needed was the BGP neighbor session state.  This is easily available in the OpenConfig BGP model#module# openconfig-bgp   +--rw bgp      +--rw neighbors         +--rw neighbor* [neighbor-address]            +--ro state               +--ro session-state?   enumerationTranslating this into an MDT sensor path config for the router looks like this#telemetry model-driven sensor-group BGP  sensor-path openconfig-bgp#bgp/neighbors/neighbor/stateNote# For a detailed explanation of MDT router configurations, see my basic MDT tutorial).Adding a destination-group and a subscription starts the router streaming out the needed data#telemetry model-driven destination-group G1  address-family ipv4 198.18.1.127 port 5432   encoding self-describing-gpb   protocol tcp  ! subscription S1  sensor-group-id BGP sample-interval 5000  destination-id G1But then what?  How do you get data from a TCP stream into a Python app?The Other Easy Part# Pipeline and KafkaMy go-to tool for consuming MDT data is pipeline, an open source utility that I\u2019ve written about before.  If you\u2019re not familiar with installing and configuring pipeline, have a read through my previous tutorial.For this demo, I used the  [testbed] input stage in the default pipeline.conf.  With the following lines uncommented, the default pipeline.conf will work \u201cas-is\u201d with the router MDT configuration in the previous section.[testbed]stage = xport_inputtype = tcpencap = stlisten = #5432That\u2019s good for input, but what about output?  Pipeline can write data to three destinations#  a file  time series databases like InfluxDB  KafkaWriting to a file would probably work (Python has extensive file handling capabilities) but it seemed clumsy.  Writing to InfluxDB would also have worked (I could use Python REST packages to query the database) but seemed too heavy weight for a simple demo.  That left me with Kafka.  I\u2019ve been wanting to do a Kafka demo for a while and there are Python packages to work with Kafka, so I figured\u2026why not?  If nothing else, I\u2019ll learn something new.For pipeline to output to Kafka, all you have to do is uncomment the following lines in the [mykafka] section of the default pipeline.conf. In the example below, I\u2019m running pipeline and Kafka on the same machine, so I used the broker address of \u201clocalhost\u201d and the topic called \u201ctelemetry.\u201d[mykafka]stage = xport_outputtype = kafkaencoding = jsonbrokers = localhost#9092topic = telemetryWith those two entries in the pipeline.conf file, I kicked off pipeline as usual#$ bin/pipeline &amp;[1] 21975Startup pipelineLoad config from [pipeline.conf], logging in [pipeline.log]Wait for ^C to shutdown$The Easiest PartSince I haven\u2019t installed Kafka before, I was concerned that it might be the long pole in my demo prep.  But it couldn\u2019t have been easier.  I followed the first two steps in the Apache Kafka Quickstart guide.  Boom.  Done.  Didn\u2019t even have to alter the default properties files for Kafka and Zookeeper.A Quick Python ScriptWith Kafka, Zookeeper and Pipeline running and the router streaming MDT, all I lacked was a little Python code to subscribe to the topic on Kafka and parse some JSON (by default, pipeline transforms the GPB from the router into a JSON object when it publishes to Kafka). With the kafka-python client, there wasn\u2019t much to it.  Here are a few lines of code I used for a quick test (note that the topic is telemetry and the Pipeline/Kafka stack is running on 10.30.111.4)#from kafka import KafkaConsumerimport jsonif __name__ == ~__main__~#    session_state = ~UNKNOWN~    consumer = KafkaConsumer('telemetry', bootstrap_servers=[~10.30.111.4#9092~])    for msg in consumer#        telemetry_msg =  msg.value        telemetry_msg_json = json.loads(telemetry_msg)        if ~Rows~ in telemetry_msg_json#            content_rows = telemetry_msg_json[~Rows~]            for row in content_rows#            if row[~Keys~][~neighbor-address~] == '10.8.0.1'#                    new_session_state = row[~Content~][~session-state~]                    if session_state != new_session_state#                        print(~\\nSession state changed from {0#s} to {1#s} at epoch time {2#d}~                              .format(session_state, new_session_state, row[~Timestamp~]))                        session_state = new_session_stateIn SumThere was a little more code to write to tie everything together and tidy it up, but my part of the demo was basically done.  From a telemetry perspective, it was trivial to integrate into the demo by using Kafka.  To recap, the main pieces were#  Configure the router to stream BGP session state.  Configure (basically uncomment some lines in the default pipeline.conf) and run pipeline.  Download and run Kafka and Zookeeper.  Use the kafka-python package in a Python script to acquire and process the session state from the telemetry topic on Kafka.Although I didn\u2019t get the learning experience that comes from having really complicated things go deeply wrong, this was a fun little exercise.If you\u2019re in Las Vegas for CiscoLive next week, stop by our booth and talk to us about what you want to do in a model-driven network!", "url": "https://xrdocs.github.io/telemetry/blogs/2017-06-21-building-a-ciscolive-demo-with-telemetry-and-kafka/", "tags": "iosxr, cisco, Telemetry, MDT, YDK, Kafka", "title": "Enhancing a CiscoLive Demo with Telemetry and Kafka", "author": "Shelly Cadora"}, "blogs-filtering-autobw": {"content": "Telemetry recently took center stage at SDX Demo Friday with a new demo showcasing the RSVP-TE auto-bandwidth feature.  In the demo, the TE tunnel headend streamed data about the output bytes sent per tunnel and the resulting applied auto-bandwidth.  We streamed the data to SignalFX\u2019s cloud monitoring system and were able to show nice visualizations of auto-bandwidth in action as well as some cool alerting capabilities.This demo gave us an opportunity to exercise the new filtering capability in IOS XR 6.0.1. The operational data for a TE Tunnel headend is contained in the native path RootOper.MPLS_TE.P2P_P2MPTunnel.TunnelHead({\u2018TunnelName\u2019# \u2018tunnel-te10\u2019}). Streaming this path would result in over 600 lines of output for a single tunnel, with multiple layers of hierarchy.  To filter that data down to a single value, you can use a IncludeField in the policy file as follows#{   ~Name~#~RSVPTEPolicy~,   ~Metadata~#{      ~Version~#1,      ~Description~#~This policy collects auto bw stats~,      ~Comment~#~This is the first draft~   },   ~CollectionGroups~#{      ~FirstGroup~#{         ~Period~#10,         ~Paths~#{            ~RootOper.MPLS_TE.P2P_P2MPTunnel.TunnelHead({'TunnelName'# 'tunnel-te10'})~#{               ~IncludeFields~#[                  {                     ~P2PInfo~#[                        {                           ~AutoBandwidthOper~#[                              ~LastBandwidthApplied~                           ]                        }                     ]                  }               ]            }         }      }   }}With this IncludeFilter, the telemetry engine will only encode the latest applied auto-bandwidth value for the specified TE tunnel (which is nested two levels down from the top level of the path).Filtering on the router is a big win from a performance perspective.  Obviously, the collector (SignalFX in this case) benefits if it has to process less data.  But the router benefits, too.  Internally, the telemetry process still retrieves the entire \u201cbag\u201d of data (i.e. the 600 lines of stuff) to take advantage of bulk retrieval optimizations.  That\u2019s pretty much a fixed cost in terms of CPU utilization.  The good news is that filtering optimizations allow the encoding process to completely skip over everything except the fields you want.  Skipping is much more efficient than processing, which decreases the demand on the CPU.  Moreover, the resulting data stream is much smaller.  Since a large proportion of the telemetry CPU usage is for packet IO, a smaller data stream again means less CPU utilization.  So for maximum efficiency, filter when you can!", "url": "https://xrdocs.github.io/telemetry/blogs/filtering_autobw", "tags": "iosxr, telemetry", "title": "Filtering Telemetry for RSVP-TE Auto-Bandwidth Demo", "author": "Shelly Cadora"}, "tutorials-2017-08-04-programming-ios-xr-with-grpc-and-go": {"content": "     Programming IOS-XR with gRPC and Go  Introduction  Prerequisites  Configuring the router for secure gRPC connections  Installing Go on the Ubuntu VM  Getting the gRPC library for Cisco IOS XR  Compiling the first example  A few pointers on the code  IntroductionThe goal of this tutorial is to demonstrate how to program an IOS XR device using the gRPC framework. For this purpose, we will use a gRPC library for Cisco IOS XR written in Go.The objective is to have a single interface/connection to retrieve info from the device, apply configs to it, generate telemetry streams, program the RIB/FIB and so on.We picked Go, due its simplicity, readability, portability and concurrency primitives.This tutorial assumes that you have gone through the XR Toolbox Series before. If you haven\u2019t checked out the earlier parts to the XR toolbox Series, then you can do so here#  XR Toolbox SeriesPrerequisitesWe will use this Vagrantfile to setup and run the topology as shown below#So you basically need to make sure you download the IOS XRv image as described here# IOS-XR Vagrant Quick Start and install Vagrant and VirtualBox.Then run vagrant up in the folder where you have the Vagrantfile.Request access to the IOS XRv Vagrant box by filling up the form here. This example was run with IOS XR version 6.1.2.Configuring the router for secure gRPC connectionsFirst login to the router (password# vagrant).ssh -p 2223 vagrant@localhostApply the following gRPC and interface config.grpc port 57344 tls ! address-family ipv4!interface GigabitEthernet0/0/0/0 ipv4 address 192.0.2.1 255.255.255.0 no shut !Then copy the content of the certificate file generated in /misc/config/grpc/. We will need this info later on.bash cat /misc/config/grpc/ems.pemInstalling Go on the Ubuntu VMFirst login to the Ubuntu VM.vagrant ssh vm-1Let\u2019s start by installing Go as described in the Go Wiki.sudo add-apt-repository ppa#longsleep/golang-backportssudo apt-get updatesudo apt-get install golang-1.8-go -yNow that we have installed Go, let\u2019s create a workspace directory.mkdir $HOME/gomkdir $HOME/go/srcmkdir $HOME/go/binmkdir $HOME/go/pkgAnd setup some environment variables. You might want to write these to your profile file.export GOROOT=/usr/lib/go-1.8/export GOPATH=$HOME/goexport PATH=$PATH#$GOPATH/bin#$GOROOT/binYou can verify the installation as follows#ubuntu@vm-1#~$ go versiongo version go1.8.3 linux/amd64ubuntu@vm-1#~$ cd $GOPATHubuntu@vm-1#~/go$ lsbin  pkg  srcubuntu@vm-1#~/go$That\u2019s it! Go is installed in the Ubuntu VM.Getting the gRPC library for Cisco IOS XRThis is super easy with the Go tools.go get github.com/nleiva/xrgrpcThat\u2019s it!. All the code and dependencies are now in the VM.Compiling the first exampleIn this example we will use the GetConfig RPC to request the config of the IOS-XRv device for the YANG paths specified in yangpaths.json.{\t    ~Cisco-IOS-XR-ifmgr-cfg#interface-configurations~# [null],    ~Cisco-IOS-XR-telemetry-model-driven-cfg#telemetry-model-driven~# [null],    ~Cisco-IOS-XR-ipv4-bgp-cfg#bgp~# [null],    ~Cisco-IOS-XR-clns-isis-cfg#isis~# [null]}For this purpose we go to the definetarget4 example folder and copy the content of certificate file we obtained previously.cd ~/go/src/github.com/nleiva/xrgrpc/example/definetarget4vim ems.pem Let\u2019s just compile the code (main.go) for now.go buildAnd now you can run the binary file created.ubuntu@vm-1#~/go/src/github.com/nleiva/xrgrpc/example/definetarget4$ ./definetarget4Config from 192.0.2.1#57344 { ~data~# {  ~Cisco-IOS-XR-ifmgr-cfg#interface-configurations~# {   ~interface-configuration~# [    {     ~active~# ~act~,     ~interface-name~# ~MgmtEth0/RP0/CPU0/0~,     ~Cisco-IOS-XR-ipv4-io-cfg#ipv4-network~# {      ~addresses~# {       ~dhcp~# [        null       ]      }     }    },    {     ~active~# ~act~,     ~interface-name~# ~GigabitEthernet0/0/0/0~,     ~Cisco-IOS-XR-ipv4-io-cfg#ipv4-network~# {      ~addresses~# {       ~primary~# {        ~address~# ~192.0.2.1~,        ~netmask~# ~255.255.255.0~       }      }     }    }   ]  } }}2017/08/04 18#51#00 This process took 901.242827msA few pointers on the codeWe will document a complete walk-through in a following tutorial. Well, if you are impatient like me, you can take a look at other examples documented in the repo in the meantime.In this example we basically did four things.1) Parse the YANG path input. If none, the default is ../input/yangpaths.json.  ypath #= flag.String(~ypath~, ~../input/yangpaths.json~, ~YANG path arguments~)  flag.Parse()2) Identify the target. IP address, user credentials, cert file location and a timeout.  router, err #= xr.BuildRouter(      xr.WithUsername(~vagrant~),      xr.WithPassword(~vagrant~),      xr.WithHost(~192.0.2.1#57344~),      xr.WithCreds(~ems.pem~),      xr.WithTimeout(5),  )3) Connect to the device. This has to be done just once for all the following RPC calls. In this example we are just making one, but this connection can be re-used to configure the device, generate a telemetry stream or program the RIB/FIB.  conn, ctx, err #= xr.Connect(*router)  if err != nil {      log.Fatalf(~Could not setup a client connection to %s, %v~, router.Host, err)  }  defer conn.Close()4) Make the GetConfig call and print out the response.  output, err = xr.GetConfig(ctx, conn, string(js), id)  if err != nil {      log.Fatalf(~Could not get the config from %s, %v~, router.Host, err)  }  fmt.Printf(~\\nConfig from %s\\n %s\\n~, router.Host, output)This concludes this tutorial/example. Stay tuned for more!.Some useful links below#  Part 2# Validate the intent of network config changes  gRPC Getting Started  gRPC and GPB for Networking Engineers", "url": "https://xrdocs.github.io/programmability/tutorials/2017-08-04-programming-ios-xr-with-grpc-and-go/", "tags": "vagrant, iosxr, gRPC, Go, VirtualBox, Cisco, YANG", "title": "Programming IOS-XR with gRPC and Go", "author": "Nicolas Leiva"}, "tutorials-2017-08-04-wan-automation-engine-simulation-and-the-simulation-analysis-tool": {"content": "     On This Page  Overview  WAE Simulation          Example# Simulation of an Interface Failure      Example# Simulation of an IGP Metric Change      Example# Simulate Adding a New Customer to the Network        The Simulation Analysis Tool  Conclusion  OverviewThe main objective of WAE is to build an abstracted network model that correlates topology,  traffic and state information. The primary focus of the WAE network model is the multivendor devices that participate in the IGP (OSPF or IS-IS). For example, if you go to a router and do a \u201cshow isis database verbose\u201d or \u201cshow ospf database router\u201d, the nodes and links you see in the output are the nodes and links you will see in the WAE model. In addition, Segment Routing policies, connections to eBGP peers, DWDM topologies and more are also included in the model.The WAE Design application uses the collected model to simulate \u201cwhat if\u201d scenarios, and has tools for various simulation and optimization scenarios. The purpose of this tutorial is to demonstrate the simulation capabilities of WAE Design. The same capabilities of the WAE Design application are also available via APIs. In an upcoming release on WAE, we will take advantage of the WAE APIs for intelligent automation workflows.  Note#      The network model used in this tutorial is from the WAE Design samples directory# us_wan_L1.txt    If you don\u2019t have the WAE Design application, see the tutorial Using dCloud to Access the WAN Automation Engine Demos.    If using dCloud, use the US East datacenter and launch the demo for \u201cWAE Live\u201d. The WAE Design application will be on the workstation desktop.  WAE SimulationWAE Design simulates traffic routed through the network using Demands. A demand represents a potential flow of traffic from source to destination. Demands are routed according the topology and protocols configured in the simulation, and any change in these, such as a network component failure or an IGP or LSP configuration change, will result in an instant update to the demand routings and all properties (such as interface utilizations) in the tables and plot derived from them. The list of all demands is referred to as the traffic matrix for a network.To see more information on how the demand mesh is derived from measured data such as SNMP traffic stats and NetFlow, see the white paper Building Accurate Traffic Matrices with Demand Deduction Simulation is visible in the network plot by selecting the Simulated Traffic view of the Network Plot drop-down in the left side of the visualization toolbar. In the simulated traffic view, the interface utilization is determined by the sum of all demand traffic routed through each interface divided by the associated circuit capacity. The network plot illustrates the utilization of each interface by the color and amount each interface is filled. More in-depth measured information and simulated results are available in the Property Tables.Example# Simulation of an Interface FailureIn WAE Design do the following tasks#  Open us_wan_L1.txt and make sure you have the network plot set to the Simulated Traffic view as shown above.  Right-click on the interface from site SJC to site KCY and select Filter to Demands through selected interface -&gt; All  Note the Demands Property Table now has 5 of the 95 demands selected. Select a Demand from er1.sjc to er1.wdc to see the simulated path of the demand on the network plot.  Right-click on the circuit between site SJC and site KCY and select Fail.  Observe the dashed line which represents the new simulated path the demand would take.  Click an empty area of the plot to de-select the demand and also observe the impact on the overall topology of that circuit failure. Note that this failure caused traffic demands to shift, resulting in congestion between site WDC and site NYC.  When finished right-click an open area of the plot and select Recover.Example# Simulation of an IGP Metric ChangeIn WAE Design do the following tasks#  Open 2 copies of the model us_wan_L1.txt  Make sure you have the network plot set to the Simulated Traffic view as shown above.  On one of the copies, right-click on the interface from site SJC to site KCY and select Properties  Change the metric on the interface on cr1.sjc to cr1.kcy from 74 to 70 and select OK.  Toggle between the plan files to observe the difference before and after.  To run a report of the differences, select Tools -&gt; Reports -&gt; Compare Plans  Run a report to compare the demand routings between the plans and observe the results of the report. Note the various fields such as path metric and simulated latency differences before and after.Example# Simulate Adding a New Customer to the NetworkIn WAE Design do the following tasks#  Open the model us_wan_L1.txt  Make sure you have the network plot set to the Simulated Traffic view as shown above.  Select Insert -&gt; Demands -&gt; Demand  In the Demand Properties menu, set the following fields          Name# New_customer      Source# er1.bos      Destination# er1.mia      Traffic# 700 (mbps)      Select OK.        View the impact of the demand on the topology.  Find the demand in the Demands table, right-click and select Plot Demand.  A brief deep-dive on WAE simulation#  If you browse the WAE Design RPC API documentation on DevNet, you will notice there are two aspects to a simulation.            The route simulation will route the LSPs and demands based on the network state, discovered LSP paths and metrics and simulate the paths if not available. From the route simulation, you can determine the paths of the LSPs and demands through the network.              The traffic simulation will determine the utilizations based on the route simulation.      The Simulation Analysis Tool In the previous section, you simulated the failure of a circuit and observed the impact. You can simulate failures of other objects as well. However, if you want to find out which failure will cause the greatest impact to the topology, rather than simulate each failure one by one you can use the Simulation Analysis.  Select Tools -&gt; Simulation Analysis  Select the objects to examine and click OKThe Simulation Analysis tool will go through each object in the selected properties table, simulate the failure and record the impact. An example of this is shown for circuits in the animated picture below.When the Simulation Analysis tool completes, you will now be able to see the Worst-Case and Failure Impact traffic views. The Worst-Case traffic view essentially says some failure somewhere will cause traffic to shift and this link will reach the utilization level. To see the object that caused this utilization level, right-click on an interface and select \u201cFail to WC\u201d. This will take you to the Simulated Traffic view with the failure applied. In contrast, the Failure Impact view displays the objects according to the impact they will have on the topology if they fail.ConclusionUsing the WAE Design application, you can simulate a variety of \u201cwhat if\u201d scenarios. Some examples include simulating changes in topology, traffic or configured properties such as metrics. Simulation is a fundamental aspect of WAE and the capabilities of the WAE Design application are also available via API, future releases will use the API for automated workflows. Additional simulation and analysis tools are also available via WAE function packs.", "url": "https://xrdocs.github.io/automation/tutorials/2017-08-04-wan-automation-engine-simulation-and-the-simulation-analysis-tool/", "tags": "cisco, WAE, Design, Capacity Planning, Automation", "title": "WAN Automation Engine Simulation and the Simulation Analysis Tool", "author": "Josh Peters"}, "blogs-2017-09-21-ios-xr-ztp-learning-through-packet-captures": {"content": "     On This Page  Introduction  DHCPv4 using BOOTP filename          Packet Captures                  DHCP Discover (Router to DHCP Server)          DHCP Offer (DHCP Server to Router)                      DHCPv4 using Option 67 bootfile-name (IOS-XR Release 6.2.25+)          Packet Captures                  DHCP Discover (Router to DHCP Server)          DHCP Offer (DHCP Server to Router)                      DHCPv6 using Option 59          Packet Captures                  DHCPv6 SOLICIT (Router to DHCPv6 Server)          DHCPv6 Advertise (DHCP Server to Router)                      IntroductionZero Touch Provisioning is quite often considered the cornerstone of web scale deployment practices. It brings forth a mindset that is quite emblematic of the way Large Scale (Web) Service providers provision their environment#  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u201cThe network device should never have to be configured manually through its console - from the instant that it is powered on right up until the services are brought up and telemetry data starts flowing.\u201dThere are dozens of techniques that vendors have brought forward over the years to enable users to push a configuration down to their devices often using on-premise DHCP servers and encoding the communication with the device within DHCP options. Over the years as devices became natively scriptable, a script of the user\u2019s choice may be downloaded to automate provisioning of the entire system (NOS, agents, scripts etc.) on the whole and not just the configuration of the Network OS.IOS-XR is no exception and as Patrick\u2019s excellent tutorial illustrates#  https#//xrdocs.github.io/software-management/tutorials/2016-08-26-working-with-ztp/a lot of headway has been made in enabling IOS-XR to be completely scriptable as soon as it is powered on.To understand the variety of options available to classify the router when it first identifies itself to the DHCP server and to supply the required script, let\u2019s look at packet captures in the following scenarios#  DHCPv4 using BOOTP filename to supply script/config location  DHCPv4 using Option 67 (bootfile-name) to supply script/config location.  DHCPv6 using Option 59 (OPT_BOOTFILE_URL) to supply script/config location.  The packet captures of complete DHCP transactions  along with a sample isc-dhcp server config for each of the above cases has been made available on Github here#  https#//github.com/ios-xr/ztp-pcapDHCPv4 using BOOTP filenameFor this purpose we use the the DHCPv4 server configuration located here.The config is reproduced here for the reader\u2019s convenience#option space cisco-vendor-id-vendor-class code width 1 length width 1;option vendor-class.cisco-vendor-id-vendor-class code 9 = {string};######### Network 11.11.11.0/24 ################shared-network 11-11-11-0 {####### Pools ##############  subnet 11.11.11.0 netmask 255.255.255.0 {    option subnet-mask 255.255.255.0;\toption broadcast-address 11.11.11.255;\toption routers 11.11.11.2;\toption domain-name-servers 11.11.11.2;\toption domain-name ~cisco.local~;\t# DDNS statements  \tddns-domainname ~cisco.local.~;\t# use this domain name to update A RR (forward map)  \tddns-rev-domainname ~in-addr.arpa.~;  \t# use this domain name to update PTR RR (reverse map)    }######## Matching Classes ##########  class ~ncs5508~ {       match if (substring(option dhcp-client-identifier,0,11) = ~FGE194714QS~);  }  pool {      allow members of ~ncs5508~;      range 11.11.11.47 11.11.11.50;      next-server 11.11.11.2;      if exists user-class and option user-class = ~iPXE~ {         filename=~http#//11.11.11.2#9090/ncs5500-mini-x-6.2.25.10I.iso~;      }        if exists user-class and option user-class = ~exr-config~ {       if (substring(option vendor-class.cisco-vendor-id-vendor-class,3,11)=~FGE194714QS~)         {          if (substring(option vendor-class.cisco-vendor-id-vendor-class,19,99)=~NCS-5508~)          {                       filename=~http#//11.11.11.2#9090/scripts/exhaustive_ztp_script.py~;          }        }      }      ddns-hostname ~ncs-5508-local~;      option routers 11.11.11.2;  }}Packet CapturesAll the relevant packet captures for this scenario have been shared on cloudshark# https#//www.cloudshark.org/captures/2b821c09ed7b and are embedded below.  You can also find the corresponding .pcap file in the github repo here# https#//github.com/ios-xr/ztp-pcap/blob/master/6225/pcap/dhcpv4-filename.pcapDHCP Discover (Router to DHCP Server)Play around with the embedded cloudshark decode of the DHCP discover packet below#    Interact above or View on Cloudshark  \u00a0\u00a0The DHCP discover packet sent by the router encodes the following information#      dhcp-client-identifier (option 61)# This encodes the Serial Number of the device as a string.  On the DHCP server this option can be used to identify the device during iPXE as well as during the ZTP phase based solely on the Serial Number of the device identified in the purchase order. This unique identification allows complete automation of the device bringup (image and config/script download without ever logging into the device). In the DHCP server configuration above, this match is identified in red.        vendor-class-identifier (option 60) # This option encodes the following information in this example#    PXEClient#Arch#00009#UNDI#003010#PID#NCS-5508    and is identical in the iPXE and ZTP phases. This can be broken down into#          The type of client# e.g. PXEClient      The architecture of The system (Arch)# e.g.# 00009 Identify an EFI system using a x86-64 CPU      The Universal Network Driver Interface (UNDI)# e.g.# 003010 (first 3 octets identify the major version and last 3 octets identify the minor version)      The Product Identifier (PID)# e.g.# NCS-5508            Vendor-Identifying Vendor Class Option (vivco/option 124)# This option can be used to enforce more granular classification of the network device and the isc-dhcp config that processes this information is marked in lime green (   ) in the dhcp server configuration above. This option was introduced to have parity with the corresponding DHCPv6 option (16) on which option 124 is modeled.   This option encodes the following information#          Vendor Enterprise Number#  The Cisco IANA Enterprise Number is 9. This is the first 4 bytes within the option and is encoded as an integer 32 in the option.      Serial Number# Option 124/vivco defines a data option field that may contain any vendor specific information (RFC 3925). The first 14 characters identifies the Serial Number# (SN# + &lt;11 character Serial Number&gt;).      Platform PID# The remaining data option field encodes the platform name (NCS-5508 in this example).            User Class Information (Option 77)#  This option is used by the client (router) to identify the current stage of operation. There are two provisioning stages #          IPXE#  This is the image download phase and is triggered when the device is brought up without an image or is forced into the iPXE mode in the BIOS. When the network device is performing iPXE, the user-class information encodes the string#  iPXE      ZTP#  This is the stage during which the network device expects to download the configuration/provisioning script that it should apply/execute. During this phase, the user-class information encodes the string# exr-config      Don\u2019t be alarmed by the \u201cmalformed option\u201d indication in the packet capture embedded above for option 77. This is a known issue with wireshark due to the variation in the interpretation of option 77 ( see https#//ask.wireshark.org/questions/35332/dhcp-option-77-malformed-option/55006).DHCP Offer (DHCP Server to Router)The cloudshark decode of the DHCP offer message in response to the request described above is shown below#    Interact above or View on Cloudshark  \u00a0\u00a0While there are multiple options that the Server responds with, there are certain options/fields in particular that the IOS-XR ZTP infrastructure utilizes to determine the location of the script/config to download and the routing required to reach the web server. These are#      BOOTP Filename# While some DHCP servers might consider this obsolete (for e.g. KEA DHCP Server), there are a few legacy DHCP servers capable of setting and returning the BOOTP filename (like ISC-DHCP 4.x). When this is done (as shown by the yellow (&nbsp;&nbsp;) highlight), the filename gets set in the BOOTP flags ( expand the Bootp flags in the DHCP offer capture above). IOS-XR will accept this and download the target file based on it. IOS-XR will parse the BOOTP filename to identify the server IPv4 address and filename separately.        Router (Option 3)# As explained above, IOS-XR uses the filename to parse the server IPv4 address and combines it with the Router IP (option 3) as the gateway to install a static route towards the server IP during the ZTP process.  The remaining two captures in https#//www.cloudshark.org/captures/2b821c09ed7b  identify the DHCP request/reply exchange to wrap up the complete exchange between the router and the DHCP server.DHCPv4 using Option 67 bootfile-name (IOS-XR Release 6.2.25+)Post IOS-XR release version 6.2.25, IOS-XR ZTP also supports explicitly setting the bootfile-name (option 67) in place of the BOOTP filename explained above.For this purpose we use the the DHCPv4 server configuration located here.The config is reproduced here for the reader\u2019s convenience#option space cisco-vendor-id-vendor-class code width 1 length width 1;option vendor-class.cisco-vendor-id-vendor-class code 9 = {string};######### Network 11.11.11.0/24 ################shared-network 11-11-11-0 {####### Pools ##############  subnet 11.11.11.0 netmask 255.255.255.0 {    option subnet-mask 255.255.255.0;\toption broadcast-address 11.11.11.255;\toption routers 11.11.11.2;\toption domain-name-servers 11.11.11.2;\toption domain-name ~cisco.local~;\t# DDNS statements  \tddns-domainname ~cisco.local.~;\t# use this domain name to update A RR (forward map)  \tddns-rev-domainname ~in-addr.arpa.~;  \t# use this domain name to update PTR RR (reverse map)    }######## Matching Classes ##########  class ~ncs5508~ {       match if (substring(option dhcp-client-identifier,0,11) = ~FGE194714QS~);  }  pool {      allow members of ~ncs5508~;      range 11.11.11.47 11.11.11.50;      next-server 11.11.11.2;      if exists user-class and option user-class = ~iPXE~ {         filename=~http#//11.11.11.2#9090/ncs5500-mini-x-6.2.25.10I.iso~;      }        if exists user-class and option user-class = ~exr-config~ {       if (substring(option vendor-class.cisco-vendor-id-vendor-class,3,11)=~FGE194714QS~)         {          if (substring(option vendor-class.cisco-vendor-id-vendor-class,19,99)=~NCS-5508~)          {                       option bootfile-name ~http#//11.11.11.2#9090/scripts/exhaustive_ztp_script.py~;          }        }      }      ddns-hostname ~ncs-5508-local~;      option routers 11.11.11.2;  }}Packet CapturesAll the relevant packet captures for this scenario have been shared on cloudshark# https#//www.cloudshark.org/captures/bba324c2b261 and are embedded below.  You can also find the corresponding .pcap file in the github repo here# https#//github.com/ios-xr/ztp-pcap/blob/master/6225/pcap/dhcpv4-bootfilename.pcapDHCP Discover (Router to DHCP Server)Take a look at embedded cloudshark decode of the DHCP discover packet.    Interact above or View on Cloudshark  \u00a0\u00a0The DHCP discover packet sent by the router encodes the following information#      dhcp-client-identifier (option 61)# This encodes the Serial Number of the device as a string.  On the DHCP server this option can be used to identify the device during iPXE as well as during the ZTP phase based solely on the Serial Number of the device identified in the purchase order. This unique identification allows complete automation of the device bringup (image and config/script download without ever logging into the device). In the DHCP server configuration above, this match is identified in red.        vendor-class-identifier (option 60) # This option encodes the following information in this example#    PXEClient#Arch#00009#UNDI#003010#PID#NCS-5508    and is identical in the iPXE and ZTP phases. This can be broken down into#          The type of client# e.g. PXEClient      The architecture of The system (Arch)# e.g.# 00009 Identify an EFI system using a x86-64 CPU      The Universal Network Driver Interface (UNDI)# e.g.# 003010 (first 3 octets identify the major version and last 3 octets identify the minor version)      The Product Identifier (PID)# e.g.# NCS-5508            Vendor-Identifying Vendor Class Option (vivco/option 124)# This option can be used to enforce more granular classification of the network device and the isc-dhcp config that processes this information is marked in green (   ) in the dhcp server configuration above. This option was introduced to have parity with the corresponding DHCPv6 option (16) on which option 124 is modeled.   This option encodes the following information#          Vendor Enterprise Number#  [The Cisco IANA Enterprise Number is 9. This is the first 4 bytes within the option and is encoded as an integer 32 in the option.      Serial Number# Option 124/vivco defines a data option field that may contain any vendor specific information (RFC 3925). The first 14 characters identifies the Serial Number# (SN# + &lt;11 character Serial Number&gt;).      Platform PID# The remaining data option field encodes the platform name (NCS-5508 in this example).            User Class Information (Option 77)#  This option is used by the client (router) to identify the current stage of operation. There are two provisioning stages #          IPXE#  This is the image download phase and is triggered when the device is brought up without an image or is forced into the iPXE mode in the BIOS. When the network device is performing iPXE, the user-class information encodes the string#  iPXE      ZTP#  This is the stage during which the network device expects to download the configuration/provisioning script that it should apply/execute. During this phase, the user-class information encodes the string# exr-config      Don\u2019t be alarmed by the \u201cmalformed option\u201d indication in the packet capture embedded above for option 77. This is a known issue with wireshark due to the variation in the interpretation of option 77 ( see https#//ask.wireshark.org/questions/35332/dhcp-option-77-malformed-option/55006).DHCP Offer (DHCP Server to Router)The cloudshark decode of the DHCP offer message in response to the request described above is shown below#    Interact above or View on Cloudshark  \u00a0\u00a0While there are multiple options that the Server responds with, there are certain options/fields in particular that the IOS-XR ZTP infrastructure utilizes to determine the location of the script/config to download and the routing required to reach the web server. These are#      Option 67 (bootfile-name)# As part of 6.2.25, we support processing option 67 to glean the location of the script/config to download. When this option is used (as shown by the yellow (&nbsp;&nbsp;) highlight), the filename is NOT set in the BOOTP flags ( expand the Bootp flags in the DHCP offer capture above to see this), instead we see a separate option-67 field.. IOS-XR will accept this and download the target file based on it. It will parse the option-67 bootfile-name to identify the server IPv4 address and filename separately.        Router (Option 3)# As explained above, IOS-XR uses the filename to parse the server IPv4 address and combines it with the Router IP (option 3) as the gateway to install a static route towards the server IP during the ZTP process.  The remaining two captures in https#//www.cloudshark.org/captures/bba324c2b261  identify the DHCP request/reply exchange to wrap up the complete exchange between the router and the DHCP server.DHCPv6 using Option 59Post IOS-XR release version 6.2.25, IOS-XR ZTP also supports explicitly setting the bootfile-name (option 67) in place of the BOOTP filename explained above.For this purpose we use the the DHCPv4 server configuration located here.The config is reproduced here for the reader\u2019s convenience#option dhcp6.user-class code 15 = string;option dhcp6.bootfile-url code 59 = string;option dhcp6.name-servers 2001#420#210d##a;option dhcp6.domain-search ~cisco.com~;option dhcp6.fqdn code 39 = string;option dhcp6.vendor-class code 16 = { integer 32, integer 16, string };ddns-update-style none;# option definitions common to all supported networks...option domain-name ~example.org~;option domain-name-servers ns1.example.org, ns2.example.org;default-lease-time 600;max-lease-time 7200;shared-network 2001-dba-100 {  subnet6 2001#dba#100##/64 {    # Range for clients    range6 2001#dba#100##10 2001#dba#100##30;    # Range for clients requesting a temporary address    range6 2001#dba#100##/64 temporary;    option dhcp6.name-servers 2001#dba#100##1;    option dhcp6.domain-search ~cisco.local~;     if exists dhcp6.user-class and substring(option dhcp6.user-class, 2, 4) = ~iPXE~ {      option dhcp6.bootfile-url = ~http#//[2001#dba#100##1]/ncs5k-mini-4~;    } else if exists dhcp6.user-class and substring(option dhcp6.user-class, 0, 10) = ~exr-config~     {      if substring(option dhcp6.client-id, 1, 5) = 02#00#00#00#09 {         if substring(option dhcp6.client-id, 6, 99) = 46#47#45#31#39#34#37#31#34#51#53#00 {           if substring (option dhcp6.vendor-class, 43, 99) = ~NCS-5508~ {            option dhcp6.bootfile-url = ~http#//[2001#dba#100##1]#9090/scripts/exhaustive_ztp_script.py~;          }        }      }    }  }}Packet CapturesAll the relevant packet captures for this scenario have been shared on cloudshark# https#//www.cloudshark.org/captures/eeedef4dd779 and are embedded below.  You can also find the corresponding .pcap file in the github repo here# https#//github.com/ios-xr/ztp-pcap/blob/master/6225/pcap/dhcpv6.pcapDHCPv6 SOLICIT (Router to DHCPv6 Server)Take a look at embedded cloudshark decode of the DHCPv6 Solicit packet.    Interact above or View on Cloudshark  \u00a0\u00a0The DHCPv6 Solicit packet sent by the router encodes the following information#      Client Identifier (option 1)# In DHCPv6 specification - RFC 3315 expects the client identifier to contain the DUID of the requesting device. The RFC also goes into further details on what the DUID must look like # DUID. Based off this, IOS-XR uses the following structure for the DUID field#          DUID Type# There are 3 DUID types defined in the RFC above, and IOS-XR uses type 2 = \u201cVendor-assigned unique ID based on Enterprise Number\u201d. This is encoded as a two type field in hex# 00#02      Enterprise Number# The Cisco IANA Enterprise Number is 9. This is the first 4 bytes within the option and as part of the hex string#  00#00#00#09This unique identification allows complete automation of the device bringup (image and config/script download without ever logging into the device). In the DHCP server configuration above, this match is identified in red.      Identifier#  This field contains the encoded Serial Number of the device in hex. In the above example, it is# 46#47#45#31#39#34#37#31#34#51#53#00 which translates to FGE194714QS in ascii.        Thus, the resultant field is 00#02#00#00#00#09#46#47#45#31#39#34#37#31#34#51#53#00. The classification against this field is highlighted in red (\u00a0\u00a0) in the DHCPv6 server config above.        vendor-class (option 16) # This option encodes the following information in this example#    Enterprise-Number PXEClient#Arch#00009#UNDI#003010#PID#NCS-5508    and is identical in the iPXE and ZTP phases. This can be broken down into#          Enterprise Number#  The Cisco IANA Enterprise Number is 9. This is the first 4 bytes within the option and is encoded as an integer 32 in the option.      The type of client# e.g. PXEClient      The architecture of The system (Arch)# e.g.# 00009 Identify an EFI system using a x86-64 CPU      The Universal Network Driver Interface (UNDI)# e.g.# 003010 (first 3 octets identify the major version and last 3 octets identify the minor version)      The Product Identifier (PID)# e.g.# NCS-5508. If you see the above dhcpv6 server config, the part highlighted in green (\u00a0\u00a0) is used to extract and classify against the Platform ID (PID).            User Class (Option 15)#  This option is used by the client (router) to identify the current stage of operation. There are two provisioning stages #          IPXE#  This is the image download phase and is triggered when the device is brought up without an image or is forced into the iPXE mode in the BIOS. When the network device is performing iPXE, the user-class information encodes the string#  iPXE      ZTP#  This is the stage during which the network device expects to download the configuration/provisioning script that it should apply/execute. During this phase, the user-class information encodes the string# exr-config      DHCPv6 Advertise (DHCP Server to Router)The cloudshark decode of the DHCP offer message in response to the request described above is shown below#    Interact above or View on Cloudshark  \u00a0\u00a0For DHCPv6, the primary option that the router needs from the Server is#  Boot File URL (Option 59)# This Option encodes the Boot file URL that is sent back to the router in response. IOS-XR will accept this and download the target file based on it. This file may be a script or config and will be executed/applied accordingly.The remaining two captures in https#//www.cloudshark.org/captures/eeedef4dd779  identify the DHCPv6 request/reply exchange to wrap up the complete exchange between the router and the DHCPv6 server.Hopefully, this blog is useful to anyone looking to deploy ZTP with IOS-XR. Do reach out if there are any concerns and we\u2019ll do our best to help out.", "url": "https://xrdocs.github.io/software-management/blogs/2017-09-21-ios-xr-ztp-learning-through-packet-captures/", "tags": "iosxr, cisco, linux, ZTP, DHCPv6, dhcp, dhcpv4, option 124, vivco, pcap, cloudshark, wireshark", "title": "IOS-XR ZTP: Learning through Packet Captures", "author": "Akshat Sharma"}, "tutorials-ncs5500-routing-in-vrf": {"content": "     Understanding NCS5500 Resources  S01E08 NCS5500 Routes in VRF          Previously on \u201cUnderstanding NCS5500 Resources\u201d      Let\u2019s configure it on a eTCAM card      And on a non-eTCAM card      Allocation mode      Conclusion        S01E08 NCS5500 Routes in VRFPreviously on \u201cUnderstanding NCS5500 Resources\u201dIn previous posts\u2026 Well ok, you got it now. You can check all the former articles in the page here. We presented the different platforms, based on Qumran-MX, Jericho and Jericho+. We detailed all the mechanisms used to optimized the routes sorting inside the various memories and we also detailed the impact of features like URPF.Last week, we\u2019ve been asked if it\u2019s possible \u201cto run the Internet Feed inside a VRF/VPN\u201d.It\u2019s indeed a very good question since we used to have some platforms where the scale of routes inside VRF was significantly different than the capability in Global Routing Table.Short answer# yes we support it. But it\u2019s important to set it up correctly to avoid surprises.It has been explain extensively in the former posts, so we suppose you are now familiar with the logic of sorting and storing routes in different memories depending on the product (whether or not we have external TCAM) and on the prefix length.Let\u2019s configure it on a eTCAM cardLet\u2019s configure an interface and advertise 85k routes (IPv4/27). For this example, we will use a Jericho line cards with eTCAM (NC55-24X100G-SE) running IOS XR 6.3.2.Note# L3VPN was available in some specific images but is officially supported only in 6.3.2. Before this release, it was possible to configure VRF-lite. What will be described below applies for both.vrf TESTaddress-family ipv4 unicast!!interface HundredGigE0/7/0/2cdpvrf TESTipv4 address 192.168.21.1 255.255.255.0!router bgp 100vrf TEST  rd 113579#13579  address-family ipv4 unicast  !  neighbor 192.168.21.2   remote-as 100   update-source HundredGigE0/7/0/2   address-family ipv4 unicast    route-policy ROUTE-FILTER in    maximum-prefix 8000000 75    route-policy PERMIT-ANY out   !  !!!And the BGP routes received from my neighbor#RP/0/RP0/CPU0#5508-1-6.3.2#sh bgp vrf TEST summaryBGP VRF TEST, state# ActiveBGP Route Distinguisher# 113579#13579VRF ID# 0x60000003BGP router identifier 1.1.1.1, local AS number 100Non-stop routing is enabledBGP table state# ActiveTable ID# 0xe0000003   RD version# 85622BGP main routing table version 85622BGP NSR Initial initsync version 1 (Reached)BGP NSR/ISSU Sync-Group versions 85622/0BGP is operating in STANDALONE mode.Process       RcvTblVer   bRIB/RIB   LabelVer  ImportVer  SendTblVer  StandbyVerSpeaker           85622      85622      85622      85622       85622       85622Neighbor        Spk    AS MsgRcvd MsgSent   TblVer  InQ OutQ  Up/Down  St/PfxRcd192.168.21.2      0   100  355498      44    85622    0    0 00#39#18      85614RP/0/RP0/CPU0#5508-1-6.3.2#These routes being IPv4/27, they will be stored in external TCAM.Let\u2019s examine the memory resources#RP/0/RP0/CPU0#5508-1-6.3.2#sh contr npu resources all loc 0/7/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP --Current Usage    NPU-0        Total In-Use                # 85645    (11 %)        iproute                     # 40       (0 %)        ip6route                    # 0        (0 %)        mplslabel                   # 85614    (11 %)-- SNIP --HW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 251311        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP --Current Usage    NPU-0        Total In-Use                # 52       (0 %)        iproute                     # 0        (0 %)        ip6route                    # 38       (0 %)        ipmcroute                   # 1        (0 %)-- SNIP --HW Resource Information    Name                            # encapOOR Information    NPU-0        Estimated Max Entries       # 80000        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP --Current Usage    NPU-0        Total In-Use                # 4        (0 %)        ipnh                        # 2        (0 %)        ip6nh                       # 2        (0 %)        mplsnh                      # 0        (0 %)-- SNIP --HW Resource Information    Name                            # ext_tcam_ipv4OOR Information    NPU-0        Estimated Max Entries       # 2048000        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP --Current Usage    NPU-0        Total In-Use                # 85623    (4 %)        iproute                     # 85635    (4 %)-- SNIP --HW Resource Information    Name                            # fecOOR Information    NPU-0        Estimated Max Entries       # 126976        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP --Current Usage    NPU-0        Total In-Use                # 65       (0 %)        ipnhgroup                   # 55       (0 %)        ip6nhgroup                  # 10       (0 %)-- SNIP --HW Resource Information    Name                            # ecmp_fecOOR Information    NPU-0        Estimated Max Entries       # 4096        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP --Current Usage    NPU-0        Total In-Use                # 0        (0 %)        ipnhgroup                   # 0        (0 %)        ip6nhgroup                  # 0        (0 %) -- SNIP --As expected we found 85635 iproute in the externaltcamv4, but also we notice the presence of 85614 mplslabel entries in the LEM memory. So for each prefix learnt in the VRF TEST, we associate by default a label and it consumes one entry in the LEM even if it\u2019s not a IPv4/32.This is indeed the default behavior# per-prefix label allocation\u2026If your design permits it (and it should be the case in 99% of the times), we advise you modify the label allocation mode to \u201cper-vrf\u201d.Addendum#Several comments received on this aspect. Let\u2019s create a dedicated section on the allocation mode.RP/0/RP0/CPU0#5508-1-6.3.2#confRP/0/RP0/CPU0#5508-1-6.3.2(config)#RP/0/RP0/CPU0#5508-1-6.3.2(config)#router bgp 100RP/0/RP0/CPU0#5508-1-6.3.2(config-bgp)# vrf TESTRP/0/RP0/CPU0#5508-1-6.3.2(config-bgp-vrf)# address-family ipv4 unicastRP/0/RP0/CPU0#5508-1-6.3.2(config-bgp-vrf-af)#  label mode per-vrfRP/0/RP0/CPU0#5508-1-6.3.2(config-bgp-vrf-af)#commitRP/0/RP0/CPU0#5508-1-6.3.2(config-bgp-vrf-af)#endRP/0/RP0/CPU0#5508-1-6.3.2#Let\u2019s now check the impact on LEM#RP/0/RP0/CPU0#5508-1-6.3.2#sh contr npu resources all loc 0/7/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP --Current Usage    NPU-0        Total In-Use                # 46       (0 %)        iproute                     # 40       (0 %)        ip6route                    # 0        (0 %)        mplslabel                   # 1        (0 %)-- SNIP --HW Resource Information    Name                            # ext_tcam_ipv4OOR Information    NPU-0        Estimated Max Entries       # 2048000        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP --Current Usage    NPU-0        Total In-Use                # 85623    (4 %)        iproute                     # 85635    (4 %)-- SNIP --       It changes everthing now that we allocate only one entry for the MPLS label. For instance, it permits to push easily a full internet view and much more (for instance 435k extra host routes).RP/0/RP0/CPU0#5508-1-6.3.2#sh bgp vrf TEST summaryBGP VRF TEST, state# ActiveBGP Route Distinguisher# 113579#13579VRF ID# 0x60000003BGP router identifier 1.1.1.1, local AS number 100Non-stop routing is enabledBGP table state# ActiveTable ID# 0xe0000003   RD version# 1877292BGP main routing table version 1877292BGP NSR Initial initsync version 1 (Reached)BGP NSR/ISSU Sync-Group versions 1877292/0BGP is operating in STANDALONE mode.Process       RcvTblVer   bRIB/RIB   LabelVer  ImportVer  SendTblVer  StandbyVerSpeaker         1877292    1877292    1877292    1877292     1877292     1877292Neighbor        Spk    AS MsgRcvd MsgSent   TblVer  InQ OutQ  Up/Down  St/PfxRcd192.168.21.2      0   100 1261510     148  1877292    0    0 02#18#40    1186410RP/0/RP0/CPU0#5508-1-6.3.2#sh route vrf TEST sumRoute Source                     Routes     Backup     Deleted     Memory(bytes)local                            1          0          0           240connected                        1          0          0           240dagr                             0          0          0           0bgp 100                          1186410    0          0           284738400static                           1          0          0           240Total                            1186413    0          0           284739120RP/0/RP0/CPU0#5508-1-6.3.2#sh contr npu resources all loc 0/7/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP --Current Usage    NPU-0        Total In-Use                # 434784   (55 %)        iproute                     # 434793   (55 %)        ip6route                    # 0        (0 %)        mplslabel                   # 1        (0 %)-- SNIP --HW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 251311        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP --Current Usage    NPU-0        Total In-Use                # 52       (0 %)        iproute                     # 0        (0 %)        ip6route                    # 38       (0 %)        ipmcroute                   # 1        (0 %)-- SNIP --HW Resource Information    Name                            # encapOOR Information    NPU-0        Estimated Max Entries       # 80000        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP --Current Usage    NPU-0        Total In-Use                # 4        (0 %)        ipnh                        # 2        (0 %)        ip6nh                       # 2        (0 %)        mplsnh                      # 0        (0 %)-- SNIP --HW Resource Information    Name                            # ext_tcam_ipv4OOR Information    NPU-0        Estimated Max Entries       # 2048000        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP --Current Usage    NPU-0        Total In-Use                # 751665   (37 %)        iproute                     # 751677   (37 %)-- SNIP --And on a non-eTCAM cardAlso we can check how a non-eTCAM line cards (NC55-36X100G) can do with the full view (we just filter the IPv4/32 from the same BGP peer)#RP/0/RP0/CPU0#5508-1-6.3.2#sh run route-policy ROUTE-FILTERroute-policy ROUTE-FILTER  if destination in (0.0.0.0/0 le 31) then    pass  else    drop  endifend-policyRP/0/RP0/CPU0#5508-1-6.3.2#RP/0/RP0/CPU0#5508-1-6.3.2#sh route vrf TEST summaryRoute Source                     Routes     Backup     Deleted     Memory(bytes)local                            1          0          0           240connected                        1          0          0           240dagr                             0          0          0           0bgp 100                          751657     0          0           180397680static                           1          0          0           240Total                            751660     0          0           180398400RP/0/RP0/CPU0#5508-1-6.3.2#RP/0/RP0/CPU0#5508-1-6.3.2#sh dpa resources iproute loc 0/2/CPU0~iproute~ DPA Table (Id# 24, Scope# Global)--------------------------------------------------IPv4 Prefix len distributionPrefix   Actual       Prefix   Actual /0       4            /1       0 /2       0            /3       0 /4       4            /5       0 /6       0            /7       0 /8       15           /9       13 /10      35           /11      106 /12      285          /13      550 /14      1066         /15      1880 /16      13419        /17      7773 /18      13636        /19      25026 /20      38261        /21      43073 /22      80751        /23      67073 /24      376990       /25      567 /26      2032         /27      4863 /28      15599        /29      16868 /30      41736        /31      52 /32      39                          NPU ID# NPU-0           NPU-1           NPU-2           NPU-3           NPU-4           NPU-5                          In Use# 751716          751716          751716          751716          751716          751716                          RP/0/RP0/CPU0#5508-1-6.3.2#sh contr npu resources all loc 0/2/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green        OOR State Change Time       # 2018.Apr.02 10#32#37 PDT        -- SNIP --Current Usage    NPU-0        Total In-Use                # 377026   (48 %)        iproute                     # 349729   (44 %)        ip6route                    # 0        (0 %)        mplslabel                   # 1        (0 %)        -- SNIP --HW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 418492        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Yellow        OOR State Change Time       # 2018.Apr.02 09#39#01 PDT        -- SNIP --Current Usage    NPU-0        Total In-Use                # 374731   (90 %)        iproute                     # 374687   (90 %)        ip6route                    # 38       (0 %)        ipmcroute                   # 1        (0 %)        -- SNIP --We notice inconsistencies in the LEM numbers between Total-in-use and the total below. It\u2019s a cosmetic issue that will be handled in the next release.So, we can verify with this output that we are not consuming entries with mplslabel in LEM for each prefix.Allocation modeWe received several comments just after posting this article, related to the allocation mode used here. Let\u2019s try to summarize the key points.TL;DR# per-ce mode being by default the resilient one in this XR implementation, it\u2019s the best bet if you don\u2019t know which one to select instead of the per-prefix.Several use-cases involving \u201cmaximum-path eiBGP\u201d can be broken by per-vrf allocation and he recommends to use per-CE when possible. To compare the different options#  per-prefix (default)  Good label diversity for core loadbalancing,  able to get MPLS statistics (note# this last comment is not applicable for NCS5500 since we don\u2019t have statistics in the \u201cshow mpls forwarding\u201d, it\u2019s more appropriate for CRS, ASR9k, \u2026)  Can cause scale issues  per-CE (resilient)  Single label allocated by CE, whatever number of prefixes, improved scale  EIBGP multipath, PIC is supported, single Label lookup  per-VRF  Single label allocated for the whole VRF, thus additional lookup required to forward traffic  Potential forwarding loop during local traffic diversion to support PIC  No support for EIBGP multipathA lot of litterature is available for free on places like CiscoLive (London 2013 BRKIPM-2265) (pdf file).Let\u2019s verify that per-ce allocation is not changing anything in the resource usage#RP/0/RP0/CPU0#5508-1-6.3.2#confRP/0/RP0/CPU0#5508-1-6.3.2(config)#router bgp 100RP/0/RP0/CPU0#5508-1-6.3.2(config-bgp)#vrf TESTRP/0/RP0/CPU0#5508-1-6.3.2(config-bgp-vrf)#address-family ipv4 unicastRP/0/RP0/CPU0#5508-1-6.3.2(config-bgp-vrf-af)#   label mode per-?per-ce  per-prefix  per-vrfRP/0/RP0/CPU0#5508-1-6.3.2(config-bgp-vrf-af)#   label mode per-ceRP/0/RP0/CPU0#5508-1-6.3.2(config-bgp-vrf-af)#commitRP/0/RP0/CPU0#5508-1-6.3.2(config-bgp-vrf-af)#endRP/0/RP0/CPU0#5508-1-6.3.2#RP/0/RP0/CPU0#5508-1-6.3.2#sh contr npu resources lem loc 0/2/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green        OOR State Change Time       # 2018.Apr.02 10#32#37 PDT-- SNIP --Current Usage    NPU-0        Total In-Use                # 377026   (48 %)        iproute                     # 349730   (44 %)        ip6route                    # 0        (0 %)        mplslabel                   # 2        (0 %)        -- SNIP --        RP/0/RP0/CPU0#5508-1-6.3.2#sh contr npu resources lem loc 0/7/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green        -- SNIP --Current Usage    NPU-0        Total In-Use                # 42       (0 %)        iproute                     # 40       (0 %)        ip6route                    # 0        (0 %)        mplslabel                   # 2        (0 %)ConclusionIt\u2019s possible to learn a large number of routes in VRF but it\u2019s important to change the default label allocation mode to per-vrf or per-ce, otherwise we will create one label entry for each prefix learnt.Thanks to Lukas Mergenthaler, Fred Cuiller and Phil Bedard for their suggestions and comments.", "url": "https://xrdocs.github.io/cloud-scale-networking/tutorials/ncs5500-routing-in-vrf/", "tags": "iosxr, ncs5500, xr, internet, vrf", "title": "NCS5500 Routing in VRF", "author": "Nicolas Fevrier"}, "blogs-2016-07-12-building-an-ios-xrv-vagrant-virtualbox": {"content": "A new way to try out IOS-XR..An \u2018IOS XRv (64-bit)\u2019 image will be available for users from IOS XR 6.1.1 onwards. This is the successor to the previous IOS XRv (32-bit) QNX based virtual platform. It is based on the latest IOS XR OS which is built on 64-bit Wind River Linux, and has amongst many other changes, a separate Adminplane and complete access to the underlying linux environment.You will likely see newer and better variants of this image as we continue to work on tools for developers.Our primary focus will continue to be on consistent tooling and workflows such as Vagrant boxes, build tools and open-source sample applications to get developers and users started quickly and easily.We hope that these tools help enable developers consume and learn IOS-XR, build applications for it and participate in our community on Github.  Check us out on Github#  Sample Applications and Build tools # https#//github.com/ios-xr Open Source Documentation#  https#//github.com/xrdocs  hosted here# https#//xrdocs.github.ioCan\u2019t wait to get the ISO? Jump here# Getting your hands on the ISOLinux and XR 6.0.0+      This version of IOS XR has an infrastructure that allows people to develop and run their own applications in Linux containers on the router itself.        Network and System Automation can be accomplished using shell scripts, puppet,chef, Ansible etc.        Customers can tap into telemetry that provides improved visibility into a network at a far granular level and through a much more scalable approach than SNMP.        XR configuration itself can be automated using Model Driven APIs with native, common and OpenConfig  YANG models supported.  IOS XRv (64-bit)Naming and release      The image itself is named# name-features-architecture.format, e.g# iosxrv-fullk9-x64.iso        Producing a box and releasing it through devhub.cisco.com allows us to get code to the developer far quicker than the standard process.        This platform is provided free but as free software has no support - please read the licenses very carefully.  Vagrant VirtualBoxCisco is providing customers with a Vagrant VirtualBox offering. Vagrant is a superb tool for application development. Amongst others you can use this box to#      Test native and container applications on IOS-XR        Use configuration management tools like Chef/Puppet/Ansible/Shell as Vagrant provisioners        Create complicated topologies and a variety of other use cases  This box is designed to come up fully operational with an embedded Vagrantfile that does all of the work to provide a user and tools access to the box. With a simple \u2018vagrant add\u2019 and \u2018vagrant up\u2019 you will have a IOS XR virtual router to play with. \u2018vagrant ssh\u2019 drops the user directly into the XR Linux namespace as user \u2018vagrant\u2019. Using vagrant port, you can see which port (usually 2222 with a single node) to ssh to get access to the IOS XR Console/CLI.The user can design their own Vagrantfiles to do more complex bringups including multiple nodes, and bootstrap configuration. There are examples below.How to get hold of the box, bring it up etc# https#//xrdocs.github.io/application-hosting/tutorials/iosxr-vagrant-quickstartYou will need an active Cisco CCO id.For tutorials on some of the cool things you can do with this box see# https#//xrdocs.github.io/application-hosting/tutorials/Cisco has open-sourced the toolingFinally as was the purpose of this blog, we have open-sourced the code to build the Vagrant VirtualBox from an IOS XR ISO.https#//github.com/ios-xr/iosxrv-x64-vboxGetting your hands on the ISO  To download the ISO, you will need an API-KEY and a CCO-ID  To get the API-KEY and a CCO-ID, browse to the following link and follow the steps#  Steps to Generate API-KEYOnce done, download the ISO as shown#$ ISOURL=~https#//devhub.cisco.com/artifactory/XRv64-snapshot/latest/iosxrv-fullk9-x64.latest.iso~$ curl -u your-cco-id#API-KEY $ISOURL --output ~/iosxrv-fullk9-x64.isoI hope you enjoyed this quick blog. The links above provide far more information. As one of the technical leads behind the new platform, and author of the vagrant tooling I\u2019m very motivated to make this a great platform for Cisco customers. Please contact me at rwellum@cisco.com for any questions or concerns.", "url": "https://xrdocs.github.io/application-hosting/blogs/2016-07-12-building-an-ios-xrv-vagrant-virtualbox/", "tags": "vagrant, iosxr, cisco, linux", "title": "Building  your own IOS XRv Vagrant box", "author": "Richard Wellum"}, "tutorials-2016-08-08-configuring-model-driven-telemetry-with-ydk": {"content": "     Configuring MDT with YDK  YDK# Automating YANG without XML  Connect to the router  Define the sensor group  Apply the SensorGroup object to the router  Instantiate a Subscription object and apply it  What did all that code do?  Clean up, clean up, everybody clean up!  Conclusion  YDK# Automating YANG without XMLIn an earlier tutorial, I wrote about how to configure MDT using the OpenConfig Telemetry YANG model with ncclient and a lot of XML.  An even simpler way to do this is to use YDK, a developer toolkit that automatically generates APIs directly from YANG models.  The Python classes that are generated by YDK mirror the YANG model hierarchy. So if you know some Python and you understand the YANG model, you can start writing code, no knowledge of NETCONF or XML required.In this blog, I\u2019ll explain how to configure telemetry for gRPC dialin using YDK and the OpenConfig Telemetry YANG model.Connect to the routerYDK leverages ncclient to handle the NETCONF connection, so this bit of code might look similar to what you\u2019ve done before, using the YDK provider library instead of ncclient#from ydk.providers import NetconfServiceProviderfrom ydk.services import CRUDServiceHOST = '10.30.111.9'PORT = 830USER = 'cisco'PASS = 'cisco'xr = NetconfServiceProvider(address=HOST,\tport=PORT,\tusername=USER,\tpassword=PASS,\tprotocol = 'ssh')With that, we are now connected to the router#CLI Output#RP/0/RP0/CPU0#SunC#show netconf-yang clientsMon Aug  8 23#01#48.210 UTCNetconf clientsclient session ID|     NC version|    client connect time|        last OP time|        last OP type|    &lt;lock&gt;|       1386485520|            1.1|         0d  0h  0m  5s|                    |                    |        No|RP/0/RP0/CPU0#SunC#Define the sensor groupNow that our script is connected to the router, we\u2019ll start by defining the sensor-group.  Here\u2019s the first bit of YDK for that#import ydk.models.openconfig.openconfig_telemetry as oc_telemetrysgroup = oc_telemetry.TelemetrySystem.SensorGroups.SensorGroup()sgroup.sensor_group_id=~SGroup4~sgroup.config.sensor_group_id=~SGroup4~So how did I come up with that?  Look back at the first part of the OC Telemetry YANG model#PYANG Output#module# openconfig-telemetry   +--rw telemetry-system      +--rw sensor-groups      |  +--rw sensor-group* [sensor-group-id]      |     +--rw sensor-group-id    -&gt; ../config/sensor-group-id      |     +--rw config      |     |  +--rw sensor-group-id?   stringStart from the top and walk down from telemetry-system to sensor-groups to sensor-group.  Replace the dashes and lowercase syntax with CamelCase syntax and you get the class that instantiates that first object# TelemetrySystem.SensorGroups.SensorGroup().  Down to the next level, we have the leaf \u201csensor-group-id.\u201d  YDK converts this to an object attribute by replacing the hyphens with underscores.  The sensor-group-id list key is actually a leaf-ref to config/sensor-group-id, both of which are required (hence the two lines that seem redundant but are actually required for syntactic validation because of the structure of the YANG model).Going down a little farther in the YANG model with some help from some pyang options, we see that the sensor-group contains a list of sensor-paths.PYANG Output#$ pyang -f tree openconfig-telemetry.yang --tree-path=telemetry-system/sensor-groups/sensor-group/sensor-paths/sensor-path/configmodule# openconfig-telemetry   +--rw telemetry-system      +--rw sensor-groups         +--rw sensor-group* [sensor-group-id]            +--rw sensor-paths               +--rw sensor-path* [path]                  +--rw config                     +--rw path?             string$This is how that maps to YDK code#sgroup.sensor_paths = sgroup.SensorPaths()new_sensorpath = sgroup.SensorPaths.SensorPath()new_sensorpath.path = 'Cisco-IOS-XR-infra-statsd-oper#infra-statistics%2finterfaces%2finterface%2flatest%2fgeneric-counters'new_sensorpath.config.path = 'Cisco-IOS-XR-infra-statsd-oper#infra-statistics%2finterfaces%2finterface%2flatest%2fgeneric-counters'sgroup.sensor_paths.sensor_path.append(new_sensorpath)So again, following the YANG model, we define the top-level SensorPaths object, then a SensorPath with an object attribute \u201cpath\u201d that actually specifies the YANG model that we want to stream (in this case, our old friend, interface statistics).Note that the \u201c%2f\u201d in the path attributes represent URL encodings of the forward slash character (\u201c/\u201d).  The code would look a little better if you used a utility such as urllib to do the string substitution for you, so you can use the more natural looking path with \u201c/\u201d characters like this#import urllibsgroup.sensor_paths = sgroup.SensorPaths()new_sensorpath = sgroup.SensorPaths.SensorPath()interface_stats_path = urllib.quote('Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters', safe='#')new_sensorpath.path = interface_stats_pathnew_sensorpath.config.path = interface_stats_pathsgroup.sensor_paths.sensor_path.append(new_sensorpath)Apply the SensorGroup object to the routerOnce you\u2019ve populated the object, it\u2019s trivial to apply it to the router using the create method on the CRUDService object from YDK#from ydk.services import CRUDServicerpc_service = CRUDService()rpc_service.create(xr, sgroup)Instantiate a Subscription object and apply itThe Subscription is the final piece of the config.  Again, refer to the YANG model to understand the Python class that you should use.  I\u2019ll use pyang with the tree-path option to make it clearer#PYANG Output#$pyang -f tree --tree-path telemetry-system/subscriptions/persistent/subscription/sensor-profiles/sensor-profile openconfig-telemetry.yangmodule# openconfig-telemetry   +--rw telemetry-system      +--rw subscriptions         +--rw persistent            +--rw subscription* [subscription-id]               +--rw sensor-profiles                  +--rw sensor-profile* [sensor-group]                     +--rw sensor-group    -&gt; ../config/sensor-group                     +--rw config                     |  +--rw sensor-group?         -&gt; /telemetry-system/sensor-groups/sensor-group/config/sensor-group-id                     |  +--rw sample-interval?      uint64                     |  +--rw heartbeat-interval?   uint64                     |  +--rw suppress-redundant?   boolean                     +--ro state                        +--ro sensor-group?         -&gt; /telemetry-system/sensor-groups/sensor-group/config/sensor-group-id                        +--ro sample-interval?      uint64                        +--ro heartbeat-interval?   uint64                        +--ro suppress-redundant?   booleanThis is how that ends up in YDK code#sub = oc_telemetry.TelemetrySystem.Subscriptions.Persistent.Subscription()sub.subscription_id = 4sub.config.subscription_id = 4sub.sensor_profiles = sub.SensorProfiles()new_sgroup = sub.SensorProfiles.SensorProfile()new_sgroup.sensor_group = 'SGroup4'new_sgroup.config.sensor_group = 'SGroup4'new_sgroup.config.sample_interval = 30000sub.sensor_profiles.sensor_profile.append(new_sgroup)rpc_service.create(xr, sub)What did all that code do?So this is how all that shows up in CLI#CLI Output#RP/0/RP0/CPU0#SunC#show run telemetry model-drivenTue Aug  9 17#52#38.462 UTCtelemetry model-driven sensor-group SGroup4  sensor-path Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters ! subscription 4  sensor-group-id SGroup4 sample-interval 30000 !!RP/0/RP0/CPU0#SunC#And that is all you need for Model-Driven Telemetry using gRPC dialin.Clean up, clean up, everybody clean up!Need to delete the telemetry config completely?  Here\u2019s how#rpc_service.delete(xr, oc_telemetry.TelemetrySystem())ConclusionIn this tutorial, we looked at a couple dozen lines of YDK code that added and then removed five lines of CLI.  So you might be thinking \u201cand that helps me be more efficient\u2026how?\u201d  But the power of automation in general and YDK in particular can\u2019t be fully revealed in a single, simple example like this.  The real power of YDK is that it allows you to do this for any YANG model on the box, automatically generating Python classes that inherit the syntactic checks and requirements of the underlying model, while also handling all the details of the underlying encoding and transport (no understanding of XML or NETCONF chunk framing required!).  Give a try and see what you think!", "url": "https://xrdocs.github.io/telemetry/tutorials/2016-08-08-configuring-model-driven-telemetry-with-ydk/", "tags": "cisco, YDK, telemetry, MDT, OpenConfig, YANG", "title": "Configuring Model-Driven Telemetry (MDT) with YDK", "author": "Shelly Cadora"}, "tutorials-2016-08-22-using-puppet-with-iosxr-6-1-1": {"content": "     IOS-XR# Puppet  Introduction  Prerequisites  The ciscoyang Puppet Module          Description        Setup          Pre-setup      Puppet Master      Puppet Agent / IOS-XRv        Usage          Puppet Manifest      The cisco_yang Puppet Type      The cisco_yang_netconf Puppet Type        Apply Sample Puppet Manifest  IntroductionThe goal of this tutorial is to set up Puppet Master and Puppet Agent on an Ubuntu and IOS-XRv vagrant instances respectively. This setup was tested on OSX, but the workflow is the same for other environments.Prerequisites  Vagrant 1.8.4 for your Operating System.  Virtualbox 5.0.x for your Operating System.  A computer with atleast 8G free memory.  Vagrantfile and scripts for provisioningVagrant 1.8.5 sets the permissions on ~vagrant/.ssh/authorized_keys to 0644 (world-readable) when replacing the insecure public key with a newly generated one. Since sshd will only accept keys readable just by their owner, vagrant up returns an error, since it cannot connect with the new key and it already removed the insecure key. This is Vagrant bug #7610, which affects CentOS Puppet-Master. You can either downgrade to Vagrant 1.8.4 or add config.ssh.username = ~vagrant~ and config.ssh.password = ~vagrant~ lines to Vagrantfile. More information here.The ciscoyang Puppet ModuleThe ciscoyang module allows configuration of IOS-XR through Cisco supported YANG data models in JSON/XML format. This module bundles the cisco_yang and cisco_yang_netconf Puppet types, providers, Beaker tests, and sample manifests to enable users to configure and manage IOS-XR.This GitHub repository contains the latest version of the ciscoyang module source code. Supported versions of the ciscoyang module are available at Puppet Forge.DescriptionThis module enables management of supported Cisco Network Elements through the cisco_yang and cisco_yang_netconf Puppet types and providers.A typical role-based architecture scenario might involve a network administrator who uses a version control system to manage various YANG-based configuration files. An IT administrator who is responsible for the puppet infrastructure can simply reference the YANG files from a puppet manifest in order to deploy the configurationSetupPre-setupClone the vagrant-xrdocs repository with puppet tutorial#$ cd ~$ git clone https#//github.com/ios-xr/vagrant-xrdocs.git$ cd ~/vagrant-xrdocs/puppet-tutorials/app_hosting/centos-pm/$ lsVagrantfile  iosxrv.sh  scripts  xr_config  configs  puppetmaster.shTo add an IOS-XR box, you need to download it.  IOS-XR Vagrant is currently in Private Beta  To download the box, you will need an API-KEY and a CCO-ID  To get the API-KEY and a CCO-ID, browse to the following link and follow the steps#  Steps to Generate API-KEY$ BOXURL=~http#//devhub.cisco.com/artifactory/appdevci-release/XRv64/latest/iosxrv-fullk9-x64.box~$ curl -u CCO-ID#API-KEY $BOXURL --output ~/iosxrv-fullk9-x64.box$ vagrant box add --name IOS-XRv ~/iosxrv-fullk9-x64.boxOf course, you should replace  CCO-ID with your cisco.com ID and API-KEY with the key you generated and copied using the above link.We should now have IOS-XR box available, Use the vagrant box list command to display the current set of boxes on your system as shown below#$ vagrant box listIOS-XRv         (virtualbox, 0)The Vagrantfile contains 2 Vagrant boxes; PuppetMaster and IOS-XRv.If you go to app_hosting directory, you will find that we have two different setups of puppetmaster.$ cd ~/iosxr/vagrant-xrdocs/puppet-tutorials/app_hosting/$ lscentos-pm       ubuntu-pmcentos-pm and ubuntu-pm has puppetserver installed on CentOS and Ubuntu respectivley. CentOS workflow installs beaker package to run beaker test. So consider centos-pm for development purpose.Boot up the IOS-XR and Puppet-Master boxes#$ cd ~/vagrant-xrdocs/puppet-tutorials/app_hosting/centos-pm/$ lsVagrantfile  iosxrv.sh  scripts  xr_config  configs  puppetmaster.sh$ vagrant upBringing machine 'puppetmaster' up with 'virtualbox' provider...Bringing machine 'iosxrv' up with 'virtualbox' provider...This will take some time. If guest OS logs a message to stderr then you might see few red lines. Ignore them.Look for \u201cvagrant up\u201d welcome message to confirm the machine has booted#==&gt; iosxrv# Machine 'iosxrv' has a post `vagrant up` message. This is a message==&gt; iosxrv# from the creator of the Vagrantfile, and not from Vagrant itself#==&gt; iosxrv#==&gt; iosxrv#==&gt; iosxrv#     Welcome to the IOS XRv (64-bit) VirtualBox.==&gt; iosxrv#     To connect to the XR Linux shell, use# 'vagrant ssh'.==&gt; iosxrv#     To ssh to the XR Console, use# 'vagrant port' (vagrant version &gt; 1.8)==&gt; iosxrv#     to determine the port that maps to guestport 22,==&gt; iosxrv#     then# 'ssh vagrant@localhost -p &lt;forwarded port&gt;'==&gt; iosxrv#==&gt; iosxrv#     IMPORTANT#  READ CAREFULLY==&gt; iosxrv#     The Software is subject to and governed by the terms and conditions==&gt; iosxrv#     of the End User License Agreement and the Supplemental End User==&gt; iosxrv#     License Agreement accompanying the product, made available at the==&gt; iosxrv#     time of your order, or posted on the Cisco website at==&gt; iosxrv#     www.cisco.com/go/terms (collectively, the 'Agreement').==&gt; iosxrv#     As set forth more fully in the Agreement, use of the Software is==&gt; iosxrv#     strictly limited to internal use in a non-production environment==&gt; iosxrv#     solely for demonstration and evaluation purposes. Downloading,==&gt; iosxrv#     installing, or using the Software constitutes acceptance of the==&gt; iosxrv#     Agreement, and you are binding yourself and the business entity==&gt; iosxrv#     that you represent to the Agreement. If you do not agree to all==&gt; iosxrv#     of the terms of the Agreement, then Cisco is unwilling to license==&gt; iosxrv#     the Software to you and (a) you may not download, install or use the==&gt; iosxrv#     Software, and (b) you may return the Software as more fully set forth==&gt; iosxrv#     in the Agreement.Puppet MasterTo access the Puppet Master box just issue the vagrant ssh command (no password required)#$ vagrant ssh puppetmasterThe Puppet Master instance is already configured via file \u201cpuppetmaster.sh\u201d. This section is only for the user\u2019s information.  Let\u2019s review the \u201cpuppetmaster.sh\u201d script.The first line adds Puppet Master and IOS-XRv host information in /etc/hosts file.  yes | sudo cp /home/ubuntu/hosts /etc/hosts &gt; /dev/null 2&gt;&amp;1    Next, downloads required packages for Puppet Master and updates the system.  wget -q https#//apt.puppetlabs.com/puppetlabs-release-pc1-xenial.debsudo dpkg -i puppetlabs-release-pc1-xenial.deb &gt; /dev/null 2&gt;&amp;1sudo apt update -qq &gt; /dev/null 2&gt;&amp;1sudo apt-get install puppetserver -qq &gt; /dev/null    Next, script clones the Puppet-Yang github repository and installs ciscoyang puppet module#  git clone https#//github.com/cisco/cisco-yang-puppet-module.git -qcd cisco-yang-puppet-module/opt/puppetlabs/puppet/bin/puppet module build &gt; /dev/nullsudo /opt/puppetlabs/puppet/bin/puppet module install pkg/*.tar.gz    The last section creates a puppet configuration file and ensures that puppetserver service is running on the Puppet Master  yes | sudo cp /home/ubuntu/puppet.conf /etc/puppetlabs/puppet/puppet.confsudo /opt/puppetlabs/bin/puppet resource service puppetserver ensure=running enable=true &gt; /dev/null  Puppet Agent / IOS-XRvTo access the IOS-XRv bash shell just issue the vagrant ssh command (no password required)#$ vagrant ssh iosxrvTo access the XR console on IOS-XRv requires an additional step to figure out the ssh port#$ vagrant port iosxrvThe forwarded ports for the machine are listed below. Please note thatthese values may differ from values configured in the Vagrantfile if theprovider supports automatic port collision detection and resolution.    22 (guest) =&gt; 2223 (host) 57722 (guest) =&gt; 2200 (host) $ ssh -p 2223 vagrant@localhost # password# vagrantvagrant@localhost's password#RP/0/RP0/CPU0#xrv9k#The IOS-XRv instance is already configured via \u201ciosxrv.sh\u201d. This section is only for the user\u2019s information.  Let\u2019s review the \u201ciosxrv.sh\u201d script.The first section installs puppet agent on IOS-XRv.  sudo rpm --import http#//yum.puppetlabs.com/RPM-GPG-KEY-puppetlabssudo rpm --import http#//yum.puppetlabs.com/RPM-GPG-KEY-reductivewget -q https#//yum.puppetlabs.com/puppetlabs-release-pc1-cisco-wrlinux-7.noarch.rpmsudo yum install -y puppetlabs-release-pc1-cisco-wrlinux-7.noarch.rpm &gt; /dev/nullsudo yum update -y &gt; /dev/nullsudo yum install -y puppet &gt; /dev/null    Next, downloads and installs grpcs gem.  export PATH=/opt/puppetlabs/puppet/bin#$PATHwget -q https#//rubygems.org/downloads/grpc-0.15.0-x86_64-linux.gemsudo /opt/puppetlabs/puppet/bin/gem install --no-rdoc --no-ri grpc &gt; /dev/null    Next, copies configuration files#  yes | sudo cp /home/vagrant/puppet.conf /etc/puppetlabs/puppet/puppet.confyes | sudo cp /home/vagrant/hosts /etc/hostsyes | sudo cp /home/vagrant/cisco_yang.yaml /etc/cisco_yang.yaml  UsagePuppet ManifestThis section explains puppet manifest. This section is only for the user\u2019s information. To apply manifest, jump to apply sample manifest section.The following example manifest shows how to use ciscoyang to configure two VRF instances on a Cisco IOS-XR device.node 'default' {  cisco_yang { 'my-config'#    ensure =&gt; present,    target =&gt; '{~Cisco-IOS-XR-infra-rsi-cfg#vrfs~# [null]}',    source =&gt; '{~Cisco-IOS-XR-infra-rsi-cfg#vrfs~# {          ~vrf~#[            {                ~vrf-name~#~VOIP~,                ~description~#~Voice over IP~,                ~vpn-id~#{~vpn-oui~#875, ~vpn-index~#3},                ~create~#[null]            },            {                ~vrf-name~#~INTERNET~,                ~description~#~Generic external traffic~,                ~vpn-id~#{~vpn-oui~#875,~vpn-index~#22},                ~create~#[null]            }]      }    }',  }}The following example manifest shows how to copy a file from the Puppet master to the agent and then reference it from the manifest.  file { '/root/bgp.json'# source =&gt; 'puppet#///modules/ciscoyang/models/bgp.json' }  cisco_yang { '{~Cisco-IOS-XR-ipv4-bgp-cfg#bgp~# [null]}'#    ensure =&gt; present,    mode   =&gt; replace,    source =&gt; '/root/bgp.json',  }}The following example manifest shows how to use ciscoyang to configure two VRF instances on a Cisco IOS-XR device using the Yang NETCONF type.node 'default' {  cisco_yang_netconf { 'my-config'#    target =&gt; '&lt;vrfs xmlns=~http#//cisco.com/ns/yang/Cisco-IOS-XR-infra-rsi-cfg~/&gt;',    source =&gt; '&lt;vrfs xmlns=~http#//cisco.com/ns/yang/Cisco-IOS-XR-infra-rsi-cfg~&gt;                 &lt;vrf&gt;                   &lt;vrf-name&gt;VOIP&lt;/vrf-name&gt;                   &lt;create/&gt;                   &lt;description&gt;Voice over IP&lt;/description&gt;                   &lt;vpn-id&gt;                     &lt;vpn-oui&gt;875&lt;/vpn-oui&gt;                     &lt;vpn-index&gt;3&lt;/vpn-index&gt;                   &lt;/vpn-id&gt;                 &lt;/vrf&gt;                 &lt;vrf&gt;                   &lt;vrf-name&gt;INTERNET&lt;/vrf-name&gt;                   &lt;create/&gt;                   &lt;description&gt;Generic external traffic&lt;/description&gt;                   &lt;vpn-id&gt;                     &lt;vpn-oui&gt;875&lt;/vpn-oui&gt;                     &lt;vpn-index&gt;22&lt;/vpn-index&gt;                   &lt;/vpn-id&gt;                 &lt;/vrf&gt;              &lt;/vrfs&gt;',    mode =&gt; replace,    force =&gt; false,  }}The cisco_yang Puppet TypeAllows IOS-XR to be configured using YANG models in JSON format via gRPC.Parameters  targetThe model path of the target node in YANG JSON format, or a reference to a local file containing the model path. For example, to configure the list of vrfs in IOS-XR, you could specify a target of '{~Cisco-IOS-XR-infra-rsi-cfg#vrfs~# [null]}' or reference a file which contained the same JSON string.  modeDetermines which mode is used when setting configuration via ensure=&gt;present. Valid values are replace and merge (which is the default). If replace is specified, the current configuration will be replaced by the configuration in the source property (corresponding to the ReplaceConfig gRPC operation). If merge is specified, the configuration in the source property will be merged into the current configuration (corresponding to the MergeConfig gRPC operation).  forceValid values are true and false (which is the default). If true is specified, then the config in the source property is set on the device regardless of the current value. If false is specified (or no value is specified), the default behavior is to set the configuration only if it is different from the running configuration.Properties  ensureDetermines whether a certain configuration should be present or not on the device. Valid values are present and absent.  sourceThe model data in YANG JSON format, or a reference to a local file containing the model data. This property is only used when ensure=&gt;present is specified. In addition, if source is not specified when ensure=&gt;present is used, source will default to the value of the target parameter. This removes some amount of redundancy when the source and target values are the same (or very similar).The cisco_yang_netconf Puppet TypeAllows IOS-XR to be configured using YANG models in XML format via NETCONF.Parameters  targetThe Yang Netconf XML formatted string or file location containing the filter used to query the existing configuration. For example, to configure the list of vrfs in IOS-XR, you could specify a target of \u2018\u2019 or reference a file which contained the equivalent Netconf XML string.  modeDetermines which mode is used when setting configuration. Valid values are replace and merge (which is the default). If replace is specified, the current configuration will be replaced by the configuration in the source property. If merge is specified, the configuration in the source property will be merged into the current configuration.  forceValid values are true and false (which is the default). If true is specified, then the config in the source property is set on the device regardless of the current value. If false is specified (or no value is specified), the default behavior is to set the configuration only if it is different from the running configuration.Properties  sourceThe model data in YANG XML Netconf format, or a reference to a local file containing the model data. The Netconf protocol does not allow deletion of configuration subtrees, but instead requires addition of \u2018operation=\u201ddelete\u201d\u2019 attributes in the YANG XML specifed in the source property.Apply Sample Puppet ManifestCreate Sample ManifestA sample manifest file is included in Puppet-Yang git repository. Copy sample manifest file at right location on puppet master.$ vagrant ssh puppetmaster$ find . -name site.pp./cisco-yang-puppet-module/examples/site.pp$ sudo cp ./cisco-yang-puppet-module/examples/site.pp /etc/puppetlabs/code/environments/production/manifests/$ exitThe sample puppet manifest looks like#node 'default' {  file { ~/root/temp/vrfs.json~#    source =&gt; ~puppet#///modules/ciscoyang/models/defaults/vrfs.json~}  # Configure two vrfs (VOIP &amp; INTERNET)  cisco_yang { '{~Cisco-IOS-XR-infra-rsi-cfg#vrfs~# [null]}'#    ensure =&gt; present,    source =&gt; '/root/temp/vrfs.json',  }}Apply Sample ManifestThe sample manifest above requires /root/temp directory on puppet agent to copy XR configuration file vrfs.json.$ vagrant ssh iosxrv$ sudo mkdir /root/temp/$ exitThe vrfs.json file#{   ~Cisco-IOS-XR-infra-rsi-cfg#vrfs~#{      ~vrf~#[{            ~vrf-name~#~VOIP~,            ~description~#~Voice over IP~,            ~vpn-id~#{~vpn-oui~#87, ~vpn-index~#3},            ~create~#[null]         },         {            ~vrf-name~#~INTERNET~,            ~description~#~Generic external traffic~,            ~vpn-id~#{~vpn-oui~#85, ~vpn-index~#22},            ~create~#[null]         }]   }}Run puppet agent puppet agent -t to apply configuration on IOS-XRv.$ vagrant ssh iosxrv$ sudo puppet agent -t$ exitVerify the applied configuration#$ ssh -p 2223 vagrant@localhost # password# vagrantvagrant@localhost's password#RP/0/RP0/CPU0#xrv9k#show running-config vrfFri Aug 19 00#02#40.505 UTCvrf VOIP description Voice over IP vpn id 57#3!vrf INTERNET description Generic external traffic vpn id 55#16!$ exit", "url": "https://xrdocs.github.io/application-hosting/tutorials/2016-08-22-using-puppet-with-iosxr-6-1-1", "tags": "vagrant, iosxr, cisco, linux, Puppet, xr toolbox", "title": "Using Puppet with IOS-XR 6.1.1", "author": "Sushrut Shirole"}, "tutorials-2017-05-05-mdt-with-grpc-transport-tricks": {"content": "     MDT with gRPC# Transport Tricks  gRPC  What is gRPC again?  What Does gRPC see?  Just Tell Me How to Fix It  I Didn\u2019t Configure TPA But It Still Works, So There!  Conclusion  gRPCIn previous tutorials, I\u2019ve covered how to configure a router for Model-Driven Telemetry (MDT) with gRPC dial-out and dial-in.  In this tutorial, I\u2019ll discuss some advanced topics and gotchas that you might encounter as you work with gRPC.Note that you may not need to read this blog!  It is entirely likely that your gRPC connection will \u201cjust work.\u201d  But for the few corner cases where it doesn\u2019t, you might have to read this.  For example, if you can get TCP dial-out to work but not gRPC dial-out, keep reading\u2026What is gRPC again?gRPC is an open source RPC framework that leverages HTTP/2 as a transport.  Compared to simple TCP transport, gRPC brings two important features to MDT# 1) Optional encryption with TLS and 2) Support for \u201cdial-in\u201d (from collector to router).Now bear with me for a moment, as this next bit get a little complicated.  If you are familiar with the 64 bit IOS XR software architecture, you may already be aware that IOS XR runs in a container on top of a Linux kernel.  The gRPC server used by MDT lives in the IOS XR container (it\u2019s part of the IOS XR Linux shell) but it is not part of the XR Control Plane proper.  This means that gRPC uses the Linux networking stack (not the XR networking stack).  And this is where problems can happen.What Does gRPC see?To see the world from gRPC\u2019s perspective, drop into the XR Linux shell and take a look at the routes there#RP/0/RP0/CPU0#SunC#bashFri May  5 21#22#04.749 UTC[xr-vm_node0_RP0_CPU0#~]$netstat -rKernel IP routing tableDestination     Gateway         Genmask         Flags   MSS Window  irtt Iface10.30.111.0     *               255.255.255.0   U         0 0          0 Mg0_RP0_CPU0_0[xr-vm_node0_RP0_CPU0#~]$From this output, you can see that there is only a single route out the management interface.  If your gRPC collector lives on that subnet, the gRPC process will be able to find it.  So that\u2019s one reason some lucky people don\u2019t have to read this blog.  But if your collector is reachable through some other port, gRPC doesn\u2019t know how to get there.  One symptom is that your subscription will stay in the dreaded \u201cNot Active\u201d state#RP/0/RP0/CPU0#SunC#show telem model destination DGroup1 | include StateFri May  5 22#16#48.995 UTC    State#                Not ActiveIf you are doing gRPC dial-out, you will see this trace#RP/0/RP0/CPU0#SunC#show grpc trace emsFri May  5 21#36#58.868 UTCMay  5 21#36#57.774 ems/grpc 0/RP0/CPU0 t19523 EMS-GRPC# grpc# Conn.resetTransport failed to create client transport# connection error# desc = ~transport# dial tcp 172.30.8.4#5432# connect# network is unreachable~; Reconnecting to ~172.30.8.4#5432~May  5 21#38#01.626 ems/grpc 0/RP0/CPU0 t13628 EMS-GRPC# Failed to dial 172.30.8.4#5432# grpc# timed out trying to connect; please retry.RP/0/RP0/CPU0#SunC#Just Tell Me How to Fix ItOne way to fix this for both dial-in and dial-out is by configuring a Third-Party App (TPA) source address.  Configuring the TPA sets a src-hint for Linux applications, so that originating traffic from the applications can be tied to any reachable IP of XR.RP/0/RP0/CPU0#SunC(config)#tpa address-family ipv4 update-source GigabitEthernet 0/0/0/0By doing this, we automatically get a default route in the Linux shell (the fwdintf takes the traffic back to XR for routing)#[xr-vm_node0_RP0_CPU0#~]$netstat -rKernel IP routing tableDestination     Gateway         Genmask         Flags   MSS Window  irtt Ifacedefault         *               0.0.0.0         U         0 0          0 fwdintf10.30.111.0     *               255.255.255.0   U         0 0          0 Mg0_RP0_CPU0_0[xr-vm_node0_RP0_CPU0#~]$So now, gRPC has a route back to the collector.  That\u2019s all you need for dial-in.For dial-out, gRPC now knows to use GigabitEthernet0/0/0/0 as a source address. You can see that here#[xr-vm_node0_RP0_CPU0#~]$ip routedefault dev fwdintf  scope link  src 172.30.8.5310.30.111.0/24 dev Mg0_RP0_CPU0_0  proto kernel  scope link  src 10.30.111.9[xr-vm_node0_RP0_CPU0#~]$See that \u201csrc 172.30.8.53\u201d ?  That\u2019s the source address that gRPC will use when sending MDT traffic in dial-out mode.Note that you can use any operational interface for the update-source, with the exception of dot1q-tagged VLAN sub-interfaces (as of IOS XR 6.2).  If you\u2019ve used update-source in other contexts (e.g. BGP neighbors configs), then you know that using a Loopback address is typically preferred since Loopbacks never goes down.  Just make sure that the Loopback you specify is return-path-routable from your collector!And speaking of Loopbacks\u2026I Didn\u2019t Configure TPA But It Still Works, So There!So some lucky people who didn\u2019t configure TPA can still get gRPC to work!  Doesn\u2019t seem fair, does it?  Well, the reason is that they have a Loopback (any Loopback except Loopback 1 which is reserved \u2013 gory detail fans read this).  When a Loopback interface is configured, you also get a default route in the Linux stack#RP/0/RP0/CPU0#SunC(config)#no tpaRP/0/RP0/CPU0#SunC(config)#int loop0RP/0/RP0/CPU0#SunC(config-if)#ipv4 address 5.5.5.5/32RP/0/RP0/CPU0#SunC(config-if)#commitRP/0/RP0/CPU0#SunC(config-if)#endRP/0/RP0/CPU0#SunC#bashFri May  5 22#01#59.141 UTC[xr-vm_node0_RP0_CPU0#~]$netstat -rKernel IP routing tableDestination     Gateway         Genmask         Flags   MSS Window  irtt Ifacedefault         *               0.0.0.0         U         0 0          0 fwdintf10.30.111.0     *               255.255.255.0   U         0 0          0 Mg0_RP0_CPU0_0That\u2019s good for dial-in, but what about dial-out?  Well, it still might work. Check out the src address below#[xr-vm_node0_RP0_CPU0#~]$ip routedefault dev fwdintf  scope link  src 5.5.5.510.30.111.0/24 dev Mg0_RP0_CPU0_0  proto kernel  scope link  src 10.30.111.9[xr-vm_node0_RP0_CPU0#~]$Traffic sent to the collector will have a source address of 5.5.5.5.  If your collector has a route back to 5.5.5.5 (e.g. you\u2019re distributing your loopback addresses in your IGP), then great.  If not, then the collector will drop the packet and you\u2019ll need the TPA config for an interface IP address that is routable from the collector.ConclusionI hope you didn\u2019t have to read this tutorial at all.  But if you did and even if you glazed over the bits about the Linux networking stack and XR Linux shell, just remember this# to make gRPC work, use a routable Loopback or TPA update-source.", "url": "https://xrdocs.github.io/telemetry/tutorials/2017-05-05-mdt-with-grpc-transport-tricks/", "tags": "iosxr, MDT, Telemetry, gRPC", "title": "MDT with gRPC: Transport Tricks", "author": "Shelly Cadora"}, "tutorials-2017-04-10-using-pipeline-integrating-with-influxdb": {"content": "     Integrating Pipeline with InfluxDB  Using Pipeline          Preparing the Router      Getting Influxdb      Getting Pipeline      Pipeline.conf      Running Pipeline      Seeing the Data Before It Goes To InfluxDB      InfluxDB      Conclusion        Using PipelineIn an earlier blog, I discussed how to configure Pipeline to write Model-Driven-Telemetry (MDT) data to a plain text file. In this tutorial, I\u2019ll describe the Pipeline configuration that enables you to write telemetry data into InfluxDB, an open source platform for time-series data.Here\u2019s a picture of what we are trying to do#Pipeline and InfluxDB can run on the same server or on different servers, as long as there is connectivity between them.Preparing the RouterThis tutorial assumes that you\u2019ve already configured your router for model-driven telemetry (MDT) with TCP dial-out using the instructions in this tutorial. The IP address and port that you specify in the destination-group in the router config should match the IP address and port on which Pipeline is listening.Getting InfluxdbThis tutorial assumes that you have a working instance of InfluxDB with an IP address that is accessible from your Pipeline instance and has a database named \u201cmdt_db\u201d.   If you want to use a different database name, edit the pipeline.conf output stage configuration below.InfluxDB is available from github and includes documentation on creating databases.  InfluxDB is also available as a Docker container.Getting PipelinePipeline is available from github.Pipeline.confConfiguring the Input Stage for TCP Dial-OutFor this tutorial, I\u2019ll use the default pipeline.conf input stage for MDT TCP Dial-Out described in the TCP to Textfile tutorial.  If you take out all the comments, this reduces to 5 lines in pipeline.conf#[testbed]stage = xport_inputtype = tcpencap = stlisten = #5432This [testbed] section shown above will work \u201cas is\u201d for MDT with TCP dial-out.  If you want to change the port that Pipeline listens on to something other than \u201c5432\u201d, you can edit this section of the pipeline.conf.  Otherwise, we\u2019re good to go for the input stage.Configuring the Output Stage for InfluxDBTo push the data to InfluxDB, we need a \u201cmetrics\u201d output stage in Pipeline.  The default pipeline.conf file comes with an example metrics stage section called [mymetrics].  Taking out the comments, the important lines are as follows#[mymetrics]stage = xport_outputtype = metricsfile = metrics.jsondump = metricsdump.txtoutput = influxinflux = http#//10.152.176.74#8086database = mdt_dbThis configuration instructs Pipeline to post MDT data to an InfluxDB instance at 10.152.176.74#8086 that has a database named mdt_db.Before posting the data to influxdb, pipeline transforms the data according to the instructions in the metrics.json file.  More on this in the next section.Finally, the dump = metricsdump.txt option lets you locally dump a copy of the same data that is being pushed to influxdb.  This is useful for first-time setup and debugging.Using metrics.jsonTL;DR If you are using the sensor-path from the TCP to Textfile tutorial and the default metrics.json, you actually have nothing to do.  But if you have a burning desire to know how things works, please read the rest of the section!YANG models define data hierarchies.  Because MDT is based on YANG models, the raw telemetry data from a router is also hierarchical.  Time-series databases, however, typically expect data in a simple format# metric name, metric value, timestamp and, optionally, some tags or keys.  In influxdb, this format is called the \u201cLine Protocol.\u201dOne of the important functions of Pipeline is to take the hierarchical YANG-based data and transform it into the Line Protocol for easy consumption by influxdb.  Pipeline takes the complex, hierarchical YANG-modeled data and flattens it into multiple time series.  Pipeline uses the metrics.json file to perform the transformation. The metrics.json file contains a series of json objects, one for each YANG model and sub-tree path that the router streams.Take the sensor-path configured on the router in the TCP Dial Out Tutorial# Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters.  The corresponding object in the default metrics.json is below#{\t\t~basepath~ # ~Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters~,\t\t~spec~ # {\t\t\t~fields~ # [\t\t\t\t{~name~ # ~interface-name~, ~tag~ # true},\t\t\t\t{~name~ # ~packets-received~},\t\t\t\t{~name~ # ~bytes-received~},\t\t\t\t{~name~ # ~packets-sent~},\t\t\t\t{~name~ # ~bytes-sent~},\t\t\t\t{~name~ # ~output-drops~},\t\t\t\t{~name~ # ~output-queue-drops~},\t\t\t\t{~name~ # ~input-drops~},\t\t\t\t{~name~ # ~input-queue-drops~},\t\t\t\t{~name~ # ~input-errors~},\t\t\t\t{~name~ # ~crc-errors~},\t\t\t\t{~name~ # ~input-ignored-packets~},\t\t\t\t{~name~ # ~output-errors~},\t\t\t\t{~name~ # ~output-buffer-failures~},\t\t\t\t{~name~ # ~carrier-transitions~}\t\t\t]\t\t}\t}This entry in the metrics.json file enables Pipeline to post interface statistics in the influxdb Line Protocol with the following characteristics#Measurement#  Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-countersTag Names and Values  EncodingPath=Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counter  Producer=SunC  interface-name=MgmtEth0/RP0/CPU0/0Field Keys and Values  bytes-received=307428735  bytes-sent=23017070265        Timestamp  1491942788950000000You might have noticed that \u201cinterface-name\u201d is one of the Tag Names, not a Field Key above. There are two ways to get an MDT metric marked as a Tag.  First, recall that the router sends MDT data as one of two types# Keys and Content.  Pipeline will automatically translate items in the MDT Keys section to a Tag.  You can also use the metrics.json file.  Any entry in the metrics.json file with ~tag~ # true will be added to the Tag Names in the Line Protocol and not sent as a Field Key.Also good to know# if you don\u2019t have an entry in the metrics.json file, then that data point will not be posted to InfluxDB, even if the router sends that data to Pipeline.  That\u2019s actually a feature!  Because bulk data collection is more efficient for the router, the router streams data at the container level of the YANG model.  That means you will sometimes receive more data than you actually need.  Pipeline gives you the ability to filter what data gets passed on to your time series database.Final takeaway, if the path you are streaming is already described in the metrics.json and has all the fields you care about (as is this case here), there is nothing to do.  Adding objects to the metrics.json will be the topic of a future tutorial.Running PipelineRun pipeline as usual, by executing the binary in the bin directory. Pipeline will use the pipeline.conf file by default.  Pipeline will prompt you for credentials to use when posting to influxdb.scadora@darcy#~/bigmuddy-network-telemetry-pipeline$ bin/pipelineStartup pipelineLoad config from [pipeline.conf], logging in [pipeline.log]CRYPT Client [mymetrics],[http#//10.152.176.84#8086] Enter username# admin Enter password#Wait for ^C to shutdownPower users will appreciate the -log= -debug option for pipeline#scadora@darcy#~/bigmuddy-network-telemetry-pipeline$ bin/pipeline -log= -debugINFO[2017-04-12 14#41#05.038501] Conductor says hello, loading config          config=pipeline.conf debug=true fluentd= logfile= maxthreads=1 tag=pipeline version=~v1.0.0(bigmuddy)~DEBU[2017-04-12 14#41#05.039562] Conductor processing section...               name=conductor section=inspector tag=pipelineDEBU[2017-04-12 14#41#05.039690] Conductor processing section, type...         name=conductor section=inspector tag=pipeline type=tapINFO[2017-04-12 14#41#05.039800] Conductor starting up section                 name=conductor section=inspector stage=~xport_output~ tag=pipelineDEBU[2017-04-12 14#41#05.039887] Conductor processing section...               name=conductor section=mymetrics tag=pipelineDEBU[2017-04-12 14#41#05.039940] Conductor processing section, type...         name=conductor section=mymetrics tag=pipeline type=metricsINFO[2017-04-12 14#41#05.039982] Conductor starting up section                 name=conductor section=mymetrics stage=~xport_output~ tag=pipeline&lt;output snipped for brevity&gt;Seeing the Data Before It Goes To InfluxDBSince we configure a \u201cdump\u201d file in the [mymetrics] output stage above, Pipeline will dump a local copy of the data it posts to InfluxDB into a text file in the Line Protocol format.  This is a good way to confirm that Pipeline is receiving data from the router and parsing it with a valid metrics.json entry.scadora@darcy#~/bigmuddy-network-telemetry-pipeline$ tail -f metricsdump.txt_wkid0Server# [http#//10.152.176.84#8086], wkid 0, writing 7 points in db# mdt_db(prec# [ms], consistency# [], retention# [])\tCisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters,EncodingPath=Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters,Producer=SunC,interface-name=Bundle-Ether1 bytes-received=175069849,bytes-sent=9057828,carrier-transitions=0i,crc-errors=0i,input-drops=0i,input-errors=0i,input-ignored-packets=0i,input-queue-drops=0i,output-buffer-failures=0i,output-drops=0i,output-errors=0i,output-queue-drops=0i,packets-received=1189543,packets-sent=103020 1491943978355000000\tCisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters,EncodingPath=Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters,Producer=SunC,interface-name=Null0 bytes-received=0,bytes-sent=0,carrier-transitions=0i,crc-errors=0i,input-drops=0i,input-errors=0i,input-ignored-packets=0i,input-queue-drops=0i,output-buffer-failures=0i,output-drops=0i,output-errors=0i,output-queue-drops=0i,packets-received=0,packets-sent=0 1491943978355000000\tCisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters,EncodingPath=Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters,Producer=SunC,interface-name=MgmtEth0/RP0/CPU0/0 bytes-received=307431285,bytes-sent=23017071885,carrier-transitions=1i,crc-errors=0i,input-drops=139i,input-errors=0i,input-ignored-packets=0i,input-queue-drops=0i,output-buffer-failures=0i,output-drops=0i,output-errors=0i,output-queue-drops=0i,packets-received=4338703,packets-sent=16808000 1491943978355000000InfluxDBTo validate that the data has been received by influxdb, you can use curl to query the database#$ curl -G 'http#//localhost#8086/query?pretty=true' --data-urlencode ~db=mdt_db~ --data-urlencode ~q=SELECT \\~bytes-sent\\~ FROM \\~Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters\\~ WHERE \\~interface-name\\~='GigabitEthernet0/0/0/0'~{    ~results~# [        {            ~series~# [                {                    ~name~# ~Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters~,                    ~columns~# [                        ~time~,                        ~bytes-sent~                    ],                    ~values~# [                        [                            ~2017-04-11T21#04#57.205Z~,                            1.911903356e+09                        ],                        [                            ~2017-04-11T21#05#27.214Z~,                            1.911903356e+09                        ],                        [                            ~2017-04-11T21#05#57.226Z~,                            1.911911181e+09                        ]                    ]                }            ]        }    ]}If you are using grafana to query and visualize your influxdb data, you can use all the queries and dashboards you know and love, as in this simple graph of packets sent on Gigabit Ethernet 0/0/0/0#For those hearty souls who slogged through the Using metrics.json section, note that we could use interface-name in the Where clause of the query above because it was sent as a Tag in the Line Protocol.ConclusionPipeline gives you a easy, flexible way to get data into commonly used open-source tools like influxdb.  Give it a try and let us know what you think!", "url": "https://xrdocs.github.io/telemetry/tutorials/2017-04-10-using-pipeline-integrating-with-influxdb/", "tags": "iosxr, telemetry, MDT, pipeline", "title": "Using Pipeline: Integrating with InfluxDB", "author": "Shelly Cadora"}, "tutorials-2017-02-26-running-docker-containers-on-ios-xr-6-1-2": {"content": "     Running Docker Containers on IOS-XR  Introduction  Pre-requisites          Vagrant IOS-XR box      Physical (NCS5500 and ASR9k)        Understand the topology          Vagrant Setup      NCS5500 and ASR9k Setup        Install docker-engine on the devbox          Vagrant setup      NCS5500 and ASR9k setup        Docker Daemon support on IOS-XR          Vagrant and NCS5500 architecture      ASR9k architecture      Vagrant setup Docker Client Access      NCS5500 and ASR9k Docker Client Access        Launch a Docker Container  Public Dockerhub registry          Vagrant Setup      NCS5500 and ASR9k Setup        Private \u201cinsecure\u201d registry          Setting up the insecure registry      Vagrant Setup      NCS5500 setup      ASR9k setup        Private Self-Signed Registry          Setting up a self-signed Docker Registry      Vagrant Setup      NCS5500 and ASR9k Setup        Docker Save/Load Technique          Create a docker image tarball      Vagrant Setup      NCS5500 and ASR9k setup.        Docker export/import Technique          Create a custom docker Container tarball/snapshot      Vagrant Setup      NCS5500 and ASR9k setup.        What can I do with the Docker container?          Testing out a Web Server        IntroductionIf you haven\u2019t checked out the earlier parts to the XR toolbox Series, then you can do so here#  XR Toolbox SeriesThe purpose of this series is simple. Get users started with an IOS-XR setup on their laptop and incrementally enable them to try out the application-hosting infrastructure on IOS-XR.In this part, we explore how a user can spin up Docker containers on IOS-XR. There are multiple ways to do this and we\u2019ll explore each one#      Public  Dockerhub Registry# This is the simplest setup that most docker users would be well aware of. All you need to do is set up reachability to dockerhub with the correct dns resolution.        Private \u201cinsecure\u201d registry# Some users may choose to do this, specially if they\u2019re running a local docker registry inside a secured part of their network.        Private \u201cself-signed\u201d registry# This is more secure than the \u201cinsecure\u201d setup, and allows a user to enable TLS.        Private \u201csecure\u201d registry# Set up reachability to your private registry, created using a certificate obtained from a CA. The steps used to set this up are identical to a private self-signed registry except for the creation of the certificate. We won\u2019t really tackle this scenario separately in this tutorial due to the absence of said certificate #).        Tarball image/container#  This is the simplest setup - very similar to LXC deployments. In this case, a user may create and set up a container completely off-box, package it up as an image or a container tar ball, transfer it to the router and then load/import it, before running.  For each case, we will compare IOS-XR running as a Vagrant box with IOS-XR running on a physical box (NCS5500 and ASR9k). They should be identical, except for reachability through the Management ports.Pre-requisitesVagrant IOS-XR boxIf you\u2019re bringing up the topology on your laptop using the IOS-XR vagrant box, then#  Meet the pre-requisites specified in the IOS-XR Vagrant Quick Start guide# Pre-requisites. The topology here will require about 5G RAM and 2 cores on the user\u2019s laptop.  Clone the following repository# https#//github.com/ios-xr/vagrant-xrdocs, before we start.cd ~/git clone https#//github.com/ios-xr/vagrant-xrdocs.gitcd vagrant-xrdocs/You will notice a few directories. We will utilize the docker-app-topo-bootstrap directory in this tutorial.AKSHSHAR-M-K0DS#vagrant-xrdocs akshshar$ pwd/Users/akshshar/vagrant-xrdocsAKSHSHAR-M-K0DS#vagrant-xrdocs akshshar$ ls docker-app-topo-bootstrap/Vagrantfile\tconfigs\t\tscriptsAKSHSHAR-M-K0DS#vagrant-xrdocs akshshar$ Physical (NCS5500 and ASR9k)On the other hand, if you have an NCS5500 or ASR9k lying around (don\u2019t we all?), then load up a 6.1.2+ image on the router and connect an Ubuntu server (for the purpose of this tutorial), to the Management network of the router.The server needs to be reachable from the router over the Management network.Further, we\u2019re going to enable SSH access in XR CLI and in  XR linux shell to achieve an equivalence between the NCS5500/ASR9k and Vagrant setup.Note# NCS5500 steps are described, but ASR9k works in exactly the same way.Enable SSH access in the XR CLIOn my NCS5500 setup, I can enable SSH in XR in the default (global) vrf with the following steps and CLI#RP/0/RP0/CPU0#ncs5508#crypto key generate rsaMon Mar  6 05#28#57.184 UTCThe name for the keys will be# the_default  Choose the size of the key modulus in the range of 512 to 4096 for your General Purpose Keypair. Choosing a key modulus greater than 512 may take a few minutes.How many bits in the modulus [2048]# Generating RSA keys ...Done w/ crypto generate keypair[OK]RP/0/RP0/CPU0#ncs5508#RP/0/RP0/CPU0#ncs5508#show  running-config sshMon Mar  6 05#29#51.819 UTCssh server v2ssh server vrf defaultRP/0/RP0/CPU0#ncs5508#Enable SSH access to XR linux shellThis is openssh running in the XR linux environment. Users may choose to keep this disabled based on the kind of operations they intend to have. Enabling it in a given network namespace (equivalent to XR vrf) opens up port 57722 on all the IP addresses reachable in that VRF.In 6.1.2, only global-vrf (default vrf) is supported in the linux environment for SSH and apps. Post 6.3.1, support for Mgmt vrfs in the linux shell will be brought in.To enable SSH access in the XR linux shell for a sudo user, we\u2019ll take 3 steps#      Enable the \u201csudo\u201d group permissions in /etc/sudoers    Open up /etc/sudoers using vi in the XR bash shell and uncomment the following line#    # %sudo ALL=(ALL) ALL        Save and exit (#wq in vi).        Create a non-root user. This is important. For security reasons, root user access over SSH (SSH    in the linux shell) is disabled. Only the root XR user can create new (sudo or non-sudo) users,    so use the \u201cbash\u201d cli to get into the shell#    RP/0/RP0/CPU0#ncs5508#RP/0/RP0/CPU0#ncs5508#bashMon Mar  6 06#16#01.391 UTC  [ncs5508#~]$[ncs5508#~]$adduser ciscoLogin name for new user []#ciscoUser id for cisco [ defaults to next available]#Initial group for cisco [users]#Additional groups for cisco []#sudocisco's home directory [/home/cisco]#cisco's shell [/bin/bash]#cisco's account expiry date (MM/DD/YY) []#OK, Im about to make a new account. Heres what you entered so far#New login name# ciscoNew UID# [Next available]Initial group# users/usr/sbin/adduser# line 68# [# -G# binary operator expectedAdditional groups# sudoHome directory# /home/ciscoShell# /bin/bashExpiry date# [no expiration]This is it... if you want to bail out, you'd better do it now.Making new account...useradd# user 'cisco' already existsChanging the user information for ciscoEnter the new value, or press ENTER for the default    Full Name []#     Room Number []#     Work Phone []#     Home Phone []#     Other []# Enter new UNIX password# Retype new UNIX password# passwd# password updated successfullyDone...[ncs5508#~]$            Finally enable SSH access by starting the sshd_operns service#    [ncs5508#~]$service sshd_operns startMon Mar 6 06#21#53 UTC 2017 /etc/init.d/sshd_operns# Waiting for OPERNS interface creation...Mon Mar 6 06#21#53 UTC 2017 /etc/init.d/sshd_operns# Press ^C to stop if needed.Mon Mar 6 06#21#54 UTC 2017 /etc/init.d/sshd_operns# Found nic, Mg0_RP0_CPU0_0Mon Mar 6 06#21#54 UTC 2017 /etc/init.d/sshd_operns# Waiting for OPERNS management interface      creation...Mon Mar 6 06#21#54 UTC 2017 /etc/init.d/sshd_operns# Found nic, Mg0_RP0_CPU0_0Mon Mar 6 06#21#54 UTC 2017 /etc/init.d/sshd_operns# OPERNS is readyMon Mar 6 06#21#54 UTC 2017 /etc/init.d/sshd_operns# Start sshd_opernsStarting OpenBSD Secure Shell server# sshd  generating ssh RSA key...  generating ssh ECDSA key...  generating ssh DSA key...  generating ssh ED25519 key...[ncs5508#~]$        Check that the sshd_operns service is now listening on port 57722 in the global-vrf network        namespace#    netns_identify utility is to check which network namespace a process is in. $$ gets the pid      of the current shell. In the output below, tpnns is a symbolic link of  global-vrf. So they        both mean the same thing - XR default VRF mapped to a network namespace in linux. All XR          interfaces in the default(global) vrf will appear in the linux shell in this network namespace.    Issuing an ifconfig will show up these interfaces.    [ncs5508#~]$netns_identify $$tpnnsglobal-vrf[ncs5508#~]$netstat -nlp | grep 57722tcp        0      0 0.0.0.0#57722           0.0.0.0#*               LISTEN      622/sshd        tcp6       0      0 ###57722                ###*                    LISTEN      622/sshd        [ncs5508#~]$[ncs5508#~]$ifconfigMg0_RP0_CPU0_0 Link encap#Ethernet  HWaddr 80#e0#1d#00#fc#ea            inet addr#11.11.11.59  Mask#255.255.255.0          inet6 addr# fe80##82e0#1dff#fe00#fcea/64 Scope#Link          UP RUNNING NOARP MULTICAST  MTU#1514  Metric#1          RX packets#3830 errors#0 dropped#0 overruns#0 frame#0          TX packets#4 errors#0 dropped#0 overruns#0 carrier#3          collisions#0 txqueuelen#1000           RX bytes#1288428 (1.2 MiB)  TX bytes#280 (280.0 B)fwd_ew    Link encap#Ethernet  HWaddr 00#00#00#00#00#0b            inet6 addr# fe80##200#ff#fe00#b/64 Scope#Link          UP RUNNING NOARP MULTICAST  MTU#1500  Metric#1          RX packets#18 errors#0 dropped#10 overruns#0 frame#0          TX packets#2 errors#0 dropped#1 overruns#0 carrier#0          collisions#0 txqueuelen#1000           RX bytes#486 (486.0 B)  TX bytes#140 (140.0 B)  fwdintf   Link encap#Ethernet  HWaddr 00#00#00#00#00#0a            inet6 addr# fe80##200#ff#fe00#a/64 Scope#Link          UP RUNNING NOARP MULTICAST  MTU#1500  Metric#1          RX packets#0 errors#0 dropped#0 overruns#0 frame#0          TX packets#2 errors#0 dropped#1 overruns#0 carrier#0          collisions#0 txqueuelen#1000           RX bytes#0 (0.0 B)  TX bytes#140 (140.0 B)lo        Link encap#Local Loopback            inet addr#127.0.0.1  Mask#255.0.0.0          inet6 addr# ##1/128 Scope#Host          UP LOOPBACK RUNNING NOARP MULTICAST  MTU#65536  Metric#1          RX packets#0 errors#0 dropped#0 overruns#0 frame#0          TX packets#0 errors#0 dropped#0 overruns#0 carrier#0          collisions#0 txqueuelen#0           RX bytes#0 (0.0 B)  TX bytes#0 (0.0 B)lo#0      Link encap#Local Loopback            inet addr#1.1.1.1  Mask#255.255.255.255          UP LOOPBACK RUNNING NOARP MULTICAST  MTU#65536  Metric#1[ncs5508#~]$       Awesome! Now let\u2019s test SSH access directly into the linux shell#As seen from the above output, the Mgmt port (Mg0_RP0_CPU0_0) has an IP 11.11.11.59 and the port 57722 is open all the IP addresses in the corresponding network namespace.From the directly connected \u201cdevbox\u201d or jumpserver I can then issue an ssh as follows#cisco@dhcpserver#~$ ssh cisco@11.11.11.59 -p 57722cisco@11.11.11.59's password# -sh# /var/log/boot.log# Permission deniedncs5508#~$ ncs5508#~$ sudo -iPassword# [ncs5508#~]$ [ncs5508#~]$ whoamiroot[ncs5508#~]$ Works like a charm!Understand the topologyThe topology I\u2019m using differs slightly between the vagrant setup and the NCS5500 setup.This is owing to the fact that the Management port of the vagrant IOS-XR box is used up in the NAT network. So to show equivalence between the two setups, I directly connect the Gig0/0/0/0 interface of Vagrant ios-xrv64 with eth1 of the devbox as shown in the figure below.The two topologies in use are#Vagrant SetupNCS5500 and ASR9k SetupInstall docker-engine on the devboxVagrant setupFor the Vagrant setup, you will see a script called docker_install.sh under the scripts folder#AKSHSHAR-M-K0DS#docker-app-topo-bootstrap akshshar$ pwd/Users/akshshar/vagrant-xrdocs/docker-app-topo-bootstrapAKSHSHAR-M-K0DS#docker-app-topo-bootstrap akshshar$ lsVagrantfile\tconfigs\t\tscriptsAKSHSHAR-M-K0DS#docker-app-topo-bootstrap akshshar$ ls scripts/apply_config.sh\t\tdocker_install.shAKSHSHAR-M-K0DS#docker-app-topo-bootstrap akshshar$ This is the vagrant provisioner for the devbox and will install docker-engine on boot (vagrant up).NCS5500 and ASR9k setupIn this case, the devbox must be provisioned by the user. On an ubuntu devbox, docker-engine can be installed by following the instructions at#  https#//docs.docker.com/engine/installation/linux/ubuntu/Perfect! Now we\u2019re all set with the topology and SSH access. Before we begin, let\u2019s understand the docker daemon/client setup inside IOS-XR.Docker Daemon support on IOS-XRVagrant and NCS5500 architectureIf you haven\u2019t already gone through the basic overview on the application hosting infrastructure on XR, I would urge you to have a quick read#  https#//xrdocs.github.io/application-hosting/blogs/2016-06-28-xr-app-hosting-architecture-quick-look/  Relevant Platforms# The LXC architecture described above and expanded on below is relevant to the following platforms#      NCS5500 (NCS5501, NCS5501-SE, NCS5502, NCS5502-SE, NCS5508, NCS5516)    NCS5000    NCS5011    XRv9k    IOS-XRv64 (Vagrant box and ISO)  From the above article it becomes fairly clear that internally the IOS-XR architecture involves a Host layer running the libvirtd daemon and IOS-XR runs as an LXC spawned using the daemon.Further, the \u201cvirsh\u201d client is provided within the XR LXC, so that a user may have client level access to the daemon while sitting inside the XR LXC itself.The setup for launching LXCs in IOS-XR is shown below#The Docker client/daemon setup follows the exact same principle as shown below. Docker Daemon runs on the host and Docker client is made available inside the XR LXC for easy operationalization#ASR9k architectureThe ASR9k architecture is slightly different. In ASR9k, IOS-XR runs inside its own VM on the 64-bit Linux host to be able to support ISSU requirements relevant to traditional Service Provider deployments.In this case, the libvirtd and docker daemons are available inside the XR control plane VM itself.This does not change the user experience from a docker client or virsh client perspective. The difference is mainly how one may interact with the docker daemon as we\u2019ll touch upon in subsequent sections.This is what the architecture looks like for ASR9k#ASR9k LXC/libvirt Setup#Libvirt daemon is local to the XR control plane VM.ASR9k Docker Setup#Docker daemon is local to the XR control plane VM.Alright, so can we verify this?Vagrant setup Docker Client AccessOn your vagrant box, there are two ways to get access to the docker client#      Drop into the \u201cbash\u201d shell from XR CLI# Using \u201cbash\u201d ensures that the correct environment variables are sourced to gain access to the Docker Daemon on the host#    Password for the XR CLI#   vagrant       AKSHSHAR-M-K0DS#docker-app-topo-bootstrap akshshar$ vagrant port rtr  The forwarded ports for the machine are listed below. Please note that these values may differ from values configured in the Vagrantfile if the provider supports automatic port collision detection and resolution.     22 (guest) =&gt; 2223 (host)  57722 (guest) =&gt; 2222 (host) AKSHSHAR-M-K0DS#docker-app-topo-bootstrap akshshar$  AKSHSHAR-M-K0DS#docker-app-topo-bootstrap akshshar$  AKSHSHAR-M-K0DS#docker-app-topo-bootstrap akshshar$  AKSHSHAR-M-K0DS#docker-app-topo-bootstrap akshshar$ ssh -p 2223 vagrant@localhost The authenticity of host '[localhost]#2223 ([127.0.0.1]#2223)' can't be established. RSA key fingerprint is SHA256#uHev9uiAa0LM36RnnxDYuRyKywra8Oe/G5Gt34OiBqk. Are you sure you want to continue connecting (yes/no)? yes Warning# Permanently added '[localhost]#2223' (RSA) to the list of known hosts. vagrant@localhost's password#  RP/0/RP0/CPU0#ios# RP/0/RP0/CPU0#ios# RP/0/RP0/CPU0#ios#bash Sun Mar  5 18#17#18.380 UTC [xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$whoami root [xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$docker ps CONTAINER ID    IMAGE      COMMAND      CREATED       STATUS        PORTS         NAMES [xr-vm_node0_RP0_CPU0#~]$       Bear in mind that when you drop into the XR linux shell using the \u201cbash\u201d CLI, you are droppped in as root. This is why you can access the docker client without any hassle.  For any other  user, you will need to first become root (using sudo).        Drop directly into the Linux shell over SSH (port 57722)#    From the above output for vagrant port rtr, the port 57722 on XR (running openssh in the XR linux shell) is accessible via port 2222 on the host machine (laptop)#    Use either vagrant ssh rtr or ssh -p 2222 vagrant@localhost to drop into the XR linux shell    Username# vagrantPassword# vagrant          AKSHSHAR-M-K0DS#docker-app-topo-bootstrap akshshar$ vagrant ssh rtr Last login# Sun Mar  5 18#55#20 2017 from 10.0.2.2 xr-vm_node0_RP0_CPU0#~$  xr-vm_node0_RP0_CPU0#~$whoami vagrant xr-vm_node0_RP0_CPU0#~$  xr-vm_node0_RP0_CPU0#~$ sudo -i  [xr-vm_node0_RP0_CPU0#~]$  [xr-vm_node0_RP0_CPU0#~]$ whoami root [xr-vm_node0_RP0_CPU0#~]$  [xr-vm_node0_RP0_CPU0#~]$ docker ps CONTAINER ID      IMAGE       COMMAND       CREATED       STATUS       PORTS        NAMES [xr-vm_node0_RP0_CPU0#~]$        As shown above, we become root by using -i flag for sudo to make sure the correct environment variables are sourced.  NCS5500 and ASR9k Docker Client AccessIf you followed the steps in the pre-requisites section above # Pre-requisites, you would already have access to your NCS5500/ASR9k device over XR SSH (CLI, port 22) as well as sshd_operns (XR linux shell, port 57722)Following the Vagrant model, over XR SSH, we use the \u201cbash\u201d CLI to access the docker client on the NCS5500/ASR9k#Note# The steps for ASR9k are identical. NCS5500 steps are shown below.cisco@dhcpserver#~$ cisco@dhcpserver#~$ ssh root@11.11.11.59The authenticity of host '11.11.11.59 (11.11.11.59)' can't be established.RSA key fingerprint is 8a#42#49#bf#4c#cd#f9#3c#e1#19#f9#02#b6#3a#ad#01.Are you sure you want to continue connecting (yes/no)? yesWarning# Permanently added '11.11.11.59' (RSA) to the list of known hosts.Password# RP/0/RP0/CPU0#ncs5508#RP/0/RP0/CPU0#ncs5508#RP/0/RP0/CPU0#ncs5508#bashMon Mar  6 09#36#37.221 UTC[ncs5508#~]$whoamiroot[ncs5508#~]$docker psCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES[ncs5508#~]$[ncs5508#~]$Similarly, for direct access to the linux shell, we ssh over 57722, become sudo and then access the docker client#SSH password and sudo password for user cisco will be whatever you\u2019ve set up during the Pre-requisites stage.cisco@dhcpserver#~$ ssh cisco@11.11.11.59 -p 57722cisco@11.11.11.59's password# Permission denied, please try again.cisco@11.11.11.59's password# Last login# Mon Mar  6 06#30#47 2017 from 11.11.11.2-sh# /var/log/boot.log# Permission deniedncs5508#~$ ncs5508#~$ ncs5508#~$ sudo -iPassword# [ncs5508#~]$ [ncs5508#~]$ docker psCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES[ncs5508#~]$ Launch a Docker ContainerAs discussed earlier, we\u2019ll showcase a few different techniques through which a user may spin up a docker container on IOS-XR.Public Dockerhub registryThis is the simplest setup that most docker users would know already. The obvious configuration necessary would be to make sure connectivity to the internet is available from the router.This may not be the preferred setup for production deployments, understandably, since direct connectivity to the internet from a production router is not typical. The next few techniques with private registries or tarball based docker container bringup might be more your cup of tea, in that case.Vagrant SetupThe vagrant IOS-XR box comes with connectivity to the internet already. All you need to do is set up the domain name-server in the global-vrf (before 6.3.1, we only support the global/default vrf for the docker daemon image downloads).Remember that we\u2019re setting up this domain name on per vrf basis. In the future, we intend to sync this through XR CLI for all vrfs to the corresponding network namespaces. Before 6.3.1, of course only global-vrf may be used.Update /etc/netns/global-vrf/resolv.conf to point to a reachable nameserver, in this case 8.8.8.8#[xr-vm_node0_RP0_CPU0#~]$cat /etc/netns/global-vrf/resolv.confnameserver 8.8.8.8[xr-vm_node0_RP0_CPU0#~]$Again, become root with the correct environment (sudo -i)  to execute the relevant docker commands to spin up the container.[xr-vm_node0_RP0_CPU0#~]$sudo -i[xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ whoami    root[xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$docker psCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES[xr-vm_node0_RP0_CPU0#~]$docker imagesREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$ docker run -itd --name ubuntu -v /var/run/netns/global-vrf#/var/run/netns/global-vrf --cap-add=SYS_ADMIN ubuntu bashUnable to find image 'ubuntu#latest' locallylatest# Pulling from library/ubuntud54efb8db41d# Pull complete f8b845f45a87# Pull complete e8db7bf7c39f# Pull complete 9654c40e9079# Pull complete 6d9ef359eaaa# Pull complete Digest# sha256#dd7808d8792c9841d0b460122f1acf0a2dd1f56404f8d1e56298048885e45535Status# Downloaded newer image for ubuntu#latest495ec2ab0b201418999e159b81a934072be504b05cc278192d8152efd4965635[xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ docker psCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES495ec2ab0b20        ubuntu              ~bash~              7 minutes ago       Up 7 minutes                            ubuntu[xr-vm_node0_RP0_CPU0#~]$ ```    You will notice two peculiar things in the command we run#            Mounting of /var/run/netns/&lt;vrf-name&gt;# We mount /var/run/netns/&lt;vrf-name&gt; into the docker container. This is an option we use to mount the appropriate network namespace(s) (one or more -v options may be used) into the container. These network namespaces (XR release 6.3.1+) are created on the host and then bind-mounted into the XR LXC for user convenience. In case of ASR9k, these network namespaces are local. The docker container, running on the host (inside XR VM in case of ASR9k), will simply inherit these network namespaces through the /var/run/netns/&lt;vrf-name&gt; mount. Each Network namespace may correspond to a VRF in XR (CLI option to achieve this will be available post 6.3.1. Bear in mind that before 6.3.1 release only the global-vrf is supported in the XR linux shell.              \u2013cap-add=SYS_ADMIN flag# We\u2019re using the --cap-add=SYS_ADMIN flag because even when network namespaces are mounted from the \u201chost\u201d (or XR VM in case of ASR9k) into the docker container, a user can change into a particular network namespace or execute commands in a particular namespace, only if the container is launched with privileged capabilties.      Yay! The container\u2019s running. We can get into the container by starting bash through a docker exec. If you\u2019re running container images that do not support a shell, try docker attach instead.[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$docker exec -it ubuntu bashroot@bf408eb70f88#/# root@bf408eb70f88#/# cat /etc/*-release DISTRIB_ID=UbuntuDISTRIB_RELEASE=16.04DISTRIB_CODENAME=xenialDISTRIB_DESCRIPTION=~Ubuntu 16.04.2 LTS~NAME=~Ubuntu~VERSION=~16.04.2 LTS (Xenial Xerus)~ID=ubuntuID_LIKE=debianPRETTY_NAME=~Ubuntu 16.04.2 LTS~VERSION_ID=~16.04~HOME_URL=~http#//www.ubuntu.com/~SUPPORT_URL=~http#//help.ubuntu.com/~BUG_REPORT_URL=~http#//bugs.launchpad.net/ubuntu/~VERSION_CODENAME=xenialUBUNTU_CODENAME=xenialroot@bf408eb70f88#/# NCS5500 and ASR9k SetupRemember the topology for the NCS5508/ASR9k setup?# NCS5500 and ASR9k Setup TopologyIn order to reach the internet, the NCS5508/ASR9k needs to be configured with a default route through the Management port which is NAT-ted (using iptables Masquerade rules, not shown here) to the outside world through devbox.Note# Steps below are applicable to ASR9k as well.Read the note below if you need a refresher on the routing in XR\u2019s linux kernel#  Setting up Default routes in the Linux Kernel#  For those who understand the basic principle behind the IOS-XR Packet I/O architecture for Linux application traffic (see here# Application hosting Infrastructure in IOS-XR ), it might be clear that routes in the linux kernel are controlled through the \u201ctpa\u201d CLI.  This leads to 3 types of routes#      Default route through \u201cfwdintf\u201d # To allow packets through the front panel ports by default. Herein the update-source CLI is used to set the source IP address of the packets.    East-West route through \u201cfwd_ew\u201d # This enables packets to flow between XR and a linux app running in a given vrf (network namespace - only global-vrf supported before 6.3.1 release).    Management Subnet#  The directly connected subnet for the Management port as well non-default routes in the RIB through the Management port.  To set up a default route through the Management port#Prior to 6.3.1 releasePrior to 6.3.1, there is no direct knob in the tpa CLI to help set this up. So we drop into the linux shell directly and set the default route ourselves#RP/0/RP0/CPU0#ncs5508#bashWed Mar  8 02#06#54.590 UTC[ncs5508#~]$[ncs5508#~]$[ncs5508#~]$ip routedefault dev fwdintf  scope link  src 1.1.1.1 10.10.10.10 dev fwd_ew  scope link  src 1.1.1.1 11.11.11.0/24 dev Mg0_RP0_CPU0_0  proto kernel  scope link  src 11.11.11.59 [ncs5508#~]$[ncs5508#~]$[ncs5508#~]$ip route del default[ncs5508#~]$ip route add default via 11.11.11.2 dev Mg0_RP0_CPU0_0[ncs5508#~]$[ncs5508#~]$ip routedefault via 11.11.11.2 dev Mg0_RP0_CPU0_0 10.10.10.10 dev fwd_ew  scope link  src 1.1.1.1 11.11.11.0/24 dev Mg0_RP0_CPU0_0  proto kernel  scope link  src 11.11.11.59 [ncs5508#~]$Having done the above change, set up the DNS server in global-vrf network namespace, much like in the Vagrant setup#[ncs5508#~]$cat /etc/netns/global-vrf/resolv.confnameserver ######[ncs5508#~]$Of course, use an actual IP address of the DNS server in your network, and not #####. I use it to simply hide the private DNS IP in my setup #)[ncs5508#~]$[ncs5508#~]$[ncs5508#~]$docker run -itd --name ubuntu --cap-add=SYS_ADMIN -v /var/run/netns#/var/run/netns ubuntu bashUnable to find image 'ubuntu#latest' locallylatest# Pulling from library/ubuntud54efb8db41d# Pull complete f8b845f45a87# Pull complete e8db7bf7c39f# Pull complete 9654c40e9079# Pull complete 6d9ef359eaaa# Pull complete Digest# sha256#dd7808d8792c9841d0b460122f1acf0a2dd1f56404f8d1e56298048885e45535Status# Downloaded newer image for ubuntu#latest67b781a19b5a164d77ee7ed95201c422e70be57c9ee6547a7e8e9457f8db514b[ncs5508#~]$[ncs5508#~]$[ncs5508#~]$docker psCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES67b781a19b5a        ubuntu              ~bash~              3 minutes ago       Up 3 minutes                            ubuntu[ncs5508#~]$Post 6.3.1 releasePost 6.3.1, the default route wouldn\u2019t have to be set using the linux command (ip route default\u2026). We have introduced a default-route CLI under tpa (along with vrfs, but more on that in another blog).The CLI will look something like #tpa  vrf &lt;vrf-name&gt;    address-family ipv4[ipv6]      default-route east-westThe advantage of introducing a CLI is that it helps handle the routes in the linux kernel across reloads and switchovers as well.Private \u201cinsecure\u201d registryThis is a straightforward technique when a user expects to bring up private registries for their docker images in a secure part of the network (so that connection between the registry and the router doesn\u2019t necessarily need to be secured) #      We spin up an insecure docker registry(which is itself a docker container pulled down from dockerhub) on our devbox.        We then modify /etc/sysconfig/docker in XR linux to add the insecure registry information        Set up the route to the registry        Populate the registry with some docker images from dockerhub        Pull the relevant images from the insecure registry down to XR\u2019s docker daemon and spin up containers  Setting up the insecure registryLet\u2019s begin by spinning up a registry on the devbox in our Vagrant setup. The same exact steps are relevant to the devbox environment on the NCS5500/ASR9k setup as well. We follow the steps described here# https#//docs.docker.com/registry/deploying/AKSHSHAR-M-K0DS#docker-app-topo-bootstrap akshshar$vagrant ssh devbox Welcome to Ubuntu 14.04.5 LTS (GNU/Linux 3.13.0-95-generic x86_64) * Documentation#  https#//help.ubuntu.com/ System information disabled due to load higher than 1.0  Get cloud support with Ubuntu Advantage Cloud Guest#    http#//www.ubuntu.com/business/services/cloud0 packages can be updated.0 updates are security updates.New release '16.04.2 LTS' available.Run 'do-release-upgrade' to upgrade to it.vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ sudo -s root@vagrant-ubuntu-trusty-64#~# root@vagrant-ubuntu-trusty-64#~# docker run -d -p 5000#5000 --restart=always --name registry registry#2Unable to find image 'registry#2' locally2# Pulling from library/registry709515475419# Pull complete df6e278d8f96# Pull complete 16218e264e88# Pull complete 16748da81f63# Pull complete 8d73e673c34c# Pull complete Digest# sha256#28be0609f90ef53e86e1872a11d672434ce1361711760cf1fe059efd222f8d37Status# Downloaded newer image for registry#2b6a2a5fef7b7c201ee4d162b56f1e35054e25225ad27ad3fbf3a267d2ef9fb7aroot@vagrant-ubuntu-trusty-64#~# root@vagrant-ubuntu-trusty-64#~# docker pull ubuntu &amp;&amp; docker tag ubuntu localhost#5000/ubuntuUsing default tag# latestlatest# Pulling from library/ubuntud54efb8db41d# Pull complete f8b845f45a87# Pull complete e8db7bf7c39f# Pull complete 9654c40e9079# Pull complete 6d9ef359eaaa# Pull complete Digest# sha256#dd7808d8792c9841d0b460122f1acf0a2dd1f56404f8d1e56298048885e45535Status# Downloaded newer image for ubuntu#latestroot@vagrant-ubuntu-trusty-64#~# root@vagrant-ubuntu-trusty-64#~# docker push localhost#5000/ubuntu The push refers to a repository [localhost#5000/ubuntu]56827159aa8b# Pushed 440e02c3dcde# Pushed 29660d0e5bb2# Pushed 85782553e37a# Pushed 745f5be9952c# Pushed latest# digest# sha256#6b079ae764a6affcb632231349d4a5e1b084bece8c46883c099863ee2aeb5cf8 size# 1357root@vagrant-ubuntu-trusty-64#~# root@vagrant-ubuntu-trusty-64#~#    In the above steps, we\u2019ve simply set up the registry on the devbox, pulled down an ubuntu docker image from dockerhub and pushed the image to the local registry.Vagrant SetupBefore we start let\u2019s come back to square-one on our Vagrant setup. Delete the previously running container and downloaded image#[xr-vm_node0_RP0_CPU0#~]$ docker stop ubuntu &amp;&amp; docker rm ubuntuubuntuubuntu[xr-vm_node0_RP0_CPU0#~]$ docker rmi ubuntuUntagged# ubuntu#latestDeleted# sha256#0ef2e08ed3fabfc44002ccb846c4f2416a2135affc3ce39538834059606f32ddDeleted# sha256#0d58a35162057295d273c5fb8b7e26124a31588cdadad125f4bce63b638dddb5Deleted# sha256#cb7f997e049c07cdd872b8354052c808499937645f6164912c4126015df036ccDeleted# sha256#fcb4581c4f016b2e9761f8f69239433e1e123d6f5234ca9c30c33eba698487ccDeleted# sha256#b53cd3273b78f7f9e7059231fe0a7ed52e0f8e3657363eb015c61b2a6942af87Deleted# sha256#745f5be9952c1a22dd4225ed6c8d7b760fe0d3583efd52f91992463b53f7aea3[xr-vm_node0_RP0_CPU0#~]$ Now let\u2019s set up XR\u2019s docker daemon to accept the insecure registry located on the directly connected network on Gig0/0/0/0.Based off the config applied via the Vagrantfile, the reachable IP address of the registry running on devbox = 11.1.1.20, port 5000.Log into XR CLI. We will first make sure that the request from XR\u2019s docker daemon originates with a source IP that is reachable from the docker registry. So set the TPA ip address = Gig0/0/0/0 ip address (directly connected subnet)#RP/0/RP0/CPU0#ios(config)#tpaRP/0/RP0/CPU0#ios(config-tpa)#address-family ipv4 ?  update-source  Update the Source for Third Party  &lt;cr&gt;           RP/0/RP0/CPU0#ios(config-tpa)#address-family ipv4 RP/0/RP0/CPU0#ios(config-tpa-afi)#update-source gigabitEthernet 0/0/0/0 RP/0/RP0/CPU0#ios(config-tpa-afi)#commitMon Mar  6 05#08#32.436 UTCRP/0/RP0/CPU0#ios(config-tpa-afi)#This should lead to the following routes in the linux kernel#RP/0/RP0/CPU0#ios#RP/0/RP0/CPU0#ios#bashMon Mar  6 05#35#49.459 UTC[xr-vm_node0_RP0_CPU0#~]$ip routedefault dev fwdintf  scope link  src 11.1.1.10 10.0.2.0/24 dev Mg0_RP0_CPU0_0  proto kernel  scope link  src 10.0.2.15 [xr-vm_node0_RP0_CPU0#~]$Before we launch the container, we need to configure the XR docker daemon to disregard security for our registry. This is done by modifying /etc/sysconfig/docker inside the XR LXC. My eventual configuration looks something like#[xr-vm_node0_RP0_CPU0#~]$cat /etc/sysconfig/docker# DOCKER_OPTS can be used to add insecure private registries to be supported # by the docker daemon# eg # DOCKER_OPTS=~--insecure-registry foo --insecure-registry bar~# Following are the valid configs# DOCKER_OPTS=~&lt;space&gt;--insecure-registry&lt;space&gt;foo~# DOCKER_OPTS+=~&lt;space&gt;--insecure-registry&lt;space&gt;bar~DOCKER_OPTS=~ --insecure-registry 11.1.1.20#5000~[xr-vm_node0_RP0_CPU0#~]$As the instructions/comments inside the file indicate, make sure there is a space before \u2013insecure-registry flag. Further, in a normal docker daemon setup, a user is supposed to restart the docker daemon when changes to /etc/sysconfig/docker are made. In case of XR, this is not needed. We handle automatic restarts of the docker daemon when a user makes changes to /etc/sysconfig/docker and saves it. Further, since the docker daemon will be automatically restarted, wait for about 10-15 seconds before issuing any docker commands.Now issue the docker run command to launch the container on XR.RP/0/RP0/CPU0#ios#RP/0/RP0/CPU0#ios#bashMon Mar  6 05#51#14.341 UTC[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$docker run -itd --name ubuntu -v /var/run/netns --cap-add=SYS_ADMIN 11.1.1.20#5000/ubuntu bashUnable to find image '11.1.1.20#5000/ubuntu#latest' locallylatest# Pulling from ubuntufec6b243e075# Pull complete 190e0e9a3e79# Pull complete 0d79cf192e4c# Pull complete 38398c307b51# Pull complete 356665655a72# Pull complete Digest# sha256#6b079ae764a6affcb632231349d4a5e1b084bece8c46883c099863ee2aeb5cf8Status# Downloaded newer image for 11.1.1.20#5000/ubuntu#latestbf408eb70f88c8050c29fb46610d354a113a46edbece105acc68507e71442d38[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$docker psCONTAINER ID        IMAGE                   COMMAND             CREATED             STATUS              PORTS               NAMESbf408eb70f88        11.1.1.20#5000/ubuntu   ~bash~              8 seconds ago       Up 8 seconds                            ubuntu[xr-vm_node0_RP0_CPU0#~]$There, you\u2019ve launched a docker container on XR using a private \u201cinsecure\u201d registry.NCS5500 setupThe workflow is more or less identical to the Vagrant setup.In this case we\u2019re setting up the registry to be reachable over the Management network (and over the same subnet). For this, you don\u2019t need to set the TPA IP.If you\u2019ve followed the steps above in the Setting up the Insecure Registry section, then you should have an insecure registry already running on the devbox environment, along with a \u201cpushed\u201d ubuntu image.Now hop over to the NCS5500 and issue the \u201cbash\u201d CLI. Your \u201cip route\u201d setup should look something like this#RP/0/RP0/CPU0#ncs5508#bashTue Mar  7 00#29#56.416 UTC[ncs5508#~]$ip routedefault dev fwdintf  scope link  src 1.1.1.110.10.10.10 dev fwd_ew  scope link  src 1.1.1.1 11.11.11.0/24 dev Mg0_RP0_CPU0_0  proto kernel  scope link  src 11.11.11.59[ncs5508#~]$[ncs5508#~]$[ncs5508#~]$We won\u2019t be leveraging the tpa setup for the fwdintf interface (meant for reachability over front panel/data ports) and instead just use the local management network subnet (11.11.11.0/24) for reachability to the docker registry.Further, much like before, set up /etc/sysconfig/docker to disregard security for our registry.[ncs5508#~]$cat /etc/sysconfig/docker# DOCKER_OPTS can be used to add insecure private registries to be supported # by the docker daemon# eg # DOCKER_OPTS=~--insecure-registry foo --insecure-registry bar~# Following are the valid configs# DOCKER_OPTS=~&lt;space&gt;--insecure-registry&lt;space&gt;foo~# DOCKER_OPTS+=~&lt;space&gt;--insecure-registry&lt;space&gt;bar~DOCKER_OPTS=~ --insecure-registry 11.11.11.2#5000~[ncs5508#~]$When you make the above change,the docker daemon will be automatically restarted. Wait for about 10-15 seconds before issuing any docker commands.Now we can issue a docker run (or docker pull followed by a docker run) to download and launch the docker ubuntu image from the registry.[ncs5508#~]$docker run -itd --name ubuntu -v /var/run/netns --cap-add=SYS_ADMIN 11.11.11.2#5000/ubuntuUnable to find image '11.11.11.2#5000/ubuntu#latest' locallylatest# Pulling from ubuntud54efb8db41d# Pull complete f8b845f45a87# Pull complete e8db7bf7c39f# Pull complete 9654c40e9079# Pull complete 6d9ef359eaaa# Pull complete Digest# sha256#dd7808d8792c9841d0b460122f1acf0a2dd1f56404f8d1e56298048885e45535Status# Downloaded newer image for 11.11.11.2#5000/ubuntu#latestaa73f6a81b9346131118b84f30ddfc2d3bd981a4a54ea21ba2e2bc5c3d18d348[ncs5508#~]$[ncs5508#~]$docker psCONTAINER ID        IMAGE                    COMMAND             CREATED             STATUS              PORTS               NAMESaa73f6a81b93        11.11.11.2#5000/ubuntu   ~/bin/bash~         4 hours ago         Up 4 hours                              ubuntu[ncs5508#~]$ASR9k setupThe ASR9k setup for an insecure docker registry is slightly different from Vagrant IOS-XR or NCS platforms. There is no automatic mechanism to restart the docker daemon.The user must restart the docker daemon once they modify the /etc/sysconfig/docker file.Again, we\u2019re setting up the registry to be reachable over the Management network (and over the same subnet). For this, you don\u2019t need to set the TPA IP.Now hop over to the ASR9k and issue the \u201cbash\u201d CLI. Your \u201cip route\u201d setup should look something like this#RP/0/RSP1/CPU0#asr9k#bashTue Mar  7 00#29#56.416 UTC[asr9k#~]$ip routedefault dev fwdintf  scope link  src 1.1.1.110.10.10.10 dev fwd_ew  scope link  src 1.1.1.1 11.11.11.0/24 dev Mg0_RP0_CPU0_0  proto kernel  scope link  src 11.11.11.59[asr9k#~]$[asr9k#~]$[asr9k#~]$We won\u2019t be leveraging the tpa setup for the fwdintf interface (meant for reachability over front panel/data ports) and instead just use the local management network subnet (11.11.11.0/24) for reachability to the docker registry.Further, much like before, set up /etc/sysconfig/docker to disregard security for our registry.[asr9k#~]$cat /etc/sysconfig/docker# DOCKER_OPTS can be used to add insecure private registries to be supported # by the docker daemon# eg # DOCKER_OPTS=~--insecure-registry foo --insecure-registry bar~# Following are the valid configs# DOCKER_OPTS=~&lt;space&gt;--insecure-registry&lt;space&gt;foo~# DOCKER_OPTS+=~&lt;space&gt;--insecure-registry&lt;space&gt;bar~DOCKER_OPTS=~ --insecure-registry 11.11.11.2#5000~[asr9k#~]$Important# For the ASR9k, you need to restart the docker daemon for the above config change to take effect.[asr9k#~]$service docker restartdocker stop/waitingdocker start/running, process 12276[asr9k#~]$Now we can issue a docker run (or docker pull followed by a docker run) to download and launch the docker ubuntu image from the registry.[asr9k#~]$docker run -itd --name ubuntu -v /var/run/netns --cap-add=SYS_ADMIN 11.11.11.2#5000/ubuntuUnable to find image '11.11.11.2#5000/ubuntu#latest' locallylatest# Pulling from ubuntud54efb8db41d# Pull complete f8b845f45a87# Pull complete e8db7bf7c39f# Pull complete 9654c40e9079# Pull complete 6d9ef359eaaa# Pull complete Digest# sha256#dd7808d8792c9841d0b460122f1acf0a2dd1f56404f8d1e56298048885e45535Status# Downloaded newer image for 11.11.11.2#5000/ubuntu#latestaa73f6a81b9346131118b84f30ddfc2d3bd981a4a54ea21ba2e2bc5c3d18d348[ncs5508#~]$[ncs5508#~]$docker psCONTAINER ID        IMAGE                    COMMAND             CREATED             STATUS              PORTS               NAMESaa73f6a81b93        11.11.11.2#5000/ubuntu   ~/bin/bash~         4 hours ago         Up 4 hours                              ubuntu[asr9k#~]$Private Self-Signed RegistryThis technique is a bit more secure than the insecure registry setup and may be used to more or less secure the connection between the router\u2019s docker daemon and the docker registry running externally. The basic steps involved are#      Generate your own certificate on the devbox        Use the result to start your docker registry with TLS enabled        Copy the certificates to the /etc/docker/certs.d/ folder on the router        Don\u2019t forget to restart the Docker daemon for the ASR9k. In case of other platforms, the restart is automatic        Set up the route to the registry        Populate the registry with some docker images from dockerhub        Pull the relevant images from the registry down to XR\u2019s docker daemon and spin up containers  Setting up a self-signed Docker RegistryAKSHSHAR-M-K0DS#docker-app-topo-bootstrap akshshar$ vagrant ssh devboxWelcome to Ubuntu 14.04.5 LTS (GNU/Linux 3.13.0-95-generic x86_64) * Documentation#  https#//help.ubuntu.com/ System information disabled due to load higher than 1.0  Get cloud support with Ubuntu Advantage Cloud Guest#    http#//www.ubuntu.com/business/services/cloud0 packages can be updated.0 updates are security updates.New release '16.04.2 LTS' available.Run 'do-release-upgrade' to upgrade to it.vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ mkdir -p certs &amp;&amp; openssl req -newkey rsa#4096 -nodes -sha256 -keyout certs/domain.key -x509 -days 365 -out certs/domain.crt Generating a 4096 bit RSA private key.......................++..........................++writing new private key to 'certs/domain.key'-----You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter '.', the field will be left blank.-----Country Name (2 letter code) [AU]#State or Province Name (full name) [Some-State]#Locality Name (eg, city) []#Organization Name (eg, company) [Internet Widgits Pty Ltd]#Organizational Unit Name (eg, section) []#Common Name (e.g. server FQDN or YOUR name) []#devbox.comEmail Address []#vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ cd certs/vagrant@vagrant-ubuntu-trusty-64#~/certs$ lsdomain.crt  domain.keyvagrant@vagrant-ubuntu-trusty-64#~/certs$ vagrant@vagrant-ubuntu-trusty-64#~/certs$ vagrant@vagrant-ubuntu-trusty-64#~/certs$ vagrant@vagrant-ubuntu-trusty-64#~/certs$ cd ..vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ sudo docker run -d -p 5000#5000 --restart=always --name registry -v `pwd`/certs#/certs -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key registry#2 Unable to find image 'registry#2' locally2# Pulling from library/registry709515475419# Pull complete df6e278d8f96# Pull complete 16218e264e88# Pull complete 16748da81f63# Pull complete 8d73e673c34c# Pull complete Digest# sha256#28be0609f90ef53e86e1872a11d672434ce1361711760cf1fe059efd222f8d37Status# Downloaded newer image for registry#2c423ae398af2ec05fabd9c1efc29b846b21c63af71ed0b59ba6ec7f4d13a6762vagrant@vagrant-ubuntu-trusty-64#~$ sudo docker ps CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMESc423ae398af2        registry#2          ~/entrypoint.sh /e...~   5 seconds ago       Up 4 seconds        0.0.0.0#5000-&gt;5000/tcp   registryvagrant@vagrant-ubuntu-trusty-64#~$ Now pull an ubuntu image (just an example) from dockerhub and push it to the local registry#vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ sudo -sroot@vagrant-ubuntu-trusty-64#~# root@vagrant-ubuntu-trusty-64#~# docker pull ubuntu &amp;&amp; docker tag ubuntu localhost#5000/ubuntu Using default tag# latestlatest# Pulling from library/ubuntud54efb8db41d# Pull complete f8b845f45a87# Pull complete e8db7bf7c39f# Pull complete 9654c40e9079# Pull complete 6d9ef359eaaa# Pull complete Digest# sha256#dd7808d8792c9841d0b460122f1acf0a2dd1f56404f8d1e56298048885e45535Status# Downloaded newer image for ubuntu#latestroot@vagrant-ubuntu-trusty-64#~# root@vagrant-ubuntu-trusty-64#~# root@vagrant-ubuntu-trusty-64#~# root@vagrant-ubuntu-trusty-64#~#  docker push localhost#5000/ubuntu The push refers to a repository [localhost#5000/ubuntu]56827159aa8b# Layer already exists 440e02c3dcde# Layer already exists 29660d0e5bb2# Layer already exists 85782553e37a# Layer already exists 745f5be9952c# Layer already exists latest# digest# sha256#6b079ae764a6affcb632231349d4a5e1b084bece8c46883c099863ee2aeb5cf8 size# 1357root@vagrant-ubuntu-trusty-64#~# root@vagrant-ubuntu-trusty-64#~# docker images REPOSITORY              TAG                 IMAGE ID            CREATED             SIZEregistry                2                   047218491f8c        5 weeks ago         33.2 MBubuntu                  latest              0ef2e08ed3fa        5 weeks ago         130 MBlocalhost#5000/ubuntu   latest              0ef2e08ed3fa        5 weeks ago         130 MBroot@vagrant-ubuntu-trusty-64#~# Vagrant SetupAll we have to do get out docker daemon on the router working with the self-signed docker registry is to make sure the certificate is available in the right directory# /etc/docker/certs.d/ in the XR shell.Hop over to the router and create folder with name = \u201c&lt;Common Name of the certificate&gt;#5000\u201d in the folder /etc/docker/certs.d/ as shown below#Hop into the router shell from your host/laptop#AKSHSHAR-M-K0DS#docker-app-topo-bootstrap akshshar$ vagrant ssh rtrLast login# Sun Apr  2 13#45#29 2017 from 10.0.2.2xr-vm_node0_RP0_CPU0#~$ xr-vm_node0_RP0_CPU0#~$ xr-vm_node0_RP0_CPU0#~$ xr-vm_node0_RP0_CPU0#~$ sudo -i[xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ Create a folder named devbox.com#5000 under /etc/docker/certs.d.The folder name = &amp;lt;Common Name of the certificate&amp;gt;#&amp;lt;Port opened by the registry&amp;gt;[xr-vm_node0_RP0_CPU0#~]$ mkdir /etc/docker/certs.d/devbox.com#5000[xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ Add the dns entry for devbox.com in /etc/hosts of the vrf you\u2019re working in. Since before 6.3.1, we only support global-vrf in the linux kernel, we set up /etc/hosts of the global-vrf network namespace to create a pointer to devbox.com. To do this change into the correct network namespace (global-vrf) and edit /etc/hosts as shown below#Another way to do this would be to edit  /etc/netns/global-vrf/hosts file and then change into the network namespace for the subsequent scp to immediately work.[xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ ip netns exec global-vrf bash[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$ cat /etc/hosts 127.0.0.1\tlocalhost.localdomain\t\tlocalhost11.1.1.20       devbox.com [xr-vm_node0_RP0_CPU0#~]$ Here, 11.1.1.20 is the IP address of the directly connected interface of the devbox on the port Gi0/0/0/0 of the IOS-XR instance.[xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ scp vagrant@devbox.com#~/certs/domain.crt /etc/docker/certs.d/devbox.com\\#5000/ca.crtvagrant@devbox.com's password# domain.crt                                                                                                                                                              100% 1976     1.9KB/s   00#00    [xr-vm_node0_RP0_CPU0#~]$ Perfect. Now wait about 5-10 seconds as the certificate gets automatically sync-ed to the underlying host layer (remember, the docker daemon is running on the host).Pull the docker image from the registry#[xr-vm_node0_RP0_CPU0#~]$ docker pull devbox.com#5000/ubuntuUsing default tag# latestlatest# Pulling from ubuntufec6b243e075# Pull complete 190e0e9a3e79# Pull complete 0d79cf192e4c# Pull complete 38398c307b51# Pull complete 356665655a72# Pull complete Digest# sha256#6b079ae764a6affcb632231349d4a5e1b084bece8c46883c099863ee2aeb5cf8Status# Downloaded newer image for devbox.com#5000/ubuntu#latest[xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ docker images REPOSITORY               TAG                 IMAGE ID            CREATED             SIZEdevbox.com#5000/ubuntu   latest              0ef2e08ed3fa        4 weeks ago         130 MB[xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ Spin it up! #[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$ docker run -itd --name ubuntu -v /var/run/netns/global-vrf#/var/run/netns/global-vrf --cap-add=SYS_ADMIN devbox.com#5000/ubuntu bashb50424bbe195fd4b79c0d375dcc081228395da467d1c0d5367897180c421b41d[xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ docker psCONTAINER ID        IMAGE                    COMMAND             CREATED             STATUS              PORTS               NAMESb50424bbe195        devbox.com#5000/ubuntu   ~bash~              4 seconds ago       Up 3 seconds                            ubuntu[xr-vm_node0_RP0_CPU0#~]$ NCS5500 and ASR9k SetupThe setup of the self-signed registry is already covered above in the Setting up a Self-Signed Docker Registry section.The steps for NCS5500 and ASR9k are identical from hereon and match what we did for the Vagrant setup. To be thorough, here are the steps on an NCS5500 setup#Hop over to the router and issue the \u201cbash\u201d CLI.Now change into the network namespace (explicitly) and set up /etc/hosts (In my setup, the devbox is reachable over the management port on IP=11.11.11.2) #[ncs5508#~]$ip netns exec global-vrf bash [ncs5508#~]$cat /etc/hosts127.0.0.1\tlocalhost.localdomain\t\tlocalhost127.0.1.1    ncs5508.cisco.com    ncs550811.11.11.2 devbox.com[ncs5508#~]$[ncs5508#~]$[ncs5508#~]$Set up the directory to store the certificates created for the docker registry#[ncs5508#~]$[ncs5508#~]$mkdir /etc/docker/certs.d/devbox.com#5000[ncs5508#~]$[ncs5508#~]$scp over the self-signed certificate from the devbox into the above directory#[ncs5508#~]$scp cisco@devbox.com#~/certs/domain.crt /etc/docker/certs.d/devbox.com\\#5000/ca.crtWarning# Permanently added 'devbox.com,11.11.11.2' (ECDSA) to the list of known hosts.cisco@devbox.com's password# domain.crt                                    100% 1976     1.9KB/s   00#00    [ncs5508#~]$Now pull the docker image from the registry and spin it up#[ncs5508#~]$docker pull devbox.com#5000/ubuntuUsing default tag# latestlatest# Pulling from ubuntud54efb8db41d# Pull complete f8b845f45a87# Pull complete e8db7bf7c39f# Pull complete 9654c40e9079# Pull complete 6d9ef359eaaa# Pull complete Digest# sha256#dd7808d8792c9841d0b460122f1acf0a2dd1f56404f8d1e56298048885e45535Status# Downloaded newer image for devbox.com#5000/ubuntu#latest[ncs5508#~]$[ncs5508#~]$  docker run -itd --name ubuntu -v /var/run/netns/global-vrf#/var/run/netns/global-vrf --cap-add=SYS_ADMIN devbox.com#5000/ubuntu bash3b4721fa053a97325ccaa2ac98b3dc3fd9fb224543e0ed699be597f773ab875d[ncs5508#~]$[ncs5508#~]$[ncs5508#~]$docker psCONTAINER ID        IMAGE                    COMMAND             CREATED             STATUS              PORTS               NAMES3b4721fa053a        devbox.com#5000/ubuntu   ~bash~              5 seconds ago       Up 4 seconds                            ubuntu[ncs5508#~]$Docker Save/Load TechniqueThis is the potentially the easiest secure technique if you don\u2019t want to meddle around with certificates on a docker registry and potentially don\u2019t want a registry at all.Create a docker image tarballAs a first step, on your devbox create a docker image tar ball. You can either pull the relevant docker image into your devbox (From dockerhub or some other private registry) or build it on your own on the devbox (we will not delve into this here# for details# https#//docs.docker.com/engine/getstarted/step_four/).Once you have the image locally, issue a docker save to save the image into a loadable tar-ball.This is shown below#vagrant@vagrant-ubuntu-trusty-64#~$ sudo docker images REPOSITORY              TAG                 IMAGE ID            CREATED             SIZEregistry                2                   047218491f8c        5 weeks ago         33.2 MBlocalhost#5000/ubuntu   latest              0ef2e08ed3fa        5 weeks ago         130 MBubuntu                  latest              0ef2e08ed3fa        5 weeks ago         130 MBvagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ sudo docker save ubuntu &gt; ubuntu.tar vagrant@vagrant-ubuntu-trusty-64#~$ Vagrant SetupLogin to your Router (directly into the shell or by issuing the bash command in XR CLI). We first scp the docker image tar ball into an available volume on the router and then load it up.[xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ df -h  /misc/app_host/Filesystem                       Size  Used Avail Use% Mounted on/dev/mapper/app_vol_grp-app_lv0  3.9G  260M  3.5G   7% /misc/app_host[xr-vm_node0_RP0_CPU0#~]$ scp vagrant@11.1.1.20#~/ubuntu.tar /misc/app_host/vagrant@11.1.1.20's password# ubuntu.tar                                                                                                                                                             100%  129MB 107.7KB/s   20#31    [xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$  docker load &lt; /misc/app_host/ubuntu.tar [xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ docker imagesREPOSITORY               TAG                 IMAGE ID            CREATED             SIZEubuntu                   latest              0ef2e08ed3fa        4 weeks ago         130 MB[xr-vm_node0_RP0_CPU0#~]$ Now go ahead and spin it up as shown earlier#[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$ docker run -itd --name ubuntu -v /var/run/netns/global-vrf#/var/run/netns/global-vrf --cap-add=SYS_ADMIN ubuntu bashb50424bbe195fd4b79c0d375dcc081228395da467d1c0d5367897180c421b41d[xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ docker psCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES108a5ad711ca        ubuntu              ~bash~              3 seconds ago       Up 2 seconds                            ubuntu[xr-vm_node0_RP0_CPU0#~]$ NCS5500 and ASR9k setup.NCS5500 and ASR9k follow the exact same steps as the Vagrant box above. For completeness, though#[ncs5508#~]$[ncs5508#~]$scp cisco@11.11.11.2#~/ubuntu.tar /misc/app_host/cisco@11.11.11.2's password# ubuntu.tar                                    100%  317MB  10.2MB/s   00#31    [ncs5508#~]$[ncs5508#~]$docker load &lt; /misc/app_host/ubuntu.tar [ncs5508#~]$[ncs5508#~]$[ncs5508#~]$[ncs5508#~]$docker psCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES[ncs5508#~]$[ncs5508#~]$ docker run -itd --name ubuntu -v /var/run/netns/global-vrf#/var/run/netns/global-vrf --cap-add=SYS_ADMIN ubuntu bashffc95e05e05c6e2e6b8e4aa05b299f513fd5df6d1ca8fe641cfa7f44671e6f07[ncs5508#~]$[ncs5508#~]$[ncs5508#~]$docker psCONTAINER ID        IMAGE               COMMAND             CREATED              STATUS              PORTS               NAMESffc95e05e05c        ubuntu              ~bash~              About a minute ago   Up About a minute                       ubuntu[ncs5508#~]$Docker export/import TechniqueA lot of times you might create a tar ball from a custom Docker container on your server (devbox) and would like to run the custom container directly on the router. This technique explores that option.Create a custom docker Container tarball/snapshotAs a first step, on your devbox spin up a docker container from an image you\u2019d like to customize.Assuming you\u2019ve already learnt how to pull docker images into your devbox environment, let\u2019s spin up an ubuntu container and install iproute2 on it#root@vagrant-ubuntu-trusty-64#~# docker images ubuntuREPOSITORY          TAG                 IMAGE ID            CREATED             SIZEubuntu              latest              0ef2e08ed3fa        5 weeks ago         130 MBroot@vagrant-ubuntu-trusty-64#~# docker run -itd --name ubuntu ubuntu basha544ddc41b1fd92cf6b7a751dcafaf63de36f6499f59c256918ca23c32645159Now exec into the created container and start installing iproute2 and python(we\u2019ll use this later)#root@vagrant-ubuntu-trusty-64#~#  docker exec -it ubuntu bash root@a544ddc41b1f#/# root@3cc4d9dd0056#/# apt-get update &amp;&amp; apt-get install -y iproute2 pythonGet#1 http#//archive.ubuntu.com/ubuntu xenial InRelease [247 kB]Get#2 http#//archive.ubuntu.com/ubuntu xenial-updates InRelease [102 kB]Get#3 http#//archive.ubuntu.com/ubuntu xenial-security InRelease [102 kB]Get#4 http#//archive.ubuntu.com/ubuntu xenial/main Sources [1103 kB]Get#5 http#//archive.ubuntu.com/ubuntu xenial/restricted Sources [5179 B]############################  SNIP Output  ######################################## Get#18 http#//archive.ubuntu.com/ubuntu xenial-security/universe Sources [30.0 kB]Get#19 http#//archive.ubuntu.com/ubuntu xenial-security/main amd64 Packages [303 kB]Get#20 http#//archive.ubuntu.com/ubuntu xenial-security/restricted amd64 Packages [12.8 kB]Get#21 http#//archive.ubuntu.com/ubuntu xenial-security/universe amd64 Packages [132 kB]############################  SNIP Output  ######################################## The following NEW packages will be installed#  file iproute2 libatm1 libexpat1 libffi6 libmagic1 libmnl0 libpython-stdlib libpython2.7-minimal libpython2.7-stdlib libsqlite3-0 libssl1.0.0 libxtables11 mime-support python  python-minimal python2.7 python2.7-minimal0 upgraded, 4 newly installed, 0 to remove and 8 not upgraded.Need to get 586 kB of archives.After this operation, 1808 kB of additional disk space will be used.Get#1 http#//archive.ubuntu.com/ubuntu xenial/main amd64 libatm1 amd64 1#2.5.1-1.5 [24.2 kB]Get#2 http#//archive.ubuntu.com/ubuntu xenial/main amd64 libmnl0 amd64 1.0.3-5 [12.0 kB]Get#3 http#//archive.ubuntu.com/ubuntu xenial/main amd64 iproute2 amd64 4.3.0-1ubuntu3 [522 kB]Get#4 http#//archive.ubuntu.com/ubuntu xenial/main amd64 libxtables11 amd64 1.6.0-2ubuntu3 [27.2 kB]Fetched 586 kB in 0s (11.1 MB/s)   debconf# delaying package configuration, since apt-utils is not installedSelecting previously unselected package libatm1#amd64.(Reading database ... 7256 files and directories currently installed.)Preparing to unpack .../libatm1_1%3a2.5.1-1.5_amd64.deb ...############################  SNIP Output  ######################################## Setting up libmnl0#amd64 (1.0.3-5) ...Setting up iproute2 (4.3.0-1ubuntu3) ...Setting up libxtables11#amd64 (1.6.0-2ubuntu3) ...Processing triggers for libc-bin (2.23-0ubuntu5) ...root@3cc4d9dd0056#/# exitexitroot@vagrant-ubuntu-trusty-64#~# Finally, use the docker export command to save your custom container tar ball#root@vagrant-ubuntu-trusty-64#~# root@vagrant-ubuntu-trusty-64#~# docker export ubuntu_iproute2 &gt; ubuntu_iproute2.tar root@vagrant-ubuntu-trusty-64#~# ls -l ubuntu_iproute2.tar -rw-r--r-- 1 root root 147474432 Apr  8 11#31 ubuntu_iproute2.tarroot@vagrant-ubuntu-trusty-64#~# Vagrant SetupJust like the previous technique, scp the docker container tar ball into the router, but this time import it#scp the tarball onto the router#AKSHSHAR-M-K0DS#docker-app-topo-bootstrap akshshar$ vagrant ssh rtrxr-vm_node0_RP0_CPU0#~$sudo -i[xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ scp  vagrant@11.1.1.20#~/ubuntu_iproute2.tar /misc/app_host/vagrant@10.0.2.2's password# ubuntu_iproute2.tar                                                                                                                                                     100%  141MB  17.6MB/s   00#08    [xr-vm_node0_RP0_CPU0#~]$ Now import the tar ball and spin up the docker container#[xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ docker import /misc/app_host/ubuntu_iproute2.tar ubuntu_iproute2 sha256#26265a51af3e826b92130ef6bc8a1ead85988908b836c2659164d482e0a73248[xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ docker images ubuntu_iproute2REPOSITORY          TAG                 IMAGE ID            CREATED             SIZEubuntu_iproute2     latest              26265a51af3e        38 seconds ago      141.7 MB[xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ docker run -itd --name ubuntu_iproute2 -v /var/run/netns/global-vrf#/var/run/netns/global-vrf --cap-add=SYS_ADMIN ubuntu_iproute2 bash3736cb8350e324636ebad4822bcd4437451c5ba59b9b5d025c7ba9914afd4379[xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ docker psCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES3736cb8350e3        ubuntu_iproute2     ~bash~              29 seconds ago      Up 28 seconds                           ubuntu_iproute2NCS5500 and ASR9k setup.NCS5500 and ASR9k follow the exact same steps as the Vagrant box above. For completeness, though#RP/0/RP0/CPU0#ncs5508#bashSun Apr  9 11#29#09.531 UTC[ncs5508#~]$[ncs5508#~]$[ncs5508#~]$[ncs5508#~]$[ncs5508#~]$[ncs5508#~]$scp cisco@11.11.11.2#~/ubuntu_iproute2.tar /misc/app_host/cisco@11.11.11.2's password# ubuntu_iproute2.tar                           100%  141MB  10.1MB/s   00#14    [ncs5508#~]$[ncs5508#~]$[ncs5508#~]$docker import /misc/app_host/ubuntu_iproute2.tar  ubuntu_iproute2 sha256#170f8ce009cc920160e47b3e4e7dae1a0711ae4542c9ef0dcfcca4007741a13f[ncs5508#~]$[ncs5508#~]$docker images ubuntu_iproute2REPOSITORY          TAG                 IMAGE ID            CREATED             SIZEubuntu_iproute2     latest              170f8ce009cc        25 seconds ago      141.7 MB[ncs5508#~]$[ncs5508#~]$docker run -itd --name ubuntu_iproute2 -v /var/run/netns/global-vrf#/var/run/netns/global-vrf --cap-add=SYS_ADMIN ubuntu_iproute2 bash 36f8ae4cad2c575885f2c1243a042972dc74e7dd541e270c06628fe141a5f63a[ncs5508#~]$[ncs5508#~]$docker psCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES36f8ae4cad2c        ubuntu_iproute2     ~bash~              4 seconds ago       Up 4 seconds                            ubuntu_iproute2And there you have it! We\u2019ve successfully tried all the possible techniques through which a docker image can be pulled into the router before we spin up the container.What can I do with the Docker container?As a user you might be wondering#  What can processes inside the spun-up Docker container really do?The answer# everything that a native app/agent (running inside the XR process space) can do from the perspective of reachability and binding to XR interface IP addresses.You basically have a distribution of your choice with complete access to XR RIB/FIB (through routes in the kernel) and interfaces (data and management) to bind to.Docker images by default are extremely basic and do not include most utilities. To be able to showcase the kind of access that a container has, I pull in a special ubuntu docker image with pre-installed iproute2. To understand how to do this follow the previous section# Importing a Custom Docker container tar ballAt the end of the previous section you would have the ubuntu_iproute2 container up and running#We\u2019re running the steps below on an NCS5500. But the steps are the same for a vagrant setup or for ASR9k.[ncs5508#~]$docker psCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES36f8ae4cad2c        ubuntu_iproute2     ~bash~              9 minutes ago       Up 9 minutes                            ubuntu_iproute2[ncs5508#~]$Now exec into the running container using docker exec#[ncs5508#~]$[ncs5508#~]$docker exec -it ubuntu_iproute2 bashroot@36f8ae4cad2c#/# root@36f8ae4cad2c#/# To view the IOS-XR network interfaces and the relevant routes in the kernel, exec into the global-vrf network namespace#If you remember, every docker run command we have run till now involves mounting the relevant network namespace into the container under /var/run/netns.root@36f8ae4cad2c#/# ip netns exec global-vrf bash root@36f8ae4cad2c#/# root@36f8ae4cad2c#/# ip routedefault dev fwdintf  scope link  src 11.11.11.59 10.10.10.10 dev fwd_ew  scope link  src 11.11.11.59 11.11.11.0/24 dev Mg0_RP0_CPU0_0  proto kernel  scope link  src 11.11.11.59 root@36f8ae4cad2c#/# root@36f8ae4cad2c#/# root@36f8ae4cad2c#/# ip link show1# lo# &lt;LOOPBACK,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default     link/loopback 00#00#00#00#00#00 brd 00#00#00#00#00#003# fwdintf# &lt;MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UNKNOWN mode DEFAULT group default qlen 1000    link/ether 00#00#00#00#00#0a brd ff#ff#ff#ff#ff#ff4# fwd_ew# &lt;MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UNKNOWN mode DEFAULT group default qlen 1000    link/ether 00#00#00#00#00#0b brd ff#ff#ff#ff#ff#ff7# Hg0_0_0_0# &lt;&gt; mtu 1514 qdisc noop state DOWN mode DEFAULT group default qlen 1000    link/ether 0c#11#67#46#10#00 brd ff#ff#ff#ff#ff#ff8# Hg0_0_0_35# &lt;&gt; mtu 1514 qdisc noop state DOWN mode DEFAULT group default qlen 1000    link/ether 0c#11#67#46#10#8c brd ff#ff#ff#ff#ff#ff9# Hg0_0_0_34# &lt;&gt; mtu 1514 qdisc noop state DOWN mode DEFAULT group default qlen 1000    link/ether 0c#11#67#46#10#88 brd ff#ff#ff#ff#ff#ff10# Hg0_0_0_33# &lt;&gt; mtu 1514 qdisc noop state DOWN mode DEFAULT group default qlen 1000    link/ether 0c#11#67#46#10#84 brd ff#ff#ff#ff#ff#ff############################  SNIP Output  ######################################## 47# Hg0_0_0_1# &lt;&gt; mtu 1514 qdisc noop state DOWN mode DEFAULT group default qlen 1000    link/ether 0c#11#67#46#10#04 brd ff#ff#ff#ff#ff#ff48# Fg0_0_0_32# &lt;&gt; mtu 1514 qdisc noop state DOWN mode DEFAULT group default qlen 1000    link/ether 0c#11#67#46#10#80 brd ff#ff#ff#ff#ff#ff49# Fg0_0_0_28# &lt;&gt; mtu 1514 qdisc noop state DOWN mode DEFAULT group default qlen 1000    link/ether 0c#11#67#46#10#70 brd ff#ff#ff#ff#ff#ff53# Mg0_RP0_CPU0_0# &lt;MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1514 qdisc pfifo_fast state UNKNOWN mode DEFAULT group default qlen 1000    link/ether 80#e0#1d#00#fc#ea brd ff#ff#ff#ff#ff#ffroot@36f8ae4cad2c#/# Awesome! The entire XR routing stack is your oyster #).Testing out a Web ServerLet\u2019s test this setup out quickly. If you remember, we installed python as part of the ubuntu_iproute2 custom container creation. We\u2019ll spin up a python HTTP web server inside the docker container and see if we can reach it from the outside.root@642894d230a8#/# ip netns exec global-vrf bashroot@642894d230a8#/# root@642894d230a8#/# root@642894d230a8#/# ip addr show Mg0_RP0_CPU0_053# Mg0_RP0_CPU0_0# &lt;MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1514 qdisc pfifo_fast state UNKNOWN group default qlen 1000    link/ether 80#e0#1d#00#fc#ea brd ff#ff#ff#ff#ff#ff    inet 11.11.11.59/24 scope global Mg0_RP0_CPU0_0       valid_lft forever preferred_lft forever    inet6 fe80##82e0#1dff#fe00#fcea/64 scope link        valid_lft forever preferred_lft foreverroot@642894d230a8#/# root@642894d230a8#/# root@642894d230a8#/# python -m SimpleHTTPServer 8080root@642894d230a8#/# root@642894d230a8#/# root@642894d230a8#/# echo  ~Hello World~ &gt; /test.txtroot@642894d230a8#/# root@642894d230a8#/# python -m SimpleHTTPServer 8080Serving HTTP on 0.0.0.0 port 8080 ...Hop onto the connected devbox and issue a wget for the test.txt file we created above#root@dhcpserver#~# wget http#//11.11.11.59#8080/test.txt--2017-04-08 12#46#50--  http#//11.11.11.59#8080/test.txtConnecting to 11.11.11.59#8080... connected.HTTP request sent, awaiting response... 200 OKLength# 12 [text/plain]Saving to# \u2018test.txt\u2019100%[========================================================================================================================================&gt;] 12          --.-K/s   in 0s      2017-04-08 12#46#50 (2.13 MB/s) - \u2018test.txt\u2019 saved [12/12]root@dhcpserver#~# The request coming in to the docker container#root@642894d230a8#/# python -m SimpleHTTPServer 8080Serving HTTP on 0.0.0.0 port 8080 ...11.11.11.2 - - [09/Apr/2017 12#09#07] ~GET /test.txt HTTP/1.1~ 200 -Success! It all works as expected.", "url": "https://xrdocs.github.io/application-hosting/tutorials/2017-02-26-running-docker-containers-on-ios-xr-6-1-2/", "tags": "vagrant, iosxr, NCS5500, docker, xr toolbox", "title": "XR toolbox, Part 6: Running Docker Containers on IOS-XR (6.1.2+)", "author": "Akshat Sharma"}, "tutorials-2016-08-26-working-with-ztp": {"content": "     IOS-XR# Working with ZTP  Purpose of ZTP  How ZTP works  ZTP requirement          DHCP server configuration      HTTP Server requirement        ZTP utilities          ztp_helper.sh        ZTP CLI Commands  ZTP Logging          Simple ZTP Example      More Complex Example        Purpose of ZTPZTP was designed to perform 2 different operations#  Download and apply an initial configuration.  Download and execute a shell script.How ZTP worksThe ZTP process is executed or invoked inside the control plane LXC Linux shell. Prior to IOS-XR 6.1.1 ZTP was executed within the default network namespace and could not access directly the data interfaces. Starting with IOS-XR 6.1.1, ZTP is executed inside the global-VRF network namespace with full access to all the data interfaces. This document is based on the IOS-XR 6.1.1 implementation.ZTP is launched from XR process manager (processmgr) when the system reaches level 999 (last processes to be scheduled for execution). At the beginning of its execution, ZTP will scan the configuration for the presence of a username. If there are no username configured, ZTP will fork a DHCP client on the management interface for IPv4 and IPv6 simultaneously, and wait for a response.If the DHCP response contains an option 67 (option 59 for IPv6), ZTP will download the file using the URI provided by option 67 (or option 59 for IPv6).If the file received is not a text file or the file is larger than 100 MB ZTP will erase the file and terminate its execution.Otherwise it will analyze the first line of the text file received, if the first line of the file starts with \u201d!! IOS XR\u201d, it will consider it as a configuration file and pass it to the command line interpreter for syntax verification and commit it.If the first line starts with \u201d#!/bin/bash\u201d or \u201d#!/bin/sh\u201d ZTP will assume this is a script and start the execution, as illustrate below.If the text file cannot be interpreted as a shell script or a configuration file, ZTP will erase the file and terminate its execution.The script can use all the Linux tools available in the Control Plane LXC and perform addition HTTP GET using wget or curl for example to install package and/or download and apply configuration blocks. Note# In IOS-XR release 6.1.1 ZTP can also be invoked from the command line interpreter in this case it will start its execution even if a username or a configuration is present in the system.ZTP requirementZTP requires 2 external services# a DHCP server and an HTTP server, as illustrated above, the support for tftp has been dropped for security and reliability reasons.DHCP server configurationThe basic configuration described below provides a fixed IP address and a configuration file taking in account only the mac address of the management interface.host ncs-5001-rp0 {   hardware ethernet e4#c7#22#be#10#ba;   fixed-address 172.30.12.54;   filename ~http#//172.30.0.22/configs/ncs5001-1.config~;}A more elaborate example that takes into account option 77 or option 15 for IPv6 (user-class) embedded in the dhcp request sent by the client, ZTP embed the string \u201cexr-config\u201d in the DHCP request as described below. The if statement also take into account the capability to re-image the system using iPXE (see iPXE deep dive document)host ncs-5001-rp0 {   hardware ethernet e4#c7#22#be#10#ba;   fixed-address 172.30.12.54;   if exists user-class and option user-class = ~iPXE~ {      filename = ~http#//172.30.0.22/boot.ipxe~;   } elsif exists user-class and option user-class = ~exr-config~ {      filename = ~http#//172.30.0.22/scripts/ncs-5001-rp0_ztp.sh~;   }}Since ZTP does not require any intervention on the system, an easier way to provision the system is to use the serial number printed on the box and/or the RP, the configuration is then as follow#host ncs-5001-rp0 {   option dhcp-client-identifier ~FOC1947R144~;   fixed-address 172.30.12.54;   if exists user-class and option user-class = ~iPXE~ {      filename = ~http#//172.30.0.22/boot.ipxe~;   } elsif exists user-class and option user-class = ~exr-config~ {      filename = ~http#//172.30.0.22/scripts/ncs-5001-rp0_ztp.sh~;   }}Note# The DHCP configuration examples described in this document use the open-source isc-dhcp-server syntax.HTTP Server requirementThe HTTP server should be reachable from the management interface or from a data interface if invoked manually and should be readable.ZTP utilitiesZTP includes a set of CLI commands and a set of shell utilities that can be sourced within the user script.ztp_helper.shztp_helper.sh is a shell script that can be sourced by the user script, it provides simple utilities to access some XR functionalities. These utilities are#xrcmd# Runs an XR exec commandxrcmd \u201cshow running\u201dxrapply# Applies the block of configuration, specified in a file#cat &gt;/tmp/config &lt;&lt;EOF!! XR config examplehostname plutoEOFxrapply /tmp/configxrapply_with_reason# Same as above, but specify a reason for commit history trackingcat &gt;/tmp/config &lt;&lt;EOF!! XR config examplehostname saturnEOFxrapply_with_reason ~this is an important name change~ /tmp/configxrapply_string# Applies a block of configuration specified in a string. Use \u201c\\n\u201d to delimit line of configuration statement.xrapply_string ~hostname mars\\n interface TenGigE0/0/0/0\\n ipv4 address 172.30.0.144/24\\n\u201dxrapply_string_with_reason# As above, but specify a reason for commit history tracking#xrapply_string_with_reason \u201dsystem renamed again~ ~hostname venus\\n interface TenGigE0/0/0/0\\n ipv4 address 172.30.0.144/24\\n\u201dZTP CLI Commandsztp initiate# Invokes a new ZTP DHCP session, logs will go to the console and /disk0#/ztp/ztp.logztp initiate allows the execution of a script even of the system has already been configured. This command is useful for testing ZTP without forcing a reload. This command is particularly useful to test scripts or if some manual operations are required before provisioning the box. With ZTP initiate you can specify any data interfaces on the system to be used for the whole ZTP process.RP/0/RP0/CPU0#venus#ztp initiate debug verbose interface TenGigE 0/0/0/0Invoke ZTP? (this may change your configuration) [confirm] [y/n] #ztp terminate# Terminates any ZTP session in progressRP/0/RP0/CPU0#venus#ztp terminate verboseMon Oct 10 16#52#38.507 UTCTerminate ZTP? (this may leave your system in a partially configured state) [confirm] [y/n] #yZTP terminatedztp breakout# Performs a 4x10 breakout detection on all 40 Gig interfaces, by default if no link is detected on any of the four 10Gig interfaces, the port will remain in 40 Gig mode.The subcommand nosignal-stay-in-breakout-mode will force the port in breakout mode even if there is no link signal detected but will place the interfaces in shutdown mode. The subcommand nosignal-stay-in-state-noshut will leave the port in breakout mode but will place the four 10Gig interface in no shutdown mode.The command \u201cztp breakout\u201d may not be supported on the ASR9K routers.RP/0/RP0/CPU0#venus#ztp breakout ?apply  XR configuration commands to apply(cisco-support)debug  Run with additional logging to the console(cisco-support)hostname  XR hostname to set(cisco-support)nosignal-stay-in-breakout-mode On no signal, prefer interfaces to remain in breakout mode(cisco-support)nosignal-stay-in-state-noshut  On no signal, prefer interfaces to be noshut(cisco-support)verbose  Run with logging to the console(cisco-support)                           ztp clean# Remove all ZTP files saved on diskRP/0/RP0/CPU0#venus#ztp clean verboseMon Oct 10 17#03#43.581 UTCRemove all ZTP temporary files and logs? [confirm] [y/n] #yAll ZTP files have been removed.If you now wish ZTP to run again from boot, do 'conf t/commit replace' followed by reload.ZTP LoggingZTP logs its operation on the flash file system in the directory /disk0#/ztp/. ZTP logs all the transaction with the DHCP server and all the state transition. Prior executions of ZTP are also logged in /disk0#/ztp/old_logs/Simple ZTP ExampleIn the following example we will review the execution of a simple configuration script downloaded from a data interface using the command \u201cztp initiate interface Ten 0/0/0/0 verbose\u201d, this script will unshut all the interfaces of the system and configure a load interval of 30 sec on all of them.#!/bin/bash############################################################################## *** Be careful this is powerful and can potentially destroy your system ***#                *** !!! Use at your own risk !!! ***## Script file should be saved on the backend HTTP server## Tested on NCS-5501 with IOS-XR 6.1.1##############################################################################source ztp_helper.shconfig_file=~/tmp/config.txt~interfaces=$(xrcmd ~show interfaces brief~)function activate_all_if(){  arInt=($(echo $interfaces | grep -oE '(Te|Fo|Hu)[0-9]*/[0-9]*/[0-9]*/[0-9]*'))  for int in ${arInt[*]}; do    echo -ne ~interface $int\\n no shutdown\\n load-interval 30\\n~ &gt;&gt; $config_file  done  xrapply_with_reason ~Initial ZTP configuration~ $config_file}### Script entry pointif [ -f $config_file ]; then  /bin/rm -f $config_fileelse  /bin/touch $config_filefiactivate_all_if;exit 0More Complex ExampleIn this example, the HTTP server hosts a CSV file that contains devices serial number followed by the hostname. The HTTP server also contains a basic configuration file that need to be applied. Finally a local repository accessible by HTTP contains IOS-XR and third party packages to be installed.After bootup ZTP will provide its serial number and query the back-end database using HTTP POST, once it obtains its hostname it will perform a version check, if the version on the system does not match the desired version, the system will change the boot order forcing a reboot using iPXE that will hopefully re-image the system to the desired version.If the system is running the correct version the script proceed by installing the k9sec package and create a generic RSA key for SSH. It will then add a local repository for third party packages and install midnight commander and its dependent packages. The script finishes its execution after downloading and applying the configuration.ZTP Script ncs-5001-rp0_ztp.sh#!/bin/bash############################################################################## *** Be careful this is powerful and can potentially destroy your system ***#                *** !!! Use at your own risk !!! ***## Script file should be saved on the backend HTTP server## Tested on NCS-5501 with IOS-XR 6.1.1##############################################################################export LOGFILE=/disk0#/ztp/user-script.logexport HTTP_SERVER=http#//172.30.0.22export SYSLOG_SERVER=172.30.0.22export SYSLOG_PORT=514export CONFIG_PATH=configsexport SCRIPT_PATH=scriptsexport RPM_PATH=~packages/ncs5k/6.1.1~export PHP_SCRIPT=~php/device_name.php~export DESIRED_VER=~6.1.1~K9SEC_RPM=ncs5k-k9sec-3.1.0.0-r611.x86_64.rpm## ztp_helper is inside the Fretta Code-base - ASSUMPTIONsource ztp_helper.shfunction ztp_log() {    # Sends logging information to local file and syslog server    syslog ~$1~    echo ~$(date +~%b %d %H#%M#%S~) ~$1 &gt;&gt; $LOGFILE}function syslog() {    # Sends syslog messages with netcat (nc)  echo ~ztp-script# ~$1 | nc -u -q1 $SYSLOG_SERVER $SYSLOG_PORT}function get_hostname(){    # Uses serial number to query a remote database and get hostname using HTTP POST    local sn=$(dmidecode | grep -m 1 ~Serial Number#~ | awk '{print $NF}');    local result=~`wget -O- --post-data=~serial=$sn~ ${HTTP_SERVER}/${PHP_SCRIPT}`~;    if [ ~$result~ != ~Not found~ ]; then            DEVNAME=$result;            return 0    else    \tztp_log ~Serial $sn not found, hostname not set~;        return 1    fi}function download_config(){\t# Downloads config using hostname    ztp_log ~### Downloading system configuration ###~;    /usr/bin/wget ${HTTP_SERVER}/${CONFIG_PATH}/${DEVNAME}.config -O /disk0#/new-config 2&gt;&amp;1 &gt;&gt; $LOGFILE    if [[ ~$?~ != 0 ]]; then    \tztp_log ~### Error downloading system configuration ###~    else        ztp_log ~### Downloading system configuration complete ###~;    fi}function apply_config(){\t# Applies initial configuration    ztp_log ~### Applying initial system configuration ###~;    xrapply_with_reason ~Initial ZTP configuration~ /disk0#/new-config 2&gt;&amp;1 &gt;&gt; $LOGFILE;    ztp_log ~### Checking for errors ###~;    local config_status=$(xrcmd ~show configuration failed~);    if [[ $config_status ]]; then    \techo $config_status  &gt;&gt; $LOGFILE        ztp_log ~!!! Error encounter applying configuration file, review the log !!!!~;    fi    ztp_log ~### Applying system configuration complete ###~;}function install_k9sec_pkg(){    # Installs the k9sec package from repository, create a RSA key modulus 1024    ztp_log ~### XR K9SEC INSTALL ###~    /usr/bin/wget ${HTTP_SERVER}/${RPM_PATH}/${K9SEC_RPM} -O /disk0#/$K9SEC_RPM 2&gt;&amp;1    if [[ ~$?~ != 0 ]]; then        ztp_log ~### Error downloading $K9SEC_RPM ###~    else        ztp_log ~### Downloading $K9SEC_PKG complete ###~;    fi  xrcmd ~install update source /disk0#/ $K9SEC_RPM~ 2&gt;&amp;1 &gt;&gt; $LOGFILE  local complete=0  while [ ~$complete~ = 0 ]; do        complete=`xrcmd ~show install active~ | grep k9sec | head -n1 | wc -l`        ztp_log ~Waiting for k9sec package to be activated~        sleep 5    done    if [[ -z $(xrcmd ~show crypto key mypubkey rsa~) ]]; then        echo ~1024~ | xrcmd ~crypto key generate rsa~    else        echo -ne ~yes\\n 1024\\n~ | xrcmd ~crypto key generate rsa~    fi    rm -f /disk0#/$K9SEC_RPM    ztp_log ~### XR K9SEC INSTALL COMPLETE ###~}function check_version(){\t# returns 0 is version matches, 1 otherwise    local current_ver=`xrcmd ~show version~ | grep Version | grep Cisco | cut -d ~ ~ -f 6`;    ztp_log ~current=$current_ver, desired=$DESIRED_VER~;    if [ ~$DESIRED_VER~ = ~$current_version~ ]; then        return 0    else        return 1    fi}function reboot_ipxe(){    # Do not use in production, may not be supported on NCS-5508     ztp_log ~### Mounting EFIvar and changing boot order~    local EFI_FILESYS=~/sys/firmware/efi/efivars~    if [ ! -d $EFI_FILESYS ]; then        ztp_log ~EFI mount point not present~    fi     /bin/mount -t efivarfs efivarfs $EFI_FILESYS    if [[ ~$?~ != 0 ]]; then    ztp_log ~Error mounting efivars filesystem~;  fi  local iPXE=$(/usr/sbin/efibootmgr | grep IPXE | awk -v FS=~(Boot|*)~ '{print $2}')  local MMC=$(/usr/sbin/efibootmgr | grep ~HS-SD/MMC~ | awk -v FS=~(Boot|*)~ '{print $2}')  local Shell=$(/usr/sbin/efibootmgr | grep Shell | awk -v FS=~(Boot|*)~ '{print $2}')    /usr/sbin/efibootmgr -o $iPXE,$MMC,$Shell    if [[ ~$?~ != 0 ]]; then    ztp_log ~Error changing boot order~;  fi    ztp_log ~### Resetting the system~;    echo 1 &gt; /proc/sys/kernel/sysrq     echo b &gt; /proc/sysrq-trigger    ztp_log ~Unable to reset the system~;}function add_repo(){\t# add a local repo to yum package manager    /usr/bin/yum-config-manager --add-repo ${HTTP_SERVER}/${RPM_PATH} 2&gt;&amp;1}function install_mc(){\t# uses yum to install packages and dependant package(s) automatically    if /usr/bin/yum list installed ~mc~ &gt;/dev/null 2&gt;&amp;1; then    \tztp_log ~### Installing midnight commander~;        /usr/bin/yum install mc -y 2&gt;&amp;1    else    \tztp_log ~### Midnight commander already installed ###~    fi}# ==== Script entry point ====get_hostname;if [[ ~$?~ != 0 ]]; then    ztp_log ~No valid hostname found terminating ZTP~;    exit 1fiztp_log ~Hello from ${DEVNAME} !!!~;check_version;if  [[ ~$?~ != 0 ]]; then    ztp_log ~Version mismatch, we will upgrade using iPXE~;    reboot_ipxe;else    ztp_log ~Version match, proceeding to configuration~;fiztp_log ~Starting autoprovision process...~;install_k9sec_pkg;add_repo;install_mc;download_config;apply_config;ztp_log ~Autoprovision complete...~;exit 0Backend PHP script device_name.php&lt;?php$file = 'inventory.txt';$searchfor = ($_POST['serial']);// the following line prevents the browser from parsing this as HTML.header('Content-Type# text/plain');// get the file contents, assuming the file to be readable (and exist)$contents = file_get_contents($file);// escape special characters in the query$pattern = preg_quote($searchfor, '/');// finalise the regular expression, matching the whole line$pattern = ~/^.*$pattern.*\\$/m~;// search, and store first matching occurences in $matchesif(preg_match($pattern, $contents, $matches)){   //match the last element of the  line   preg_match('/[^,]*$/', $matches[0], $results);   echo $results[0];}else{   echo ~Not found~;}?&gt;CSV file inventory.txtFOC2647D246,ncs-5001-aFOC1568P682,ncs-5001-bFOC1947R143,ncs-5001-cLogging outputOct 11 11#05#38 172.30.0.54 ztp-script# Hello from ncs-5001-c !!!Oct 11 11#05#40 172.30.0.54 ztp-script# current=6.1.1, desired=6.1.1Oct 11 11#05#40 172.30.0.54 ztp-script# Version match, proceeding to configurationOct 11 11#05#41 172.30.0.54 ztp-script# Starting autoprovision process...Oct 11 11#05#42 172.30.0.54 ztp-script# ### XR K9SEC INSTALL ###Oct 11 11#05#44 172.30.0.54 ztp-script# ### Downloading complete ###Oct 11 11#05#55 172.30.0.54 ztp-script# Waiting for k9sec package to be activatedOct 11 11#06#01 172.30.0.54 ztp-script# ### XR K9SEC INSTALL COMPLETE ###Oct 11 11#06#03 172.30.0.54 ztp-script# ### Installing midnight commander ###Oct 11 11#06#04 172.30.0.54 ztp-script# ### Downloading system configuration ###Oct 11 11#06#05 172.30.0.54 ztp-script# ### Downloading system configuration complete ###Oct 11 11#06#06 172.30.0.54 ztp-script# ### Applying initial system configuration ###Oct 11 11#06#11 172.30.0.54 ztp-script# !!! Checking for errors !!!Oct 11 11#06#14 172.30.0.54 ztp-script# ### Applying system configuration complete ###Oct 11 11#06#15 172.30.0.54 ztp-script# Autoprovision complete...", "url": "https://xrdocs.github.io/software-management/tutorials/2016-08-26-working-with-ztp/", "tags": "iosxr, cisco", "title": "Working with Zero Touch Provisioning", "author": "Patrick Warichet"}, "tutorials-2018-02-13-filtering-in-telemetry-where-to-apply-and-why": {"content": "Let\u2019s continue to explore smaller features available in IOS-XR Model Driven Telemetry, following the previous post, where sample intervals were explained. The goal of this post is to explain what filtering is, how you can use it and couple of benefits coming with filtering.Why filtering?As an engineer, each time someone starts talking about filtering you may start thinking about electric circuits or (radio) signals. In both cases filtering is used to get rid of everything, that is not needed. Like removing of high order harmonics, that can lead to equipment damage (in electric circuits) or improper signal processing and recovery.Streaming Telemetry in IOS XR appeared back in 6.0.1 release and there are around 200 Native YANG models available today (with 6.3.1 release). The major goal is to make every counter in a box available to you for offline processing. If to look through the models, one can see that IOS XR has [mostly] a model per feature or protocol. This is very convenient and one can quickly find the needed model and start exploring it. But there is also another side of having a model per feature or protocol. For example, MPLS Traffic Engineering has been available in IOS XR for many years and has a very wide coverage. As the result, MPLS-TE YANG native model has more than 41k leafs of operational data! Correlate this with the number of tunnels you can have and you can see, that the amount of data streamed out could be enormous. With modern Streaming Telemetry you can afford this. But the question comes right away \u2013 do I really want to get all that data? In most situations, the answer will be \u201cNo\u201d.Filtering optionsThe very first step for you in any configuration should be an exact path definition. If you\u2019re interested in getting summary information about your auto-mesh tunnels, there is absolutely no need to stream all other 41k different counters at all! Find what you need#$ pyang -f tree Cisco-IOS-XR-mpls-te-oper.yang --tree-path mpls-te/auto-tunnel/mesh/summarymodule# Cisco-IOS-XR-mpls-te-oper   +--ro mpls-te      +--ro auto-tunnel         +--ro mesh            +--ro summary              +--ro auto-mesh-tunnels?        uint32               +--ro up-auto-mesh-tunnels?     uint32               +--ro down-auto-mesh-tunnels?   uint32               +--ro frr-auto-mesh-tunnels?    uint32               +--ro auto-mesh-groups?         uint32               +--ro auto-mesh-destinations?   uint32 And it is easy now to get your sensor path based on that information#telemetry model-driven sensor-group mpls-te   sensor-path Cisco-IOS-XR-mpls-te-oper#mpls-te/auto-tunnel/mesh/summaryAs soon as you have your sensor path defined, there might be an option to do even more filtering. The first option is to define what you want to insert into your Time Series Database (TSDB) in Pipeline configuration. \u201cMetrics.json\u201d is a file used in Pipeline to define what you want to be inserted in your TSDB. Everything NOT specified in that file will be dropped. You can find a high-level overview of this behavior with InfluxDB here and it will be explained deeper in upcoming tutorials.Yet another option available for you is to do filtering on the router itself. Starting with IOS XR 6.2.2 release you can configure filtering within your sensor paths. Have a look at the popular Interface Stats sensor path#$ pyang -f tree Cisco-IOS-XR-infra-statsd-oper.yang --tree-path infra-statistics/interfaces/interface/latest/generic-countersmodule# Cisco-IOS-XR-infra-statsd-oper   +--ro infra-statistics      +--ro interfaces         +--ro interface* [interface-name]             +--ro latest               +--ro generic-counters                  +--ro packets-received?                    uint64                  +--ro bytes-received?                      uint64                  +--ro packets-sent?                        uint64                  +--ro bytes-sent?                          uint64                  +--ro multicast-packets-received?          uint64 \t\u2026In the highlighted section you can see \u201cinterface-name\u201d in square brackets. It shows that all the leafs below will be sent for each interface. And this is exactly the place where you can apply filtering! Your router might have a big number of interfaces. If you are interested in 100G interfaces only, or if you don\u2019t care about sub-interfaces, or if you just need to get stats from your core facing ports, you can achieve this with filtering!There are two ways to apply filtering for interfaces#  using regex  specifying an interfaceThis is an example of how you can ask a router to send you stats for 100G interfaces only#sensor-path Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface[interface-name='HundredGigE*']/latest/generic-countersAn asterisk (a \u201c*\u201d symbol) above is used to represent \u201cany\u201d interface that is 100G (\u201cHundredGigE\u201d). This way Streaming Telemetry will push stats for all 100G interfaces on a router.Specifying an exact interface is straightforward#sensor-path Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface[interface-name='HundredGigE0/0/0/0']/latest/generic-countersAs you can see, configuration of filtering is easy and all you need to do, is to specify exactly what you want to stream out (where a model has this choice).You can find opportunities for filtering in other models as well#$ pyang -f tree Cisco-IOS-XR-ip-rib-ipv4-oper.yang --tree-path rib/vrfs/vrf/afs/af/safs/saf/ip-rib-route-table-names/ip-rib-route-table-name/protocol/bgp/as/informationmodule# Cisco-IOS-XR-ip-rib-ipv4-oper   +--ro rib      +--ro vrfs        +--ro vrf* [vrf-name]            +--ro afs              +--ro af* [af-name]                  +--ro safs                    +--ro saf* [saf-name]                        +--ro ip-rib-route-table-names                          +--ro ip-rib-route-table-name* [route-table-name]                              +--ro protocol                                 +--ro bgp                                   +--ro as* [as]                                       +--ro information                                          +--ro protocol-names?                string                                          +--ro instance?                      string                                          +--ro version?                       uint32                                          +--ro redistribution-client-count?   uint32                                          +--ro protocol-clients-count?        uint32                                          +--ro routes-counts?                 uint32                                          +--ro active-routes-count?           uint32                                          +--ro deleted-routes-count?          uint32                                          +--ro paths-count?                   uint32                                          +--ro protocol-route-memory?         uint32                                          +--ro backup-routes-count?           uint32As you can see, there are several places where you can apply filtering. Usually in such models you will go with filtering for an exact element, like this#sensor-path Cisco-IOS-XR-ip-rib-ipv4-oper#rib/vrfs/vrf[vrf-name='MDT']/afs/af/safs/saf/ip-rib-route-table-names/ip-rib-route-table-name/protocol/bgp/as/informationConclusionAs soon as you start trying telemetry, make sure you stream a specific path within a model and not all the counters from that model. It will remove wasting of resources on the router, on the wire and on the collection side. After you specified useful paths, you have 2 ways to fine tune your telemetry experience# filter on the router and filter on the collector. Filtering on the router gives you a benefit to stream data for the needed elements, like interfaces under attention, specific VRFs or address-families. On the collector side you may specify which fields you want to insert into your database. Both ways help with improving resource utilization. Filtering on the router side also brings additional not so obvious benefits to the internal MDT operation. Stay tuned, an MDT internal architecture overview will be provided soon!", "url": "https://xrdocs.github.io/telemetry/tutorials/2018-02-13-filtering-in-telemetry-where-to-apply-and-why/", "tags": "iosxr, MDT, Telemetry, Filtering in MDT, Streaming Telemetry", "title": "Filtering in Telemetry. Where to apply and why?", "author": "Viktor Osipchuk"}, "tutorials-2016-10-24-configuring-model-driven-telemetry-mdt-with-ydk-and-xr-native-yang-model": {"content": "     Configuring MDT with YDK + XR native YANG  Getting a complete MDT configuration with Native YANG and YDK  Tutorial goal  Connect to the router and import YDK\u2019s libraries  Define and apply the destination group  Define and apply the sensor group  Define and apply the subcription  Clean  Conclusion  Getting a complete MDT configuration with Native YANG and YDKIn an earlier tutorial, Shelly introduces a methodology to configure MDT using YDK and the OpenConfig Telemetry YANG model.This document provides a similar tutorial, addressing a complete XR Telemetry TCP dial-out configuration using the native YANG model and YDK.I have tested the configuration in this document using the relative recent Vagrant IOS-XRv box version 6.2.1.15I.If you are looking for more information on IOS-XRv for Vagrant, you may follow Akshat tutorial IOS-XRv Vagrant Quick Start for step by step instructions.If you are not familiar with IOS-XRv, follow Akshat tutorial IOS-XRv Vagrant Quick Start for step by step instructions.Tutorial goalBy the end of this tutorial, you will have implemented the following configuration using YDK on the router under testing. If you are unfamiliar with the configuration just check the following tutorial Configuring Model-Driven Telemetry (MDT)CLI Output#test_XR#show running-config telemetry model-drivenFri Oct 21 06#51#06.926 UTCtelemetry model-driven destination-group DG_Test  address family ipv4 192.168.10.3 port 5432   encoding self-describing-gpb   protocol tcp  ! ! sensor-group SG_Test  sensor-path Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters ! subscription 1  sensor-group-id SG_Test sample-interval 30000  destination-id DG_Test !!Connect to the router and import YDK\u2019s librariesAs described in previous YDK tutorials, we are importing the YDK Netconf library to communicate with the router.We also import the CRUDService YDK\u2019s library (taking care of create, read, update and delete YDK objects from the router) and the IOS_XR native YDK model.The Empty type that we import from ydk.types has a special purpose later in the document to signal with its presence, the request to activate the submitted subscription.from ydk.providers import NetconfServiceProviderfrom ydk.services import CRUDServicefrom ydk.types import Emptyimport ydk.models.cisco_ios_xr.Cisco_IOS_XR_telemetry_model_driven_cfg as xr_telemetryHOST = '192.168.10.2'PORT = 830USER = 'vagrant'PASS = 'vagrant'xr = NetconfServiceProvider(address=HOST,\tport=PORT,\tusername=USER,\tpassword=PASS,\tprotocol = 'ssh')With that, we are now connected to the router#CLI Output#RP/0/RP0/CPU0#test_XR#show netconf-yang clientsFri Oct 21 01#36#02.850 UTCNetconf clientsclient session ID|     NC version|    client connect time|        last OP time|        last OP type|    &lt;lock&gt;|       4261169968|            1.1|         0d  0h  0m 28s|                    |                    |        No|RP/0/RP0/CPU0#test_XR#Define and apply the destination groupTo access the native XR telemetry YANG model used in this tutorial (Cisco-IOS-XR-telemetry-model-driven-cfg.yang) use the YANG public repository.Explore this same repository to see the other vendors and standard model YANGs but just in case you are looking for the OpenConfig, you will have to use YANG OpenConfig repository.To explore the telemetry YANG model read directly the yang file or for example, follow a friendlier  tree that the Pyang utility generates.Note# if you have installed the YDK environment, you can use Pyang from this environment as pyang -f tree Cisco-IOS-XR-telemetry-model-driven-cfg.yangPYANG output for the destination-groups#module# Cisco-IOS-XR-telemetry-model-driven-cfg   +--rw telemetry-model-driven      &lt;SNIP&gt;      +--rw destination-groups      |  +--rw destination-group* [destination-id]      |     +--rw destinations      |     |  +--rw destination* [address-family]      |     |     +--rw address-family    Af      |     |     +--rw ipv4* [ipv4-address destination-port]      |     |     |  +--rw ipv4-address        inet#ip-address-no-zone      |     |     |  +--rw destination-port    xr#Cisco-ios-xr-port-number      |     |     |  +--rw protocol!      |     |     |  |  +--rw protocol        Proto-type      |     |     |  |  +--rw tls-hostname?   string      |     |     |  |  +--rw no-tls?         int32      |     |     |  +--rw encoding?           Encode-type      |     |     +--rw ipv6* [ipv6-address destination-port]      |     |        +--rw ipv6-address        xr#Cisco-ios-xr-string      |     |        +--rw destination-port    xr#Cisco-ios-xr-port-number      |     |        +--rw protocol!      |     |        |  +--rw protocol        Proto-type      |     |        |  +--rw tls-hostname?   string      |     |        |  +--rw no-tls?         int32      |     |        +--rw encoding?           Encode-type      |     +--rw destination-id    xr#Cisco-ios-xr-stringThis is what the YANG model maps to YDK code for our example#dgroup=xr_telemetry.TelemetryModelDriven.DestinationGroups.DestinationGroup()dgroup.destination_id=~DG_Test~dgroup.destinations=dgroup.Destinations()new_destination=dgroup.Destinations.Destination()new_destination.address_family=xr_telemetry.AfEnum.IPV4new_ipv4=xr_telemetry.TelemetryModelDriven.DestinationGroups.DestinationGroup().Destinations().Destination().Ipv4()new_ipv4.destination_port=5432new_ipv4.ipv4_address=~192.168.10.3~new_ipv4.encoding=xr_telemetry.EncodeTypeEnum.SELF_DESCRIBING_GPBnew_ipv4.protocol=xr_telemetry.TelemetryModelDriven.DestinationGroups.DestinationGroup().Destinations().Destination().Ipv4().Protocol()new_ipv4.protocol.protocol=xr_telemetry.ProtoTypeEnum.TCPnew_destination.ipv4.append(new_ipv4)dgroup.destinations.destination.append(new_destination)Once you\u2019ve populated the object, we can apply it to the router using the create method on the CRUDService object from YDK#rpc_service = CRUDService()rpc_service.create(xr, dgroup)And here is the expected CLI output with the destination group describing where and how to steam#CLI Output#RP/0/RP0/CPU0#test_XR#sh running-config telemetry model-drivenFri Oct 21 06#35#06.731 UTCtelemetry model-driven destination-group DG_Test  address family ipv4 192.168.10.3 port 5432   encoding self-describing-gpb   protocol tcp  ! !!Define and apply the sensor groupAs for the destination group, this is the section of the YANG model for the sensor group#PYANG output for the sensor-groups#module# Cisco-IOS-XR-telemetry-model-driven-cfg  +--rw telemetry-model-driven\t  +--rw sensor-groups      |  +--rw sensor-group* [sensor-group-identifier]      |     +--rw sensor-paths      |     |  +--rw sensor-path* [telemetry-sensor-path]      |     |     +--rw telemetry-sensor-path    string      |     +--rw enable?                    empty      |     +--rw sensor-group-identifier    xr#Cisco-ios-xr-string\t&lt;SNIP&gt;\u2026 and the YDK code that it maps to#sgroup = xr_telemetry.TelemetryModelDriven.SensorGroups.SensorGroup()sgroup.sensor_group_identifier=~SG_Test~sgroup.sensor_paths = sgroup.SensorPaths()new_sensorpath = sgroup.SensorPaths.SensorPath()new_sensorpath.telemetry_sensor_path = 'Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters'sgroup.sensor_paths.sensor_path.append(new_sensorpath)Now we are ready to submit the sensor group object just populated with the same create method from the CRUDService object#rpc_service.create(xr, sgroup)Note# you need to initialize the rpc_service as rpc_service = CRUDService() a single time.If you remember, we have already done it when creating the destination group but if you skipped the previous step, add it before requesting to create for the sensor group.Let\u2019s check the CLI running-configuration again. You should now find the destination (from the previous step) and sensor group just created in place#CLI Output#RP/0/RP0/CPU0#test_XR#show running-config telemetry model-drivenFri Oct 21 06#45#58.444 UTCtelemetry model-driven destination-group DG_Test  address family ipv4 192.168.10.3 port 5432   encoding self-describing-gpb   protocol tcp  ! ! sensor-group SG_Test  sensor-path Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters !!Define and apply the subcriptionThe final step in our configration is the subcription.PYANG output for the subcription#module# Cisco-IOS-XR-telemetry-model-driven-cfg  +--rw telemetry-model-driven\t&lt;SNIP&gt;      +--rw subscriptions      |  +--rw subscription* [subscription-identifier]      |     +--rw source-address!      |     |  +--rw address-family    Af      |     |  +--rw ip-address?       inet#ipv4-address-no-zone      |     |  +--rw ipv6-address?     string      |     +--rw sensor-profiles      |     |  +--rw sensor-profile* [sensorgroupid]      |     |     +--rw sample-interval?      uint32      |     |     +--rw heartbeat-interval?   uint32      |     |     +--rw supress-redundant?    empty      |     |     +--rw sensorgroupid         xr#Cisco-ios-xr-string      |     +--rw destination-profiles      |     |  +--rw destination-profile* [destination-id]      |     |     +--rw enable?           empty      |     |     +--rw destination-id    xr#Cisco-ios-xr-string      |     +--rw source-qos-marking?        uint32      |     +--rw subscription-identifier    xr#Cisco-ios-xr-string\t&lt;SNIP&gt;This is how that ends up in YDK code#sub = xr_telemetry.TelemetryModelDriven.Subscriptions.Subscription()sub.subscription_identifier = ~1~sub.sensor_profiles = sub.SensorProfiles()sub.destination_profiles = sub.DestinationProfiles()new_sprofile = sub.SensorProfiles.SensorProfile()new_sprofile.sensorgroupid = 'SG_Test'new_sprofile.sample_interval = 30000new_dprofile = sub.DestinationProfiles.DestinationProfile()new_dprofile.destination_id=~DG_Test~new_dprofile.enable=Empty()sub.sensor_profiles.sensor_profile.append(new_sprofile)sub.destination_profiles.destination_profile.append(new_dprofile)rpc_service.create(xr, sub)If you check your router running-configuration, you should now have a complete TCP dial-out telemetry configuration  as#CLI Output#P/0/RP0/CPU0#test_XR#show running-config telemetry model-drivenFri Oct 21 06#51#06.926 UTCtelemetry model-driven destination-group DG_Test  address family ipv4 192.168.10.3 port 5432   encoding self-describing-gpb   protocol tcp  ! ! sensor-group SG_Test  sensor-path Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters ! subscription 1  sensor-group-id SG_Test sample-interval 30000  destination-id DG_Test !!CleanOne last command to delete the configuration#rpc_service.delete(xr, xr_telemetry.TelemetryModelDriven())And confirm in the router\u2019s \u2018show running-config\u2019CLI Output#RP/0/RP0/CPU0#test_XR#show running-config telemetry model-drivenFri Oct 21 06#59#46.743 UTC% No such configuration item(s)RP/0/RP0/CPU0#test_XR#ConclusionThis tutorial complements the concepts explained by Shelly in her earlier tutorial.The same values in programmability using YANG models, automatic generation of Python classes that inherit the syntactic checks and requirements of the underlying model, while also handling all the details for the sensor group using the native telemetry YANG model.", "url": "https://xrdocs.github.io/telemetry/tutorials/2016-10-24-configuring-model-driven-telemetry-mdt-with-ydk-and-xr-native-yang-model/", "tags": "iosxr, YDK, YANG, Telemetry", "title": "Configuring Model-Driven Telemetry (MDT) with YDK and XR Native YANG model", "author": "Marco Umer"}, "blogs-2018-05-09-metro-design-implementation-guide": {"content": "     On This Page  Targets  Testbed Overview          Devices        Role-Based Configuration          Transport IOS-XR \u2013 All IOS-XR nodes                  IGP Protocol (ISIS) and Segment Routing MPLS configuration          MPLS Segment Routing Traffic Engineering (SRTE) configuration                    Transport IOS-XE \u2013 All IOS-XE nodes                  Segment Routing MPLS configuration          IGP-ISIS configuration          MPLS Segment Routing Traffic Engineering (SRTE)          Area Border Routers (ABRs) IGP-ISIS Redistribution configuration                    BGP \u2013 Access or Provider Edge Routers                  IOS-XR configuration          IOS-XE configuration                    Area Border Routers (ABRs) IGP Topology Distribution      Transport Route Reflector (tRR)      Services Route Reflector (sRR)      Segment Routing Path Computation Element (SR-PCE)      Segment Routing Traffic Engineering (SRTE) and Services Integration                  On Demand Next-Hop (ODN) configuration \u2013 IOS-XR          On Demand Next-Hop (ODN) configuration \u2013 IOS-XE          Preferred Path configuration \u2013 IOS-XR          Preferred Path configuration \u2013 IOS-XE                      Services          End-To-End Services                  L3VPN MP-BGP VPNv4 On-Demand Next-Hop                          Access Router Service Provisioning (IOS-XE)#                                L2VPN Single-Homed EVPN-VPWS On-Demand Next-Hop                          Access Router Service Provisioning (IOS-XR)#                                L2VPN Static Pseudowire (PW) \u2013 Preferred Path (PCEP)                          Access Router Service Provisioning (IOS-XR)#              Access Router Service Provisioning (IOS-XE)#                                End-To-End Services Data Plane                    Hierarchical Services                  L3VPN \u2013 Single-Homed EVPN-VPWS, MP-BGP VPNv4/6 with Pseudowire-Headend (PWHE)                          Access Router Service Provisioning (IOS-XR)#              Access Router Service Provisioning (IOS-XE)#              Provider Edge Router Service Provisioning (IOS-XR)#                                L3VPN \u2013 Anycast Static Pseudowire (PW), MP-BGP VPNv4 with Anycast IRB                          Access Router Service Provisioning (IOS-XR)#              Access Router Service Provisioning (IOS-XE)#              Provider Edge Routers Service Provisioning (IOS-XR)#                                L2/L3VPN \u2013 Anycast Static Pseudowire (PW), Multipoint EVPN with Anycast IRB                          Access Router Service Provisioning (IOS-XR)#              Access Router Service Provisioning (IOS-XE)#              Provider Edge Routers Service Provisioning (IOS-XR)#                                            Targets      Hardware#                  ASR9000 as Provider Edge (PE) node                    NCS5500 as Aggregation and P-Aggregation Node                    ASR920 and NCS5500 (standing for the NCS540) as Access Router                  Software#                  IOS-XR 6.3.2 on ASR9000 and NCS5500                    IOS-XE 16.8.1 on ASR920                  Key technologies                  Transport# End-To-End Segment-Routing                    Network Programmability# SRTE Inter-Domain LSPs with On-DemandNext Hop                    Network Availability# TI-LFA/Anycast-SID                    Services# BGP-based L2 and L3 Virtual Private Network services(EVPN and L3VPN)            Testbed OverviewFigure 1# Compass Metro Fabric High Level TopologyFigure 2# Testbed Physical TopologyFigure 3# Testbed Route-Reflector and SR-PCE physical connectivityFigure 4# Testbed IGP DomainsDevicesAccess Routers      Cisco NCS5501-SE (IOS-XR) \u2013 A-PE1, A-PE2, A-PE3, A-PE7        Cisco ASR920 (IOS-XE) \u2013 A-PE4, A-PE5, A-PE6, A-PE9  Area Border Routers (ABRs) and Provider Edge Routers#  Cisco ASR9000 (IOS-XR) \u2013 PE1, PE2, PE3, PE4Route Reflectors (RRs)#  Cisco IOS XRv 9000 \u2013 tRR1-A, tRR1-B, sRR1-A, sRR1-B, sRR2-A, sRR2-B,sRR3-A, sRR3-BSegment Routing Path Computation Element (SR-PCE)#  Cisco IOS XRv 9000 \u2013 SR-PCE1-A, SR-PCE1-B, SR-PCE2-A, SR-PCE2-B, SR-PCE3-A, SR-PCE3-BRole-Based ConfigurationTransport IOS-XR \u2013 All IOS-XR nodesIGP Protocol (ISIS) and Segment Routing MPLS configurationRouter isis configurationkey chain ISIS-KEY key 1 accept-lifetime 00#00#00 january 01 2018 infinite key-string password 00071A150754 send-lifetime 00#00#00 january 01 2018 infinite cryptographic-algorithm HMAC-MD5All Routers, except Provider Edge (PE) Routers, are part of one IGPdomain (ISIS ACCESS or ISIS-CORE). PEs act as Area Border Routers (ABRs)and run two IGP processes (ISIS-ACCESS and ISIS-CORE). Please note thatLoopback 0 is part of both IGP processes.router isis ISIS-ACCESS set-overload-bit on-startup 360 is-type level-2-only net 49.0001.0101.0000.0110.00 nsr nsf cisco log adjacency changes lsp-gen-interval maximum-wait 5000 initial-wait 50 secondary-wait 200 lsp-refresh-interval 65000 max-lsp-lifetime 65535 lsp-password keychain ISIS-KEY lsp-password keychain ISIS-KEY level 1 address-family ipv4 unicast  metric-style wide  spf-interval maximum-wait 5000 initial-wait 50 secondary-wait 200  segment-routing mpls  spf prefix-priority critical tag 5000  spf prefix-priority high tag 1000 !PEs Loopback 0 is part of both IGP processes together with same\u201cprefix-sid index\u201d value. interface Loopback0  address-family ipv4 unicast   prefix-sid index 150  ! !TI-LFA FRR configuration interface TenGigE0/0/0/10  point-to-point  hello-password keychain ISIS-KEY  address-family ipv4 unicast   fast-reroute per-prefix   fast-reroute per-prefix ti-lfa   metric 100  ! ! !interface Loopback0 ipv4 address 100.0.1.50 255.255.255.255!MPLS Interface configurationinterface TenGigE0/0/0/10 bfd mode ietf bfd address-family ipv4 timers start 180 bfd address-family ipv4 multiplier 3 bfd address-family ipv4 destination 10.1.2.1 bfd address-family ipv4 fast-detect bfd address-family ipv4 minimum-interval 50 mtu 9216 ipv4 address 10.15.150.1 255.255.255.254 ipv4 unreachables disable bundle minimum-active links 1 load-interval 30 dampening!MPLS Segment Routing Traffic Engineering (SRTE) configurationipv4 unnumbered mpls traffic-eng Loopback0router isis ACCESS address-family ipv4 unicast  mpls traffic-eng level-2-only  mpls traffic-eng router-id Loopback0Transport IOS-XE \u2013 All IOS-XE nodesSegment Routing MPLS configurationmpls label range 6001 32767 static 16 6000segment-routing mpls ! set-attributes  address-family ipv4   sr-label-preferred  exit-address-family ! global-block 16000 32000 !Prefix-SID assignment to loopback 0 configuration connected-prefix-sid-map  address-family ipv4   100.0.1.51/32 index 151 range 1  exit-address-family !IGP-ISIS configurationkey chain ISIS-KEY key 1  key-string cisco   accept-lifetime 00#00#00 Jan 1 2018 infinite   send-lifetime 00#00#00 Jan 1 2018 infinite!router isis ACCESS net 49.0001.0102.0000.0254.00 is-type level-2-only authentication mode md5 authentication key-chain ISIS-KEY metric-style wide fast-flood 10 set-overload-bit on-startup 120 max-lsp-lifetime 65535 lsp-refresh-interval 65000 spf-interval 5 50 200 prc-interval 5 50 200 lsp-gen-interval 5 5 200 log-adjacency-changes segment-routing mpls segment-routing prefix-sid-map advertise-localTI-LFA FRR configuration fast-reroute per-prefix level-2 all fast-reroute ti-lfa level-2 microloop avoidance protected redistribute connected!interface Loopback0 ip address 100.0.1.51 255.255.255.255 ip router isis ACCESS isis circuit-type level-2-onlyendMPLS Interface configurationinterface TenGigabitEthernet0/0/12 mtu 9216 ip address 10.117.151.1 255.255.255.254 ip router isis ACCESS mpls ip isis circuit-type level-2-only isis network point-to-point isis metric 100endMPLS Segment Routing Traffic Engineering (SRTE)router isis ACCESS mpls traffic-eng router-id Loopback0 mpls traffic-eng level-2interface TenGigabitEthernet0/0/12 mpls traffic-eng tunnelsArea Border Routers (ABRs) IGP-ISIS Redistribution configurationPEs have to provide IP reachability for RRs, SR-PCEs and NSO between bothISIS-ACCESS and ISIS-CORE IGP domains. This is done by specific IPprefixes redistribution.router staticaddress-family ipv4 unicast  100.0.0.0/24 Null0  100.0.1.0/24 Null0  100.1.0.0/24 Null0  100.1.1.0/24 Null0prefix-set ACCESS-XTC_SvRR-LOOPBACKS  100.0.1.0/24,  100.1.1.0/24end-setprefix-set RR-LOOPBACKS  100.0.0.0/24,  100.1.0.0/24end-setredistribute Core SvRR and TvRR loopback into Access domainroute-policy CORE-TO-ACCESS1  if destination in RR-LOOPBACKS then    pass  else    drop  endifend-policyrouter isis ACCESS                                                     address-family ipv4 unicast                                            redistribute static route-policy CORE-TO-ACCESS1    redistribute Access SR-PCE and SvRR loopbacks into Core domainroute-policy ACCESS1-TO-CORE                                       if destination in ACCESS-XTC_SvRR-LOOPBACKS then                   pass                                                           else                                                                drop                                                           endif                                                          end-policy                                                       router isis CORE                      address-family ipv4 unicast                                            redistribute static route-policy CORE-TO-ACCESS1    BGP \u2013 Access or Provider Edge RoutersIOS-XR configurationrouter bgp 100 nsr bgp router-id 100.0.1.50 bgp graceful-restart ibgp policy out enforce-modifications address-family vpnv4 unicast ! address-family vpnv6 unicast ! address-family l2vpn evpn ! neighbor-group SvRR  remote-as 100  update-source Loopback0  address-family vpnv4 unicast  !  address-family vpnv6 unicast  !  address-family l2vpn evpn  ! ! neighbor 100.0.1.201  use neighbor-group SvRR !IOS-XE configurationrouter bgp 100 bgp router-id 100.0.1.51 bgp log-neighbor-changes no bgp default ipv4-unicast neighbor SvRR peer-group neighbor SvRR remote-as 100 neighbor SvRR update-source Loopback0 neighbor 100.0.1.201 peer-group SvRR ! address-family ipv4 exit-address-family ! address-family vpnv4  neighbor SvRR send-community both  neighbor SvRR next-hop-self  neighbor 100.0.1.201 activate exit-address-family ! address-family l2vpn evpn  neighbor SvRR send-community both  neighbor SvRR next-hop-self  neighbor 100.0.1.201 activate exit-address-family !Area Border Routers (ABRs) IGP Topology DistributionNext network diagram# \u201cBGP-LS Topology Distribution\u201d shows how AreaBorder Routers (ABRs) distribute IGP network topology from ISIS ACCESSand ISIS CORE to Transport Route-Reflectors (tRRs). tRRs then reflecttopology to Segment Routing Path Computation Element (SR-PCEs)Figure 5# BGP-LS Topology Distributionrouter isis ACCESS distribute link-state instance-id 101 net 49.0001.0101.0000.0001.00 address-family ipv4 unicast  mpls traffic-eng router-id Loopback0router isis CORE distribute link-state instance-id 100 net 49.0001.0100.0000.0001.00 address-family ipv4 unicast  mpls traffic-eng router-id Loopback0router bgp 100 address-family link-state link-state ! neighbor-group TvRR  remote-as 100  update-source Loopback0  address-family link-state link-state  !  neighbor 100.0.0.10  use neighbor-group TvRR ! neighbor 100.1.0.10  use neighbor-group TvRR !Transport Route Reflector (tRR)router static address-family ipv4 unicast  0.0.0.0/1 Null0router bgp 100 nsr bgp router-id 100.0.0.10 bgp graceful-restart ibgp policy out enforce-modifications address-family link-state link-state  additional-paths receive  additional-paths send ! neighbor-group RRC  remote-as 100  update-source Loopback0  address-family link-state link-state   route-reflector-client  ! ! neighbor 100.0.0.1  use neighbor-group RRC ! neighbor 100.0.0.2  use neighbor-group RRC ! neighbor 100.0.0.3  use neighbor-group RRC ! neighbor 100.0.0.4  use neighbor-group RRC ! neighbor 100.0.0.100  use neighbor-group RRC ! neighbor 100.0.1.101  use neighbor-group RRC ! neighbor 100.0.2.102  use neighbor-group RRC ! neighbor 100.1.1.101  use neighbor-group RRC !!Services Route Reflector (sRR)router static address-family ipv4 unicast  0.0.0.0/1 Null0router bgp 100 nsr bgp router-id 100.0.0.200 bgp graceful-restart ibgp policy out enforce-modifications address-family vpnv4 unicast  additional-paths receive  additional-paths send ! address-family vpnv6 unicast  additional-paths receive  additional-paths send  retain route-target all ! address-family l2vpn evpn  additional-paths receive  additional-paths send ! neighbor-group SvRR-Client  remote-as 100  update-source Loopback0  address-family l2vpn evpn   route-reflector-client  ! ! neighbor 100.0.0.1  use neighbor-group SvRR-Client ! neighbor 100.0.0.2  use neighbor-group SvRR-Client ! neighbor 100.0.0.3  use neighbor-group SvRR-Client ! neighbor 100.0.0.4  use neighbor-group SvRR-Client ! neighbor 100.2.0.5  use neighbor-group SvRR-Client  description Ixia-P1 ! neighbor 100.2.0.6  use neighbor-group SvRR-Client  description Ixia-P2 ! neighbor 100.0.1.201  use neighbor-group SvRR-Client ! neighbor 100.0.2.202  use neighbor-group SvRR-Client !!Segment Routing Path Computation Element (SR-PCE)router static address-family ipv4 unicast  0.0.0.0/1 Null0router bgp 100 nsr bgp router-id 100.0.0.100 bgp graceful-restart ibgp policy out enforce-modifications address-family link-state link-state ! neighbor-group TvRR  remote-as 100  update-source Loopback0  address-family link-state link-state  ! ! neighbor 100.0.0.10  use neighbor-group TvRR ! neighbor 100.1.0.10  use neighbor-group TvRR !!pce address ipv4 100.0.0.100!Segment Routing Traffic Engineering (SRTE) and Services IntegrationThis section shows how to integrate Traffic Engineering (SRTE) withServices. Particular usecase refers to next sub-section.On Demand Next-Hop (ODN) configuration \u2013 IOS-XRsegment-routing traffic-eng  logging   policy status  !  on-demand color 100   dynamic    pce    !    metric     type igp    !   !  !  pcc   source-address ipv4 100.0.1.50   pce address ipv4 100.0.1.101   !   pce address ipv4 100.1.1.101   !  !extcommunity-set opaque BLUE  100end-setroute-policy ODN_EVPN  set extcommunity color BLUEend-policyrouter bgp 100  address-family l2vpn evpn   route-policy ODN_EVPN out  !!On Demand Next-Hop (ODN) configuration \u2013 IOS-XEmpls traffic-eng tunnelsmpls traffic-eng pcc peer 100.0.1.101 source 100.0.1.51mpls traffic-eng pcc peer 100.0.1.111 source 100.0.1.51mpls traffic-eng pcc report-allmpls traffic-eng auto-tunnel p2p config unnumbered-interface Loopback0mpls traffic-eng auto-tunnel p2p tunnel-num min 1000 max 5000!mpls traffic-eng lsp attributes L3VPN-SRTE path-selection metric igp pce!ip community-list 1 permit 9999route-map L3VPN-ODN-TE-INIT permit 10 match community 1 set attribute-set L3VPN-SRTE!route-map L3VPN-SR-ODN-Mark-Comm permit 10 match ip address L3VPN-ODN-Prefixes set community 9999!!endrouter bgp 100 address-family vpnv4  neighbor SvRR send-community both  neighbor SvRR route-map L3VPN-ODN-TE-INIT in  neighbor SvRR route-map L3VPN-SR-ODN-Mark-Comm outPreferred Path configuration \u2013 IOS-XRsegment-routing traffic-eng  pcc   source-address ipv4 100.0.1.50   pce address ipv4 100.0.1.101   !   pce address ipv4 100.1.1.101   !  !Preferred Path configuration \u2013 IOS-XEmpls traffic-eng tunnelsmpls traffic-eng pcc peer 100.0.1.101 source 100.0.1.51mpls traffic-eng pcc peer 100.0.1.111 source 100.0.1.51mpls traffic-eng pcc report-allServicesEnd-To-End ServicesFigure 6# End-To-End Services TableL3VPN MP-BGP VPNv4 On-Demand Next-HopFigure 7# L3VPN MP-BGP VPNv4 On-Demand Next-Hop Control PlaneAccess Routers# Cisco ASR920 IOS-XE      Operator# New VPNv4 instance via CLI or NSO        Access Router# Advertises/receives VPNv4 routes to/from ServicesRoute-Reflector (sRR)        Access Router# Request SR-PCE to provide path (shortest IGP metric)to remote access router        SR-PCE# Computes and provides the path to remote router(s)        Access Router# Programs Segment Routing Traffic Engineering(SRTE) Policy to reach remote access router  Please refer to \u201cOn Demand Next-Hop (ODN) \u2013 IOS-XE\u201d section forinitial ODN configuration.Access Router Service Provisioning (IOS-XE)#VRF definition configurationvrf definition L3VPN-SRODN-1 rd 100#100 route-target export 100#100 route-target import 100#100 address-family ipv4 exit-address-familyVRF Interface configurationinterface GigabitEthernet0/0/2 mtu 9216 vrf forwarding L3VPN-SRODN-1 ip address 10.5.1.1 255.255.255.0 negotiation autoendBGP VRF configuration Static &amp; BGP neighbor\u00a0Static routing configurationrouter bgp 100 address-family ipv4 vrf L3VPN-SRODN-1  redistribute connected exit-address-familyBGP neighbor\u00a0configurationrouter bgp 100 neighbor Customer-1 peer-group neighbor Customer-1 remote-as 200 neighbor 10.10.10.1 peer-group Customer-1 address-family ipv4 vrf L3VPN-SRODN-2   neighbor 10.10.10.1 activate exit-address-familyL2VPN Single-Homed EVPN-VPWS On-Demand Next-HopFigure 8# L2VPN Single-Homed EVPN-VPWS On-Demand Next-Hop Control PlaneAccess Routers# Cisco NCS5501-SE IOS-XR      Operator# New EVPN-VPWS instance via CLI or NSO        Access Router# Advertises/receives EVPN-VPWS instance to/fromServices Route-Reflector (sRR)        Access Router# Request SR-PCE to provide path (shortest IGP metric)to remote access router        SR-PCE# Computes and provides the path to remote router(s)        Access Router# Programs Segment Routing Traffic Engineering(SRTE) Policy to reach remote access router  Please refer to \u201cOn Demand Next-Hop (ODN) \u2013 IOS-XR\u201d section forinitial ODN configuration.Access Router Service Provisioning (IOS-XR)#PORT Based service configurationl2vpn                                                                                                                                                             xconnect group evpn_vpws                                                                                                                                         p2p odn-1                                                                                                                                                        interface TenGigE0/0/0/5                                                                                                                                   neighbor evpn evi 1000 target 1 source 1  interface TenGigE0/0/0/5   l2transportVLAN Based service configurationl2vpn                                                                                                                                                             xconnect group evpn_vpws                                                                                                                                         p2p odn-1                                                                                                                  interface TenGigE0/0/0/5.1                                                                                                       neighbor evpn evi 1000 target 1 source 1  interface TenGigE0/0/0/5.1 l2transport encapsulation dot1q 1 rewrite ingress tag pop 1 symmetric!L2VPN Static Pseudowire (PW) \u2013 Preferred Path (PCEP)Figure 9# L2VPN Static Pseudowire (PW) \u2013 Preferred Path (PCEP) ControlPlaneAccess Routers# Cisco NCS5501-SE IOS-XR or Cisco ASR920 IOS-XE      Operator# New Static Pseudowire (PW) instance via CLI or NSO        Access Router# Request SR-PCE to provide path (shortest IGP metric)to remote access router        SR-PCE# Computes and provides the path to remote router(s)        Access Router# Programs Segment Routing Traffic Engineering(SRTE) Policy to reach remote access router  Access Router Service Provisioning (IOS-XR)#segment-routing                                                                                                                                                  traffic-eng                                                                                                                                                       policy GREEN-PE7   color 200 end-point ipv4 100.0.2.52   candidate-paths    preference 1     dynamic      pce      !      metric       type igpPort Based Service configurationinterface TenGigE0/0/0/15   l2transportl2vpn  pw-class static-pw-class-PE7  encapsulation mpls   control-word   preferred-path sr-te policy GREEN-PE7 p2p Static-PW-to-PE7-1                                                                                                                                    interface TenGigE0/0/0/15                                                                                                                           neighbor ipv4 100.0.2.52 pw-id 1000                          mpls static label local 1000 remote 1000 pw-class static-pw-class-PE7   VLAN Based Service configurationinterface TenGigE0/0/0/5.1001 l2transport encapsulation dot1q 1001 rewrite ingress tag pop 1 symmetricl2vpn  pw-class static-pw-class-PE7  encapsulation mpls   control-word   preferred-path sr-te policy GREEN-PE7  p2p Static-PW-to-PE7-2                                                                                                                                         interface TenGigE0/0/0/5.1001    neighbor ipv4 100.0.2.52 pw-id 1001                           mpls static label local 1001 remote 1001 pw-class static-pw-class-PE7 Access Router Service Provisioning (IOS-XE)#Port Based service with Static OAM configurationinterface GigabitEthernet0/0/1 mtu 9216 no ip address negotiation auto no keepalive service instance 10 ethernet  encapsulation default  xconnect 100.0.2.54 100 encapsulation mpls manual pw-class mpls   mpls label 100 100   no mpls control-word ! pseudowire-static-oam class static-oam                         timeout refresh send 10                                       ttl 255                             pseudowire-class mpls                                                      encapsulation mpls                                                        no control-word                                                           protocol none                                                             preferred-path interface Tunnel1                                          status protocol notification static static-oam                           !           VLAN Based Service configurationinterface GigabitEthernet0/0/1 no ip address negotiation auto service instance 1 ethernet Static-VPWS-EVC  encapsulation dot1q 10  rewrite ingress tag pop 1 symmetric  xconnect 100.0.2.54 100 encapsulation mpls manual pw-class mpls   mpls label 100 100   no mpls control-word !pseudowire-class mpls                                                      encapsulation mpls                                                        no control-word                                                           protocol none                                                             preferred-path interface Tunnel1  End-To-End Services Data PlaneFigure 10# End-To-End Services Data PlaneHierarchical ServicesFigure 11# Hierarchical Services TableL3VPN \u2013 Single-Homed EVPN-VPWS, MP-BGP VPNv4/6 with Pseudowire-Headend (PWHE)Figure 12# L3VPN \u2013 Single-Homed EVPN-VPWS, MP-BGP VPNv4/6 with Pseudowire-Headend (PWHE) Control PlaneAccess Routers# Cisco NCS5501-SE IOS-XR or Cisco ASR920 IOS-XE      Operator# New EVPN-VPWS instance via CLI or NSO        Access Router# Path to PE Router is known via ACCESS-ISIS IGP.  Provider Edge Routers# Cisco ASR9000 IOS-XR      Operator# New EVPN-VPWS instance via CLI or NSO        Provider Edge Router# Path to Access Router is known viaACCESS-ISIS IGP.        Operator# New L3VPN instance (VPNv4/6) together withPseudowire-Headend (PWHE) via CLI or NSO        Provider Edge Router# Path to remote PE is known via CORE-ISISIGP.  Access Router Service Provisioning (IOS-XR)#VLAN based service configurationl2vpn xconnect group evpn-vpws-l3vpn-PE1  p2p L3VPN-VRF1   interface TenGigE0/0/0/5.501   neighbor evpn evi 13 target 501 source 501   !  ! !interface TenGigE0/0/0/5.501 l2transport encapsulation dot1q 501 rewrite ingress tag pop 1 symmetricPort based service configurationl2vpn                                                                                                                                                             xconnect group evpn-vpws-l3vpn-PE1                                                                                            p2p odn-1                                                                                                                                                       interface TenGigE0/0/0/5                                                                                                                                   neighbor evpn evi 13 target 502 source 502  interface TenGigE0/0/0/5   l2transportAccess Router Service Provisioning (IOS-XE)#VLAN based service configurationl2vpn evpn instance 14 point-to-point vpws context evpn-pe4-pe1  service target 501 source 501  member GigabitEthernet0/0/1 service-instance 501 !interface GigabitEthernet0/0/1 service instance 501 ethernet  encapsulation dot1q 501  rewrite ingress tag pop 1 symmetric !Port based service configurationl2vpn evpn instance 14 point-to-point vpws context evpn-pe4-pe1  service target 501 source 501  member GigabitEthernet0/0/1 service-instance 501 !interface GigabitEthernet0/0/1 service instance 501 ethernet  encapsulation defaultProvider Edge Router Service Provisioning (IOS-XR)#VRF configurationvrf L3VPN-ODNTE-VRF1                                                                                                                    address-family ipv4 unicast                                                                                                             import route-target                                                                                                                     100#501                                                                                                                               !                                                                                                                                      export route-target                                                                                                                     100#501                                                                                                                               !                                                                                                                                     !                                                                                                                                      address-family ipv6 unicast                                                                                                             import route-target                                                                                                                     100#501                                                                                                                               !                                                                                                                                      export route-target                                                                                                                     100#501                                                                                                                               ! !BGP configurationrouter bgp 100                                                                                                                          vrf L3VPN-ODNTE-VRF1  rd 100#501  address-family ipv4 unicast   redistribute connected  !  address-family ipv6 unicast   redistribute connected  ! !PWHE configurationinterface PW-Ether1 vrf L3VPN-ODNTE-VRF1 ipv4 address 10.13.1.1 255.255.255.0 ipv6 address 1000#10#13##1/126 attach generic-interface-list PWHE!EVPN VPWS configuration towards Access PEl2vpn xconnect group evpn-vpws-l3vpn-A-PE3  p2p L3VPN-ODNTE-VRF1   interface PW-Ether1   neighbor evpn evi 13 target 501 source 501   !Figure 13# L3VPN \u2013 Single-Homed EVPN-VPWS, MP-BGP VPNv4/6 withPseudowire-Headend (PWHE) Data PlaneL3VPN \u2013 Anycast Static Pseudowire (PW), MP-BGP VPNv4 with Anycast IRBFigure 14# L3VPN \u2013 Anycast Static Pseudowire (PW), MP-BGP VPNv4 withAnycast IRB Control PlaneAccess Routers# Cisco NCS5501-SE IOS-XR or Cisco ASR920 IOS-XE      Operator# New Static Pseudowire (PW) instance via CLI or NSO        Access Router# Path to PE Router is known via ACCESS-ISIS IGP.  Provider Edge Routers# Cisco ASR9000 IOS-XR (Same on both PErouters in same location PE1/2 and PE3/4)      Operator# New Static Pseudowire (PW) instance via CLI or NSO        Provider Edge Routers# Path to Access Router is known viaACCESS-ISIS IGP.        Operator# New L3VPN instance (VPNv4/6) together with Anycast IRBvia CLI or NSO        Provider Edge Routers# Path to remote PEs is known via CORE-ISISIGP.  Access Router Service Provisioning (IOS-XR)#VLAN based service configurationl2vpn xconnect group Static-VPWS-PE12-H-L3VPN-AnyCast  p2p L3VPN-VRF1   interface TenGigE0/0/0/2.1   neighbor ipv4 100.100.100.12 pw-id 5001    mpls static label local 5001 remote 5001    pw-class static-pw-h-l3vpn-class   !  !interface TenGigE0/0/0/2.1 l2transport encapsulation dot1q 1 rewrite ingress tag pop 1 symmetric!l2vpn pw-class static-pw-h-l3vpn-class  encapsulation mpls   control-word  !Port based service configurationl2vpn xconnect group Static-VPWS-PE12-H-L3VPN-AnyCast  p2p L3VPN-VRF1   interface TenGigE0/0/0/2   neighbor ipv4 100.100.100.12 pw-id 5001    mpls static label local 5001 remote 5001    pw-class static-pw-h-l3vpn-class   !  !interface TenGigE0/0/0/2  l2transport!l2vpn pw-class static-pw-h-l3vpn-class  encapsulation mpls   control-word  !Access Router Service Provisioning (IOS-XE)#VLAN based service configurationinterface GigabitEthernet0/0/5 no ip address media-type auto-select negotiation auto service instance 1 ethernet  encapsulation dot1q 1  rewrite ingress tag pop 1 symmetric  xconnect 100.100.100.12 4001 encapsulation mpls manual   mpls label 4001 4001   mpls control-word !Port based service configurationinterface GigabitEthernet0/0/5 no ip address media-type auto-select negotiation auto service instance 1 ethernet  encapsulation default  xconnect 100.100.100.12 4001 encapsulation mpls manual   mpls label 4001 4001   mpls control-word !Provider Edge Routers Service Provisioning (IOS-XR)#cef adjacency route override ribAnyCast Loopback configurationinterface Loopback100 description Anycast ipv4 address 100.100.100.12 255.255.255.255!router isis ACCESS interface Loopback100 address-family ipv4 unicast prefix-sid index 1012L2VPN configurationl2vpn                                                              bridge group Static-VPWS-H-L3VPN-IRB                               bridge-domain VRF1                                                 neighbor 100.0.1.50 pw-id 5001                                     mpls static label local 5001 remote 5001                          pw-class static-pw-h-l3vpn-class                                 !                                                                 neighbor 100.0.1.51 pw-id 4001                                     mpls static label local 4001 remote 4001                          pw-class static-pw-h-l3vpn-class                                 !                                                                 routed interface BVI1                                              split-horizon group core                                         !                                                                 evi 12001   !  !EVPN configurationevpn evi 12001  !  advertise-mac  ! ! virtual neighbor 100.0.1.50 pw-id 5001  ethernet-segment   identifier type 0 12.00.00.00.00.00.50.00.01Anycast IRB configurationinterface BVI1 host-routing vrf L3VPN-AnyCast-ODNTE-VRF1 ipv4 address 12.0.1.1 255.255.255.0 mac-address 12.0.1 load-interval 30!VRF configurationvrf L3VPN-AnyCast-ODNTE-VRF1 address-family ipv4 unicast  import route-target   100#10001  !  export route-target   100#10001  ! !!BGP configurationrouter bgp 100 vrf L3VPN-AnyCast-ODNTE-VRF1  rd auto  address-family ipv4 unicast   redistribute connected  ! !Figure 15# L3VPN \u2013 Anycast Static Pseudowire (PW), MP-BGP VPNv4/6 withAnycast IRB Datal PlaneL2/L3VPN \u2013 Anycast Static Pseudowire (PW), Multipoint EVPN with Anycast IRBFigure 16# L2/L3VPN \u2013 Anycast Static Pseudowire (PW), Multipoint EVPNwith Anycast IRB Control PlaneAccess Routers# Cisco NCS5501-SE IOS-XR or Cisco ASR920 IOS-XE      Operator# New Static Pseudowire (PW) instance via CLI or NSO        Access Router# Path to PE Router is known via ACCESS-ISIS IGP.  Provider Edge Routers# Cisco ASR9000 IOS-XR (Same on both PErouters in same location PE1/2 and PE3/4)      Operator# New Static Pseudowire (PW) instance via CLI or NSO        Provider Edge Routers# Path to Access Router is known viaACCESS-ISIS IGP.        Operator# New L2VPN Multipoint EVPN instance together withAnycast IRB via CLI or NSO (Anycast IRB is optional when L2 and L3is required in same service instance)        Provider Edge Routers# Path to remote PEs is known via CORE-ISISIGP.  Please note that provisioning on Access and Provider Edge routers issame as in \u201cL3VPN \u2013 Anycast Static Pseudowire (PW), MP-BGP VPNv4/6 withAnycast IRB\u201d. In this use case there is BGP EVPN instead of MP-BGPVPNv4/6 in the core.Access Router Service Provisioning (IOS-XR)#VLAN based service configurationl2vpn xconnect group Static-VPWS-PE12-H-L3VPN-AnyCast  p2p L3VPN-VRF1   interface TenGigE0/0/0/2.1   neighbor ipv4 100.100.100.12 pw-id 5001    mpls static label local 5001 remote 5001    pw-class static-pw-h-l3vpn-class   !  !interface TenGigE0/0/0/2.1 l2transport encapsulation dot1q 1 rewrite ingress tag pop 1 symmetric!l2vpn pw-class static-pw-h-l3vpn-class  encapsulation mpls   control-word  !Port based service configurationl2vpn xconnect group Static-VPWS-PE12-H-L3VPN-AnyCast  p2p L3VPN-VRF1   interface TenGigE0/0/0/2   neighbor ipv4 100.100.100.12 pw-id 5001    mpls static label local 5001 remote 5001    pw-class static-pw-h-l3vpn-class   !  !  interface TenGigE0/0/0/2  l2transport!l2vpn pw-class static-pw-h-l3vpn-class  encapsulation mpls   control-word  !Access Router Service Provisioning (IOS-XE)#VLAN based service configurationinterface GigabitEthernet0/0/5 no ip address media-type auto-select negotiation auto service instance 1 ethernet  encapsulation dot1q 1  rewrite ingress tag pop 1 symmetric  xconnect 100.100.100.12 4001 encapsulation mpls manual   mpls label 4001 4001   mpls control-word !Port based service configurationinterface GigabitEthernet0/0/5 no ip address media-type auto-select negotiation auto service instance 1 ethernet  encapsulation default  xconnect 100.100.100.12 4001 encapsulation mpls manual   mpls label 4001 4001   mpls control-word !Provider Edge Routers Service Provisioning (IOS-XR)#cef adjacency route override ribAnyCast Loopback configurationinterface Loopback100 description Anycast ipv4 address 100.100.100.12 255.255.255.255!router isis ACCESS interface Loopback100 address-family ipv4 unicast prefix-sid index 1012L2VPN Configurationl2vpn                                                              bridge group Static-VPWS-H-L3VPN-IRB                               bridge-domain VRF1                                                 neighbor 100.0.1.50 pw-id 5001                                     mpls static label local 5001 remote 5001                          pw-class static-pw-h-l3vpn-class                                 !                                                                 neighbor 100.0.1.51 pw-id 4001                                     mpls static label local 4001 remote 4001                          pw-class static-pw-h-l3vpn-class                                 !                                                                 routed interface BVI1                                              split-horizon group core                                         !                                                                 evi 12001   !  !EVPN configurationevpn evi 12001  !  advertise-mac  ! ! virtual neighbor 100.0.1.50 pw-id 5001  ethernet-segment   identifier type 0 12.00.00.00.00.00.50.00.01Anycast IRB configurationinterface BVI1 host-routing vrf L3VPN-AnyCast-ODNTE-VRF1 ipv4 address 12.0.1.1 255.255.255.0 mac-address 12.0.1 load-interval 30!VRF configurationvrf L3VPN-AnyCast-ODNTE-VRF1 address-family ipv4 unicast  import route-target   100#10001  !  export route-target   100#10001  ! !!BGP configurationrouter bgp 100 vrf L3VPN-AnyCast-ODNTE-VRF1  rd auto  address-family ipv4 unicast   redistribute connected  ! ! Figure 17# L2/L3VPN \u2013 Anycast Static Pseudowire (PW), Multipoint EVPNwith Anycast IRB Data Plane", "url": "https://xrdocs.github.io/design/blogs/2018-05-09-metro-design-implementation-guide/", "tags": "iosxr, cisco, Metro, Design", "title": "Metro Design Implementation Guide", "author": "Jiri Chaloupka"}, "tutorials-netflow-ncs5500-test-results": {"content": "     Netflow Test Results  Introduction  The tests          Impact of the packet size      Impact of the port load / bandwidth      Impact of sampling interval      Impact of the number of flows      Impact of the active / inactive timers      Full chassis      Stress tests        Test conditions          Conclusion      Acknowledgements        IntroductionIn this last blog post on NCS5500 Netflow, we presented the NF implementation details# from the software processes to the internal networks used to transport sampled traffic and the CPU protection mechanisms. Also, we provided some important information on the various packet sizes and how should be approached the sampling-interval question.Today we will present the results of a Netflow test campaign executed in lab last month. We will see how NCS5500 behaves when we push all cursors.The testsWe will try to check various parameters today, and make sure it doesn\u2019t have any side effects. For instance, we need to make sure we are not impacting the control plane# the routing protocols handled on the same Line Card CPU should not flap or lose update. When possible, we will show the impact on LC CPU.These tests are executed on 36x100G-A-SE line cards running IOS XR 6.3.15. The card is fully wired to an Ixia chassis, able to push line rate traffic over each interface simultaneously. In some specific tests, we will use a fully loaded chassis (16-slots) with a \u201csnake\u201d configuration# each port is looped to another one to re-inject traffic and load the chassis without requiring 574x 100G testing ports.The tests have been carried out configuring Neflow v9 on physical but also bundle interfaces. To make the test more realistic, we added URPF v4+v6 to the interface configuration, dampening, ingress+egress QoS and ingress v4+v6 ACLs, LDP and RSVP-TE, and finally multicast (IGMP and PIM).All the tests have been executed with both v4 and v6 simultaneously.We made sure that a lot of \u201cnew flows\u201d were generated from Ixia using some traffic distribution knobs. Indeed, the \u201ceffort\u201d of creating a new entry in the cache compared to updating an existing one is not the same for the nfsrv process.A picture of the test device console#Let\u2019s get started\u2026Impact of the packet sizeIn this first test, we will check the impact on the CPU load when pushing different packet size.Test parameters#  each port is generating 200,000 PPS  1M flows total generated by Ixia  sample-interval configured# 1#4000  active/inactive timers# 30s/30s  timeout rate-limit 10000Variable parameter(s)#  packet size# 64B, 128B, 256B, 512BMeasurement#  CPU impact on nfproducer, nfsrv, netioResults#Comment# during all these tests, we noticed that CPU utilization is rarely completely linear. We will need to accept some margin of errors in the figures collected and presented here.Conclusion#  the packet size doesn\u2019t seem to influence significantly the CPU load  it\u2019s something we are expecting for everything above 100B @ L3 since the NPU doesn\u2019t sample more  no taildrop observed, no impact on other routing protocols (v4 or v6)Impact of the port load / bandwidthIn this second test, we are generating IMIX traffic (with packet size variable between 100B and 300B) and we simply adjust the interface load (simultaneously on the 36x ports).Test parameters#  each port is generating 100B-300B packets  1M flows total generated by Ixia  sample-interval configured# 1#4000  active/inactive timers# 30s/30s  timeout rate-limit 10000Variable parameter(s)#  interface load# 20%, 40%, 60%, 80%, 100%Measurement#  CPU impact on nfproducer, nfsrv, netioResults#We can see with some margin of error in the third measurement that CPU load for nfproducer and nfsrv is growing and reach a \u201cplateau\u201d. This can be easily explained by the shaper used on each NPU. In current release (6.3.2), we use a shaper of 133Mbps. We will increase this number in next releases (to 200Mbps).Conclusion#  bandwidth utilization has, logically, an impact on the CPU load but no taildrop were observed, no impact on other routing protocols (v4 or v6)Impact of sampling intervalHere, we will use line rate traffic on the 36 ports and we will only change the sampling-interval in our configuration. It will logically have an impact on the number of sampled packets we push from the NPUs to the Line Card CPU. So we expect the CPU load to increase.Test parameters#  each port is generating 512B packets  each port is transmitting line rate  we use all 36 ports  1M flows total generated by Ixia  active/inactive timers# 30s/30s  timeout rate-limit 10000Variable parameter(s)#  sampling interval# 1#32K, 1#16K, 1#8K, 1#4K, 1#2K# 1#1K, 1#1Measurement#  CPU impact on nfproducer, nfsrv, netioResults#Again, we will need to accept some margin of error in the measurement of the last test.We can see a progression in the CPU utilization, up to a plateau when we reach the shaper. After this value, even if we sample more aggressively, we are not pushing more sampled packets to the LC CPU.Conclusion#  with constant traffic, sampling-interval has, of course, a direct impact on the CPU load but no taildrop were observed, no impact on other routing protocols (v4 or v6)Impact of the number of flowsIn this fourth test, we will check what happens when we exceed the cache size. So we will generate more flows than the maximum cache limit we can configure (1 million entries).Test parameters#  each port is generating 512B packets  each port is transmitting line rate  we use all 36 ports  sample-interval configured# 1#4000  active/inactive timers# 30s/30s  timeout rate-limit 10000Variable parameter(s)#  Number of flows# 1M, 2M, 3MMeasurement#  CPU impact on nfproducer, nfsrv, netioResults#Very straightforward analysis# no impact at all, the CPU load stays constant.Conclusion#  once the cache reaches its limit, nothing happens# we don\u2019t remove new entries or punt packets or anything  impact on LC CPU is not noticeable regardless the actual number of flows passing through the box  of course, in such situation, the traffic matrix based on this netflow records will be inacurrate  no taildrop observed, no impact on other routing protocols (v4 or v6)Impact of the active / inactive timersThis fifth test is now stressing a different aspect of the netflow protocol# the record generation. When we manipulate the active and inactive timers, we are influencing the amount of records generated.Test parameters#  each port is generating 512B packets  each port is transmitting line rate  we use all 36 ports  sample-interval configured# 1#4000  1M flows total generated by Ixia  timeout rate-limit 50000# note it\u2019s a very high number here, we don\u2019t want to limit the amount of records and potentially pollute the testVariable parameter(s)#  active/inactive timers# 30/30, 15/15, 5/5, 1/1Measurement#  CPU impact on nfproducer, nfsrv, netioResults#It appears that only nfsrv is impacted by this test, even if we see a small increase in the netio process too.Quick refresher on the role of nfsvr#  Receives NF record packets from nf_producer  Creates a new flow cache if not already created, or update a existing flow cache (packet / byte count) for the flow monitor  Periodically ages entries form the NF cache into NF export packets  Sends the NF export packets to the NF collector using UDPNot a surprise to see the CPU load occupied by nfsvr increasing when we move to lower active/inactive timers. Since netio is used to transport the NF records, it\u2019s also logical to see a progression of the CPU load when we transmit more and more of them.Conclusion#  nfsvr and netio are the only processes impacted by more agressive active/inactive timing  if we have kept a much lower NF record rate-limiter, it\u2019s very likely we would have seen a plateau in the diagram  no taildrop observed, no impact on other routing protocols (v4 or v6)Full chassisIn this test, we used a fully loaded chassis (16 times 36x 100G connected with a \u201csnake topology\u201d) and we configured Netflow on all ports.Since the netflow is handled at the line card CPU level, the number of line cards makes this test interesting for only one aspect# we used the same collector destination address everywhere.Test parameters#  each port is generating 512B packets  each port is transmitting line rate  we use all 36 ports  sample-interval configured# 1#4000  1M flows total generated by Ixia  timeout rate-limit 10000  destination address of the collector# 173.173.173.1Picture of the testbed#Conclusion#  nfsvr, nf_producer and netio being local to each line cards, nothing noticeable  no taildrop observed, no impact on other routing protocols (v4 or v6)Stress testsFinally, we performed stress tests#  on the line card# reloading it multiple times in a row  on the processes# forcing manual restart of the various processes (nf_producer and nfsrv)RP/0/RP0/CPU0#fretta-64#process restart nfsvr location 0/5/CPU0RP/0/RP0/CPU0#Feb 25 10#59#05.975 UTC# sysmgr_control[66620]# %OS-SYSMGR-4-PROC_RESTART_NAME # User hsivasam (con0_RP0_CPU0) requested a restart of process nfsvr at 0/5/CPU0RP/0/RP0/CPU0#fretta-64#  on the configuration# configuring and unconfiguring Netflow on interfaces dozens of times in a rowRP/0/RP0/CPU0#fretta-64#sh run int hundredGigE 0/5/0/11interface HundredGigE0/5/0/11 mtu 4484 service-policy input policy-backbone-default-in.v4 service-policy output policy-backbone-default-out-P-P.v4 ipv4 address 2.254.132.2 255.255.255.0 ipv4 verify unicast source reachable-via any ipv6 verify unicast source reachable-via any ipv6 address 2001#2#254#132##2/64 load-interval 30 flow ipv4 monitor ICX sampler ICX ingress flow ipv6 monitor ICX-v6 sampler ICX ingress dampening ipv4 access-group 121 ingress ipv6 access-group ipv6-edge-peer ingress!RP/0/RP0/CPU0#fretta-64#rollback configuration last 1RP/0/RP0/CPU0#fretta-64#      on the interfaces# we forced flapping on the interfaces where netflow was configured and checked the impact. Both with bundled interfaces and physical interfaces.        clear cache record# forces the generation of all the records before flushing the cache entries.  RP/0/RP0/CPU0#fretta-64#clear flow monitor ICX cache force-export location 0/5$Clear cache entries for this monitor on this location. Continue? [confirm]RP/0/RP0/CPU0#fretta-64#Results#  no problem encountered during these tests.Test conditionsIn this last section, we simply copy paste a couple of show commands to demonstrate the routing scale used during this test.RP/0/RP0/CPU0#fretta-64#show bgp scale                                          VRF# default Neighbors Configured# 636    Established# 636    Address-Family   Prefixes Paths    PathElem   Prefix     Path       PathElem                                                 Memory     Memory     Memory    IPv4 Unicast    795399   20859177 795399     112.27MB   1.71GB     81.17MB      IPv6 Unicast    148856   745047   148856     22.71MB    62.53MB    15.47MB      ------------------------------------------------------------------------------  Total           944255   21604224 944255     134.98MB   1.77GB     96.64MB    Total VRFs Configured# 0RP/0/RP0/CPU0#fretta-64#show bgp sum                                            BGP router identifier 193.251.245.8, local AS number 1000BGP generic scan interval 60 secsNon-stop routing is enabledBGP table state# ActiveTable ID# 0xe0000000   RD version# 189937114BGP main routing table version 189937114BGP NSR Initial initsync version 808735 (Reached)BGP NSR/ISSU Sync-Group versions 189937114/0BGP scan interval 60 secsBGP is operating in STANDALONE mode.Process       RcvTblVer   bRIB/RIB   LabelVer  ImportVer  SendTblVer  StandbyVerSpeaker       189937114  189937114  189937114  189937114   189937114   189937114Neighbor        Spk    AS MsgRcvd MsgSent   TblVer  InQ OutQ  Up/Down  St/PfxRcd179.179.1.2       0  1000    6114   33893 189937114    0    0 04#54#45         10179.179.1.3       0  1000    6119   33945 189937114    0    0 04#54#48         10179.179.1.4       0  1000    6120   33947 189937114    0    0 04#54#48         10179.179.1.5       0  1000    6120   33944 189937114    0    0 04#54#44         10179.179.1.6       0  1000    6121   33947 189937114    0    0 04#54#47         10179.179.1.7       0  1000    6114   31913 189937114    0    0 05#12#25         10179.179.1.8       0  1000    6114   31913 189937114    0    0 05#12#30         10179.179.1.9       0  1000    6114   31911 189937114    0    0 05#12#26         10179.179.1.10      0  1000    6116   31910 189937114    0    0 05#12#30         10179.179.1.11      0  1000    6113   31910 189937114    0    0 05#12#25         10179.179.1.12      0  1000    6113   31912 189937114    0    0 05#12#25         10179.179.1.13      0  1000    6112   31913 189937114    0    0 05#12#28         10179.179.1.14      0  1000    6112   31912 189937114    0    0 05#12#28         10179.179.1.15      0  1000    6114   31914 189937114    0    0 05#12#27         10179.179.1.16      0  1000    6113   31911 189937114    0    0 05#12#29         10179.179.1.17      0  1000    6115   31912 189937114    0    0 05#12#28         10179.179.1.18      0  1000    6114   31912 189937114    0    0 05#12#29         10179.179.1.19      0  1000    6115   31914 189937114    0    0 05#12#26         10179.179.1.20      0  1000    6116   31912 189937114    0    0 05#12#30         10179.179.1.21      0  1000    6113   31911 189937114    0    0 05#12#26         10179.179.1.22      0  1000    6114   31911 189937114    0    0 05#12#28         10179.179.1.23      0  1000    6113   31912 189937114    0    0 05#12#26         10179.179.1.24      0  1000    6114   31911 189937114    0    0 05#12#30         10179.179.1.25      0  1000    6112   31912 189937114    0    0 05#12#25         10179.179.1.26      0  1000    6112   31910 189937114    0    0 05#12#26         10179.179.1.27      0  1000    6112   31910 189937114    0    0 05#12#25         10179.179.1.28      0  1000    6115   31914 189937114    0    0 05#12#25         10179.179.1.29      0  1000    6114   31913 189937114    0    0 05#12#26         10179.179.1.30      0  1000    6114   31911 189937114    0    0 05#12#26         10179.179.1.31      0  1000    6112   31914 189937114    0    0 05#12#26         10179.179.1.32      0  1000    6113   31914 189937114    0    0 05#12#28         10179.179.1.33      0  1000    6114   31915 189937114    0    0 05#12#29         10179.179.1.34      0  1000    6116   31913 189937114    0    0 05#12#30         10179.179.1.35      0  1000    6115   31914 189937114    0    0 05#12#29         10179.179.1.36      0  1000    6117   31915 189937114    0    0 05#12#28         10179.179.1.37      0  1000    6113   31912 189937114    0    0 05#12#30         10179.179.1.38      0  1000    6112   31909 189937114    0    0 05#12#26         10179.179.1.39      0  1000    6114   31913 189937114    0    0 05#12#28         10179.179.1.40      0  1000    6114   31912 189937114    0    0 05#12#30         10179.179.1.41      0  1000    6112   31500 189937114    0    0 05#12#28         10179.179.1.42      0  1000    6113   31913 189937114    0    0 05#12#27         10179.179.1.43      0  1000    6113   31914 189937114    0    0 05#12#28         10179.179.1.44      0  1000    6114   31912 189937114    0    0 05#12#29         10179.179.1.45      0  1000    6112   31914 189937114    0    0 05#12#26         10179.179.1.46      0  1000    6115   31912 189937114    0    0 05#12#27         10179.179.1.47      0  1000    6115   31912 189937114    0    0 05#12#26         10179.179.1.48      0  1000    6113   31911 189937114    0    0 05#12#27         10179.179.1.49      0  1000    6114   31913 189937114    0    0 05#12#30         10179.179.1.50      0  1000    6115   31914 189937114    0    0 05#12#30         10179.179.1.51      0  1000    6236   31913 189937114    0    0 05#12#30      12000187.187.1.2       0  3000    6105   26291 189937114    0    0 05#38#33       1800187.187.1.3       0  3001    6106   26294 189937114    0    0 05#38#32       1800187.187.1.4       0  3002    6108   26294 189937114    0    0 05#38#32       1800187.187.1.5       0  3003    6106   26291 189937114    0    0 05#38#34       1800187.187.1.6       0  3004    6105   26292 189937114    0    0 05#38#33       1800187.187.1.7       0  3005    6106   26294 189937114    0    0 05#38#32       1800187.187.1.8       0  3006    6106   26293 189937114    0    0 05#38#32       1800187.187.1.9       0  3007    6107   26294 189937114    0    0 05#38#35       1800187.187.1.10      0  3008    6107   26295 189937114    0    0 05#38#31       1800187.187.1.11      0  3009    6107   26295 189937114    0    0 05#38#35       1800187.187.1.12      0  3010    6107   26294 189937114    0    0 05#38#30       1800187.187.1.13      0  3011    6105   26294 189937114    0    0 05#38#30       1800187.187.1.14      0  3012    6104   26292 189937114    0    0 05#38#32       1800187.187.1.15      0  3013    6106   26294 189937114    0    0 05#38#35       1800187.187.1.16      0  3014    6109   26296 189937114    0    0 05#38#30       1800187.187.1.17      0  3015    6105   26292 189937114    0    0 05#38#34       1800187.187.1.18      0  3016    6107   26294 189937114    0    0 05#38#34       1800187.187.1.19      0  3017    6106   26292 189937114    0    0 05#38#34       1800187.187.1.20      0  3018    6107   26293 189937114    0    0 05#38#33       1800187.187.1.21      0  3019    6108   26292 189937114    0    0 05#38#33       1800187.187.1.22      0  3020    6107   26295 189937114    0    0 05#38#33       1800187.187.1.23      0  3021    6105   26293 189937114    0    0 05#38#34       1800187.187.1.24      0  3022    6105   26291 189937114    0    0 05#38#32       1800187.187.1.25      0  3023    6106   26294 189937114    0    0 05#38#35       1800187.187.1.26      0  3024    6106   26293 189937114    0    0 05#38#34       1800187.187.1.27      0  3025    6108   26296 189937114    0    0 05#38#30       1800187.187.1.28      0  3026    6106   26293 189937114    0    0 05#38#34       1800187.187.1.29      0  3027    6107   26295 189937114    0    0 05#38#35       1800187.187.1.30      0  3028    6107   26295 189937114    0    0 05#38#33       1800187.187.1.31      0  3029    6106   26292 189937114    0    0 05#38#35       1800187.187.1.32      0  3030    6106   26294 189937114    0    0 05#38#31       1800187.187.1.33      0  3031    6106   26293 189937114    0    0 05#38#33       1800187.187.1.34      0  3032    6107   26295 189937114    0    0 05#38#34       1800187.187.1.35      0  3033    6107   26293 189937114    0    0 05#38#32       1800187.187.1.36      0  3034    6104   26292 189937114    0    0 05#38#31       1800187.187.1.37      0  3035    6105   26294 189937114    0    0 05#38#33       1800187.187.1.38      0  3036    6105   26293 189937114    0    0 05#38#30       1800187.187.1.39      0  3037    6107   26295 189937114    0    0 05#38#34       1800187.187.1.40      0  3038    6107   26295 189937114    0    0 05#38#31       1800187.187.1.41      0  3039    6105   26293 189937114    0    0 05#38#35       1800187.187.1.42      0  3040    6106   26293 189937114    0    0 05#38#32       1800187.187.1.43      0  3041    6105   26295 189937114    0    0 05#38#34       1800187.187.1.44      0  3042    6106   26296 189937114    0    0 05#38#35       1800187.187.1.45      0  3043    6108   26295 189937114    0    0 05#38#31       1800187.187.1.46      0  3044    6107   26294 189937114    0    0 05#38#31       1800187.187.1.47      0  3045    6105   26293 189937114    0    0 05#38#32       1800187.187.1.48      0  3046    6107   26295 189937114    0    0 05#38#33       1800187.187.1.49      0  3047    6107   26295 189937114    0    0 05#38#31       1800187.187.1.50      0  3048    6105   26292 189937114    0    0 05#38#31       1800187.187.1.51      0  3049    6105   26291 189937114    0    0 05#38#31       1800188.1.1.2         0  1000    2669   12981 189937114    0    0 05#38#32        250188.1.1.3         0  1001    2668   12980 189937114    0    0 05#38#30        250188.1.1.4         0  1002    2669   12984 189937114    0    0 05#38#33        250188.1.1.5         0  1003    2669   12980 189937114    0    0 05#38#34        250188.1.1.6         0  1004    2669   12982 189937114    0    0 05#38#35        250188.1.1.7         0  1005    2669   12981 189937114    0    0 05#38#37        250188.1.1.8         0  1006    2669   12982 189937114    0    0 05#38#38        250188.1.1.9         0  1007    2652   11836 189937114    0    0 05#30#57        250188.1.1.10        0  1008    2669   12984 189937114    0    0 05#38#32        250188.1.1.11        0  1009    2669   12980 189937114    0    0 05#38#32        250188.1.1.12        0  1010    2668   12980 189937114    0    0 05#38#38        250188.1.1.13        0  1011    2669   12981 189937114    0    0 05#38#34        250188.1.1.14        0  1012    2669   12982 189937114    0    0 05#38#35        250188.1.1.15        0  1013    2669   12981 189937114    0    0 05#38#32        250188.1.1.16        0  1014    2670   12981 189937114    0    0 05#38#32        250188.1.1.17        0  1015    2670   12984 189937114    0    0 05#38#35        250188.1.1.18        0  1016    2669   12980 189937114    0    0 05#38#30        250188.1.1.19        0  1017    2670   12981 189937114    0    0 05#38#31        250188.1.1.20        0  1018    2669   12981 189937114    0    0 05#38#33        250188.1.1.21        0  1019    2669   12980 189937114    0    0 05#38#34        250188.1.1.22        0  1020    2669   12981 189937114    0    0 05#38#37        250188.1.1.23        0  1021    2668   12980 189937114    0    0 05#38#31        250188.1.1.24        0  1022    2670   12984 189937114    0    0 05#38#33        250188.1.1.25        0  1023    2669   12981 189937114    0    0 05#38#32        250188.1.1.26        0  1024    2670   12981 189937114    0    0 05#38#31        250188.1.1.27        0  1025    2668   12980 189937114    0    0 05#38#31        250188.1.1.28        0  1026    2670   12981 189937114    0    0 05#38#34        250188.1.1.29        0  1027    2668   12981 189937114    0    0 05#38#32        250188.1.1.30        0  1028    2669   12981 189937114    0    0 05#38#34        250188.1.1.31        0  1029    2669   12980 189937114    0    0 05#38#33        250188.1.1.32        0  1030    2669   12981 189937114    0    0 05#38#34        250188.1.1.33        0  1031    2669   12983 189937114    0    0 05#38#32        250188.1.1.34        0  1032    2669   12984 189937114    0    0 05#38#35        250188.1.1.35        0  1033    2653   11838 189937114    0    0 05#30#58        250188.1.1.36        0  1034    2669   12981 189937114    0    0 05#38#31        250188.1.1.37        0  1035    2652   11836 189937114    0    0 05#30#54        250188.1.1.38        0  1036    2670   12984 189937114    0    0 05#38#34        250188.1.1.39        0  1037    2670   12980 189937114    0    0 05#38#33        250188.1.1.40        0  1038    2670   12957 189937114    0    0 05#38#35        250188.1.1.41        0  1039    2669   12984 189937114    0    0 05#38#36        250188.1.1.42        0  1040    2670   12981 189937114    0    0 05#38#31        250188.1.1.43        0  1041    2669   12984 189937114    0    0 05#38#34        250188.1.1.44        0  1042    2652   11836 189937114    0    0 05#30#53        250188.1.1.45        0  1043    2669   12981 189937114    0    0 05#38#33        250188.1.1.46        0  1044    2669   12981 189937114    0    0 05#38#33        250188.1.1.47        0  1045    2668   12981 189937114    0    0 05#38#38        250188.1.1.48        0  1046    2653   11836 189937114    0    0 05#30#57        250188.1.1.49        0  1047    2653   11837 189937114    0    0 05#30#58        250188.1.1.50        0  1048    2668   12981 189937114    0    0 05#38#36        250188.1.1.51        0  1049    2668   12981 189937114    0    0 05#38#32        250188.1.1.52        0  1050    6092   25321 189937114    0    0 05#38#38        250188.1.1.53        0  1051    6093   25324 189937114    0    0 05#38#32        250188.1.1.54        0  1052    6092   25323 189937114    0    0 05#38#34        250188.1.1.55        0  1053    6090   25323 189937114    0    0 05#38#35        250188.1.1.56        0  1054    6092   25321 189937114    0    0 05#38#34        250188.1.1.57        0  1055    6091   25324 189937114    0    0 05#38#35        250188.1.1.58        0  1056    6074   24178 189937114    0    0 05#30#54        250188.1.1.59        0  1057    6092   25296 189937114    0    0 05#38#31        250188.1.1.60        0  1058    6091   25324 189937114    0    0 05#38#35        250188.1.1.61        0  1059    6092   25325 189937114    0    0 05#38#38        250188.1.1.62        0  1060    6091   25322 189937114    0    0 05#38#38        250188.1.1.63        0  1061    6090   25323 189937114    0    0 05#38#34        250188.1.1.64        0  1062    6091   25324 189937114    0    0 05#38#38        250188.1.1.65        0  1063    6091   25323 189937114    0    0 05#38#35        250188.1.1.66        0  1064    6092   25325 189937114    0    0 05#38#37        250188.1.1.67        0  1065    6091   25324 189937114    0    0 05#38#38        250188.1.1.68        0  1066    6091   25324 189937114    0    0 05#38#35        250188.1.1.69        0  1067    6093   25324 189937114    0    0 05#38#32        250188.1.1.70        0  1068    6090   25323 189937114    0    0 05#38#34        250188.1.1.71        0  1069    6076   24179 189937114    0    0 05#30#56        250188.1.1.72        0  1070    6091   25323 189937114    0    0 05#38#34        250188.1.1.73        0  1071    6090   25323 189937114    0    0 05#38#33        250188.1.1.74        0  1072    6090   25323 189937114    0    0 05#38#37        250188.1.1.75        0  1073    6089   25321 189937114    0    0 05#38#38        250188.1.1.76        0  1074    6091   25298 189937114    0    0 05#38#34        250188.1.1.77        0  1075    6076   24178 189937114    0    0 05#30#56        250188.1.1.78        0  1076    6092   25324 189937114    0    0 05#38#33        250188.1.1.79        0  1077    6091   25323 189937114    0    0 05#38#34        250188.1.1.80        0  1078    6092   25300 189937114    0    0 05#38#32        250188.1.1.81        0  1079    6091   25322 189937114    0    0 05#38#33        250188.1.1.82        0  1080    6091   25297 189937114    0    0 05#38#32        250188.1.1.83        0  1081    6091   25297 189937114    0    0 05#38#34        250188.1.1.84        0  1082    6089   25295 189937114    0    0 05#38#35        250188.1.1.85        0  1083    6091   25297 189937114    0    0 05#38#34        250188.1.1.86        0  1084    6092   25298 189937114    0    0 05#38#34        250188.1.1.87        0  1085    6092   25299 189937114    0    0 05#38#34        250188.1.1.88        0  1086    6093   25300 189937114    0    0 05#38#34        250188.1.1.89        0  1087    6091   25298 189937114    0    0 05#38#35        250188.1.1.90        0  1088    6091   25299 189937114    0    0 05#38#33        250188.1.1.91        0  1089    6091   25296 189937114    0    0 05#38#32        250188.1.1.92        0  1090    6091   25298 189937114    0    0 05#38#31        250188.1.1.93        0  1091    6091   25297 189937114    0    0 05#38#33        250188.1.1.94        0  1092    6091   25298 189937114    0    0 05#38#31        250188.1.1.95        0  1093    6091   25296 189937114    0    0 05#38#32        250188.1.1.96        0  1094    6090   25296 189937114    0    0 05#37#38        250188.1.1.97        0  1095    6092   25298 189937114    0    0 05#38#31        250188.1.1.98        0  1096    6092   25299 189937114    0    0 05#38#35        250188.1.1.99        0  1097    6092   25298 189937114    0    0 05#38#30        250188.1.1.100       0  1098    6091   25297 189937114    0    0 05#38#35        250188.1.1.101       0  1099    6092   25298 189937114    0    0 05#38#34        250189.1.1.2         0   100    6195   25324 189937114    0    0 05#38#33      12000189.1.1.3         0   101    6100   25324 189937114    0    0 05#38#33       1800189.1.1.4         0   102    6100   25322 189937114    0    0 05#38#34       1800189.1.1.5         0   103    6099   25322 189937114    0    0 05#38#35       1800189.1.1.6         0   104    6100   25323 189937114    0    0 05#38#32       1800189.1.1.7         0   105    6101   25323 189937114    0    0 05#38#34       1800189.1.1.8         0   106    6101   25325 189937114    0    0 05#38#35       1800189.1.1.9         0   107    6101   25324 189937114    0    0 05#38#34       1800189.1.1.10        0   108    6100   25321 189937114    0    0 05#38#34       1800189.1.1.11        0   109    6100   25323 189937114    0    0 05#38#33       1800189.1.1.12        0   110    6099   25323 189937114    0    0 05#38#32       1800189.1.1.13        0   111    6100   25323 189937114    0    0 05#38#32       1800189.1.1.14        0   112    6101   25322 189937114    0    0 05#38#32       1800189.1.1.15        0   113    6101   25322 189937114    0    0 05#38#30       1800189.1.1.16        0   114    6101   25325 189937114    0    0 05#38#33       1800189.1.1.17        0   115    6099   25322 189937114    0    0 05#38#30       1800189.1.1.18        0   116    6100   25323 189937114    0    0 05#38#34       1800189.1.1.19        0   117    6101   25324 189937114    0    0 05#38#34       1800189.1.1.20        0   118    6101   25322 189937114    0    0 05#38#33       1800189.1.1.21        0   119    6100   25323 189937114    0    0 05#38#33       1800189.1.1.22        0   120    6101   25324 189937114    0    0 05#38#30       1800189.1.1.23        0   121    6100   25324 189937114    0    0 05#38#31       1800189.1.1.24        0   122    6100   25322 189937114    0    0 05#38#34       1800189.1.1.25        0   123    6100   25324 189937114    0    0 05#38#35       1800189.1.1.26        0   124    6100   25323 189937114    0    0 05#38#32       1800189.1.1.27        0   125    6099   25322 189937114    0    0 05#38#31       1800189.1.1.28        0   126    6100   25323 189937114    0    0 05#38#32       1800189.1.1.29        0   127    6100   25324 189937114    0    0 05#38#33       1800189.1.1.30        0   128    6101   25323 189937114    0    0 05#38#31       1800189.1.1.31        0   129    6100   25322 189937114    0    0 05#38#34       1800189.1.1.32        0   130    6100   25321 189937114    0    0 05#38#33       1800189.1.1.33        0   131    6100   25322 189937114    0    0 05#38#31       1800189.1.1.34        0   132    6100   25322 189937114    0    0 05#38#31       1800189.1.1.35        0   133    6100   25323 189937114    0    0 05#38#30       1800189.1.1.36        0   134    6099   25322 189937114    0    0 05#38#34       1800189.1.1.37        0   135    6100   25323 189937114    0    0 05#38#33       1800189.1.1.38        0   136    6100   25322 189937114    0    0 05#38#35       1800189.1.1.39        0   137    6101   25323 189937114    0    0 05#38#35       1800189.1.1.40        0   138    6101   25325 189937114    0    0 05#38#34       1800189.1.1.41        0   139    6100   25323 189937114    0    0 05#38#33       1800189.1.1.42        0   140    6101   25325 189937114    0    0 05#38#35       1800189.1.1.43        0   141    6101   25325 189937114    0    0 05#38#35       1800189.1.1.44        0   142    6101   25323 189937114    0    0 05#38#32       1800189.1.1.45        0   143    6100   25323 189937114    0    0 05#38#34       1800189.1.1.46        0   144    6100   25324 189937114    0    0 05#38#32       1800189.1.1.47        0   145    6100   25323 189937114    0    0 05#38#31       1800189.1.1.48        0   146    6101   25324 189937114    0    0 05#38#32       1800189.1.1.49        0   147    6100   25323 189937114    0    0 05#38#35       1800189.1.1.50        0   148    6099   25372 189937114    0    0 05#38#31       1800189.1.1.51        0   149    6100   25322 189937114    0    0 05#38#33       1800189.1.1.52        0   150    6101   25323 189937114    0    0 05#38#31       1800189.1.1.53        0   151    6099   25322 189937114    0    0 05#38#30       1800189.1.1.54        0   152    6101   25324 189937114    0    0 05#38#34       1800189.1.1.55        0   153    6100   25323 189937114    0    0 05#38#30       1800189.1.1.56        0   154    6100   25323 189937114    0    0 05#38#35       1800189.1.1.57        0   155    6099   25321 189937114    0    0 05#38#33       1800189.1.1.58        0   156    6101   25323 189937114    0    0 05#38#31       1800189.1.1.59        0   157    6101   25323 189937114    0    0 05#38#30       1800189.1.1.60        0   158    6101   25324 189937114    0    0 05#38#30       1800189.1.1.61        0   159    6100   25324 189937114    0    0 05#38#31       1800189.1.1.62        0   160    6100   25323 189937114    0    0 05#38#32       1800189.1.1.63        0   161    6101   25322 189937114    0    0 05#38#36       1800189.1.1.64        0   162    6101   25323 189937114    0    0 05#38#35       1800189.1.1.65        0   163    6099   25323 189937114    0    0 05#38#32       1800189.1.1.66        0   164    6101   25323 189937114    0    0 05#38#32       1800189.1.1.67        0   165    6101   25323 189937114    0    0 05#38#31       1800189.1.1.68        0   166    6100   25323 189937114    0    0 05#38#31       1800189.1.1.69        0   167    6101   25325 189937114    0    0 05#38#34       1800189.1.1.70        0   168    6100   25322 189937114    0    0 05#38#32       1800189.1.1.71        0   169    6100   25322 189937114    0    0 05#38#30       1800189.1.1.72        0   170    6099   25322 189937114    0    0 05#38#30       1800189.1.1.73        0   171    6101   25324 189937114    0    0 05#38#34       1800189.1.1.74        0   172    6099   25323 189937114    0    0 05#38#30       1800189.1.1.75        0   173    6100   25323 189937114    0    0 05#38#35       1800189.1.1.76        0   174    6101   25325 189937114    0    0 05#38#30       1800189.1.1.77        0   175    6101   25322 189937114    0    0 05#38#34       1800189.1.1.78        0   176    6101   25323 189937114    0    0 05#38#33       1800189.1.1.79        0   177    6101   25323 189937114    0    0 05#38#31       1800189.1.1.80        0   178    6099   25323 189937114    0    0 05#38#33       1800189.1.1.81        0   179    6101   25324 189937114    0    0 05#38#32       1800189.1.1.82        0   180    6101   25322 189937114    0    0 05#38#35       1800189.1.1.83        0   181    6101   25324 189937114    0    0 05#38#35       1800189.1.1.84        0   182    6100   25323 189937114    0    0 05#38#32       1800189.1.1.85        0   183    6099   25322 189937114    0    0 05#38#33       1800189.1.1.86        0   184    6100   25323 189937114    0    0 05#38#34       1800189.1.1.87        0   185    6100   25321 189937114    0    0 05#38#34       1800189.1.1.88        0   186    6100   25324 189937114    0    0 05#38#31       1800189.1.1.89        0   187    6099   25321 189937114    0    0 05#38#35       1800189.1.1.90        0   188    6099   25321 189937114    0    0 05#38#34       1800189.1.1.91        0   189    6100   25323 189937114    0    0 05#38#33       1800189.1.1.92        0   190    6101   25324 189937114    0    0 05#38#34       1800189.1.1.93        0   191    6100   25322 189937114    0    0 05#38#30       1800189.1.1.94        0   192    6100   25324 189937114    0    0 05#38#34       1800189.1.1.95        0   193    6101   25324 189937114    0    0 05#38#33       1800189.1.1.96        0   194    6100   25324 189937114    0    0 05#38#34       1800189.1.1.97        0   195    6100   25321 189937114    0    0 05#38#34       1800189.1.1.98        0   196    6101   25324 189937114    0    0 05#38#31       1800189.1.1.99        0   197    6101   25323 189937114    0    0 05#38#33       1800189.1.1.100       0   198    6102   25326 189937114    0    0 05#38#35       1800189.1.1.101       0   199    6100   25323 189937114    0    0 05#38#34       1800193.251.245.7     0  1000   31824   31480 189937114    0    0 06#12#07     477709193.251.246.7     0  1000   22499   21128 189937114    0    0 06#15#57     477708193.251.246.9     0  1000   25867   27470 189937114    0    0 06#20#53     477709193.251.246.10    0  1000   25869   27470 189937114    0    0 06#20#48     477709193.251.246.11    0  1000   26643   27549 189937114    0    0 16#34#06     477709193.251.246.12    0  1000   25844   27177 189937114    0    0 06#20#49     477709193.251.246.13    0  1000   25870   27327 189937114    0    0 06#20#54     477709193.251.246.14    0  1000   25868   27470 189937114    0    0 06#20#56     477709193.251.246.15    0  1000   25867   27471 189937114    0    0 06#20#53     477709193.251.246.16    0  1000   25869   27471 189937114    0    0 06#20#51     477709193.251.246.17    0  1000   25868   27472 189937114    0    0 06#20#53     477709193.251.246.18    0  1000   25867   27470 189937114    0    0 06#20#59     477709193.251.246.19    0  1000   25869   27472 189937114    0    0 06#20#52     477709193.251.246.20    0  1000   25869   27471 189937114    0    0 06#20#57     477709193.251.246.21    0  1000   25866   27471 189937114    0    0 06#20#57     477709193.251.246.22    0  1000   25869   27470 189937114    0    0 06#20#58     477709193.251.246.23    0  1000   25869   27471 189937114    0    0 06#20#52     477709193.251.246.24    0  1000   25868   27471 189937114    0    0 06#20#55     477709193.251.246.25    0  1000   25867   27470 189937114    0    0 06#20#57     477709193.251.246.26    0  1000   25866   27470 189937114    0    0 06#20#57     477709193.251.246.27    0  1000   25868   27472 189937114    0    0 06#20#51     477709193.251.246.28    0  1000   25793   27356 189937114    0    0 06#20#24     477709193.251.246.29    0  1000   25869   27469 189937114    0    0 06#20#52     477709193.251.246.30    0  1000   25868   27470 189937114    0    0 06#20#55     477709193.251.246.31    0  1000   25793   27356 189937114    0    0 06#20#32     477709193.251.246.32    0  1000   25395   27045 189937114    0    0 06#16#47     477709193.251.246.33    0  1000   25867   27471 189937114    0    0 06#20#45     477709193.251.246.34    0  1000   25867   27468 189937114    0    0 06#20#57     477709193.251.246.35    0  1000   25868   27471 189937114    0    0 06#20#56     477709193.251.246.36    0  1000   25869   27470 189937114    0    0 06#20#54     477709193.251.246.37    0  1000   25866   27470 189937114    0    0 06#20#56     477709193.251.246.38    0  1000   25867   27472 189937114    0    0 06#20#57     477709193.251.246.39    0  1000   25793   27355 189937114    0    0 06#20#35     477709193.251.246.40    0  1000   24130   26122 189937114    0    0 06#16#28     477709193.251.246.41    0  1000   24528   26580 189937114    0    0 06#20#28     477709193.251.246.42    0  1000   24603   26694 189937114    0    0 06#20#57     477709193.251.246.43    0  1000   24528   26578 189937114    0    0 06#20#30     477709193.251.246.44    0  1000   24603   26694 189937114    0    0 06#20#58     477709193.251.246.45    0  1000   24603   26694 189937114    0    0 06#21#01     477709193.251.246.46    0  1000   24603   26694 189937114    0    0 06#20#57     477709193.251.246.47    0  1000   24528   26580 189937114    0    0 06#20#29     477709193.251.246.48    0  1000   24603   26551 189937114    0    0 06#20#59     477709193.251.246.49    0  1000   24603   26692 189937114    0    0 06#21#00     477709          RP/0/RP0/CPU0#fretta-64#show bgp ipv6 uni sumBGP router identifier 193.251.245.8, local AS number 1000BGP generic scan interval 60 secsNon-stop routing is enabledBGP table state# ActiveTable ID# 0xe0800000   RD version# 3399620BGP main routing table version 3399620BGP NSR Initial initsync version 148858 (Reached)BGP NSR/ISSU Sync-Group versions 3399620/0BGP scan interval 60 secsBGP is operating in STANDALONE mode.Process       RcvTblVer   bRIB/RIB   LabelVer  ImportVer  SendTblVer  StandbyVerSpeaker         3399620    3399620    3399620    3399620     3399620     3399620Neighbor        Spk    AS MsgRcvd MsgSent   TblVer  InQ OutQ  Up/Down  St/PfxRcd179#179#1##2      0  1000    6109   16590  3399620    0    0 05#12#17          1179#179#1##3      0  1000    6108   16590  3399620    0    0 05#12#18          1179#179#1##4      0  1000    6108   16590  3399620    0    0 05#12#13          1179#179#1##5      0  1000    6108   16590  3399620    0    0 05#12#20          1179#179#1##6      0  1000    6092   16576  3399620    0    0 05#12#25          1179#179#1##7      0  1000    6109   16591  3399620    0    0 05#12#23          1179#179#1##8      0  1000    6107   16591  3399620    0    0 05#12#26          1179#179#1##9      0  1000    6110   16590  3399620    0    0 05#12#16          1179#179#1##a      0  1000    6108   16590  3399620    0    0 05#12#22          1179#179#1##b      0  1000    6107   16589  3399620    0    0 05#12#13          1179#179#1##c      0  1000    6108   16590  3399620    0    0 05#12#18          1179#179#1##d      0  1000    6107   16590  3399620    0    0 05#12#27          1179#179#1##e      0  1000    6110   16591  3399620    0    0 05#12#13          1179#179#1##f      0  1000    6094   16575  3399620    0    0 05#12#14          1179#179#1##10     0  1000    6109   16590  3399620    0    0 05#12#25          1179#179#1##11     0  1000    6108   16590  3399620    0    0 05#12#14          1179#179#1##12     0  1000    6108   16590  3399620    0    0 05#12#28          1179#179#1##13     0  1000    6109   16590  3399620    0    0 05#12#21          1179#179#1##14     0  1000    6092   16575  3399620    0    0 05#12#15          1179#179#1##15     0  1000    6110   16590  3399620    0    0 05#12#27          1179#179#1##16     0  1000    6109   16590  3399620    0    0 05#12#25          1179#179#1##17     0  1000    6110   16588  3399620    0    0 05#12#23          1179#179#1##18     0  1000    6110   16591  3399620    0    0 05#12#25          1179#179#1##19     0  1000    6109   16591  3399620    0    0 05#12#20          1179#179#1##1a     0  1000    6093   16576  3399620    0    0 05#12#13          1179#179#1##1b     0  1000    6092   16577  3399620    0    0 05#12#21          1179#179#1##1c     0  1000    6108   16590  3399620    0    0 05#12#16          1179#179#1##1d     0  1000    6108   16588  3399620    0    0 05#12#14          1179#179#1##1e     0  1000    6091   16576  3399620    0    0 05#12#21          1179#179#1##1f     0  1000    6109   16592  3399620    0    0 05#12#24          1179#179#1##20     0  1000    6108   16590  3399620    0    0 05#12#24          1179#179#1##21     0  1000    6108   16591  3399620    0    0 05#12#22          1179#179#1##22     0  1000    6108   16591  3399620    0    0 05#12#14          1179#179#1##23     0  1000    6109   16591  3399620    0    0 05#12#22          1179#179#1##24     0  1000    6107   16589  3399620    0    0 05#12#23          1179#179#1##25     0  1000    6108   16590  3399620    0    0 05#12#18          1179#179#1##26     0  1000    6108   16590  3399620    0    0 05#12#22          1179#179#1##27     0  1000    6110   16593  3399620    0    0 05#12#13          1179#179#1##28     0  1000    6109   16590  3399620    0    0 05#12#24          1179#179#1##29     0  1000    6109   16590  3399620    0    0 05#12#20          1179#179#1##2a     0  1000    6109   16591  3399620    0    0 05#12#14          1179#179#1##2b     0  1000    6109   16592  3399620    0    0 05#12#26          1179#179#1##2c     0  1000    6109   16592  3399620    0    0 05#12#18          1179#179#1##2d     0  1000    6108   16591  3399620    0    0 05#12#19          1179#179#1##2e     0  1000    6109   16590  3399620    0    0 05#12#25          1179#179#1##2f     0  1000    6108   16590  3399620    0    0 05#12#19          1179#179#1##30     0  1000    6108   16590  3399620    0    0 05#12#23          1179#179#1##31     0  1000    6108   16591  3399620    0    0 05#12#14          1179#179#1##32     0  1000    6108   16592  3399620    0    0 05#12#23          1179#179#1##33     0  1000    6183   16592  3399620    0    0 05#12#23       2500187#187#1##2      0  3200    6092   14416  3399620    0    0 05#38#23          1187#187#1##3      0  3201    6090   14414  3399620    0    0 05#37#44          1187#187#1##4      0  3202    6092   14415  3399620    0    0 05#38#36          1187#187#1##5      0  3203    6089   14414  3399620    0    0 05#37#40          1187#187#1##6      0  3204    6090   14414  3399620    0    0 05#37#46          1187#187#1##7      0  3205    6091   14415  3399620    0    0 05#38#32          1187#187#1##8      0  3206    6090   14414  3399620    0    0 05#37#40          1187#187#1##9      0  3207    6089   14415  3399620    0    0 05#38#25          1187#187#1##a      0  3208    6092   14417  3399620    0    0 05#38#32          1187#187#1##b      0  3209    6091   14417  3399620    0    0 05#38#32          1187#187#1##c      0  3210    6091   14417  3399620    0    0 05#38#26          1187#187#1##d      0  3211    6091   14417  3399620    0    0 05#38#29          1187#187#1##e      0  3212    6091   14416  3399620    0    0 05#38#34          1187#187#1##f      0  3213    6092   14418  3399620    0    0 05#38#32          1187#187#1##10     0  3214    6091   14416  3399620    0    0 05#38#25          1187#187#1##11     0  3215    6092   14417  3399620    0    0 05#38#32          1187#187#1##12     0  3216    6091   14415  3399620    0    0 05#38#24          1187#187#1##13     0  3217    6089   14415  3399620    0    0 05#37#58          1187#187#1##14     0  3218    6090   14416  3399620    0    0 05#38#24          1187#187#1##15     0  3219    6091   14414  3399620    0    0 05#37#52          1187#187#1##16     0  3220    6091   14415  3399620    0    0 05#37#46          1187#187#1##17     0  3221    6091   14415  3399620    0    0 05#38#33          1187#187#1##18     0  3222    6091   14416  3399620    0    0 05#38#37          1187#187#1##19     0  3223    6092   14415  3399620    0    0 05#38#23          1187#187#1##1a     0  3224    6090   14416  3399620    0    0 05#38#12          1187#187#1##1b     0  3225    6091   14417  3399620    0    0 05#38#22          1187#187#1##1c     0  3226    6091   14417  3399620    0    0 05#38#40          1187#187#1##1d     0  3227    6091   14416  3399620    0    0 05#38#24          1187#187#1##1e     0  3228    6090   14416  3399620    0    0 05#37#50          1187#187#1##1f     0  3229    6091   14415  3399620    0    0 05#37#49          1187#187#1##20     0  3230    6091   14416  3399620    0    0 05#38#41          1187#187#1##21     0  3231    6090   14416  3399620    0    0 05#38#30          1187#187#1##22     0  3232    6092   14415  3399620    0    0 05#38#34          1187#187#1##23     0  3233    6086   14412  3399620    0    0 05#37#46          1187#187#1##24     0  3234    6090   14416  3399620    0    0 05#38#22          1187#187#1##25     0  3235    6092   14418  3399620    0    0 05#38#35          1187#187#1##26     0  3236    6091   14416  3399620    0    0 05#37#40          1187#187#1##27     0  3237    6091   14416  3399620    0    0 05#38#41          1187#187#1##28     0  3238    6090   14413  3399620    0    0 05#38#35          1187#187#1##29     0  3239    6092   14415  3399620    0    0 05#38#40          1187#187#1##2a     0  3240    6091   14416  3399620    0    0 05#38#04          1187#187#1##2b     0  3241    6091   14415  3399620    0    0 05#37#35          1187#187#1##2c     0  3242    6090   14415  3399620    0    0 05#37#30          1187#187#1##2d     0  3243    6090   14416  3399620    0    0 05#38#23          1187#187#1##2e     0  3244    6093   14415  3399620    0    0 05#38#37          1187#187#1##2f     0  3245    6088   14413  3399620    0    0 05#38#20          1187#187#1##30     0  3246    6089   14415  3399620    0    0 05#38#08          1187#187#1##31     0  3247    6089   14415  3399620    0    0 05#37#59          1187#187#1##32     0  3248    6093   14416  3399620    0    0 05#38#00          1187#187#1##33     0  3249    6089   14415  3399620    0    0 05#37#35          1188#1#1##2        0  2200    6100   13400  3399620    0    0 05#38#25       1500188#1#1##3        0  2201    6101   13398  3399620    0    0 05#38#36       1500188#1#1##4        0  2202    6104   13397  3399620    0    0 05#38#43       1500188#1#1##5        0  2203    6101   13397  3399620    0    0 05#38#22       1500188#1#1##6        0  2204    6101   13395  3399620    0    0 05#38#23       1500188#1#1##7        0  2205    6103   13397  3399620    0    0 05#38#40       1500188#1#1##8        0  2206    6101   13397  3399620    0    0 05#38#24       1500188#1#1##9        0  2207    6103   13396  3399620    0    0 05#38#42       1500188#1#1##a        0  2208    6101   13397  3399620    0    0 05#38#24       1500188#1#1##b        0  2209    6103   13397  3399620    0    0 05#38#35       1500188#1#1##c        0  2210    6102   13397  3399620    0    0 05#38#29       1500188#1#1##d        0  2211    6101   13397  3399620    0    0 05#38#22       1500188#1#1##e        0  2212    6098   13398  3399620    0    0 05#37#57       1500188#1#1##f        0  2213    6101   13400  3399620    0    0 05#38#42       1500188#1#1##10       0  2214    6099   13396  3399620    0    0 05#37#54       1500188#1#1##11       0  2215    6100   13399  3399620    0    0 05#38#25       1500188#1#1##12       0  2216    6100   13398  3399620    0    0 05#38#26       1500188#1#1##13       0  2217    6100   13397  3399620    0    0 05#38#19       1500188#1#1##14       0  2218    6101   13397  3399620    0    0 05#38#05       1500188#1#1##15       0  2219    6101   13399  3399620    0    0 05#38#35       1500188#1#1##16       0  2220    6091   13398  3399620    0    0 05#38#23       1500188#1#1##17       0  2221    6093   13398  3399620    0    0 05#38#30       1500188#1#1##18       0  2222    6093   13397  3399620    0    0 05#38#38       1500188#1#1##19       0  2223    6091   13398  3399620    0    0 05#38#31       1500188#1#1##1a       0  2224    6094   13399  3399620    0    0 05#38#36       1500188#1#1##1b       0  2225    6093   13398  3399620    0    0 05#38#07       1500188#1#1##1c       0  2226    6093   13398  3399620    0    0 05#38#37       1500188#1#1##1d       0  2227    6092   13396  3399620    0    0 05#38#38       1500188#1#1##1e       0  2228    6092   13395  3399620    0    0 05#37#49       1500188#1#1##1f       0  2229    6093   13397  3399620    0    0 05#38#39       1500188#1#1##20       0  2230    6094   13396  3399620    0    0 05#38#33       1500188#1#1##21       0  2231    6091   13396  3399620    0    0 05#38#30       1500188#1#1##22       0  2232    6093   13399  3399620    0    0 05#38#38       1500188#1#1##23       0  2233    6093   13398  3399620    0    0 05#38#31       1500188#1#1##24       0  2234    6092   13396  3399620    0    0 05#38#21       1500188#1#1##25       0  2235    6092   13398  3399620    0    0 05#38#36       1500188#1#1##26       0  2236    6093   13398  3399620    0    0 05#38#43       1500188#1#1##27       0  2237    6094   13397  3399620    0    0 05#38#37       1500188#1#1##28       0  2238    6092   13398  3399620    0    0 05#38#32       1500188#1#1##29       0  2239    6093   13394  3399620    0    0 05#38#24       1500188#1#1##2a       0  2240    6094   13399  3399620    0    0 05#38#40       1500188#1#1##2b       0  2241    6095   13397  3399620    0    0 05#38#41       1500188#1#1##2c       0  2242    6094   13396  3399620    0    0 05#38#34       1500188#1#1##2d       0  2243    6094   13398  3399620    0    0 05#38#42       1500188#1#1##2e       0  2244    6093   13398  3399620    0    0 05#38#32       1500188#1#1##2f       0  2245    6092   13397  3399620    0    0 05#38#38       1500188#1#1##30       0  2246    6092   13396  3399620    0    0 05#38#21       1500188#1#1##31       0  2247    6092   13396  3399620    0    0 05#38#43       1500188#1#1##32       0  2248    6093   13398  3399620    0    0 05#38#32       1500188#1#1##33       0  2249    6093   13398  3399620    0    0 05#38#38       1500188#1#1##34       0  2250    6092   13396  3399620    0    0 05#37#46       1500188#1#1##35       0  2251    6092   13395  3399620    0    0 05#37#48       1500188#1#1##36       0  2252    6094   13398  3399620    0    0 05#38#30       1500188#1#1##37       0  2253    6092   13396  3399620    0    0 05#38#24       1500188#1#1##38       0  2254    6093   13396  3399620    0    0 05#38#36       1500188#1#1##39       0  2255    6093   13396  3399620    0    0 05#38#31       1500188#1#1##3a       0  2256    6091   13395  3399620    0    0 05#38#34       1500188#1#1##3b       0  2257    6094   13398  3399620    0    0 05#38#32       1500188#1#1##3c       0  2258    6093   13398  3399620    0    0 05#38#40       1500188#1#1##3d       0  2259    6091   13398  3399620    0    0 05#38#34       1500188#1#1##3e       0  2260    6090   13395  3399620    0    0 05#38#24       1500188#1#1##3f       0  2261    6093   13396  3399620    0    0 05#38#21       1500188#1#1##40       0  2262    6093   13397  3399620    0    0 05#38#38       1500188#1#1##41       0  2263    6091   13396  3399620    0    0 05#38#25       1500188#1#1##42       0  2264    6093   13396  3399620    0    0 05#38#21       1500188#1#1##43       0  2265    6093   13398  3399620    0    0 05#38#23       1500188#1#1##44       0  2266    6095   13398  3399620    0    0 05#38#32       1500188#1#1##45       0  2267    6091   13398  3399620    0    0 05#38#34       1500188#1#1##46       0  2268    6092   13397  3399620    0    0 05#38#30       1500188#1#1##47       0  2269    6093   13398  3399620    0    0 05#38#25       1500188#1#1##48       0  2270    6091   13397  3399620    0    0 05#37#43       1500188#1#1##49       0  2271    6092   13397  3399620    0    0 05#38#34       1500188#1#1##4a       0  2272    6101   13395  3399620    0    0 05#38#20       1500188#1#1##4b       0  2273    6102   13397  3399620    0    0 05#37#44       1500188#1#1##4c       0  2274    6101   13398  3399620    0    0 05#38#38       1500188#1#1##4d       0  2275    6103   13397  3399620    0    0 05#38#30       1500188#1#1##4e       0  2276    6104   13397  3399620    0    0 05#38#42       1500188#1#1##4f       0  2277    6104   13397  3399620    0    0 05#38#34       1500188#1#1##50       0  2278    6102   13395  3399620    0    0 05#38#19       1500188#1#1##51       0  2279    6101   13397  3399620    0    0 05#38#37       1500188#1#1##52       0  2280    6102   13397  3399620    0    0 05#38#32       1500188#1#1##53       0  2281    6102   13398  3399620    0    0 05#38#37       1500188#1#1##54       0  2282    6101   13397  3399620    0    0 05#38#42       1500188#1#1##55       0  2283    6101   13396  3399620    0    0 05#38#23       1500188#1#1##56       0  2284    6101   13398  3399620    0    0 05#38#23       1500188#1#1##57       0  2285    6100   13397  3399620    0    0 05#38#21       1500188#1#1##58       0  2286    6102   13398  3399620    0    0 05#37#56       1500188#1#1##59       0  2287    6100   13398  3399620    0    0 05#38#22       1500188#1#1##5a       0  2288    6084   13397  3399620    0    0 05#38#35          1188#1#1##5b       0  2289    6086   13398  3399620    0    0 05#38#41          1188#1#1##5c       0  2290    6083   13397  3399620    0    0 05#38#20          1188#1#1##5d       0  2291    6083   13397  3399620    0    0 05#38#24          1188#1#1##5e       0  2292    6084   13398  3399620    0    0 05#38#35          1188#1#1##5f       0  2293    6082   13396  3399620    0    0 05#38#21          1188#1#1##60       0  2294    6082   13398  3399620    0    0 05#38#27          1188#1#1##61       0  2295    6081   13394  3399620    0    0 05#37#41          1188#1#1##62       0  2296    6084   13398  3399620    0    0 05#38#20          1188#1#1##63       0  2297    6083   13398  3399620    0    0 05#38#20          1188#1#1##64       0  2298    6083   13397  3399620    0    0 05#38#21          1188#1#1##65       0  2299    6085   13396  3399620    0    0 05#38#35          1189#1#1##2        0   200    6086   13398  3399620    0    0 05#38#32          1189#1#1##3        0   201    6083   13398  3399620    0    0 05#38#27          1189#1#1##4        0   202    6084   13400  3399620    0    0 05#38#29          1189#1#1##5        0   203    6084   13397  3399620    0    0 05#38#24          1189#1#1##6        0   204    6081   13397  3399620    0    0 05#38#19          1189#1#1##7        0   205    6082   13398  3399620    0    0 05#38#43          1189#1#1##8        0   206    6084   13398  3399620    0    0 05#38#27          1189#1#1##9        0   207    6083   13396  3399620    0    0 05#38#41          1189#1#1##a        0   208    6082   13397  3399620    0    0 05#37#46          1189#1#1##b        0   209    6084   13398  3399620    0    0 05#38#33          1189#1#1##c        0   210    6084   13398  3399620    0    0 05#38#28          1189#1#1##d        0   211    6084   13397  3399620    0    0 05#38#36          1189#1#1##e        0   212    6082   13395  3399620    0    0 05#37#53          1189#1#1##f        0   213    6082   13399  3399620    0    0 05#38#27          1189#1#1##10       0   214    6083   13397  3399620    0    0 05#38#27          1189#1#1##11       0   215    6084   13397  3399620    0    0 05#38#36          1189#1#1##12       0   216    6084   13397  3399620    0    0 05#38#35          1189#1#1##13       0   217    6083   13396  3399620    0    0 05#38#23          1189#1#1##14       0   218    6086   13398  3399620    0    0 05#38#34          1189#1#1##15       0   219    6083   13397  3399620    0    0 05#38#32          1189#1#1##16       0   220    6085   13399  3399620    0    0 05#38#26          1189#1#1##17       0   221    6083   13397  3399620    0    0 05#38#32          1189#1#1##18       0   222    6084   13397  3399620    0    0 05#38#25          1189#1#1##19       0   223    6082   13397  3399620    0    0 05#37#50          1189#1#1##1a       0   224    6082   13398  3399620    0    0 05#38#30          1189#1#1##1b       0   225    6081   13398  3399620    0    0 05#38#29          1189#1#1##1c       0   226    6084   13399  3399620    0    0 05#38#27          1189#1#1##1d       0   227    6084   13398  3399620    0    0 05#38#32          1189#1#1##1e       0   228    6084   13393  3399620    0    0 05#37#52          1189#1#1##1f       0   229    6083   13394  3399620    0    0 05#37#51          1189#1#1##20       0   230    6083   13397  3399620    0    0 05#38#32          1189#1#1##21       0   231    6084   13398  3399620    0    0 05#38#36          1189#1#1##22       0   232    6082   13399  3399620    0    0 05#38#29          1189#1#1##23       0   233    6082   13398  3399620    0    0 05#38#29          1189#1#1##24       0   234    6084   13397  3399620    0    0 05#38#33          1189#1#1##25       0   235    6083   13397  3399620    0    0 05#38#33          1189#1#1##26       0   236    6084   13396  3399620    0    0 05#38#38          1189#1#1##27       0   237    6083   13398  3399620    0    0 05#38#36          1189#1#1##28       0   238    6083   13397  3399620    0    0 05#38#27          1189#1#1##29       0   239    6084   13398  3399620    0    0 05#38#03          1189#1#1##2a       0   240    6085   13399  3399620    0    0 05#38#34          1189#1#1##2b       0   241    6085   13398  3399620    0    0 05#38#23          1189#1#1##2c       0   242    6081   13397  3399620    0    0 05#38#22          1189#1#1##2d       0   243    6083   13397  3399620    0    0 05#38#20          1189#1#1##2e       0   244    6082   13397  3399620    0    0 05#37#57          1189#1#1##2f       0   245    6083   13397  3399620    0    0 05#38#26          1189#1#1##30       0   246    6083   13398  3399620    0    0 05#38#40          1189#1#1##31       0   247    6083   13397  3399620    0    0 05#37#58          1189#1#1##32       0   248    6084   13397  3399620    0    0 05#38#34          1189#1#1##33       0   249    6082   13397  3399620    0    0 05#38#20          12001#688#0#1##55                  0  1000   13924   17188  3399620    0    0 22#38#34      141952001#688#0#2##70                  0  1000   11075   12569  3399620    0    0 22#38#34      141952001#688#0#2##71                  0  1000   11073   12570  3399620    0    0 22#38#27      141952001#688#0#2##72                  0  1000   11075   12451  3399620    0    0 22#38#35      141952001#688#0#2##73                  0  1000   11071   12570  3399620    0    0 22#38#29      141952001#688#0#2##74                  0  1000   11072   12571  3399620    0    0 22#38#15      141952001#688#0#2##75                  0  1000   11074   12569  3399620    0    0 22#38#01      141952001#688#0#2##76                  0  1000   11074   12570  3399620    0    0 22#38#34      141952001#688#0#2##77                  0  1000   11070   12569  3399620    0    0 22#38#32      141952001#688#0#2##78                  0  1000   11075   12450  3399620    0    0 22#38#35      141952001#688#0#2##79                  0  1000   11073   12569  3399620    0    0 22#38#32      141952001#688#0#2##80                  0  1000   11073   12570  3399620    0    0 22#38#04      141952001#688#0#2##81                  0  1000   11073   12571  3399620    0    0 22#38#38      141952001#688#0#2##82                  0  1000   11073   12570  3399620    0    0 22#38#28      141952001#688#0#2##83                  0  1000   11071   12569  3399620    0    0 22#38#31      141952001#688#0#2##84                  0  1000   11072   12569  3399620    0    0 22#38#32      141952001#688#0#2##85                  0  1000   11073   12569  3399620    0    0 22#38#34      141952001#688#0#2##86                  0  1000   11072   12569  3399620    0    0 22#38#34      141952001#688#0#2##87                  0  1000   11073   12569  3399620    0    0 22#38#30      141952001#688#0#2##88                  0  1000   11077   12569  3399620    0    0 22#38#24      141952001#688#0#2##89                  0  1000   11072   12450  3399620    0    0 22#38#30      141952001#688#0#2##90                  0  1000   11072   12571  3399620    0    0 22#38#36      141952001#688#0#2##91                  0  1000   11071   12570  3399620    0    0 22#38#30      141952001#688#0#2##92                  0  1000   11073   12451  3399620    0    0 22#38#05      141952001#688#0#2##93                  0  1000   11076   12570  3399620    0    0 22#38#32      141952001#688#0#2##94                  0  1000   11072   12569  3399620    0    0 22#38#38      141952001#688#0#2##95                  0  1000   11072   12570  3399620    0    0 22#38#00      141952001#688#0#2##96                  0  1000   11073   12570  3399620    0    0 22#38#32      141952001#688#0#2##97                  0  1000   10684   11480  3399620    0    0 22#38#36      141952001#688#0#2##98                  0  1000   11074   12570  3399620    0    0 22#38#29      141952001#688#0#2##99                  0  1000   11074   12569  3399620    0    0 22#38#34      141952001#688#0#2##100                  0  1000   11072   12569  3399620    0    0 22#38#38      141952001#688#0#2##101                  0  1000   11059   12557  3399620    0    0 22#38#07      141952001#688#0#2##102                  0  1000   11057   12556  3399620    0    0 22#38#27      141952001#688#0#2##103                  0  1000   11059   12556  3399620    0    0 22#38#38      141952001#688#0#2##104                  0  1000   11056   12555  3399620    0    0 22#38#30      141952001#688#0#2##105                  0  1000   10958   11736  3399620    0    0 22#38#29      141952001#688#0#2##106                  0  1000   11058   12557  3399620    0    0 22#37#58      141952001#688#0#2##107                  0  1000   11059   12438  3399620    0    0 22#37#59      141952001#688#0#2##108                  0  1000   10959   11617  3399620    0    0 22#38#29      141952001#688#0#2##109                  0  1000   11059   12555  3399620    0    0 22#38#27      141952001#688#0#2##110                  0  1000   11058   12555  3399620    0    0 22#38#39      141952001#689#0#2##55                  0  1000    6945   13253  3399620    0    0 22#38#26      14195RP/0/RP0/CPU0#fretta-64RP/0/RP0/CPU0#fretta-64#show mpls ldp summary   AFIs      # IPv4  Routes    # 1391 prefixes   Bindings  # 1391 prefixes       Local     # 1391       Remote    # 2041   Neighbors # 151 (151 NSR)  Hello Adj # 184   Addresses # 88   Interfaces# 35 LDP configuredRP/0/RP0/CPU0#fretta-64#ConclusionWe proved today that Netflow implementation in IOS XR 6.3.15 (and following 6.3.2) is solid and can be stressed without noticing any side effect. We pushed the scale, the sampling-interval, the timers and rate-limiters, etc and obtained consistent behavior and results.AcknowledgementsMany thanks to Hari Baskar Sivasamy, Benoit Mercier Des Rochettes for defining and executing these tests.Thanks also to Raj Kalavendi and Jisu Bhattacharya for their comments and guidance.", "url": "https://xrdocs.github.io/cloud-scale-networking/tutorials/netflow-ncs5500-test-results/", "tags": "iosxr, ncs5500, netflow, xr", "title": "Netflow on NCS5500: Test Results", "author": "Nicolas Fevrier"}, "tutorials-iosxr-vagrant-bootstrap-config": {"content": "     IOS-XR Vagrant# Bootstrap Config  Introduction  Pre-requisite  Bootstrap Configuration# Shell Provisioner          Transfer a Configuration file to XR bash      Use a Shell script to Apply XR Config        Single node bootstrap          Configuration File      Bootstrap script      Vagrantfile        Bootstrap in action!  Check out Part 1 of the XR toolbox series# IOS-XR Vagrant quick-start.IntroductionThe IOS-XR Vagrant Quick Start guideshowcases how a user can get started with an IOS-XR vagrant box.This tutorial will extend the quick-start guide to showcase how one can apply a node-specific configuration to an XR vagrant instance during boot-up itself.Make sure you take a look at the quick-start guide before proceeding.  Bear in mind that the IOS-XR vagrant box is published without a need for any custom plugins.We thought about it and felt that masking the core functionality of the router with Vagrant workflows could prevent us from showcasing some core functionalities of IOS-XR, namely #      Day 0# ZTP helpers and shell/bash based automation    Day 1# automation techniques based off YANG models    Day 2# Streaming Telemetry and application-hosting  This tutorial invariably ends up using the new shell/bash based automation techniques that have been introduced as part of the Zero Touch provisioning (ZTP) functionality in IOS-XR.Pre-requisite      Meet the pre-requisites specified in the IOS-XR Vagrant Quick Start guide# Pre-requisites        Clone the following repository# https#//github.com/ios-xr/vagrant-xrdocs, before we start.  cd ~/git clone https#//github.com/ios-xr/vagrant-xrdocs.gitcd vagrant-xrdocs/You will notice a couple of  directories. We will utilize the single_node_bootstrap directory in this tutorial.AKSHSHAR-M-K0DS#vagrant-xrdocs akshshar$ pwd/Users/akshshar/vagrant-xrdocsAKSHSHAR-M-K0DS#vagrant-xrdocs akshshar$ ls single_node_bootstrap/Vagrantfile\tconfigs\t\tscriptsAKSHSHAR-M-K0DS#vagrant-xrdocs akshshar$ Bootstrap Configuration# Shell ProvisionerThe concept is simple# We\u2019ll use the Vagrant shell provisioner to apply a bootstrap configuration to an XR instance when we issue a vagrant up.All we need is a shell provisioner section in the Vagrantfile for each node# #Source a config file and apply it to XR       config.vm.provision ~file~, source# ~configs/rtr_config~, destination# ~/home/vagrant/rtr_config~       config.vm.provision ~shell~ do |s|   s.path =  ~scripts/apply_config.sh~   s.args = [~/home/vagrant/rtr_config~] endWe will look at a complete Vagrantfile in a bit. But let\u2019s desconstruct the above piece of code.Transfer a Configuration file to XR bashconfig.vm.provision ~file~, source# ~configs/rtr_config~, destination# ~/home/vagrant/rtr_config~The above line uses the Vagrant \u201cfile\u201d provisioner to transfer a file from the host (your laptop) to the XR linux shell (bash).The root of the source directory is the working directory for your vagrant instance. Hence, the rtr_config file is located in the configs directory.Use a Shell script to Apply XR Configconfig.vm.provision ~shell~ do |s|   s.path =  ~scripts/apply_config.sh~   s.args = [~/home/vagrant/rtr_config~] endThe shell script will eventually be run on XR bash of the vagrant instance. This script is placed in the scripts directory and is named apply_config.sh.Further, the script needs the location of the router config file as an argument. This is the destination parameter in the \u201cfile\u201d provisioner above.So, in short, Vagrant copies a config file to the router bash, and then runs a shell script on the router bash to apply the config file that was copied!Single node bootstrapTo meet the above requirements, you will need a directory structure as laid out under ~/vagrant-xrdocs/single_node_bootstrap#AKSHSHAR-M-K0DS#single_node_bootstrap akshshar$ pwd/Users/akshshar/vagrant-xrdocs/single_node_bootstrapAKSHSHAR-M-K0DS#single_node_bootstrap akshshar$ tree ././\u251c\u2500\u2500 Vagrantfile\u251c\u2500\u2500 configs\u2502\u00a0\u00a0 \u2514\u2500\u2500 rtr_config\u2514\u2500\u2500 scripts    \u2514\u2500\u2500 apply_config.sh2 directories, 3 filesWe will stick to the single_node_bootstrap directory throughout this section.Configuration FileLet\u2019s assume we\u2019re applying a simple XR config that configures the grpc server on port 57891.This will be the contents of our configs/rtr_config fileThis configuration will be an addendum to the pre-existing configuration on the vagrant instance.AKSHSHAR-M-K0DS#iosxrv akshshar$ cat configs/rtr_config !! XR configuration!grpc  port 57891!endBootstrap scriptThe shell script to apply the configuration will run on XR bash. The following new shell commands are made available to enable this#  xrcmd# This command allows a user to run \u201cexec\u201d commands on XR CLI from the shell. For eg. \u201cshow run\u201d, \u201cshow version\u201d etc.  xrapply# This command allows a user to apply (append) a config file to the existing configuration.  xrapply_string# This command can be used to apply a config directly using a single inline string. For eg. xrapply_string ~interface Gig0/0/0/0\\n ip address 1.1.1.2/24 \\n no shutdown~Only the root user is allowed to run the above commands as a good security practice. Unless specified, Vagrant will always escalate the privilege to run the shell provisioner script as root.Our shell script will look something like this#AKSHSHAR-M-K0DS#iosxrv akshshar$ cat scripts/apply_config.sh #!/bin/bash## Source ztp_helper.sh to get the xrapply and xrcmd functions.source /pkg/bin/ztp_helper.shfunction configure_xr() {   ## Apply a blind config    xrapply $1   if [ $? -ne 0 ]; then       echo ~xrapply failed to run~   fi   xrcmd ~show config failed~ &gt; /home/vagrant/config_failed_check}## The location of the config file is an argument to the scriptconfig_file=$1## Call the configure_xr() function to use xrapply and xrcmd in parallelconfigure_xr $config_file## Check if there was an error during config applicationgrep -q ~ERROR~ /home/vagrant/config_failed_check## Condition based on the result of grep ($?)if [ $? -ne 0 ]; then    echo ~Configuration was successful!~    echo ~Last applied configuration was#~    xrcmd ~show configuration commit changes last 1~else    echo ~Configuration Failed. Check /home/vagrant/config_failed on the router for logs~    xrcmd ~show configuration failed~ &gt; /home/vagrant/config_failed    exit 1fi  Few things to note in the above script#      source /pkg/bin/ztp_helper.sh is necessary for the xrapply, xrcmd commands to be available.    There are comments in the script to help understand the steps taken. Essentially, the shell script blindly applies the config file specified as an argument ($1) and then checks to see if there was an error during config application.  VagrantfileTake a look at the Vagrantfile in the same directory. The shell provisioner code has been added## -*- mode# ruby -*-# vi# set ft=ruby ## All Vagrant configuration is done below. The ~2~ in Vagrant.configure# configures the configuration version (we support older styles for# backwards compatibility). Please don't change it unless you know what# you're doing.Vagrant.configure(2) do |config|    config.vm.box = ~IOS-XRv~  #Source a config file and apply it to XR        config.vm.provision ~file~, source# ~configs/rtr_config~, destination# ~/home/vagrant/rtr_config~  config.vm.provision ~shell~ do |s|    s.path =  ~scripts/apply_config.sh~    s.args = [~/home/vagrant/rtr_config~]  endendBootstrap in action!Assuming that the box (IOS-XRv) is already in the vagrant box list as shown in the  IOS-XR Vagrant Quick Start guide, just issue a vagrant up to see the magic happen#Let\u2019s get into the XR CLI to check that it worked#AKSHSHAR-M-K0DS#single_node_bootstrap akshshar$ vagrant port The forwarded ports for the machine are listed below. Please note thatthese values may differ from values configured in the Vagrantfile if theprovider supports automatic port collision detection and resolution.    22 (guest) =&gt; 2223 (host)  57722 (guest) =&gt; 2222 (host)AKSHSHAR-M-K0DS#single_node_bootstrap akshshar$ AKSHSHAR-M-K0DS#single_node_bootstrap akshshar$ ssh -p 2223 vagrant@localhost vagrant@localhost's password# RP/0/RP0/CPU0#ios#RP/0/RP0/CPU0#ios#show  running-config grpcTue May 31 16#59#44.581 UTCgrpc port 57891!RP/0/RP0/CPU0#ios#show configuration commit changes last 1Tue May 31 17#02#45.770 UTCBuilding configuration...!! IOS XR Configuration version = 6.1.1.17Igrpc port 57891!endRP/0/RP0/CPU0#ios#It worked! The config was applied as part of the vagrant up process.Head over to Part 3 of the XR Toolbox series where we bring up a typical app-development topology  \u2014&gt; App Development Topology.", "url": "https://xrdocs.github.io/application-hosting/tutorials/iosxr-vagrant-bootstrap-config", "tags": "vagrant, iosxr, cisco, xr toolbox, configuration", "title": "XR Toolbox, Part 2 : Bootstrap XR configuration with Vagrant", "author": "Akshat Sharma"}, "tutorials-2016-11-03-grpc-in-python-for-ios-xr": {"content": "     IOS-XR# gRPC in Python  Introduction  Prerequisites  Installing gRPC on the devbox  Cloning the git repo  Understanding the topology  Creating a Python gRPC Call  IntroductionThe goal of this tutorial is to set up gRPC in Python to send gRPC commands to an IOS-XR box. This tutorial assumes that you have gone through the XR Toolbox Series before. If you haven\u2019t checked out the earlier parts to the XR toolbox Series, then you can do so here#  XR Toolbox SeriesPrerequisitesBefore we begin, let\u2019s make sure you\u2019ve set up your development environment.If you haven\u2019t checked it out, go through the \u201cApp-Development Topology\u201d tutorial here#  XR Toolbox, Part 3# App Development TopologyFollow the instructions to get your topology up and running as shown below#If you\u2019ve reached the end of the above tutorial, you should be able to issue vagrant status in the vagrant-xrdocs/lxc-app-topo-bootstrap directory to see a rtr (IOS-XR) and a devbox (Ubuntu/trusty) instance running.Ensure you have the latest version of IOS-XRv.Installing gRPC on the devboxFirst login to the devboxvagrant ssh devboxLet\u2019s start by installing a few developer tools on the devbox.sudo apt-get updatesudo apt-get -y install python-dev python-pip gitNow that we have installed the developer tools, let\u2019s install gRPC for Python on the box.sudo pip install grpcioThats it! gRPC for Python is installed on the devbox.Cloning the git repoNow that we have gRPC for Python installed on the devbox. We need to get the bindings associated with IOS-XR. Let\u2019s use the library that has these bindings done.Clone the gRPC for Python library here# https#//github.com/cisco-grpc-connection-libs/ios-xr-grpc-pythoncd ~/git clone https#//github.com/cisco-grpc-connection-libs/ios-xr-grpc-python.gitcd ios-xr-grpc-pythonUnderstanding the topologyWe need to ensure that gRPC is turned on in the devbox and take note of the port.ssh vagrant@11.1.1.10Note the password would be vagrantFrom here, use show run to find check that gRPC is running and find the configured port.RP/0/RP0/CPU0#ios#show run            Wed Sep  7 16#59#19.241 UTCBuilding configuration...!! IOS XR Configuration version = 6.1.1.19I!! Last configuration change at Wed Sep  7 16#18#14 2016 by UNKNOWN!telnet vrf default ipv4 server max-servers 10username vagrant group root-lr group cisco-support secret 5 $1$0Lrs$AInvgKCO262qZh6hLMfis0!tpa address-family ipv4  update-source MgmtEth0/RP0/CPU0/0 !!interface MgmtEth0/RP0/CPU0/0 ipv4 address dhcp!interface GigabitEthernet0/0/0/0 ipv4 address 11.1.1.10 255.255.255.0!router static address-family ipv4 unicast  0.0.0.0/0 MgmtEth0/RP0/CPU0/0 10.0.2.2 !!ssh server v2ssh server vrf defaultgrpcport 57777!endRP/0/RP0/CPU0#ios#We can see that gRPC is turned on, and is on port 57777.Let\u2019s exit out and continue getting our gRPC client working.RP/0/RP0/CPU0#ios#exitConnection to 11.1.1.10 closed.vagrant@vagrant-ubuntu-trusty-64#~/ios-xr-grpc-python$Creating a Python gRPC CallThere is an example call already created. We can find it in the examples folder.cd examplesLet\u2019s first understand the json file we are going to use. The JSON below is based off the YANG model provided by Cisco# https#//github.com/YangModels/yang/blob/master/vendor/cisco/xr/611/Cisco-IOS-XR-ipv4-bgp-cfg.yang.You can walk through the hierachy using pyang, and create a JSON model similar to the example below. https#//github.com/mbj4668/pyang/wiki/TreeOutputThis JSON model is for a BGP configuration. We can see that it is defining a BGP instance and a single neighbor.vagrant@vagrant-ubuntu-trusty-64#/vagrant/ios-xr-grpc-python/examples$ cat snips/bgp_start.json{ ~Cisco-IOS-XR-ipv4-bgp-cfg#bgp~# {  ~instance~# [   {    ~instance-name~# ~default~,    ~instance-as~# [     {      ~as~# 0,      ~four-byte-as~# [       {        ~as~# 65400,        ~bgp-running~# [         null        ],        ~default-vrf~# {         ~global~# {          ~router-id~# ~11.1.1.10~,          ~global-afs~# {           ~global-af~# [            {             ~af-name~# ~ipv4-unicast~,             ~enable~# [              null             ],             ~sourced-networks~# {              ~sourced-network~# [               {                ~network-addr~# ~11.1.1.0~,                ~network-prefix~# 24               }              ]             }            }           ]          }         },         ~bgp-entity~# {          ~neighbors~# {           ~neighbor~# [            {             ~neighbor-address~# ~11.1.1.20~,             ~remote-as~# {              ~as-xx~# 0,              ~as-yy~# 65450             },             ~neighbor-afs~# {              ~neighbor-af~# [               {                ~af-name~# ~ipv4-unicast~,                ~activate~# [                 null                ],                ~next-hop-self~# true               }              ]             }            }           ]          }         }        }       }      ]     }    ]   }  ] }}Now let\u2019s use the client. There is a Python example that uses the client called grpc_cfg.py. There are 5 helper functions. The init creates a gRPC client object, then there are 4 other functions, each using a different method in gRPC for IOS-XR. They read in a JSON file and pass it to the gRPC server for configs.'''Note#This is an example to show replace and merge configs work with a get command.The example is using XRdocs vagrant topology for all the configurations'''import syssys.path.insert(0, '../')from lib.cisco_grpc_client import CiscoGRPCClientimport jsonfrom time import sleepclass Example#    def __init__(self)#        self.client = CiscoGRPCClient('11.1.1.10', 57777, 10, 'vagrant', 'vagrant')    def get(self)#        path = '{~Cisco-IOS-XR-ipv4-bgp-cfg#bgp~# [null]}'        result = self.client.getconfig(path)        print result    def replace(self)#        path = open('snips/bgp_start.json').read()        result = self.client.replaceconfig(path)        print result # If this is sucessful, then there should be no errors.    def merge(self)#        path = open('snips/bgp_merge.json').read()        result = self.client.mergeconfig(path)        print result # If this is sucessful, then there should be no errors.    def delete(self)#        path = open('snips/bgp_start.json').read()        result = self.client.deleteconfig(path)        print result # If this is sucessful, then there should be no errors.Note the fields in the client are the IP address of the router, the port, a timeout, the username, and password.Let\u2019s start with using the python interpreter to import the Example class and initialize it.vagrant@vagrant-ubuntu-trusty-64#/vagrant/ios-xr-grpc-python/examples$ pythonPython 2.7.6 (default, Jun 22 2015, 17#58#13)[GCC 4.8.2] on linux2Type ~help~, ~copyright~, ~credits~ or ~license~ for more information.&gt;&gt;&gt; from grpc_cfg import Example&gt;&gt;&gt; example = Example()We are going to start with a replace config, to add a base BGP config using the JSON file we looked at earlier.&gt;&gt;&gt; example.replace()A blank response means there are no errors.Now let\u2019s use a get request to see what is on the router.&gt;&gt;&gt; example.get()If this worked correctly you should see the JSON file we looked at, and the response from the get should be identical Now let\u2019s use a merge request to add another neighbor with the second JSON file.&gt;&gt;&gt; example.merge()&gt;&gt;&gt; example.get()The resulting config should be the first config plus the second, or in other words there are 2 neighbors defined.At this point you can see how gRPC is easy to use to get, replace, and merge configs. You can even remove a config completely using delete.We are done with this tutorial, feel free to change the path variable and experiment to see what you can do. Some useful links below#gRPC Getting StartedGetting Started With OpenConfig", "url": "https://xrdocs.github.io/programmability/tutorials/2016-11-03-grpc-in-python-for-ios-xr/", "tags": "iosxr, cisco, grpc, yang, programmability, models", "title": "Programming IOS-XR over GRPC", "author": "Karthik Kumaravel"}, "tutorials-2016-08-15-configuring-mdt-for-tcp-dial-out-using-native-yang": {"content": "     Configuring MDT dial-out using Native YANG  Getting the Most out of MDT with Native YANG  The Model  Get-Config  Edit-Config  Clean-up Time  Conclusion  Getting the Most out of MDT with Native YANGIn an earlier tutorial, I wrote about how to configure an MDT for gRPC dial-in using the OpenConfig Telemetry YANG model.  In this tutorial, I\u2019ll describe how to use the IOS XR Native YANG model to configure MDT with TCP and gRPC dialout.  I will use ncclient as a simple Python NETCONF client, but you can use whatever client you want.The ModelThe Cisco IOS XR Native YANG model for telemetry is \u201cCisco-IOS-XR-telemetry-model-driven-cfg.\u201d  It can be used to configure any telemetry feature that IOS XR (unlike the OpenConfig telemetry model, which only covers a subset of IOS XR capabilities).The NETCONF &lt;get-schema&gt; operation will give you the contents of the schema but the full YANG output can be really verbose and overwhelming, so I\u2019ll pipe the output to the pyang utility for a compact tree view with the following bit of code#from ncclient import managerimport re    xr = manager.connect(host='10.30.111.9', port=830, username='cisco', password='cisco',                    allow_agent=False,                    look_for_keys=False,                    hostkey_verify=False,                    unknown_host_cb=True)                    from subprocess import Popen, PIPE, STDOUToc = xr.get_schema('Cisco-IOS-XR-telemetry-model-driven-cfg')p = Popen(['pyang', '-f', 'tree'], stdout=PIPE, stdin=PIPE, stderr=PIPE) print(p.communicate(input=oc.data)[0])And voila#Script Output#module# Cisco-IOS-XR-telemetry-model-driven-cfg   +--rw telemetry-model-driven      +--rw sensor-groups      |  +--rw sensor-group* [sensor-group-identifier]      |     +--rw sensor-paths      |     |  +--rw sensor-path* [telemetry-sensor-path]      |     |     +--rw telemetry-sensor-path    string      |     +--rw enable?                    empty      |     +--rw sensor-group-identifier    xr#Cisco-ios-xr-string      +--rw subscriptions      |  +--rw subscription* [subscription-identifier]      |     +--rw source-address!      |     |  +--rw address-family    Af      |     |  +--rw ip-address?       inet#ipv4-address-no-zone      |     |  +--rw ipv6-address?     string      |     +--rw sensor-profiles      |     |  +--rw sensor-profile* [sensorgroupid]      |     |     +--rw sample-interval?      uint32      |     |     +--rw heartbeat-interval?   uint32      |     |     +--rw supress-redundant?    empty      |     |     +--rw sensorgroupid         xr#Cisco-ios-xr-string      |     +--rw destination-profiles      |     |  +--rw destination-profile* [destination-id]      |     |     +--rw enable?           empty      |     |     +--rw destination-id    xr#Cisco-ios-xr-string      |     +--rw source-qos-marking?        uint32      |     +--rw subscription-identifier    xr#Cisco-ios-xr-string      +--rw destination-groups      |  +--rw destination-group* [destination-id]      |     +--rw destinations      |     |  +--rw destination* [address-family]      |     |     +--rw address-family    Af      |     |     +--rw ipv4* [ipv4-address destination-port]      |     |     |  +--rw ipv4-address        inet#ip-address-no-zone      |     |     |  +--rw destination-port    xr#Cisco-ios-xr-port-number      |     |     |  +--rw protocol!      |     |     |  |  +--rw protocol        Proto-type      |     |     |  |  +--rw tls-hostname?   string      |     |     |  |  +--rw no-tls?         int32      |     |     |  +--rw encoding?           Encode-type      |     |     +--rw ipv6* [ipv6-address destination-port]      |     |        +--rw ipv6-address        xr#Cisco-ios-xr-string      |     |        +--rw destination-port    xr#Cisco-ios-xr-port-number      |     |        +--rw protocol!      |     |        |  +--rw protocol        Proto-type      |     |        |  +--rw tls-hostname?   string      |     |        |  +--rw no-tls?         int32      |     |        +--rw encoding?           Encode-type      |     +--rw destination-id    xr#Cisco-ios-xr-string      +--rw enable?               emptyYou can spend a lot of time understanding the intricacies of YANG and all the details, but all we really need to know for now is that the model has three major sections#      The destination-group tells the router where to send telemetry data and how. Only needed for dial-out configuration.        The sensor-group identifies a list of YANG models that the router should stream.        The subscription ties together the destination-group and the sensor-group.  Let\u2019s see how this works in practice.Get-ConfigWe can use the openconfig-telemetry model to filter for the telemetry config with the ncclient get_config operation. Continuing our python script from above#xr_filter = '''&lt;telemetry-model-driven xmlns=~http#//cisco.com/ns/yang/Cisco-IOS-XR-telemetry-model-driven-cfg~&gt;'''c = xr.get_config(source='running', filter=('subtree', xr_filter))print(c)And here\u2019s what we get#Script Output#&lt;?xml version=~1.0~?&gt;&lt;rpc-reply message-id=~urn#uuid#1ddd326c-e2c8-46b1-8433-11283799b9ce~ xmlns#nc=~urn#ietf#params#xml#ns#netconf#base#1.0~ xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~&gt; &lt;data&gt;  &lt;telemetry-model-driven xmlns=~http#//cisco.com/ns/yang/Cisco-IOS-XR-telemetry-model-driven-cfg~&gt;   &lt;destination-groups&gt;    &lt;destination-group&gt;     &lt;destination-id&gt;DGroup1&lt;/destination-id&gt;     &lt;destinations&gt;      &lt;destination&gt;       &lt;address-family&gt;ipv4&lt;/address-family&gt;       &lt;ipv4&gt;        &lt;ipv4-address&gt;172.30.8.4&lt;/ipv4-address&gt;        &lt;destination-port&gt;5432&lt;/destination-port&gt;        &lt;encoding&gt;self-describing-gpb&lt;/encoding&gt;        &lt;protocol&gt;         &lt;protocol&gt;tcp&lt;/protocol&gt;         &lt;tls-hostname&gt;&lt;/tls-hostname&gt;         &lt;no-tls&gt;0&lt;/no-tls&gt;        &lt;/protocol&gt;       &lt;/ipv4&gt;      &lt;/destination&gt;     &lt;/destinations&gt;    &lt;/destination-group&gt;   &lt;/destination-groups&gt;   &lt;sensor-groups&gt;    &lt;sensor-group&gt;     &lt;sensor-group-identifier&gt;SGroup1&lt;/sensor-group-identifier&gt;     &lt;enable&gt;&lt;/enable&gt;     &lt;sensor-paths&gt;      &lt;sensor-path&gt;       &lt;telemetry-sensor-path&gt;Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters&lt;/telemetry-sensor-path&gt;      &lt;/sensor-path&gt;     &lt;/sensor-paths&gt;    &lt;/sensor-group&gt;   &lt;/sensor-groups&gt;   &lt;enable&gt;&lt;/enable&gt;   &lt;subscriptions&gt;    &lt;subscription&gt;     &lt;subscription-identifier&gt;Sub1&lt;/subscription-identifier&gt;     &lt;sensor-profiles&gt;      &lt;sensor-profile&gt;       &lt;sensorgroupid&gt;SGroup1&lt;/sensorgroupid&gt;       &lt;sample-interval&gt;30000&lt;/sample-interval&gt;      &lt;/sensor-profile&gt;     &lt;/sensor-profiles&gt;     &lt;destination-profiles&gt;      &lt;destination-profile&gt;       &lt;destination-id&gt;DGroup1&lt;/destination-id&gt;       &lt;enable&gt;&lt;/enable&gt;      &lt;/destination-profile&gt;     &lt;/destination-profiles&gt;    &lt;/subscription&gt;   &lt;/subscriptions&gt;  &lt;/telemetry-model-driven&gt; &lt;/data&gt;&lt;/rpc-reply&gt;So what does all that mean to the router?  It breaks down into three parts which you\u2019ll recall from the YANG model above#      The destination-group tells the router where to send telemetry data and how.  The destination group in this configuration (\u201cDGroup1\u201d) will send telemetry data to an IPv4 address (172.30.8.4) on port 5432 with a self-describing GPB encoding via TCP.        The sensor-group identifies a list of YANG models that the router should stream.  In this case, the router has a sensor-group called \u201cSGroup1\u201d that will send interface statistics data from the IOS XR Native YANG model for interface stats.        The subscription ties together the destination-group and the sensor-group.  This router has a subscription name \u201cSub1\u201d that will send the list of models in SGroup1 to DGroup1 at an interval of 30 second (30000 milleseconds).  If you read the earlier tutorial on configuring MDT with CLI, you might recognize this as the same as the TCP dial-out configuration described there.  If you missed that thrilling installment, the XML above is the YANG equivalent of this CLI#CLI Output#telemetry model-driven   destination-group DGroup1     address family ipv4 172.30.8.4 port 5432     encoding self-describing-gpb     protocol tcp  ! ! sensor-group SGroup1  sensor-path Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters !   subscription Sub1    sensor-group-id SGroup1 sample-interval 30000    destination-id DGroup1 Edit-ConfigSo let\u2019s say we want to add a second model (Cisco-IOS-XR-wdsysmon-fd-oper) to SGroup1 to stream cpu utilization data.  We can do that with the following NETCONF operations#edit_data = '''&lt;config&gt;&lt;telemetry-model-driven xmlns=~http#//cisco.com/ns/yang/Cisco-IOS-XR-telemetry-model-driven-cfg~&gt;   &lt;sensor-groups&gt;    &lt;sensor-group&gt;     &lt;sensor-group-identifier&gt;SGroup1&lt;/sensor-group-identifier&gt;     &lt;sensor-paths&gt;      &lt;sensor-path&gt;       &lt;telemetry-sensor-path&gt;Cisco-IOS-XR-wdsysmon-fd-oper#system-monitoring&lt;/telemetry-sensor-path&gt;      &lt;/sensor-path&gt;     &lt;/sensor-paths&gt;    &lt;/sensor-group&gt;   &lt;/sensor-groups&gt;  &lt;/telemetry-model-driven&gt;&lt;/config&gt;'''xr.edit_config(edit_data, target='candidate', format='xml')xr.commit()If we do a get-config operation again, this time filtering on just the sensor-groups#xr_filter = '''&lt;telemetry-model-driven xmlns=~http#//cisco.com/ns/yang/Cisco-IOS-XR-telemetry-model-driven-cfg~&gt;&lt;sensor-groups&gt;'''c = xr.get_config(source='running', filter=('subtree', xr_filter))print(c)\u2026 we\u2019ll see that SGroup1 has the new sensor-path.Script Output#&lt;?xml version=~1.0~?&gt;&lt;rpc-reply message-id=~urn#uuid#dbcef1db-83af-43f0-b2fe-153c53fc1f82~ xmlns#nc=~urn#ietf#params#xml#ns#netconf#base#1.0~ xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~&gt; &lt;data&gt;  &lt;telemetry-model-driven xmlns=~http#//cisco.com/ns/yang/Cisco-IOS-XR-telemetry-model-driven-cfg~&gt;   &lt;sensor-groups&gt;    &lt;sensor-group&gt;     &lt;sensor-group-identifier&gt;SGroup1&lt;/sensor-group-identifier&gt;     &lt;enable&gt;&lt;/enable&gt;     &lt;sensor-paths&gt;      &lt;sensor-path&gt;       &lt;telemetry-sensor-path&gt;Cisco-IOS-XR-wdsysmon-fd-oper#system-monitoring&lt;/telemetry-sensor-path&gt;      &lt;/sensor-path&gt;      &lt;sensor-path&gt;       &lt;telemetry-sensor-path&gt;Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters&lt;/telemetry-sensor-path&gt;      &lt;/sensor-path&gt;     &lt;/sensor-paths&gt;    &lt;/sensor-group&gt;   &lt;/sensor-groups&gt;  &lt;/telemetry-model-driven&gt; &lt;/data&gt;&lt;/rpc-reply&gt;Now let\u2019s add an IPv6 destination to DGroup1 using gRPC dial-out and self-describing GPB encoding. You can do that with the following NETCONF operation#edit_data = '''&lt;config&gt;&lt;telemetry-model-driven xmlns=~http#//cisco.com/ns/yang/Cisco-IOS-XR-telemetry-model-driven-cfg~&gt;   &lt;destination-groups&gt;    &lt;destination-group&gt;     &lt;destination-id&gt;DGroup1&lt;/destination-id&gt;     &lt;destinations&gt;      &lt;destination&gt;       &lt;address-family&gt;ipv6&lt;/address-family&gt;       &lt;ipv6&gt;        &lt;ipv6-address&gt;2001#db8#0#100##b&lt;/ipv6-address&gt;        &lt;destination-port&gt;5432&lt;/destination-port&gt;        &lt;encoding&gt;self-describing-gpb&lt;/encoding&gt;        &lt;protocol&gt;         &lt;protocol&gt;grpc&lt;/protocol&gt;         &lt;tls-hostname&gt;&lt;/tls-hostname&gt;         &lt;no-tls&gt;0&lt;/no-tls&gt;        &lt;/protocol&gt;       &lt;/ipv6&gt;      &lt;/destination&gt;     &lt;/destinations&gt;    &lt;/destination-group&gt;   &lt;/destination-groups&gt;  &lt;/telemetry-model-driven&gt;&lt;/config&gt;'''xr.edit_config(edit_data, target='candidate', format='xml')xr.commit()If we do a get-config operation again, this time filtering on just the destination group#xr_filter = '''&lt;telemetry-model-driven xmlns=~http#//cisco.com/ns/yang/Cisco-IOS-XR-telemetry-model-driven-cfg~&gt;&lt;destination-groups&gt;'''c = xr.get_config(source='running', filter=('subtree', xr_filter))print(c)\u2026 we\u2019ll see that DGroup1 has the new destination.Script Output#&lt;?xml version=~1.0~?&gt;&lt;rpc-reply message-id=~urn#uuid#d3b9beaa-9b69-4f5c-a7a8-5d3dc106ce0f~ xmlns#nc=~urn#ietf#params#xml#ns#netconf#base#1.0~ xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~&gt; &lt;data&gt;  &lt;telemetry-model-driven xmlns=~http#//cisco.com/ns/yang/Cisco-IOS-XR-telemetry-model-driven-cfg~&gt;   &lt;destination-groups&gt;    &lt;destination-group&gt;     &lt;destination-id&gt;DGroup1&lt;/destination-id&gt;     &lt;destinations&gt;      &lt;destination&gt;       &lt;address-family&gt;ipv4&lt;/address-family&gt;       &lt;ipv4&gt;        &lt;ipv4-address&gt;172.30.8.4&lt;/ipv4-address&gt;        &lt;destination-port&gt;5432&lt;/destination-port&gt;        &lt;encoding&gt;self-describing-gpb&lt;/encoding&gt;        &lt;protocol&gt;         &lt;protocol&gt;tcp&lt;/protocol&gt;         &lt;tls-hostname&gt;&lt;/tls-hostname&gt;         &lt;no-tls&gt;0&lt;/no-tls&gt;        &lt;/protocol&gt;       &lt;/ipv4&gt;      &lt;/destination&gt;      &lt;destination&gt;       &lt;address-family&gt;ipv6&lt;/address-family&gt;       &lt;ipv6&gt;        &lt;ipv6-address&gt;2001#db8#0#100##b&lt;/ipv6-address&gt;        &lt;destination-port&gt;5432&lt;/destination-port&gt;        &lt;encoding&gt;self-describing-gpb&lt;/encoding&gt;        &lt;protocol&gt;         &lt;protocol&gt;grpc&lt;/protocol&gt;         &lt;tls-hostname&gt;&lt;/tls-hostname&gt;         &lt;no-tls&gt;0&lt;/no-tls&gt;        &lt;/protocol&gt;       &lt;/ipv6&gt;      &lt;/destination&gt;     &lt;/destinations&gt;    &lt;/destination-group&gt;   &lt;/destination-groups&gt;  &lt;/telemetry-model-driven&gt; &lt;/data&gt;&lt;/rpc-reply&gt;And if you need some CLI to reassure yourself that it worked, here it is#CLI Output#RP/0/RP0/CPU0#SunC#show run telemetry model-driventelemetry model-driven destination-group DGroup1  address family ipv4 172.30.8.4 port 5432   encoding self-describing-gpb   protocol tcp  !  address family ipv6 2001#db8#0#100##b port 5432   encoding self-describing-gpb   protocol grpc  ! ! sensor-group SGroup1  sensor-path Cisco-IOS-XR-wdsysmon-fd-oper#system-monitoring  sensor-path Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters ! subscription Sub1  sensor-group-id SGroup1 sample-interval 30000  destination-id DGroup1Clean-up TimeSince it\u2019s always a good idea to be able to remove what you configure, here\u2019s the XML instantiation of the YANG model to do that using the \u201cremove\u201d operation.  There are other ways to do this, but this is the most surgical.edit_data = '''&lt;config&gt;&lt;telemetry-model-driven xmlns=~http#//cisco.com/ns/yang/Cisco-IOS-XR-telemetry-model-driven-cfg~&gt;   &lt;sensor-groups&gt;    &lt;sensor-group&gt;     &lt;sensor-group-identifier&gt;SGroup1&lt;/sensor-group-identifier&gt;     &lt;enable&gt;&lt;/enable&gt;     &lt;sensor-paths&gt;      &lt;sensor-path nc#operation=~remove~&gt;       &lt;telemetry-sensor-path &gt;Cisco-IOS-XR-wdsysmon-fd-oper#system-monitoring&lt;/telemetry-sensor-path&gt;      &lt;/sensor-path&gt;     &lt;/sensor-paths&gt;    &lt;/sensor-group&gt;   &lt;/sensor-groups&gt;  &lt;destination-groups&gt;    &lt;destination-group&gt;     &lt;destination-id&gt;DGroup1&lt;/destination-id&gt;     &lt;destinations&gt;      &lt;destination &gt;       &lt;address-family&gt;ipv6&lt;/address-family&gt;       &lt;ipv6 nc#operation=~delete~&gt;        &lt;ipv6-address&gt;2001#db8#0#100##b&lt;/ipv6-address&gt;        &lt;destination-port&gt;5432&lt;/destination-port&gt;        &lt;encoding&gt;self-describing-gpb&lt;/encoding&gt;        &lt;protocol&gt;         &lt;protocol&gt;tcp&lt;/protocol&gt;         &lt;tls-hostname&gt;&lt;/tls-hostname&gt;         &lt;no-tls&gt;0&lt;/no-tls&gt;        &lt;/protocol&gt;       &lt;/ipv6&gt;      &lt;/destination&gt;     &lt;/destinations&gt;    &lt;/destination-group&gt;   &lt;/destination-groups&gt;  &lt;/telemetry-model-driven&gt;  &lt;/config&gt;'''xr.edit_config(edit_data, target='candidate', format='xml')xr.commit()xr.close_session()ConclusionThe IOS XR Native telemetry YANG model exposes the full range of functionality in Model-Driven Telemetry.  The examples in this tutorial should get you started with configuring MDT in a programmatic way.", "url": "https://xrdocs.github.io/telemetry/tutorials/2016-08-15-configuring-mdt-for-tcp-dial-out-using-native-yang/", "tags": "iosxr", "title": "Configuring Model-Driven-Telemetry (MDT) for Dial-out Using Native YANG", "author": ""}, "tutorials-iosxr-ansible": {"content": "     IOS-XR# Ansible and Vagrant  Introduction  Prerequisites          Vagrant pre-setup      devbox box pre-configuration      IOS-XRv box pre-configuration      Configure Passwordless Access into XR Linux shell      Configure Passwordless Access into XR CLI        Using Ansible Playbooks          Ansible Pre-requisites      Running Playbooks        IntroductionThe goal of this tutorial is to set up an environment that is identical for Windows, Linux or Mac-OSX users. So instead of setting up Ansible directly on the User\u2019s Desktop/Host, we simply spin up an Ubuntu vagrant instance to host our Ansible playbooks and environment. Let\u2019s call it devbox. We\u2019ll do a separate tutorial on using Ansible directly on Mac-OSX/Windows.Prerequisites  Computer with 4-5GB free RAM;  Vagrant;  Ansible;  IOS-XRv Vagrant Box  Vagrantfile and scripts for provisioning  IOS-XR Vagrant is currently in Private Beta  We explain the steps to in the section below#Vagrant pre-setupClone the repo with Vagrantfile and assisting files#$ git clone https#//github.com/ios-xr/vagrant-xrdocs.git$ cd vagrant-xrdocs/ansible-tutorials/$ lsubuntu.sh*  Vagrantfile  xr-configSetup was tested on Windows, but the workflow is the same for other environments. To add an IOS-XR box, you must first download it.  IOS-XR Vagrant is currently in Private Beta  To download the box, you will need an API-KEY and a CCO-ID  To get the API-KEY and a CCO-ID, browse to the following link and follow the steps#  Steps to Generate API-KEY$ BOXURL=~http#//devhub.cisco.com/artifactory/appdevci-release/XRv64/latest/iosxrv-fullk9-x64.box~$ curl -u your-cco-id#API-KEY $BOXURL --output ~/iosxrv-fullk9-x64.box$ vagrant box add --name IOS-XRv ~/iosxrv-fullk9-x64.boxOf course, you should replace  your-cco-id with your actual Cisco.com ID and API-KEY with the key you generated and copied using the above link.Image for devbox will be downloaded from official source#$ vagrant box add ubuntu/trusty64We should now have both the boxes available, Use the vagrant box list command to display the current set of boxes on your system as shown below#The Vagrantfile contains 2 Vagrant boxes and looks like#Vagrant.configure(2) do |config|  config.vm.provision ~shell~, inline# ~echo Hello User~  config.vm.define ~devbox~ do |devbox|    devbox.vm.box = ~ubuntu/trusty64~    devbox.vm.network #private_network, virtualbox__intnet# ~link1~, ip# ~10.1.1.10~    devbox.vm.provision #shell, path# ~ubuntu.sh~, privileged# false  end  config.vm.define ~xr~ do |xr|    xr.vm.box = ~xrv64~    xr.vm.network #private_network, virtualbox__intnet# ~link1~, ip# ~10.1.1.20~  end   endNow we are ready to boot up the boxes#mkorshun@MKORSHUN-2JPYH MINGW64 ~/Documents/workCisco/tutorial$ lsubuntu.sh*  Vagrantfile  xr-configmkorshun@MKORSHUN-2JPYH MINGW64 ~/Documents/workCisco/tutorial$ vagrant updevbox box pre-configurationTo access the devbox box just issue the command (no password required)#vagrant ssh devboxThe devbox instance is already configured via file \u201cubuntu.sh\u201d. This section is only for the user\u2019s information.  Let\u2019s review the content of the script \u201cubuntu.sh\u201dThe first four lines are responsible for downloading required packages for Ansible and updating the system.  sudo apt-get updatesudo apt-get install -y python-setuptools python-dev build-essential git libssl-dev libffi-dev sshpasssudo easy_install pip wget https#//bootstrap.pypa.io/ez_setup.py -O - | sudo python    Next, the script clones the  Ansible and the  IOSXR-Ansible repos#  git clone https#//github.com/ios-xr/iosxr-ansible.gitgit clone git#//github.com/ansible/ansible.git --recursive    It then installs Ansible and applies the variables from \u201cansible_env\u201d to the system.  cd ansible/ &amp;&amp; sudo python setup.py installecho ~source /home/vagrant/iosxr-ansible/remote/ansible_env~ &gt;&gt; /home/vagrant/.profile    The last section is responsible for generating a public key for paswordless authorization (for XR linux) and a base 64 version of it (for XR CLI)#  ssh-keygen -t rsa -f /home/vagrant/.ssh/id_rsa -q -P ~~cut -d~ ~ -f2 ~/.ssh/id_rsa.pub | base64 -d &gt; ~/.ssh/id_rsa_pub.b64  IOS-XRv box pre-configurationTo access XR Linux Shell#$ vagrant ssh rtrTo access XR console it takes one additional step to figure out port (credentials for ssh# vagrant/vagrant)#mkorshun@MKORSHUN-2JPYH MINGW64 ~/Documents/workCisco/tutorial$ vagrant port rtrThe forwarded ports for the machine are listed below. Please note thatthese values may differ from values configured in the Vagrantfile if theprovider supports automatic port collision detection and resolution. 22 (guest) = 2223 (host) 57722 (guest) = 2200 (host)   mkorshun@MKORSHUN-2JPYH MINGW64 ~/Documents/workCisco/tutorial$ ssh -p 2223 vagrant@localhostvagrant@localhost's password#RP/0/RP0/CPU0#ios#Now, let\u2019s configure an IP address on the IOS-XRv instance. Issue the following command on XR cli#conf thostname xrinterface GigabitEthernet0/0/0/0 ipv4 address 10.1.1.20 255.255.255.0 no shutdown!commitendChecking connectivity between boxes#RP/0/RP0/CPU0#ios#ping 10.1.1.10Mon May  9 08#36#33.071 UTCType escape sequence to abort.Sending 5, 100-byte ICMP Echos to 10.1.1.10, timeout is 2 seconds#!!!!!Success rate is 100 percent (5/5), round-trip min/avg/max = 1/5/20 msRP/0/RP0/CPU0#ios#Configure Passwordless Access into XR Linux shellLet\u2019s copy public part of key from devbox box and allow access without password. First,  connect to the devbox instance and copy file to XR via SCP#vagrant ssh devbox  scp -P 57722 /home/vagrant/.ssh/id_rsa.pub  vagrant@10.1.1.20#/home/vagrant/id_rsa_ubuntu.pubNow add the copied keys to authorized_keys in XR linuxvagrant ssh rtr  cat /home/vagrant/id_rsa_ubuntu.pub &gt;&gt; /home/vagrant/.ssh/authorized_keysConfigure Passwordless Access into XR CLIIf we want passwordless SSH from devbox to XR CLI, issue the following commands in XR CLI#The first command uses scp to copy the public key (base 64 encoded) to XR. Once we have the key locally, we import it using XR CLI\u2019s crypto key import command.Execute in XR CLIscp vagrant@10.1.1.10#/home/vagrant/.ssh/id_rsa_pub.b64 /disk0#/id_rsa_pub.b64crypto key import authentication rsa disk0#/id_rsa_pub.b64File \u201cid_rsa_pub.b64\u201d was created by provisioning script \u201cUbuntu.sh\u201d, during Vagrant provisioning.Using Ansible PlaybooksAnsible Pre-requisitesOn the devbox box let\u2019s configure Ansible prerequisites. We need to configure 2 files#      File \u201cansible_hosts\u201d#  It contains the ip address of the XR instance.We also specify a user to connect to the machine# \u201cansible_ssh_user=vagrant\u201d        File \u201cansible_env\u201d# Used to set up the environment for Ansible.  We do not delve into YDK for now, it\u2019s a topic for another tutorial. Note that the files ansible_hosts and ansible_env are preconfigured for our needs.cd iosxr-ansible/cd remote/vagrant@vagrant-ubuntu-trusty-64#~/iosxr-ansible/remote$ cat ansible_hosts[ss-xr]10.1.1.20 ansible_ssh_user=vagrantvagrant@vagrant-ubuntu-trusty-64#~/iosxr-ansible/remote$ cat ansible_envexport BASEDIR=/home/vagrantexport IOSXRDIR=$BASEDIR/iosxr-ansibleexport ANSIBLE_HOME=$BASEDIR/ansibleexport ANSIBLE_INVENTORY=$IOSXRDIR/remote/ansible_hostsexport ANSIBLE_LIBRARY=$IOSXRDIR/remote/libraryexport ANSIBLE_CONFIG=$IOSXRDIR/remote/ansible_cfgexport YDK_DIR=$BASEDIR/ydk/ydk-pyexport PYTHONPATH=$YDK_DIRRunning Playbookscd ~/iosxr-ansible/remote/  ansible-playbook samples/iosxr_get_facts.yml   ansible-playbook iosxr_cli.yml -e 'cmd=~show interface brief~' Usual playbook would look like#Output from our XR instance#Samples folder contains various playbooks, files started with \u201cshow_\u201d using iosxr_cli playbook and passing cmd to XR as parameter. To run playbook as \u201cvagrant\u201d user, playbook should contain string# \u201cbecome# yes\u201dFeel free to play with any playbook!", "url": "https://xrdocs.github.io/application-hosting/tutorials/IOSXR-Ansible", "tags": "vagrant, iosxr, cisco, linux, Ansible, xr toolbox", "title": "Using Ansible with IOS-XR 6.1.1", "author": "Mike Korshunov"}, "blogs-2016-06-11-nanog-67-meet-us-there": {"content": "We\u2019re up at NANOG 67 in Chicago, IL, next week!Over the course of more than 2 decades, the North American Network Operators\u2019 Group (NANOG) has been at the epicenter of the net-ops transformation.  This unique congregation of vendors, service-provider, Data-Center and Enterprise SMEs and network engineers provides a perfect opportunity to showcase some of the new enhancements in IOS-XR.As always, there is a fair bit of Cisco participation, with content focused on Streaming Telemetry, connectivity evaluation techniques and remediation techniques using Linux applications.Of course, if you\u2019re looking to talk about IOS-XR and other Cisco solutions for the Web, Data Center and Service Provider domain, you\u2019ll find a lot of us roaming about!If you\u2019re heading over to NANOG 67,  then check out the following sessions to get a gist of the upcoming enhancements in IOS-XR#Ten Lessons From Telemetry  Shelly Cadora, Cisco SystemsSuffering Withdrawal; an automated approach to connectivity evaluationMicah Croff, GitHubTim Hoffman, TwitterBruce McDougall, CiscoNick Slabakov, Juniper NetworksBeer-n-Gear Demo Booth# iperf driven OSPF path remediation demoTuesday, June 14 2016#  6#00 - 8#00 pm.Akshat Sharma, Cisco SystemsThat\u2019s a lot to look out for! But as part of the application-hosting team in IOS-XR, we\u2019re particularly excited about showing you the underlying linux infrastructure in IOS-XR and its integration with typical linux applications.At the Beer-n-Gear demo booth, We will have our own booth showcasing some cool new tricks with IOS-XR.The demo would be based off the following application on Github#https#//github.com/ios-xr/ospf-iperf-ncclient#The figure below should pretty much explain what we\u2019re going for#We\u2019ll show how you can bring up Containers on XR to run iperf with XR interfaces, and leverage YDK to affect OSPF path cost.Further, We bring you these demos using the new IOS-XR Vagrant box that is currently in private-beta.If you haven\u2019t heard about it yet, take a look at the following quick-start guide to get you going#   IOS-XR Vagrant Quick-StartSee you in Chicago!", "url": "https://xrdocs.github.io/application-hosting/blogs/2016-06-11-nanog-67-meet-us-there/", "tags": "iosxr, cisco, linux", "title": "NANOG 67:  Meet us there!", "author": "Akshat Sharma"}, "tutorials-2016-09-15-xr-data-model-overview": {"content": "In a previous blog post, we described how the Cisco IOS XR programmability framework is based on data models.  But, what format do they have?  where are the models published?  how many are available?  how are they grouped?If you are completely new to data models, all you need to understand at this point is that data models mostly specify the configuration and operational state that a device supports.  Models are defined as text files using the YANG modeling language (RFC 7950) and they arrange data in a tree structure.  While data models are human readable, their strength comes from the fact that they have well-defined syntax and semantics that facilitate the development of software tools to process them.  They simplify network automation and orchestration.  In this tutorial, we will not dig into YANG specifics.  Instead, we will overview the organization and naming of XR native models.XR devices ship with the YANG files that define the data models they support.  Using a management protocol (e.g. NETCONF, gRPC, RESTCONF), you can programmatically query a device for the list of models it supports and  retrieve the model files.  In addition, the XR models are made publicly available for download on GitHub.  In this tutorial, we will use that repository to explore the XR native models.Let\u2019s create a directory to host the YANG files and clone the git repository#~/$ mkdir -p ~/yang/modules/YangModels~/$ cd ~/yang/modules/YangModelsYangModels/$ git clone git@github.com#YangModels/yang.gitCloning into 'yang'...remote# Counting objects# 5541, done.remote# Compressing objects# 100% (52/52), done.remote# Total 5541 (delta 7), reused 0 (delta 0), pack-reused 5489Receiving objects# 100% (5541/5541), 11.82 MiB | 2.16 MiB/s, done.Resolving deltas# 100% (3090/3090), done.YangModels/$If we take a closer look at the XR files, we see that they are grouped by software release#YangModels/$ cd yang/vendor/cisco/xr/xr/$ ls530  531  532  533  600  601  611  612  check.sh  README.mdxr/$The name of XR data models use the following notation#Cisco-IOS-XR-&lt;platform&gt;&lt;technology&gt;&lt;suffix&gt;XR models start with the prefix Cisco-IOS-XR, are followed by an optional platform substring (e.g. ncs5500, asr9k, etc), followed by a technology substring (e.g. ipv4-bgp) and finally ending with a suffix that indicates whether the model defines configuration data (cfg), operational data (oper) or an action (act).  Note that a YANG model can specify multiple types of data simultaneously.  However, Cisco IOS XR defines separate models for configuration, operational data and actions.If we examine the directory for the XR 6.1.2 release, we see that there are 571 YANG files that define XR data models. The actual number of models is lower.  Each YANG file defines a module or submodule. Submodules are partial modules that contribute definitions to a module.  One or more modules and submodules define a model#xr/$ cd 612612/$ ls Cisco-IOS-XR-*.yang | wc -l571612/$Based on the naming convention above, we identify 158 configuration models in this release#612/$ ls Cisco-IOS-XR-*cfg.yang | wc -l158612/$If we look for the BGP configuration model, we can see that it is platform independent (no platform substring), is defined in file Cisco-IOS-XR-ipv4-bgp-cfg.yang and has a corresponding name Cisco-IOS-XR-ipv4-bgp-cfg#612/$ ls *bgp*cfg.yangCisco-IOS-XR-ipv4-bgp-cfg.yang612/$612/$ grep ~module Cisco~ Cisco-IOS-XR-ipv4-bgp-cfg.yangmodule Cisco-IOS-XR-ipv4-bgp-cfg {612/$Following the naming convention described earlier, we find initially 151 files associated with operational models#612/$ ls Cisco-IOS-XR-*oper.yang | wc -l151612/$If we look for the BGP operational model, we can see that the BGP operational model is platform independent (no platform substring), is defined in file Cisco-IOS-XR-ipv4-bgp-oper.yang and has a corresponding name Cisco-IOS-XR-ipv4-bgp-oper#612/$ ls *bgp*oper.yangCisco-IOS-XR-ipv4-bgp-oper.yang612/$612/$ grep ~module Cisco~ Cisco-IOS-XR-ipv4-bgp-oper.yangmodule Cisco-IOS-XR-ipv4-bgp-oper {612/$At this point we have accounted for 309 of the initial list of 571 YANG files.  What about the other 262 files?  As mentioned above, data models are defined by one or more modules and submodules. Some operational models are defined using submodels.  Those files use the suffix oper-sub followed by a sequence number.  We find 236 files that define operational submodules#612/$ ls Cisco-IOS-XR-*oper-sub[1-9].yang | wc -l236612/$One of those submodules is actually associated with the BGP operational model (Cisco-IOS-XR-ipv4-bgp-oper) that we identified before#612/$ ls Cisco-IOS-XR-*bgp*oper-sub[1-9].yangCisco-IOS-XR-ipv4-bgp-oper-sub1.yang612/$612/$ grep ~submodule Cisco\\|belongs-to~ Cisco-IOS-XR-ipv4-bgp-oper-sub1.yangsubmodule Cisco-IOS-XR-ipv4-bgp-oper-sub1 {  belongs-to Cisco-IOS-XR-ipv4-bgp-oper {612/$Now we have accounted for 545 YANG files,  what about the remaining 26 files?  Out of those, 22 files define data types used in models.  The YANG language has some built-in data types (e.g. boolean, uint32, string, etc.) that can be used as primitives to define more elaborate types (e.g. interface name, BGP ASN, etc.)  Those files use the suffix types#612/$ ls *types.yang | wc -l22612/$One of these files (Cisco-IOS-XR-ipv4-bgp-datatypes.yang) actually corresponds to data types for BGP.  It defines some of the address families used by BGP models#612/$ ls *bgp*types.yangCisco-IOS-XR-ipv4-bgp-datatypes.yang612/$What about the actions models we mentioned earlier?  They correspond to commands that can be executed on the device.  These actions are called remote procedure calls (RPCs) in YANG and are specified in files with suffix act.  The actions defined in this software release include commands to roll back configuation, test SNMP traps and generate custom Syslog messages#612/$ ls Cisco-IOS-XR-*act.yang | wc -l3612/$612/$ ls -1 Cisco-IOS-XR-*act.yangCisco-IOS-XR-cfgmgr-rollback-act.yangCisco-IOS-XR-snmp-test-trap-act.yangCisco-IOS-XR-syslog-act.yang612/$What about the other 40 YANG files that we have been conveniently ignoring in this discussion?  Those files do not define XR native data models.  We will discuss them in detail in future postings.612/$ ls *.yang | grep -v Cisco-IOS-XR | wc -l40612/$In Summary  XR native data models follow a specific naming convention (Cisco-IOS-XR-&lt;platform&gt;&lt;technology&gt;&lt;suffix&gt;)  Each model provides a single type of definition (configuration data, operational state or action)  The definition of a model may be involve multiple YANG files where each file specifies a YANG module or submodule", "url": "https://xrdocs.github.io/programmability/tutorials/2016-09-15-xr-data-model-overview/", "tags": "programmability", "title": "XR Data-model Overview", "author": "Santiago Alvarez"}, "tutorials-2016-06-23-copying-telemetry-policy-files-in-ios-xr-6-0-1": {"content": "Due to some general security improvements in 6.0.1, it\u2019s not possible to sftp/scp files directly to the /telemetry/policies directory from the outside.  If you try, you might see something like this#RP/0/RP0/CPU0#Sun601#run[xr-vm_node0_RP0_CPU0#~]$sftp scadora@172.30.8.11 Connecting to 172.30.8.11...  Password#  sftp&gt;get /tftpboot/BasicPolicy.policy /telemetry/policies/BasicPolicy.policy   RP/0/RP0/CPU0#Jun 23 16#08#00.870 # sftp[69048]# %SECURITY-SSHD-3-ERR_GENERAL # Cannot     overwrite system files  sftp&gt;The restriction on the /telemetry/policies directory will be lifted in 6.0.2, but in the meantime you can work around this by copying files to disk0# and then doing a local copy to the proper directory as follows#RP/0/RP0/CPU0#Sun601#run[xr-vm_node0_RP0_CPU0#~]$sftp scadora@172.30.8.11Connecting to 172.30.8.11...  Password#  sftp&gt; get /tftpboot/BasicPolicy.policy /disk0#/BasicPolicy.policy  Transferred 469 Bytes    469 bytes copied in 0 sec (0)bytes/sec  sftp&gt; quit  [xr-vm_node0_RP0_CPU0#~]$cp /disk0#/BasicPolicy.policy /telemetry/policies[xr-vm_node0_RP0_CPU0#~]$", "url": "https://xrdocs.github.io/telemetry/tutorials/2016-06-23-copying-telemetry-policy-files-in-ios-xr-6-0-1/", "tags": "iosxr, telemetry", "title": "Copying Telemetry Policy Files in IOS XR 6.0.1", "author": "Shelly Cadora"}, "tutorials-understanding-ncs5500-jericho-plus-systems": {"content": "     Understanding NCS5500 Resources  S01E06 Introduction of the Jericho+ based platforms and impact on the scale          Previously on \u201cUnderstanding NCS5500 Resources\u201d      Jericho+      New systems using this J+ ASIC      Let\u2019s talk about route scale      NCS55A1-36H-S Scale      NCS55A1-36H-SE-S Scale      NCS55A1-24H Scale      Conclusion        S01E06 Introduction of the Jericho+ based platforms and impact on the scalePreviously on \u201cUnderstanding NCS5500 Resources\u201dIn previous posts, we presented#  the different routers and line cards in NCS5500 portfolio  we explained how IPv4 prefixes are sorted in LEM, LPM and eTCAM  we covered how IPv6 prefixes are stored in the same databases.  we demonstrated in a video how we can handle a full IPv4 and IPv6 Internet view on \u201cBase\u201d systems and line cards (i.e. without external TCAM, only using the LEM and LPM internal to the forwarding ASIC)  finally in the fifth post, we demonstrated in another video the scale we can reach on Jericho-based systems with an external TCAMIn this episode we will introduce and study a second generation of line cards and systems based on an evolution of the Forwarding ASIC.Jericho+This Forwarding ASIC from Broadcom re-uses all of the principles of the Jericho generation, simply extending some scales#  the bandwidth capabilities and consequently, the interfaces count# we can now accomodate 9x 100G interfaces line rate per ASIC  the forwarding capability , extending it to 835MPPS (the performance is the same with lookups in internal databases or external TCAM)  some memories like LPM (for certain models) and EEDB. Also we will use a new generation eTCAM (significantly larger).\u201cCertain models\u201d? Yes, J+ exists in different flavors. Some are re-using the same LEM/LPM scale than Jericho and some others have a larger LPM memory (qualified for 1M to 1.3M instead of 256K to 350+K IPv4 entries).Both Jericho and Jericho+ can be used with current Fabric Cards (FE3600). Some restrictions may apply for the 16-slot chassis, please contact your local account team to discuss the specifics.New systems using this J+ ASICIn the modular chassis#In March 2018, we have a single line card using Jericho+# the 36x100G-A-SE (more LC are coming in the summer).The line card is timing capable (note# an RP-E is necessary to use these timing features) and only exists in scale version (with eTCAM). The supported scale in current release is 4M+ IPv4 entries. It does not include MACsec chipset. It\u2019s also the first line card supporting break-out cable 4x 25G.Internally, the line is composed of 4 Jericho+ (each one handling 9 ports QSFP). As shown in this diagram, each Jericho+ Forwarding ASIC is connected to the fabric cards via 8x 25G SERDES instead of 6 in the case of Jericho-based line cards.We are also extending the fixed-form factor portfolio with 3 new 1RU options#  NCS55A1-36H-S  NCS55A1-36H-SE-S  NCS55A1-24HLet\u2019s get started with the 36 ports options.These standalone systems are MACsec + timing capable and are available in base (NCS55A1-36H-S) and scale versions (NCS55A1-36H-SE-S). Both have the same port density.The base version shows the same route scale than a Jericho systems without external TCAM while the scale version uses a new generation eTCAM extending the scale to 4M IPv4 routes (potentially much more in the future).Internally, the system is composed of 4 Jericho+ ASICs (each one handling 9 ports QSFP) interconnected via an FE3600 chipset.The third router# NCS55A1-24H.It\u2019s a cost optimized, oversubscribbed, system that provides 24 ports QSFP. It is timing-capable but doesn\u2019t support MACsec.As shown in this diagram, the forwarding ASICs are connected back-to-back without using any fabric engine. Each ASIC handles 12 ports for a 900Gbps forwarding capability (hence the oversubscription).We will describe it in more details in the next sections but this system uses the largest version of Jericho+ ASICs. It doesn\u2019t use external TCAM but has a large LPM (1M to 1.3M prefixes instead of the 256K-350K we use on other systems in chassis or in the NCS55A1-36H-S).Let\u2019s talk about route scaleFirst, a quick reminder# the order of operation for route lookup in the NCS5500 family. It applies for both Jericho and Jericho+ systems.The prefixes are stored in LEM, LPM and when possible eTCAM.NCS55A1-36H-S ScaleOn the NCS55A1-36H-S, the principles of prefixes storage are exactly the same than Jericho systems without eTCAM.So it\u2019s possible to use two different modes#  by default# the host mode  changed by configuration# the internet modeI invite you take a look at the second and third episode of this series. You will find detailed explanations and examples with real internet views.NCS55A1-36H-SE-S ScaleThe NCS55A1-36H-SE-S is using the same Jericho+ ASIC but completed with a new generation and much larger external TCAM. In current release, it\u2019s certified for 4M IPv4 prefixes but the memory capabilities are significantly larger. We will decide in the future if it\u2019s necessary to increase the tested/validated scale.Also, please note that the way we sort routes is different between 6.3.15 and 6.3.2. It\u2019s very likely we will simplify everything in the next major release during the summer (stay tuned).The uRPF does not affect the scale of this eTCAM (on the contrary of the first generation where it was necessary to disable the dual capacity feature, reducing the eTCAM to 1M entries). Also, the hybrid ACLs are using a different zone of the eTCAM memory and don\u2019t affect the overall scale.The NG eTCAM is algorithmic and the free memory displayed in the following show commands will depend on the current table distribution (in prefix length), so don\u2019t be surprised to see numbers below 4M. Also the max estimated values are currently showing 100% regardless the number. It will be fixed in  next releases.RP/0/RP0/CPU0# 5508-6.3.2#sh route sumRoute Source                     Routes     Backup     Deleted     Memory(bytes)local                            9          0          0           2160connected                        8          1          0           2160static                           3          0          0           720bgp 100                          1224649    0          0           293915760dagr                             0          0          0           0Total                            1224669    1          0           293920800RP/0/RP0/CPU0#5508-6.3.2#sh route ipv6 sumRoute Source                     Routes     Backup     Deleted     Memory(bytes)local                            6          0          0           1584connected                        5          1          0           1584connected l2tpv3_xconnect        0          0          0           0bgp 100                          36488      0          0           9632832Total                            36499      1          0           9636000RP/0/RP0/CPU0#5508-6.3.2#sh dpa resource iproute loc 0/1/CPU0~iproute~ DPA Table (Id# 24, Scope# Global)--------------------------------------------------IPv4 Prefix len distributionPrefix   Actual       Prefix   Actual /0       3            /1       0 /2       0            /3       0 /4       3            /5       0 /6       0            /7       0 /8       16           /9       14 /10      37           /11      107 /12      288          /13      557 /14      1071         /15      1909 /16      13572        /17      8005 /18      14055        /19      25974 /20      40443        /21      45082 /22      83722        /23      71750 /24      395144       /25      2085 /26      3362         /27      5736 /28      15909        /29      17377 /30      42508        /31      112 /32      435876                          NPU ID# NPU-0           NPU-1           NPU-2           NPU-3                          In Use# 1224717         1224717         1224717         1224717                 Create Requests                           Total# 1224771         1224771         1224771         1224771                         Success# 1224771         1224771         1224771         1224771                 Delete Requests                           Total# 54              54              54              54                         Success# 54              54              54              54                 Update Requests                           Total# 287990          287990          287990          287990                         Success# 287989          287989          287989          287989                    EOD Requests                           Total# 0               0               0               0                         Success# 0               0               0               0                          Errors                     HW Failures# 0               0               0               0                Resolve Failures# 0               0               0               0                 No memory in DB# 0               0               0               0                 Not found in DB# 0               0               0               0                    Exists in DB# 0               0               0               0RP/0/RP0/CPU0#5508-6.3.2#sh dpa resource ip6route loc 0/1/CPU0~ip6route~ DPA Table (Id# 25, Scope# Global)--------------------------------------------------IPv6 Prefix len distributionPrefix   Actual            Capacity    Prefix   Actual            Capacity /0       3                 0            /1       0                 0 /2       0                 0            /3       0                 0 /4       0                 0            /5       0                 0 /6       0                 0            /7       0                 0 /8       0                 0            /9       0                 0 /10      3                 0            /11      0                 0 /12      0                 0            /13      0                 0 /14      0                 0            /15      0                 0 /16      9                 0            /17      0                 0 /18      0                 0            /19      0                 0 /20      0                 0            /21      0                 0 /22      0                 0            /23      0                 0 /24      0                 0            /25      0                 0 /26      0                 0            /27      0                 0 /28      0                 0            /29      0                 0 /30      0                 0            /31      0                 0 /32      0                 0            /33      0                 0 /34      0                 0            /35      0                 0 /36      0                 0            /37      0                 0 /38      0                 0            /39      0                 0 /40      5184              0            /41      0                 0 /42      0                 0            /43      0                 0 /44      0                 0            /45      0                 0 /46      0                 0            /47      0                 0 /48      31304             0            /49      0                 0 /50      0                 0            /51      0                 0 /52      0                 0            /53      0                 0 /54      0                 0            /55      0                 0 /56      0                 0            /57      0                 0 /58      0                 0            /59      0                 0 /60      0                 0            /61      0                 0 /62      0                 0            /63      0                 0 /64      5                 0            /65      0                 0 /66      0                 0            /67      0                 0 /68      0                 0            /69      0                 0 /70      0                 0            /71      0                 0 /72      0                 0            /73      0                 0 /74      0                 0            /75      0                 0 /76      0                 0            /77      0                 0 /78      0                 0            /79      0                 0 /80      0                 0            /81      0                 0 /82      0                 0            /83      0                 0 /84      0                 0            /85      0                 0 /86      0                 0            /87      0                 0 /88      0                 0            /89      0                 0 /90      0                 0            /91      0                 0 /92      0                 0            /93      0                 0 /94      0                 0            /95      0                 0 /96      0                 0            /97      0                 0 /98      0                 0            /99      0                 0 /100     0                 0            /101     0                 0 /102     0                 0            /103     0                 0 /104     3                 0            /105     0                 0 /106     0                 0            /107     0                 0 /108     0                 0            /109     0                 0 /110     0                 0            /111     0                 0 /112     0                 0            /113     0                 0 /114     0                 0            /115     0                 0 /116     0                 0            /117     0                 0 /118     0                 0            /119     0                 0 /120     0                 0            /121     0                 0 /122     0                 0            /123     0                 0 /124     0                 0            /125     0                 0 /126     0                 0            /127     0                 0 /128     12                0                          NPU ID# NPU-0           NPU-1           NPU-2           NPU-3                          In Use# 36523           36523           36523           36523                 Create Requests                           Total# 36523           36523           36523           36523                         Success# 36523           36523           36523           36523                 Delete Requests                           Total# 0               0               0               0                         Success# 0               0               0               0                 Update Requests                           Total# 0               0               0               0                         Success# 0               0               0               0                    EOD Requests                           Total# 0               0               0               0                         Success# 0               0               0               0                          Errors                     HW Failures# 0               0               0               0                Resolve Failures# 0               0               0               0                 No memory in DB# 0               0               0               0                 Not found in DB# 0               0               0               0                    Exists in DB# 0               0               0               0RP/0/RP0/CPU0#5508-6.3.2#sh contr npu resources lem loc 0/1/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green    NPU-1        Estimated Max Entries       # 786432        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green    NPU-2        Estimated Max Entries       # 786432        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green    NPU-3        Estimated Max Entries       # 786432        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 435877   (55 %)        iproute                     # 435876   (55 %)        ip6route                    # 0        (0 %)        mplslabel                   # 0        (0 %)    NPU-1        Total In-Use                # 435877   (55 %)        iproute                     # 435876   (55 %)        ip6route                    # 0        (0 %)        mplslabel                   # 0        (0 %)    NPU-2        Total In-Use                # 435877   (55 %)        iproute                     # 435876   (55 %)        ip6route                    # 0        (0 %)        mplslabel                   # 0        (0 %)    NPU-3        Total In-Use                # 435877   (55 %)        iproute                     # 435876   (55 %)        ip6route                    # 0        (0 %)        mplslabel                   # 0        (0 %)RP/0/RP0/CPU0#5508-6.3.2#sh contr npu resources lpm loc 0/1/CPU0HW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP --Current Usage    NPU-0        Total In-Use                # 0        (0 %)        iproute                     # 0        (0 %)        ip6route                    # 0        (0 %)        ipmcroute                   # 0        (0 %)        -- SNIP --RP/0/RP0/CPU0#5508-6.3.2#sh contr npu resources exttcamipv4 loc 0/1/CPU0HW Resource Information    Name                            # ext_tcam_ipv4OOR Information    NPU-0        Estimated Max Entries       # 788841        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Red        OOR State Change Time       # 2018.Mar.27 08#01#30 PDT-- SNIP --Current Usage    NPU-0        Total In-Use                # 788841   (100 %)        iproute                     # 788841   (100 %)        ipmcroute                   # 0        (0 %)-- SNIP --RP/0/RP0/CPU0#5508-6.3.2#sh contr npu resources exttcamipv6short loc 0/1/CPU0HW Resource Information    Name                            # ext_tcam_ipv6_shortOOR Information    NPU-0        Estimated Max Entries       # 73016        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP --Current Usage    NPU-0        Total In-Use                # 73016    (100 %)        ip6route                    # 73016    (100 %)-- SNIP --RP/0/RP0/CPU0#5508-6.3.2#sh contr npu resources exttcamipv6long loc 0/1/CPU0HW Resource Information    Name                            # ext_tcam_ipv6_longOOR Information    NPU-0        Estimated Max Entries       # 60        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP --Current Usage    NPU-0        Total In-Use                # 60       (100 %)        ip6route                    # 60       (100 %)-- SNIP --RP/0/RP0/CPU0#5508-6.3.2#sh contr npu externaltcam loc 0/1/CPU0External TCAM Resource Information=============================================================NPU  Bank   Entry  Owner       Free     Per-DB  DB   DB     Id     Size               Entries  Entry   ID   Name=============================================================0    0      80b    FLP         334744   788832  0    IPv4 UC0    1      80b    FLP         0        0       1    IPv4 RPF0    2      160b   FLP         218130   36505   3    IPv6 UC0    3      160b   FLP         0        0       4    IPv6 RPF0    4      80b    FLP         4096     0       81   INGRESS_IPV4_SRC_IP_EXT0    5      80b    FLP         4096     0       82   INGRESS_IPV4_DST_IP_EXT0    6      160b   FLP         4096     0       83   INGRESS_IPV6_SRC_IP_EXT0    7      160b   FLP         4096     0       84   INGRESS_IPV6_DST_IP_EXT0    8      80b    FLP         4096     0       85   INGRESS_IP_SRC_PORT_EXT0    9      80b    FLP         4096     0       86   INGRESS_IPV6_SRC_PORT_EXT-- SNIP --RP/0/RP0/CPU0#5508-6.3.2#NCS55A1-24H ScaleThe NCS55A1-24H is very different from the other NCS5500 routers because it uses a pair of Jericho+ with large LPM. So it occupies a particular place between the non-eTCAM and the eTCAM systems.This large LPM is algorithmic, so even if it\u2019s marketed for 1M IPv4 entries, it can fit much more depending on the prefix distribution#HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # GreenHW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 1384333        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # GreenLike the other non-eTCAM systems, we can use two different configurations# the host-optimized mode (default) and the internet-optimized mode.Let\u2019s take a full internet table made of 655487 v4 and 42852 v6 real routesand check how it fits in this system.With the host optimized mode#And with the internet optimized mode#ConclusionThree different options with the Jericho+ systems# J+ with Jericho-scale, J+ with large LPM, J+ with new generation eTCAM. They are used in one new line card offering very high route scalability (4M+ routes), and in three new 1RU systems.", "url": "https://xrdocs.github.io/cloud-scale-networking/tutorials/Understanding-ncs5500-jericho-plus-systems/", "tags": "iosxr, xr, ncs5500, jericho+, j+", "title": "Understanding NCS5500 Jericho+ Systems and their scalability", "author": "Nicolas Fevrier"}, "tutorials-2017-08-03-understanding-ncs5500-resources-s01e02": {"content": "     Understanding NCS5500 Resources  S01E02 IPv4 Prefixes          Previously on \u201cUnderstanding NCS5500 Resources\u201d      IPv4 routes and FIB Profiles      Lab verification      Real use-cases        S01E02 IPv4 PrefixesPreviously on \u201cUnderstanding NCS5500 Resources\u201dIn the previous post, we introduced the different routers and line cards in NCS5500 portfolio. We classified them into two categories# with or without external TCAM (eTCAM). And we introduced the different databases available to store information, inside and outside the Forwarding ASIC (FA).All the principles described below and the examples used to illustrate them were validated in August 2017 with Jericho-based systems, using scale (with eTCAM) and base (without eTCAM) line cards and running the two IOS XR releases available# 6.1.4 and 6.2.2. Jericho+ based systems will be used in a follow up post in the same series (season 2 ;)IPv4 routes and FIB ProfilesA quick refresh will be very useful to understand how routes are stored in NCS5500#  LPM# Longest Prefix Match Database (sometimes referred to as KAPS for KBP Assisted Prefix Search, KBP being itself Knowledge Based Processor) is an SRAM used to store IPv4 and IPv6 prefixes. Scale# variable from 128k to 400k entries. We can perform variable length prefix lookup in LPM.  LEM# Large Exact Match Database also used to store specific IPv4 and IPv6 routes, plus MAC addresses and MPLS labels. Scale# 786k entries. We perform exact match lookup in LEM.  eTCAM# external TCAMs, only present in the -SE \u201cscale\u201d line cards and systems. As the name implies, they are not a resource inside the Forwarding ASIC, it\u2019s an additional memory used to extend unicast route and ACL / classifiers scale. Scale# 2M IPv4 entries. We can also perform variable length prefix lookup in eTCAM.The origin of the prefixes is not relevant. They can be received from OSPF, ISIS, BGP but also static routes. It doesn\u2019t influence which database will be used to store them. Only the address-family (IPv4 in this discussion) and the subnet length of the prefix will be used in the decision process.Hardware programming is done through an abstraction layer# Data-Plane Agent (DPA)Also, it\u2019s important to remember we are not talking about BGP paths here but about FIB entries# if we have 10 internet transit providers advertising more or less the same 700k-ish routes (with 10 next-hop addresses), we don\u2019t have 7M entries in the FIB but 700k. Few exceptions exist (like using different VRFs for each transit provider) but they are out of the scope of this post.Originally, IPv4/32 are going in LEM and all other prefix lengths (IPv4/31-/0) are stored in LPM.We changed this default behavior by implementing FIB profiles# Host-optimized or Internet-Optimized.RP/0/RP0/CPU0#NCS5500(config)#hw-module fib ipv4 scale ?  host-optimized-disable  Configure Host optimization by default  internet-optimized      Configure Intetrnet optimizedRP/0/RP0/CPU0#NCS5500(config)#Host-optimized is the default option. Committing a change in the configuration will prompt you to reload the line-cards or chassis to enable the new profile.For a base line card (those without -SE in the product ID), we will have the following order of operation#When a packet is received, the FA performs a lookup on the destination address#  first lookup is performed in the LEM searching for a IPv4/32 exact match  second lookup is accessing the LPM searching for a variable length match between IPv4/31 and IPv4/25  third lookup is done in the LEM again, searching for a IPv4/24 exact match  finally, the fourth lookup is checking the LPM a second time searching for a variable length match between IPv4/23 and /0All is done in one single clock tick, it doesn\u2019t require any kind of recirculation and doesn\u2019t impact the performance (in bandwidth or in packet per second).This mode is particularly useful with a large number of IPv4/32 and IPv4/24 in the routing table. It could be the case for hosting companies or data centers.Using the configuration above, you can decide to enable the Internet-optimized mode. This is a feature activated globally and not per line card. After reload, you will see a very different order of operation and prefix distribution in the various databases with base line cards and systems#The order of operation LEM/LPM/LEM/LPM is now replaced by an LPM/LEM/LEM/LPM approach.  first lookup is in LPM searching for a match between IPv4/32 and IPv4/25  second lookup is performed in LEM for an exact match on IPv4/24 and IPv4/23.  third lookup is done in LEM too, and this time for also an exact match on IPv4/20  fourth and final step, a variable length lookup is executed in LPM for everything between IPv4/22 and /0Here again, everything is performed in one cycle and the activation of the Internet Optimized mode doesn\u2019t impact the forwarding performance.As the name implies, this profile has been optimized to move the largest route population present on the Internet (IPv4/24, IPv4/23, IPv4/20) into the largest memory database# the LEM. If you followed carefully, you noticed that a couple of improvement are needed to implement this sequence of lookup.First, the match on LEM needs to be on an exact prefix length but the step two is done on IPv4/24 and IPv4/23. Indeed a function in DPA splits all IPv4/23 received from the upper FIB process in two. Each IPv4/23 is programmed as two sub-sequent IPv4/24s in hardware. We will illustrate this case with an example in the lab later in this post, advertising 300,000 IPv4/23.Second, the exact match in step 3 for IPv4/20 in LEM is only possible if we don\u2019t have any IPv4/22 or IPv4/21 prefixes overlapping with this IPv4/20. This implies the system performs another pro-active check to verify we don\u2019t have overlap. If an overlap happens, the IPv4/20 prefix is moved from LEM to LPM dynamically. We will illustrate this mechanism later in the post, advertising 100,000 IPv4/20 first, then advertising 100,000 IPv4/21 overlapping on the IPv4/20. We will see the IPv4/20 moved into LPM automatically.With this Internet Optimized profile activated, it\u2019s possible to store a full internet view on base systems and line cards (we will present a couple of examples at the end of the documents).  LEM is 786k large  LPM scales from 256k to 350-400k (depending on the internet distribution, this algorithmic memory is dynamically optimized)  Total IPv4 scale for base systems is 786k + 350k = 1,136k routesWhat about the scale line cards and routers (NCS5501-SE, NCS5502-SE and all the -SE line cards) ?The two optimized profiles described earlier don\u2019t impact the lookup process on scale systems, which will always follow this order of operation#Just a two-step lookup here#  first lookup is in LEM for an exact match on IPv4/32  second and last lookup in the large eTCAM for everything between IPv4/31 and /0Needless to say, it is all done in one single operation in the Forwarding ASIC.  LEM is 786k large  eTCAM can offer up to 2M IPv4 entries  Total IPv4 scale for scale systems is 786k + 2M = 2,786k routesLab verificationLet\u2019s try to illustrate it in the lab, injecting different types of IPv4 routes.On NCS5500, the IOS XR CLI to verify the resource utilization is \u201cshow controller npu resources all location 0/x/CPU0\u201d.We will advertise prefixes from a test device and check the memory utilization. It\u2019s not an ideal approach because, for the sake of simplicity, the routes advertised through BGP are contiguous#RP/0/RP0/CPU0#NCS5500#sh route bgpB    2.0.0.0/32 [20/0] via 192.168.1.2, 04#13#13B    2.0.0.1/32 [20/0] via 192.168.1.2, 04#13#13B    2.0.0.2/32 [20/0] via 192.168.1.2, 04#13#13B    2.0.0.3/32 [20/0] via 192.168.1.2, 04#13#13B    2.0.0.4/32 [20/0] via 192.168.1.2, 04#13#13B    2.0.0.5/32 [20/0] via 192.168.1.2, 04#13#13B    2.0.0.6/32 [20/0] via 192.168.1.2, 04#13#13[...]RP/0/RP0/CPU0#NCS5500#Despite common belief, it\u2019s not an ideal situation. On the contrary, algorithmic memories (like LPM) will be capable of much higher scale with real internet prefix-length distribution. Nevertheless, it\u2019s still an ok approach to demonstrate where the prefixes are stored (based on the subnet length).We will take a look at two systems using scale line cards (24H12F) in slot 0/6 and base line cards (18H18F) in slot 0/0, and running two different IOS XR releases (6.1.4 and 6.2.2).200k IPv4 /32 routesLet\u2019s get started with the advertisement of 200,000 IPv4/32 prefixes.On base line cards running Host-optimized profile, IPv4/32 routes are going to LEM.RP/0/RP0/CPU0#NCS5500-614#sh route sumRoute Source                     Routes     Backup     Deleted     Memory(bytes)connected                        6          1          0           1680local                            7          0          0           1680static                           2          0          0           480ospf 100                         0          0          0           0dagr                             0          0          0           0bgp 100                          200000     0          0           48000000Total                            200015     1          0           48003840RP/0/RP0/CPU0#NCS5500-614#sh route bgp | i /32 | utility wc -l200000RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources lem location 0/0/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # Green[...]Current Usage    NPU-0        Total In-Use                # 200131   (25 %)        iproute                     # 200029   (25 %)        ip6route                    # 0        (0 %)        mplslabel                   # 102      (0 %)[...]RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources lpm location 0/0/CPU0HW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 87036        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 148      (0 %)        iproute                     # 5        (0 %)        ip6route                    # 117      (0 %)        ipmcroute                   # 50       (0 %)RP/0/RP0/CPU0#NCS5500-614#Estimated Max Entries (and the Current Usage percentage derived from it) are only estimations provided by the Forwarding ASIC based on the current memory occupation and prefix distribution. It\u2019s not always linear and should  be taken with a grain of salt.On base line cards running Internet-optimized profile, IPv4/32 routes are going to LPM#RP/0/RP0/CPU0#NCS5500-614#sh route bgp | i /32 | utility wc -l200000RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources lem location 0/0/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 107      (0 %)        iproute                     # 5        (0 %)        ip6route                    # 0        (0 %)        mplslabel                   # 102      (0 %)RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources lpm location 0/0/CPU0HW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 323057        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 200171   (62 %)        iproute                     # 200029   (62 %)        ip6route                    # 116      (0 %)        ipmcroute                   # 50       (0 %)RP/0/RP0/CPU0#NCS5500-614#Finaly, on scale line card, regardless of the profile enabled, the IPv4/32 are stored in LEM and not eTCAM#RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources lem location 0/6/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 200127   (25 %)        iproute                     # 200024   (25 %)        ip6route                    # 0        (0 %)        mplslabel                   # 102      (0 %)RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources exttcamipv4 location 0/6/CPU0HW Resource Information    Name                            # ext_tcam_ipv4OOR Information    NPU-0        Estimated Max Entries       # 2048000        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 10       (0 %)        iproute                     # 10       (0 %)        ipmcroute                   # 0        (0 %)RP/0/RP0/CPU0#NCS5500-614#500k IPv4 /24 routesIn this second example, we announce 500,000 IPv4/24 prefixes.With both host-optimized and internet-optimized profiles on base line cards, we will see these prefixes moved into LEM.RP/0/RP0/CPU0#NCS5500-614#sh route bgp | i /24 | utility wc -l500000RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources lem location 0/0/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 500131   (64 %)        iproute                     # 500029   (64 %)        ip6route                    # 0        (0 %)        mplslabel                   # 102      (0 %)RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources lpm location 0/0/CPU0HW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 87036        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 148      (0 %)        iproute                     # 5        (0 %)        ip6route                    # 117      (0 %)        ipmcroute                   # 50       (0 %)RP/0/RP0/CPU0#NCS5500-614#On scale line cards, only IPv4/32s are going to LEM. The rest (that includes our 500,000 IPv4/24s) will be pushed to the external TCAM#RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources lem location 0/6/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 127      (0 %)        iproute                     # 24       (0 %)        ip6route                    # 0        (0 %)        mplslabel                   # 102      (0 %)RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources lpm location 0/6/CPU0HW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 118638        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 144      (0 %)        iproute                     # 0        (0 %)        ip6route                    # 117      (0 %)        ipmcroute                   # 50       (0 %)RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources exttcamipv4 location 0/6/CPU0HW Resource Information    Name                            # ext_tcam_ipv4OOR Information    NPU-0        Estimated Max Entries       # 2048000        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 500010   (24 %)        iproute                     # 500010   (24 %)        ipmcroute                   # 0        (0 %)RP/0/RP0/CPU0#NCS5500-614#300k IPv4 /23 routesIn this third example, we announce 300,000 IPv4/23 prefixes.With the Host-optimized profiles on base line cards, they will be moved to the LPM.RP/0/RP0/CPU0#NCS5500-614#sh route sumRoute Source                     Routes     Backup     Deleted     Memory(bytes)connected                        6          1          0           1680local                            7          0          0           1680static                           2          0          0           480ospf 100                         0          0          0           0dagr                             0          0          0           0bgp 100                          300000     0          0           72000000Total                            300015     1          0           72003840RP/0/RP0/CPU0#NCS5500-614#sh route bgpB    110.0.0.0/23 [20/0] via 192.168.1.2, 00#18#17B    110.0.2.0/23 [20/0] via 192.168.1.2, 00#18#17B    110.0.4.0/23 [20/0] via 192.168.1.2, 00#18#17B    110.0.6.0/23 [20/0] via 192.168.1.2, 00#18#17B    110.0.8.0/23 [20/0] via 192.168.1.2, 00#18#17B    110.0.10.0/23 [20/0] via 192.168.1.2, 00#18#17B    110.0.12.0/23 [20/0] via 192.168.1.2, 00#18#17B    110.0.14.0/23 [20/0] via 192.168.1.2, 00#18#17B    110.0.16.0/23 [20/0] via 192.168.1.2, 00#18#17B    110.0.18.0/23 [20/0] via 192.168.1.2, 00#18#17^cRP/0/RP0/CPU0#NCS5500-614#sh route bgp | i /23 | utility wc -l300000RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources lem location 0/0/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 131      (0 %)        iproute                     # 29       (0 %)        ip6route                    # 0        (0 %)        mplslabel                   # 102      (0 %)RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources lpm location 0/0/CPU0HW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 261968        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # Red        OOR State Change Time       # 2017.Aug.04 06#59#54 UTCCurrent Usage    NPU-0        Total In-Use                # 261714   (100 %)        iproute                     # 261571   (100 %)        ip6route                    # 117      (0 %)        ipmcroute                   # 50       (0 %)RP/0/RP0/CPU0#NCS5500-614#Only 261k IPv4/23 prefixes out of the 300k were programmed. Then, we reached the max of the memory capacity (we removed the error messages reporting that extra entries have not been programmed in hardware because the LPM capacity was exceeded).Let\u2019s enable the Internet-optimized profile (and reload).This time, the 300,000 IPv4/23 will be split into two, creating 600,000 IPv4/24. And we will move them into LEM.Note# routes are not split into RIB/FIB but just when programmed into the hardware. That\u2019s why a show route will display 300,000 entries and the show contr npu resource will display 600,000.RP/0/RP0/CPU0#NCS5500-614#sh route bgp | i /23 | utility wc -l300000RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources lem location 0/0/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 600107   (76 %)        iproute                     # 600005   (76 %)        ip6route                    # 0        (0 %)        mplslabel                   # 102      (0 %)RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources lpm location 0/0/CPU0HW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 140729        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 171      (0 %)        iproute                     # 29       (0 %)        ip6route                    # 116      (0 %)        ipmcroute                   # 50       (0 %)RP/0/RP0/CPU0#NCS5500-614#The same example with scale line cards will not be dependant on the optimized profile activated, all the IPv4/23 routes will be stored in external TCAM#RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources lem location 0/6/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 127      (0 %)        iproute                     # 24       (0 %)        ip6route                    # 0        (0 %)        mplslabel                   # 102      (0 %)RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources lpm location 0/6/CPU0HW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 117819        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 143      (0 %)        iproute                     # 0        (0 %)        ip6route                    # 116      (0 %)        ipmcroute                   # 50       (0 %)RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources exttcamipv4 location 0/6/CPU0HW Resource Information    Name                            # ext_tcam_ipv4OOR Information    NPU-0        Estimated Max Entries       # 2048000        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 300010   (15 %)        iproute                     # 300010   (15 %)        ipmcroute                   # 0        (0 %)RP/0/RP0/CPU0#NCS5500-614#100k IPv4 /20 routesIn this last example, we announce 100,000 IPv4/20 prefixes.You got it, so no need to describe#  the host-optimized profile on base line cards where these 100k will be stored in LPM  the scale cards where these routes will be pushed to the external TCAMLet\u2019s focus on the behavior with base line cards running an Internet-optimized profile.We only advertise IPv4/20 routes and no overlapping routes, they will be all stored in LEM.RP/0/RP0/CPU0#NCS5500-614#sh bgp sum[...]Neighbor        Spk    AS MsgRcvd MsgSent   TblVer  InQ OutQ  Up/Down  St/PfxRcd10.11.12.1        0   100   13287    1466  4300005    0    0 13#11#23     100000RP/0/RP0/CPU0#NCS5500-614#sh route bgpB    3.0.0.0/20 [200/0] via 192.168.1.2, 10#05#09B    3.0.16.0/20 [200/0] via 192.168.1.2, 10#05#09B    3.0.32.0/20 [200/0] via 192.168.1.2, 10#05#09B    3.0.48.0/20 [200/0] via 192.168.1.2, 10#05#09B    3.0.64.0/20 [200/0] via 192.168.1.2, 10#05#09B    3.0.80.0/20 [200/0] via 192.168.1.2, 10#05#09B    3.0.96.0/20 [200/0] via 192.168.1.2, 10#05#09[...]RP/0/RP0/CPU0#NCS5500-614#sh route bgp | i /20 | utility wc -l100000RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources lem location 0/0/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # Green        Current Usage    NPU-0        Total In-Use                # 100002   (13 %)        iproute                     # 100002   (13 %)        ip6route                    # 0        (0 %)        mplslabel                   # 0        (0 %)        RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources lpm location 0/0/CPU0HW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 148883        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # Green        Current Usage    NPU-0        Total In-Use                # 153      (0 %)        iproute                     # 19       (0 %)        ip6route                    # 113      (0 %)        ipmcroute                   # 0        (0 %)        RP/0/RP0/CPU0#NCS5500-614#Now, we advertise 100,000 new IPv4/21 routes. All are overlapping the IPv4/20 we announced earlier. The IPv4/20 will no longer be stored in LEM but will be moved into LPM, for a total of 200,000 entries#RP/0/RP0/CPU0#NCS5500-614#sh bgp sumNeighbor        Spk    AS MsgRcvd MsgSent   TblVer  InQ OutQ  Up/Down  St/PfxRcd10.11.12.1        0   100   13901    1474  4600005    0    0 13#19#24     200000RP/0/RP0/CPU0#NCS5500-614#sh route bgpSat Aug  5 00#15#38.987 UTCB    3.0.0.0/20 [200/0] via 192.168.1.2, 00#00#02B    3.0.0.0/21 [200/0] via 192.168.1.2, 00#02#27B    3.0.16.0/20 [200/0] via 192.168.1.2, 00#00#02B    3.0.16.0/21 [200/0] via 192.168.1.2, 00#02#27B    3.0.32.0/20 [200/0] via 192.168.1.2, 00#00#02B    3.0.32.0/21 [200/0] via 192.168.1.2, 00#02#27B    3.0.48.0/20 [200/0] via 192.168.1.2, 00#00#02B    3.0.48.0/21 [200/0] via 192.168.1.2, 00#02#27B    3.0.64.0/20 [200/0] via 192.168.1.2, 00#00#02B    3.0.64.0/21 [200/0] via 192.168.1.2, 00#02#27B    3.0.80.0/20 [200/0] via 192.168.1.2, 00#00#02B    3.0.80.0/21 [200/0] via 192.168.1.2, 00#02#27B    3.0.96.0/20 [200/0] via 192.168.1.2, 00#00#02B    3.0.96.0/21 [200/0] via 192.168.1.2, 00#02#27[...]RP/0/RP0/CPU0#NCS5500-614#sh route bgp | i /20 | utility wc -l100000RP/0/RP0/CPU0#NCS5500-614#sh route bgp | i /21 | utility wc -l100000RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources lem location 0/0/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 2        (0 %)        iproute                     # 2        (0 %)        ip6route                    # 0        (0 %)        mplslabel                   # 0        (0 %)RP/0/RP0/CPU0#NCS5500-614#sh contr npu resources lpm location 0/0/CPU0HW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 539335        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 200153   (37 %)        iproute                     # 200019   (37 %)        ip6route                    # 113      (0 %)        ipmcroute                   # 0        (0 %)RP/0/RP0/CPU0#NCS5500-614#Real use-casesTo conclude, let\u2019s illustrate with real but anonymized use-cases.On a base system running IOS XR 6.2.2 with internet-optimized profile and a \u201csmall\u201d internet table.RP/0/RP0/CPU0#5501#show route sumRoute Source                     Routes     Backup     Deleted     Memory(bytes)connected                        2          3          0           1200         local                            5          0          0           1200         local LSPV                       1          0          0           240          static                           2          0          0           480          ospf 1                           677        2          0           163072       bgp xxxx                         615680     10         0           147765600    dagr                             0          0          0           0            Total                            616367     15         0           147931792    RP/0/RP0/CPU0#5501#show dpa resources iproute location 0/0/CPU0~iproute~ DPA Table (Id# 17, Scope# Global)--------------------------------------------------IPv4 Prefix len distribution Prefix   Actual       Prefix   Actual /0       1            /1       0            /2       0            /3       0            /4       1            /5       0            /6       0            /7       0            /8       15           /9       9            /10      35           /11      102          /12      277          /13      527          /14      955          /15      1703         /16      12966        /17      7325         /18      12874        /19      23469        /20      35743        /21      39283        /22      72797        /23      60852        /24      346773       /25      3            /26      19           /27      21           /28      17           /29      13           /30      229          /31      0            /32      368         [...]RP/0/RP0/CPU0#5501#show contr npu resources all location 0/0/CPU0 HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432          Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 498080   (63 %)        iproute                     # 507304   (65 %)        ip6route                    # 12818    (2 %)        mplslabel                   # 677      (0 %)HW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 510070          Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 192543   (38 %)        iproute                     # 176254   (35 %)        ip6route                    # 15583    (3 %)        ipmcroute                   # 0        (0 %)Same route distribution on a scale system running IOS XR 6.2.2#RP/0/RP0/CPU0#5501-SE#show route sum Route Source                     Routes     Backup     Deleted     Memory(bytes)connected                        4          3          0           1680         local                            7          0          0           1680         local LSPV                       1          0          0           240          static                           2          0          0           480          ospf 1                           677        2          0           163072       bgp xxxx                         615681     10         0           147765840    dagr                             0          0          0           0            Total                            616372     15         0           147932992     RP/0/RP0/CPU0#5501-SE#show dpa resources iproute location 0/0/CPU0 ~iproute~ DPA Table (Id# 17, Scope# Global)--------------------------------------------------IPv4 Prefix len distribution Prefix   Actual            Capacity    Prefix   Actual            Capacity  /0       1                 20           /1       0                 20           /2       0                 20           /3       0                 20           /4       1                 20           /5       0                 20           /6       0                 20           /7       0                 20           /8       15                20           /9       9                 20           /10      35                205          /11      102               409          /12      277               818          /13      527               1636         /14      955               3275         /15      1703              5731         /16      12966             42368        /17      7325              25379        /18      12874             42571        /19      23469             86576        /20      35743             127308       /21      39283             141634       /22      72797             231894       /23      60852             207107       /24      346773            1105235      /25      4                 4298         /26      19                4503         /27      21                3275         /28      17                2865         /29      13                6959         /30      231               2865         /31      0                 205          /32      376               20           [\u2026]RP/0/RP0/CPU0#5501-SE#show contr npu resources all location 0/0/CPU0 HW Resource Information    Name                            # lem OOR Information    NPU-0        Estimated Max Entries       # 786432          Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # Green Current Usage    NPU-0        Total In-Use                # 13887    (2 %)        iproute                     # 376      (0 %)        ip6route                    # 12827    (2 %)        mplslabel                   # 677      (0 %) HW Resource Information    Name                            # lpm OOR Information    NPU-0        Estimated Max Entries       # 551346          Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # Green Current Usage    NPU-0        Total In-Use                # 15612    (3 %)        iproute                     # 0        (0 %)        ip6route                    # 15589    (3 %)        ipmcroute                   # 0        (0 %) HW Resource Information    Name                            # ext_tcam_ipv4 OOR Information    NPU-0        Estimated Max Entries       # 2048000         Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # Green Current Usage    NPU-0        Total In-Use                # 616012   (30 %)        iproute                     # 616012   (30 %)        ipmcroute                   # 0        (0 %) Examples above show it\u2019s possible to store a full internet view in a base system.With a relatively small table of 616k routes, we have LEM used at approximatively 65%. But it\u2019s frequent to see larger internet tables (closer to 700k in August 2017), with many peering routes and internal routes. It still fits in but doesn\u2019t give much room for future growth.We advise to prefer scale line cards and systems for such use-cases.In the next episode, we will cover IPv6 prefixes. Stay tuned.", "url": "https://xrdocs.github.io/cloud-scale-networking/tutorials/2017-08-03-understanding-ncs5500-resources-s01e02/", "tags": "NCS5500, NCS 5500, LPM, LEM, eTCAM, XR, IOSXR, Memory", "title": "Understanding NCS5500 Resources (S01E02)", "author": "Nicolas Fevrier"}, "tutorials-2018-01-25-s01e05-large-routing-tables-on-scale-ncs-5500-systems": {"content": "     Understanding NCS5500 Resources  S01E05 Large Routing Tables on \u201cScale\u201d NCS 5500 Systems          Previously on \u201cUnderstanding NCS5500 Resources\u201d      The demo      CLI outputs        S01E05 Large Routing Tables on \u201cScale\u201d NCS 5500 SystemsPreviously on \u201cUnderstanding NCS5500 Resources\u201dIn previous posts, we presented#  the different routers and line cards in NCS5500 portfolio  we explained how IPv4 prefixes are sorted in LEM, LPM and eTCAM  we covered how IPv6 prefixes are stored in the same databases.  and finally we demonstrated in a video how we can handle a full IPv4 and IPv6 Internet view on base systems and line cards (i.e. without external TCAM, only using the LEM and LPM internal to the forwarding ASIC)Today, we are pushing the limits further. We will take a much larger existing (ie. real) routing table (internet + a very large number of host routes), we will add a projection of the internet table to year 2025 and we will see how it can fit in a Jericho-based system with External TCAMThe demoIn this YouTube video, we will#  describe the line cards and systems using Jericho / Qumran-MX forwarding ASICs with external TCAM (identified with the \u201c-SE\u201d at the end of the Product ID)  explain the different memories we can use to store the routes and what logic is used to decide where the different prefix types will go  run the demo          first with a real very large routing table of 1.2M IPv4 and 64k IPv6 routes  (the v4 table size comes from a full internet view, a large number of peering routes and 436k host routes)      then we will project ourself to 2025 and guesstimate how large the v4 and v6 public table will be      we will advertise these extra routes, see how the router absorbs them and how much free space we have left in the different memories      https#//www.youtube.com/watch?v=lVC3ppgi7akCLI outputsWe jump directly to the larger use-case# large internet table from 2025 with 436k IPv4 host routes.Such large number of host routes can be caused by DDoS mitigation systems (the /32s being used to divert the traffic targeted to specific victims) or by L3 VMs migration between domains.RP/0/RP0/CPU0#TME-5508-6.2.3#sh route sumRoute Source                     Routes     Backup     Deleted     Memory(bytes)local                            2          0          0           480connected                        2          0          0           480bgp 100                          1612272    0          0           386945280dagr                             0          0          0           0static                           0          0          0           0Total                            1612276    0          0           386946240RP/0/RP0/CPU0#TME-5508-6.2.3#sh route ipv6 un sumRoute Source                     Routes     Backup     Deleted     Memory(bytes)local                            2          0          0           528connected                        2          0          0           528connected l2tpv3_xconnect        0          0          0           0bgp 100                          108243     0          0           28576152static                           0          1          0           264Total                            108247     1          0           28577472RP/0/RP0/CPU0#TME-5508-6.2.3#sh dpa resources iproute loc 0/6/CPU0~iproute~ DPA Table (Id# 18, Scope# Global)--------------------------------------------------IPv4 Prefix len distributionPrefix   Actual            Capacity    Prefix   Actual            Capacity /0       1                 16           /1       0                 16 /2       0                 16           /3       0                 16 /4       1                 16           /5       0                 16 /6       0                 16           /7       0                 16 /8       16                16           /9       14                16 /10      37                163          /11      107               327 /12      288               654          /13      557               1309 /14      1071              2620         /15      1909              4585 /16      13572             33905        /17      8005              20309 /18      23343             34068        /19      38018             69283 /20      40443             101879       /21      45082             113343 /22      148685            185575       /23      116728            165738 /24      651486            884472       /25      2085              3439 /26      3362              3603         /27      5736              2620 /28      15909             2292         /29      17377             5568 /30      42507             2292         /31      112               163 /32      435847            16                          NPU ID# NPU-0           NPU-1           NPU-2           NPU-3                          In Use# 1612298         1612298         1612298         1612298                 Create Requests                           Total# 2285630         2285630         2285630         2285630                         Success# 2285630         2285630         2285630         2285630                 Delete Requests                           Total# 673332          673332          673332          673332                         Success# 673332          673332          673332          673332                 Update Requests                           Total# 2680653         2680653         2680653         2680653                         Success# 2680651         2680651         2680651         2680651                    EOD Requests                           Total# 0               0               0               0                         Success# 0               0               0               0                          Errors                     HW Failures# 0               0               0               0                Resolve Failures# 0               0               0               0                 No memory in DB# 0               0               0               0                 Not found in DB# 0               0               0               0                    Exists in DB# 0               0               0               0RP/0/RP0/CPU0#TME-5508-6.2.3#sh dpa resources ip6route loc 0/6/CPU0~ip6route~ DPA Table (Id# 19, Scope# Global)--------------------------------------------------IPv6 Prefix len distributionPrefix   Actual       Prefix   Actual /0       1            /1       0 /2       0            /3       0 /4       0            /5       0 /6       0            /7       0 /8       0            /9       0 /10      1            /11      0 /12      0            /13      0 /14      0            /15      0 /16      4            /17      0 /18      0            /19      2 /20      9            /21      3 /22      4            /23      4 /24      20           /25      6 /26      15           /27      17 /28      80           /29      2889 /30      189          /31      132 /32      10091        /33      684 /34      454          /35      423 /36      3738         /37      292 /38      686          /39      165 /40      7578         /41      219 /42      417          /43      129 /44      7899         /45      187 /46      1498         /47      376 /48      52338        /49      13 /50      12           /51      4 /52      16           /53      0 /54      1            /55      8 /56      11622        /57      16 /58      2            /59      0 /60      3            /61      0 /62      1            /63      0 /64      5152         /65      0 /66      0            /67      0 /68      0            /69      0 /70      0            /71      0 /72      0            /73      0 /74      0            /75      0 /76      0            /77      0 /78      0            /79      0 /80      0            /81      0 /82      0            /83      0 /84      0            /85      0 /86      0            /87      0 /88      0            /89      0 /90      0            /91      0 /92      0            /93      0 /94      0            /95      0 /96      1            /97      0 /98      0            /99      0 /100     0            /101     0 /102     0            /103     0 /104     1            /105     0 /106     0            /107     0 /108     0            /109     0 /110     0            /111     0 /112     0            /113     0 /114     0            /115     4 /116     0            /117     0 /118     0            /119     0 /120     0            /121     0 /122     71           /123     0 /124     15           /125     0 /126     24           /127     18 /128     731                          NPU ID# NPU-0           NPU-1           NPU-2           NPU-3                          In Use# 108265          108265          108265          108265                 Create Requests                           Total# 171646          171646          171646          171646                         Success# 171646          171646          171646          171646                 Delete Requests                           Total# 63381           63381           63381           63381                         Success# 63381           63381           63381           63381                 Update Requests                           Total# 4               4               4               4                         Success# 2               2               2               2                    EOD Requests                           Total# 0               0               0               0                         Success# 0               0               0               0                          Errors                     HW Failures# 0               0               0               0                Resolve Failures# 0               0               0               0                 No memory in DB# 0               0               0               0                 Not found in DB# 0               0               0               0                    Exists in DB# 0               0               0               0RP/0/RP0/CPU0#TME-5508-6.2.3#sh contr npu resources lem loc 0/6/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # Green    NPU-1        Estimated Max Entries       # 786432        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # Green    NPU-2        Estimated Max Entries       # 786432        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # Green    NPU-3        Estimated Max Entries       # 786432        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 488186   (62 %)        iproute                     # 435847   (55 %)        ip6route                    # 52338    (7 %)        mplslabel                   # 0        (0 %)    NPU-1        Total In-Use                # 488186   (62 %)        iproute                     # 435847   (55 %)        ip6route                    # 52338    (7 %)        mplslabel                   # 0        (0 %)    NPU-2        Total In-Use                # 488186   (62 %)        iproute                     # 435847   (55 %)        ip6route                    # 52338    (7 %)        mplslabel                   # 0        (0 %)    NPU-3        Total In-Use                # 488186   (62 %)        iproute                     # 435847   (55 %)        ip6route                    # 52338    (7 %)        mplslabel                   # 0        (0 %)RP/0/RP0/CPU0#TME-5508-6.2.3#sh contr npu resources lpm loc 0/6/CPU0HW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 486043        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # Green    NPU-1        Estimated Max Entries       # 486043        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # Green    NPU-2        Estimated Max Entries       # 486043        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # Green    NPU-3        Estimated Max Entries       # 486043        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 55950    (12 %)        iproute                     # 0        (0 %)        ip6route                    # 55927    (12 %)        ipmcroute                   # 0        (0 %)    NPU-1        Total In-Use                # 55950    (12 %)        iproute                     # 0        (0 %)        ip6route                    # 55927    (12 %)        ipmcroute                   # 0        (0 %)    NPU-2        Total In-Use                # 55950    (12 %)        iproute                     # 0        (0 %)        ip6route                    # 55927    (12 %)        ipmcroute                   # 0        (0 %)    NPU-3        Total In-Use                # 55950    (12 %)        iproute                     # 0        (0 %)        ip6route                    # 55927    (12 %)        ipmcroute                   # 0        (0 %)RP/0/RP0/CPU0#TME-5508-6.2.3#sh contr npu resources exttcamipv4 loc 0/6/CPU0HW Resource Information    Name                            # ext_tcam_ipv4OOR Information    NPU-0        Estimated Max Entries       # 1638400        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # Green    NPU-1        Estimated Max Entries       # 1638400        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # Green    NPU-2        Estimated Max Entries       # 1638400        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # Green    NPU-3        Estimated Max Entries       # 1638400        Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # 1176451  (72 %)        iproute                     # 1176451  (72 %)        ipmcroute                   # 0        (0 %)    NPU-1        Total In-Use                # 1176451  (72 %)        iproute                     # 1176451  (72 %)        ipmcroute                   # 0        (0 %)    NPU-2        Total In-Use                # 1176451  (72 %)        iproute                     # 1176451  (72 %)        ipmcroute                   # 0        (0 %)    NPU-3        Total In-Use                # 1176451  (72 %)        iproute                     # 1176451  (72 %)        ipmcroute                   # 0        (0 %)RP/0/RP0/CPU0#TME-5508-6.2.3#The 2025 internet estimation is described in the previous post. As mentioned in this post and in the video, the method is certainly a matter of debate. Let\u2019s take it for what it is# an estimation.In these use-cases with large public routing table and extreme amount of host routes, we are far from reaching the limits of the systems based on Jericho ASICs with External TCAMs.We are using 62% of LEM, 12% of LPM and 72% of eTCAM.All these counters can be streamed with telemetry. Example of visualization with Grafana#Important to understand that default carving in IOS XR 6.2.3 is allocating 20% for hybrid ACLs. This default behavior will change in releases 6.3.x onwards where we will allocate 100% of the space to IPv4 prefixes and it will be only when configuring hybrid ACLs that we will re-carve to allocation eTCAM space.We can verify the current carving status with the following#RP/0/RP0/CPU0#TME-5508-6.2.3#sh contr npu externaltcam loc 0/6/CPU0External TCAM Resource Information=============================================================NPU  Bank   Entry  Owner       Free     Per-DB  DB   DB     Id     Size               Entries  Entry   ID   Name=============================================================0    0      80b    FLP         461952   1176448  15   IPV4 DC0    1      80b    FLP         28672    0       76   INGRESS_IPV4_SRC_IP_EXT0    2      80b    FLP         28672    0       77   INGRESS_IPV4_DST_IP_EXT0    3      160b   FLP         26624    0       78   INGRESS_IPV6_SRC_IP_EXT0    4      160b   FLP         26624    0       79   INGRESS_IPV6_DST_IP_EXT0    5      80b    FLP         28672    0       80   INGRESS_IP_SRC_PORT_EXT0    6      80b    FLP         28672    0       81   INGRESS_IPV6_SRC_PORT_EXT1    0      80b    FLP         461952   1176448  15   IPV4 DC1    1      80b    FLP         28672    0       76   INGRESS_IPV4_SRC_IP_EXT1    2      80b    FLP         28672    0       77   INGRESS_IPV4_DST_IP_EXT1    3      160b   FLP         26624    0       78   INGRESS_IPV6_SRC_IP_EXT1    4      160b   FLP         26624    0       79   INGRESS_IPV6_DST_IP_EXT1    5      80b    FLP         28672    0       80   INGRESS_IP_SRC_PORT_EXT1    6      80b    FLP         28672    0       81   INGRESS_IPV6_SRC_PORT_EXT2    0      80b    FLP         461952   1176448  15   IPV4 DC2    1      80b    FLP         28672    0       76   INGRESS_IPV4_SRC_IP_EXT2    2      80b    FLP         28672    0       77   INGRESS_IPV4_DST_IP_EXT2    3      160b   FLP         26624    0       78   INGRESS_IPV6_SRC_IP_EXT2    4      160b   FLP         26624    0       79   INGRESS_IPV6_DST_IP_EXT2    5      80b    FLP         28672    0       80   INGRESS_IP_SRC_PORT_EXT2    6      80b    FLP         28672    0       81   INGRESS_IPV6_SRC_PORT_EXT3    0      80b    FLP         461952   1176448  15   IPV4 DC3    1      80b    FLP         28672    0       76   INGRESS_IPV4_SRC_IP_EXT3    2      80b    FLP         28672    0       77   INGRESS_IPV4_DST_IP_EXT3    3      160b   FLP         26624    0       78   INGRESS_IPV6_SRC_IP_EXT3    4      160b   FLP         26624    0       79   INGRESS_IPV6_DST_IP_EXT3    5      80b    FLP         28672    0       80   INGRESS_IP_SRC_PORT_EXT3    6      80b    FLP         28672    0       81   INGRESS_IPV6_SRC_PORT_EXTRP/0/RP0/CPU0#TME-5508-6.2.3#We have still 461952 routes left in the external TCAM.In a follow up post, we will detail the mechanisms available to mix base and scale line cards in the same chassis, and how your network needs to be designed for such requirements.", "url": "https://xrdocs.github.io/cloud-scale-networking/tutorials/2018-01-25-s01e05-large-routing-tables-on-scale-ncs-5500-systems/", "tags": "ncs 5500, ncs5500, demo, video, youtube, large scale, routing, lem, lpm, etcam, internet", "title": "S01E05 Large Routing Tables on &quot;Scale&quot; NCS 5500 Systems", "author": "Nicolas Fevrier"}, "tutorials-2016-07-09-pathchecker-iperf-netconf-for-ospf-path-failover": {"content": "     Launching a Container App  Introduction  Understand the topology  Pre-requisites  Clone the git repo  Spin up the devbox  Create the Pathchecker LXC tar ball          Launch an Ubuntu LXC inside devbox      Install Application dependencies inside LXC      Fetch the application code from Github      Change SSH port inside the container      Package up the LXC        Launch Router Topology  Test out pathchecker!          Check current OSPF cost/path state      Start iperf server on rtr2      Start pathchecker on rtr1 (LXC)      Create impairment on Active path      Verify the Failover was successful        IntroductionIf you haven\u2019t checked out the XR toolbox Series, then you can do so here#  XR Toolbox SeriesThis series is meant to help a beginner get started with application-hosting on IOS-XR.In this tutorial we intend to utilize almost all the techniques learnt in the above series to solve a path remediation problem#      Set up a couple of paths between two routers. Bring up OSPF neighborship on both links. One link is forced to be the reference link by increasing the ospf cost of the other link.        Use a monitoring technique to determine the bandwidth, jitter, packet loss etc. parameters along the active traffic path. In this example, we utilize a python app called pathchecker that in turn uses iperf to measure link health.        Simulate network degradation to force pathchecker (running inside an LXC) to initiate failover by changing the OSPF path cost over a netconf session.  This is illustrated below#Understand the topologyAs illustrated above, there are 3 nodes in the topology#      rtr1 # The router on the left. This is the origin of the traffic. We run the pathchecker code inside an ubuntu container on this router. The path failover happens rtr1 interfaces as needed.        devbox # This node serves two purposes. We use it to create our ubuntu LXC tar ball with the pathchecker code before deploying it to the router. It also houses two bridge networks (one for each path) so that we can create very granular impairment on each path to test our app.        rtr2 # This is the destination router. pathchecker uses an iperf client on rtr1 to get a health estimate of the active path. You need an iperf server running on rtr2 for the pathchecker app to talk to.  Pre-requisites      Make sure you have Vagrant and Virtualbox installed on your system.        The system must have 9-10G RAM available.        Go through the Vagrant quick-start tutorial, if you haven\u2019t already, to learn how to use Vagrant with IOS-XR#   IOS-XR vagrant quick-start        It would be beneficial for the user to go through the XR Toolbox Series. But it is not a hard requirement. Following the steps in this tutorial should work out just fine for this demo.  Once you have everything set up, you should be able to see the IOS-XRv vagrant box in the vagrant box list command#  AKSHSHAR-M-K0DS#~ akshshar$ vagrant box list  IOS-XRv (virtualbox, 0)  AKSHSHAR-M-K0DS#~ akshshar$ Clone the git repoThe entire environment can be replicated on any environment running vagrant provided around 9-10G RAM is available. The topology will include 2 IOS-XR routers (8G RAM) and an ubuntu instance (around 512 MB RAM).Clone the pathchecker code from here#  https#//github.com/ios-xr/pathcheckerAKSHSHAR-M-K0DS#~ akshshar$ git clone https#//github.com/ios-xr/pathchecker.git Cloning into 'pathchecker'...remote# Counting objects# 46, done.remote# Compressing objects# 100% (28/28), done.remote# Total 46 (delta 8), reused 0 (delta 0), pack-reused 18Unpacking objects# 100% (46/46), done.Checking connectivity... done.AKSHSHAR-M-K0DS#~ akshshar$ Spin up the devboxBefore we spin up the routers, we need to create the container tar ball for the pathchecker code. The way I\u2019ve set up the launch scripts for rtr1, the bringup will fail without the container tar ball in the directory.Move to the Vagrant directory and launch only the devbox node#AKSHSHAR-M-K0DS#~ akshshar$ cd pathchecker/AKSHSHAR-M-K0DS#pathchecker akshshar$ cd vagrant/AKSHSHAR-M-K0DS#vagrant akshshar$ pwd/Users/akshshar/pathchecker/vagrantAKSHSHAR-M-K0DS#vagrant akshshar$ vagrant up devbox Bringing machine 'devbox' up with 'virtualbox' provider...==&gt; devbox# Importing base box 'ubuntu/trusty64'...---------------------------- snip output ---------------------------------==&gt; devbox# Running provisioner# file...AKSHSHAR-M-K0DS#vagrant akshshar$ AKSHSHAR-M-K0DS#vagrant akshshar$ AKSHSHAR-M-K0DS#vagrant akshshar$ vagrant status Current machine states#rtr1                      not created (virtualbox)devbox                    running (virtualbox)rtr2                      not created (virtualbox)This environment represents multiple VMs. The VMs are all listedabove with their current state. For more information about a specificVM, run `vagrant status NAME`.AKSHSHAR-M-K0DS#vagrant akshshar$ Create the Pathchecker LXC tar ballLaunch an Ubuntu LXC inside devboxSSH into \u201cdevbox\u201d#vagrant ssh devboxCreate the pathchecker lxc template#vagrant@vagrant-ubuntu-trusty-64#~$  sudo lxc-create -t ubuntu --name pathchecker Checking cache download in /var/cache/lxc/trusty/rootfs-amd64 ... Installing packages in template# ssh,vim,language-pack-enDownloading ubuntu trusty minimal ...I# Retrieving Release I# Retrieving Release.gpg I# Checking Release signature------------------------------ snip output ------------------------------------Start the container. You will be dropped into the console once boot is complete.Username#  ubuntuPassword#  ubuntuvagrant@vagrant-ubuntu-trusty-64#~$ sudo lxc-start --name pathchecker &lt;4&gt;init# hostname main process (3) terminated with status 1&lt;4&gt;init# plymouth-upstart-bridge main process (5) terminated with status 1&lt;4&gt;init# plymouth-upstart-bridge main process ended, respawningUbuntu 14.04.4 LTS nc_iperf consolepathchecker login# ubuntuPassword#      Welcome to Ubuntu 14.04.4 LTS (GNU/Linux 3.13.0-87-generic x86_64) * Documentation#  https#//help.ubuntu.com/The programs included with the Ubuntu system are free software;the exact distribution terms for each program are described in theindividual files in /usr/share/doc/*/copyright.Ubuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted byapplicable law.ubuntu@pathchecker#~$ Install Application dependencies inside LXCInstall iperf and all the dependencies required to install ncclient inside the container. We\u2019ll also install git, will need it to fetch our app.sudo apt-get -y install python-pip python-lxml python-dev libffi-dev libssl-dev iperf gitInstall the latest ncclient code and jinja2 code using pip (required for our app). We also downgrade the cryptography package to 1.2.1 to circumvent a current bug in the package.sudo pip install ncclient jinja2 cryptography==1.2.1Perfect, all the dependencies for our app are now installed.Fetch the application code from GithubFetch our app from Github#ubuntu@pathchecker#~$ git clone https#//github.com/ios-xr/pathchecker.gitCloning into 'pathchecker'...remote# Counting objects# 46, done.remote# Compressing objects# 100% (28/28), done.remote# Total 46 (delta 8), reused 0 (delta 0), pack-reused 18Unpacking objects# 100% (46/46), done.Checking connectivity... done.ubuntu@pathchecker#~$ Change SSH port inside the containerWhen we deploy the container to IOS-XR, we will share XR\u2019s network namespace. Since IOS-XR already uses up port 22 and port 57722 for its own purposes, we need to pick some other port for our container.P.S. If you check the Vagrantfile, we intend to expose port 58822 to the user\u2019s laptop directly, on rtr1.Let\u2019s change the SSH port to 58822#ubuntu@pathchecker#~$ sudo sed -i s/Port\\ 22/Port\\ 58822/ /etc/ssh/sshd_config ubuntu@pathchecker#~$ Check that your port was updated successfully#ubuntu@pathchecker#~$ cat /etc/ssh/sshd_config | grep PortPort 58822ubuntu@pathchecker#~$ We\u2019re good!Package up the LXCNow, shutdown the container#ubuntu@pathchecker#~$ sudo shutdown -h now ubuntu@pathchecker#~$ Broadcast message from ubuntu@pathchecker\t(/dev/lxc/console) at 10#24 ...The system is going down for halt NOW!------------------------------ snip output ------------------------------------You\u2019re back on devbox.Become root and package up your container tar ballsudo -scd /var/lib/lxc/pathchecker/rootfs/tar -czvf /vagrant/pathchecker_rootfs.tar.gz *  See what we did there? We packaged up the container tar ball as pathchecker_rootfs.tar.gz under /vagrant directory. Why is this important?Well, Vagrant also automatically shares a certain directory with your laptop (for most types of guest operating systems). So the /vagrant is automatically mapped to the directory in which you launched your vagrant instance. To check this, let\u2019s get out of our vagrant instance and issue an ls in your launch directory#vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ exitlogoutConnection to 127.0.0.1 closed.AKSHSHAR-M-K0DS#vagrant akshshar$ AKSHSHAR-M-K0DS#vagrant akshshar$ pwd /Users/akshshar/pathchecker/vagrantAKSHSHAR-M-K0DS#vagrant akshshar$ ls -l pathchecker_rootfs.tar.gz  -rw-r--r--  1 akshshar  staff  301262995 Jul 18 07#57 pathchecker_rootfs.tar.gzAKSHSHAR-M-K0DS#vagrant akshshar$ Launch Router TopologyTo launch the two routers in the topology, make sure you are in the vagrant directory under pathchecker and issue a vagrant upAKSHSHAR-M-K0DS#vagrant akshshar$ pwd/Users/akshshar/pathchecker/vagrantAKSHSHAR-M-K0DS#vagrant akshshar$ AKSHSHAR-M-K0DS#vagrant akshshar$ vagrant upBringing machine 'rtr1' up with 'virtualbox' provider...Bringing machine 'devbox' up with 'virtualbox' provider...Bringing machine 'rtr2' up with 'virtualbox' provider...-------------------------------- snip output --------------------------------------Once everything is up, you should see the three nodes running#  AKSHSHAR-M-K0DS#vagrant akshshar$ vagrant statusCurrent machine states#rtr1                      running (virtualbox)devbox                    running (virtualbox)rtr2                      running (virtualbox)This environment represents multiple VMs. The VMs are all listedabove with their current state. For more information about a specificVM, run `vagrant status NAME`.We\u2019re all set! Let\u2019s test out our application.Test out pathchecker!Before we begin, let\u2019s dump some configuration outputs on rtr1#Check current OSPF cost/path stateAKSHSHAR-M-K0DS#vagrant akshshar$ vagrant port rtr1The forwarded ports for the machine are listed below. Please note thatthese values may differ from values configured in the Vagrantfile if theprovider supports automatic port collision detection and resolution.22 (guest) =&gt; 2223 (host) 57722 (guest) =&gt; 2200 (host) 58822 (guest) =&gt; 58822 (host)AKSHSHAR-M-K0DS#vagrant akshshar$ ssh -p 2223 vagrant@localhost The authenticity of host '[localhost]#2223 ([127.0.0.1]#2223)' can't be established.RSA key fingerprint is b1#c1#5e#a5#7e#e7#c0#4f#32#ef#85#f9#3d#27#36#0f.Are you sure you want to continue connecting (yes/no)? yesWarning# Permanently added '[localhost]#2223' (RSA) to the list of known hosts.vagrant@localhost's password# RP/0/RP0/CPU0#rtr1#RP/0/RP0/CPU0#rtr1#show  running-config  router ospf Mon Jul 18 15#25#53.875 UTCrouter ospf apphost area 0  interface Loopback0  !  interface GigabitEthernet0/0/0/0  !  interface GigabitEthernet0/0/0/1    cost 20  ! !!RP/0/RP0/CPU0#rtr1#show route 2.2.2.2 Mon Jul 18 15#26#03.576 UTCRouting entry for 2.2.2.2/32  Known via ~ospf apphost~, distance 110, metric 2, type intra area  Installed Jul 18 15#18#28.218 for 00#07#35  Routing Descriptor Blocks   10.1.1.20, from 2.2.2.2, via GigabitEthernet0/0/0/0      Route metric is 2  No advertising protos. RP/0/RP0/CPU0#rtr1#We can see that the current OSPF cost on Gig0/0/0/1 is 20, higher than Gig0/0/0/0. Hence as the route to 2.2.2.2 (loopback 0 of rtr2) shows, the current path selected is through Gig0/0/0/0Start iperf server on rtr2iperf was already installed on rtr2 as a native application (more on native apps here# XR toolbox part 5# Running a native WRL7 App) during the vagrant up process.Start iperf server on rtr2 and set it up to accept UDP packets#AKSHSHAR-M-K0DS#vagrant akshshar$ vagrant ssh rtr2 Last login# Mon Jul 18 15#57#05 2016 from 10.0.2.2xr-vm_node0_RP0_CPU0#~$ xr-vm_node0_RP0_CPU0#~$ iperf -s -u ------------------------------------------------------------Server listening on UDP port 5001Receiving 1470 byte datagramsUDP buffer size# 64.0 MByte (default)------------------------------------------------------------Start pathchecker on rtr1 (LXC)SSH into the pathchecker ubuntu container (already brought up as part of vagrant up process) by using port 58822 on your laptop#Password for user \u201cubuntu\u201d # ubuntuAKSHSHAR-M-K0DS#vagrant akshshar$ AKSHSHAR-M-K0DS#vagrant akshshar$ ssh -p 58822 ubuntu@localhostThe authenticity of host '[localhost]#58822 ([127.0.0.1]#58822)' can't be established.RSA key fingerprint is 19#54#83#a9#7a#9f#0a#18#62#d1#f3#91#87#3c#e9#0b.Are you sure you want to continue connecting (yes/no)? yesWarning# Permanently added '[localhost]#58822' (RSA) to the list of known hosts.ubuntu@localhost's password# Welcome to Ubuntu 14.04.4 LTS (GNU/Linux 3.14.23-WR7.0.0.2_standard x86_64) * Documentation#  https#//help.ubuntu.com/Last login# Mon Jul 18 15#19#45 2016 from 10.0.2.2ubuntu@pathchecker#~$ ubuntu@pathchecker#~$ ubuntu@pathchecker#~$ The pc_run.sh script simply runs the pathchecker.py application with a few sample parameters#ubuntu@pathchecker#~$ ubuntu@pathchecker#~$ cat ./pathchecker/pc_run.sh #!/bin/bash./pathchecker.py --host 6.6.6.6 -u vagrant -p vagrant --port 830 -c 10 -o apphost -a 0 -i GigabitEthernet0/0/0/0 -s 2.2.2.2  -j 4 -l 5 -f -t 10ubuntu@pathchecker#~$ Based on above output, the \u201c-l\u201d option represents the threshold for packet loss and has been set to 5% for this run. Similarly,  jitter has a threshold value of 4.Start the pathchecker app by running the pc_run.sh script in the pathchecker repository#ubuntu@pathchecker#~$ cd pathchecker/ ubuntu@pathchecker#~/pathchecker$ ./pc_run.sh Error while opening state file, let's assume low cost stateCurrently, on reference link GigabitEthernet0/0/0/0 Starting an iperf run.....20160718162513,1.1.1.1,62786,2.2.2.2,5001,6,0.0-10.0,1311240,104899220160718162513,1.1.1.1,62786,2.2.2.2,5001,6,0.0-10.0,1312710,104847420160718162513,2.2.2.2,5001,1.1.1.1,62786,6,0.0-10.0,1312710,1048679,2.453,0,892,0.000,1bw is1025.5546875jitter is2.453pkt_loss is0.000verdict isFalseCurrently, on reference link GigabitEthernet0/0/0/0Starting an iperf run.....Perfect! The App seems to be running fine on the reference link Gig0/0/0/0.Create impairment on Active pathWith the app running, let\u2019s scoot over to \u201cdevbox\u201d which will also act as our impairment node.AKSHSHAR-M-K0DS#vagrant akshshar$ vagrant ssh devbox Welcome to Ubuntu 14.04.4 LTS (GNU/Linux 3.13.0-87-generic x86_64) * Documentation#  https#//help.ubuntu.com/  System information as of Mon Jul 18 16#38#49 UTC 2016  System load#  0.0               Processes#             76  Usage of /#   6.3% of 39.34GB   Users logged in#       0  Memory usage# 32%               IP address for eth0#   10.0.2.15  Swap usage#   0%                IP address for lxcbr0# 10.0.3.1  Graph this data and manage this system at#    https#//landscape.canonical.com/  Get cloud support with Ubuntu Advantage Cloud Guest#    http#//www.ubuntu.com/business/services/cloudLast login# Mon Jul 18 16#38#50 2016 from 10.0.2.2vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ lsimpair_backup.sh  impair_reference.sh  stop_impair.shvagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ cat impair_reference.sh #!/bin/bashecho ~Stopping all current impairments~sudo tc qdisc del dev eth3 root &amp;&gt; /dev/nullsudo tc qdisc del dev eth4 root &amp;&gt; /dev/nullecho ~Starting packet loss on reference link~sudo tc qdisc add dev eth3 root netem loss 7% vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ ./impair_reference.shStopping all current impairmentsStarting packet loss on reference linkvagrant@vagrant-ubuntu-trusty-64#~$ As we can see, the reference impairment script creates a packet loss of 7% on the reference linkTake a look at the running pathchecker application on rtr1. It should switch to the backup link once it detects an increase in packet loss beyond 5% (as specified in the pc_run.sh file)#Currently, on reference link GigabitEthernet0/0/0/0Starting an iperf run.....20160718164745,1.1.1.1,60318,2.2.2.2,5001,6,0.0-10.0,1311240,104899220160718164745,1.1.1.1,60318,2.2.2.2,5001,6,0.0-10.0,1312710,104851620160718164745,2.2.2.2,5001,1.1.1.1,60318,6,0.0-573.0,1312710,18328,5.215,0,892,0.000,1bw is1025.5546875jitter is5.215pkt_loss is0.000verdict isTrueWoah! iperf run reported discrepancy, increase cost of reference link !Increasing cost of the reference link GigabitEthernet0/0/0/0Currently, on backup link Starting an iperf run.....20160718164755,1.1.1.1,61649,2.2.2.2,5001,6,0.0-10.0,1311240,104899220160718164755,1.1.1.1,61649,2.2.2.2,5001,6,0.0-10.0,1312710,104857720160718164755,2.2.2.2,5001,1.1.1.1,61649,6,0.0-583.3,1312710,18002,1.627,0,893,0.000,0bw is1025.5546875jitter is1.627pkt_loss is0.000verdict isFalseCurrently, on backup linkStarting an iperf run.....20160718164805,1.1.1.1,59343,2.2.2.2,5001,6,0.0-10.0,1311240,104899220160718164805,1.1.1.1,59343,2.2.2.2,5001,6,0.0-10.0,1312710,104852020160718164805,2.2.2.2,5001,1.1.1.1,59343,6,0.0-593.4,1312710,17697,2.038,0,893,0.000,0The app initiated the failover! Let\u2019s see how the router responded.Verify the Failover was successfulAKSHSHAR-M-K0DS#vagrant akshshar$ ssh -p 2223 vagrant@localhostvagrant@localhost's password# RP/0/RP0/CPU0#rtr1#RP/0/RP0/CPU0#rtr1#RP/0/RP0/CPU0#rtr1#show  running-config  router ospfMon Jul 18 17#50#47.851 UTCrouter ospf apphost area 0  interface Loopback0  !  interface GigabitEthernet0/0/0/0   cost 30  !  interface GigabitEthernet0/0/0/1   cost 20  ! !!RP/0/RP0/CPU0#rtr1#Great! The Cost of the Gig0/0/0/0 (reference) interface has been increased to 30, greater than the cost of Gig0/0/0/1. This forces the failover to happen to the Gig0/0/0/1 for the iperf traffic (or any traffic destined to rtr2).RP/0/RP0/CPU0#rtr1#show route 2.2.2.2Mon Jul 18 18#01#49.297 UTCRouting entry for 2.2.2.2/32  Known via ~ospf apphost~, distance 110, metric 21, type intra area  Installed Jul 18 16#47#45.705 for 01#14#03  Routing Descriptor Blocks  11.1.1.20, from 2.2.2.2, via GigabitEthernet0/0/0/1      Route metric is 21  No advertising protos. RP/0/RP0/CPU0#rtr1#It works! The failover happened and the next hop for 2.2.2.2 (loopback0 of rtr2) is now 11.1.1.20 through Gig0/0/0/1 (the backup link).We leave it upto the reader to try and impair the backup link now and see the App switch the path back to the reference interface.", "url": "https://xrdocs.github.io/application-hosting/tutorials/2016-07-09-pathchecker-iperf-netconf-for-ospf-path-failover/", "tags": "vagrant, iosxr, cisco, linux, iperf, ospf, netconf, pathchecker", "title": "Pathchecker:  iperf + netconf for OSPF path failover", "author": "Akshat Sharma"}, "tutorials-2016-10-13-using-model-driven-telemetry-mdt-for-if-mib-data": {"content": "     Using MDT for IF-MIB Data  Data from the IF-MIB          MDT Configuration for IF-MIB equivalence      OID-YANG Table        Data from the IF-MIBOne of the most commonly polled MIBs is the Interfaces MIB (IF-MIB).  Pretty much everyone needs to know how many packets and bytes were sent and received on a given interface.  So it\u2019s not surprising that one of the first questions we get is how to get the IF-MIB data from MDT.MDT Configuration for IF-MIB equivalenceAs you can see from the table below, most of the interface statistics are in the Cisco-IOS-XR-infra-statsd-oper.yang model, with some state parameters in Cisco-IOS-XR-infra-statsd-oper.yang, and a couple SNMP-specific values in Cisco-IOS-XR-snmp-agent-oper.yang.Leaving aside the SNMP-specific parameters, here is what the sensor-path configuration in MDT would look like for the IF-MIB#RP/0/RP0/CPU0#SunC(config)#telemetry model-drivenRP/0/RP0/CPU0#SunC(config-model-driven)#sensor-group SGroup1RP/0/RP0/CPU0#SunC(config-model-driven-snsr-grp)# sensor-path Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-countersRP/0/RP0/CPU0#SunC(config-model-driven-snsr-grp)# sensor-path Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interfaceRP/0/RP0/CPU0#SunC(config-model-driven-snsr-grp)# commitFor the complete MDT configuration, see my configuration tutorial.With that, you should be streaming all your favorite IF-MIB data at a fraction of the cost of doing an SNMP poll.OID-YANG TableBelow is a table of the most commonly requested IF-MIB OIDs, their corresponding YANG models, containers, leafs and any usage notes.            OID      Yang-Path      YANG Leaf      Notes                  ifAlias      Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface      description      \u00a0              ifHCInBroadcastPkts      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters      broadcast-packets-received      \u00a0              ifHCInMulticastPkts      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters      multicast-packets-received      \u00a0              ifHCInUcastPkts      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters      N/A      Must be calculated# packets-received - multicast-packets-received - broadcast-packets-received              ifHCOutBroadcastPkts      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters      broadcast-packets-sent      \u00a0              ifHCOutMulticastPkts      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters      multicast-packets-sent      \u00a0              ifHCOutUcastPkts      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters      N/A      Must be calculated# packets-sent - multicast-packets-sent - broadcast-packets-sent              ifIndex      Cisco-IOS-XR-snmp-agent-oper#snmp/interface-indexes/      if-index      \u00a0              ifLastChange      Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface      last-state-transition-time      last-state-transition-time is the elapsed time since last state change while ifLastChange is the sysUpTime value of the last state change              ifOutDiscards      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters      output-drops      \u00a0              ifOutErrors      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters      output-errors      \u00a0              ifStackStatus      Cisco-IOS-XR-snmp-agent-oper/snmp/      if-stack-status      \u00a0              ifAdminStatus      Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface      state      \u00a0              ifDescr      Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface      interface-name      \u00a0              ifHCInOctets      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters      bytes-received      \u00a0              ifHCOutOctets      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters      bytes-sent      \u00a0              ifHighSpeed      Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface      speed      ifHighSpeed is in Mbps, speed is in kbps              ifInErrors      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters      input-errors      \u00a0              ifOperStatus      Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface      state      \u00a0              ifPhysAddress      Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface      address      \u00a0              ifType      Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface      interface-type      \u00a0              ifInDiscards      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters      input-drops      \u00a0              ifInOctets      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters      bytes-received      \u00a0              ifMtu      Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface      mtu      \u00a0              ifName      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters      interface-name      interface-name format is \u201cHundredGigE0_3_0_0\u201d              ifOutOctets      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters      bytes-sent      \u00a0              ifSpeed      Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface      bandwidth      \u00a0      ", "url": "https://xrdocs.github.io/telemetry/tutorials/2016-10-13-using-model-driven-telemetry-mdt-for-if-mib-data/", "tags": "iosxr", "title": "Using Model-Driven Telemetry (MDT) for IF-MIB Data", "author": "Shelly Cadora"}, "tutorials-2017-08-02-understanding-ncs5500-resources-s01e01": {"content": "     Understanding NCS5500 Resources  S01E01 The Platforms  NCS5500 Portfolio          Using external TCAM      Not using external TCAM        Resources / Memories  S01E01 The PlatformsIn the marketing datasheet, you probably read that NCS5501-SE supports up to 2.7M+ routes or that NCS5502 support up to 1.1M routes. It\u2019s true, but it\u2019s actually a bit more complex since it will not be 2.7M of any kind of routes. So, how many routes can I actually use ? Well, it depends\u2026This series of posts aim at explaining in detail how NCS5500 routers use the different memory resources available for each type of features or prefixes. But we will go further than just discussing \u201chow many routes\u201d and we will try to identify how other data types (Next-hop, load balancing information, ACL entries, \u2026) are affecting the scale.Today, we will start describing the hardware implementation then we will explain how \u201cdatabases\u201d are used, which profiles can be enabled and how they can be monitored and troubleshot.NCS5500 PortfolioRouters in the NCS5500 portfolio offer diverse form-factors. Some are fixed (1RU, 2RU), others are modular (4-slot, 8-slot, 16-slot) with multiple line cards types.In August 2017, with one exception covered in a follow-up xrdocs post, we are leveraging Qumran-MX or Jericho forwarding ASICs (FA). Qumran is used for System-on-Chip (SoC) routers like NCS5501 and NCS5501-SE, all other systems are using several Jerichos interconnected via Fabric Engines.Update# In December 2017, Jericho+ systems are available in line cards (36x 100G with NG eTCAM) and in fixed formed 1RU (36x 100G with or without NG eTCAM, 24x 100G with a larger internal memory). They will be described in follow-up posts.We can categorize these systems and line cards in two families#Using external TCAM(named \u201cScale\u201d and identified with -SE in the product ID)  NCS5501-SE  NCS5502-SE  NC55-24X100G-SE  NC55-24H12F-SERP/0/RP0/CPU0#Router#sh platform | i XR RUN0/RP0/CPU0        NCS-5501-SE(Active)        IOS XR RUN        NSHUTRP/0/RP0/CPU0#Router#RP/0/RP0/CPU0#Router#sh plat | i XR RUN0/6/CPU0          NC55-24H12F-SE             IOS XR RUN        NSHUT0/7/CPU0          NC55-24X100G-SE            IOS XR RUN        NSHUT0/RP0/CPU0        NC55-RP(Active)            IOS XR RUN        NSHUT0/RP1/CPU0        NC55-RP(Standby)           IOS XR RUN        NSHUTRP/0/RP0/CPU0#Router#Not using external TCAMonly the memories inside the FA (named \u201cBase\u201d)  NCS5501  NCS5502  NC55-36X100G  NC55-18H18F  NC55-36x100G-S (MACsec card)  NC55-6X200-DWDM-S (Coherent card)RP/0/RP0/CPU0#Router#show platform | i XR RUN0/RP0/CPU0        NCS-5501(Active)           IOS XR RUN        NSHUTRP/0/RP0/CPU0#Router#RP/0/RP0/CPU0#Router#sh platform | i XR RUN0/0/CPU0          NC55-36X100G               IOS XR RUN        NSHUT0/1/CPU0          NC55-18H18F                IOS XR RUN        NSHUT0/RP0/CPU0        NC55-RP(Active)            IOS XR RUN        NSHUT0/RP1/CPU0        NC55-RP(Standby)           IOS XR RUN        NSHUTRP/0/RP0/CPU0#Router#Note# Inside a modular chassis, we can mix and match eTCAM and non-eTCAM line cards. A feature is available to decide where the prefixes should be programmed (differentiating IGP and BGP, and using specific ext-communities).So basically, this external memory used to extend the scale in terms of routes and classifiers (Access-list entries for instance) is what differentiates the systems and line cards. eTCAM should not be confused with the 4GB external packet buffer which is present on the side of each FA, regardless the type of system or line card. The eTCAM only handles prefixes and ACEs, not packets. The external packet buffer will be used in case of queue congestion only. It\u2019s a very rapid graphical memory, specifically used for packets.If you are familiar with traditional IOS XR routers, there are some similarities and some differences with the classification of line cards \u201c-SE vs -TR\u201d on ASR9000, or \u201c-FP vs -MSC vs -LSP\u201d on CRS routers#  route and feature scales can be different among the different types of LC  but not the number of queues or the capability to support Hierarchical QoS (it\u2019s not the case for NCS5500 routers, QoS capability is the same on -SE and non-SE)We have two eTCAM blocks per FA offering up to 2M additional routes and they are soldered to the board. It\u2019s not a field-replaceable part. This means you can not convert a NC55-36X100G non-eTCAM card into an eTCAM card.Resources / MemoriesEach forwarding ASIC is made of two cores (0 and 1). Also we have an ingress and an egress pipeline. Each pipeline itself is made of different blocks. For clarity and intellectual property reasons, we will simplify the description and represent the series of blocks as just a Packet Processor (PP) and a Traffic Manager (TM).Along the pipeline, the different blocks can access (read or write) different \u201cdatabases\u201d.They are memory entities used to store specific type of information.In follow up posts, we will describe in detail how they are used, but let\u2019s introduce them right now.  The Longest Prefix Match Database (LPM sometimes referred to as KAPS for KBP Assisted Prefix Search, KBP being itself Knowledge Based Processor) is an SRAM used to store IPv4 and IPv6 prefixes. It\u2019s an algorithmic memory qualified for 256k entries IPv4 and 128k entries IPv6 in the worst case. We will see it can go much higher with internet distribution.  The Large Exact Match Database (LEM) is used to store IPv4 and IPv6 routes also, plus MAC addresses and MPLS labels. It scales to 786k entries.  The Internal TCAM (iTCAM) is used for Packet classification (ACL, QoS) and is 48k entries large.  The FEC database is used to store NextHop (128k entries), containing also the FEC ECMP (4k entries).  Egress Encapsulation DB (EEDB) is used for egress rewrites (96k entries), including adjacency encapsulation like link-local details from ARP, ND and for MPLS labels or GRE headers.All these databases are present inside the Forwarding ASIC.  The external TCAMs (eTCAM) are only present in the -SE line cards and systems and, as the name implies, are not a resource inside the Forwarding ASIC. They are used to extend unicast route and ACL / classifiers scale (up to 2M IPv4 entries).RP/0/RP0/CPU0#NCS5501-622#show contr npu resources all location 0/0/CPU0HW Resource Information    Name                            # lemOOR Information    NPU-0        Estimated Max Entries       # 786432          Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # XXXXX    (X %)        iproute                     # XXXXX    (X %)        ip6route                    # XXXXX    (X %)        mplslabel                   # XXXXX    (X %)HW Resource Information    Name                            # lpmOOR Information    NPU-0        Estimated Max Entries       # 351346          Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # XXXXX    (X %)        iproute                     # XXXXX    (X %)        ip6route                    # XXXXX    (X %)        ipmcroute                   # XXXXX    (X %)HW Resource Information    Name                            # encapOOR Information    NPU-0        Estimated Max Entries       # 100000          Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # XXX      (X %)        ipnh                        # XXX      (X %)        ip6nh                       # XXX      (X %)        mplsnh                      # XXX      (X %)HW Resource Information    Name                            # ext_tcam_ipv4OOR Information    NPU-0        Estimated Max Entries       # 2048000         Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # XXXXXX   (X %)        iproute                     # XXXXXX   (X %)        ipmcroute                   # XXXXX    (X %)HW Resource Information    Name                            # ext_tcam_ipv6_shortOOR Information    NPU-0        Estimated Max Entries       # 0               Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # XXXXX    (X %)        ip6route                    # XXXXX    (X %)HW Resource Information    Name                            # ext_tcam_ipv6_longOOR Information    NPU-0        Estimated Max Entries       # 0               Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # XXXXX    (X %)        ip6route                    # XXXXX    (X %)HW Resource Information    Name                            # fecOOR Information    NPU-0        Estimated Max Entries       # 126976          Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # XXXX     (X %)        ipnhgroup                   # XXXX     (X %)        ip6nhgroup                  # XXXX     (X %)HW Resource Information    Name                            # ecmp_fecOOR Information    NPU-0        Estimated Max Entries       # 4096            Red Threshold               # 95 %        Yellow Threshold            # 80 %        OOR State                   # GreenCurrent Usage    NPU-0        Total In-Use                # XXXXX    (X %)        ipnhgroup                   # XXXXX    (X %)        ip6nhgroup                  # XXXXX    (X %)RP/0/RP0/CPU0#NCS5501-622#Depending on the address family (IPv4 or IPv6), but also depending on the prefix subnet length, routes will be sorted and stored in LEM, LPM or eTCAM. Route handling will depend on the platform type, the IOS XR release running and the profile activated. That\u2019s what we will cover in the next episode", "url": "https://xrdocs.github.io/cloud-scale-networking/tutorials/2017-08-02-understanding-ncs5500-resources-s01e01/", "tags": "NCS5500, NCS 5500, LPM, LEM, eTCAM", "title": "Understanding NCS5500 Resources (S01E01)", "author": "Nicolas Fevrier"}, "blogs-2017-01-20-model-driven-telemetry-dial-in-or-dial-out": {"content": "     Dial-In or Dial-Out?  Transport Options  Dial-Out Vs. Dial-In  TCP Dial-Out  gRPC Dial-Out  gRPC Dial-In  Decisions, Decisions  Transport OptionsIn one of my first tutorials on configuring Model-Driven Telemetry (MDT), I blithely referred to three options for transport# TCP dial-out, gRPC dial-out and gRPC dial-in.  It\u2019s all well and good to know how to configure each one, but what\u2019s the difference and which one should you choose?  This blog tackles those questions.Dial-Out Vs. Dial-InWhen we say \u201cdial-out,\u201d we are speaking from the router\u2019s perspective# the router \u201cdials out\u201d to the collector.  In other words, the router sends the SYN packet in the TCP handshake.Anyone who has had to modify ACLs to enable a new SNMP manager to connect to the network can appreciate the value of the dial-out option.  Since the router initiates the connection, you don\u2019t have to worry about opening up ports for inbound management traffic.  Dial-out can also leverage Anycast addresses for HA and/or load-balancing.With dial-in, on the other hand, the router listens passively on a specified port until the collector \u201cdials-in.\u201dAfter the initial session establishment, the router still pushes the data off the box at the configured interval.  This is very important!  Don\u2019t be fooled by the direction of the SYN packet.  There is no polling mechanism in MDT.Dial-in appeals to folks who are looking for a \u201csingle channel\u201d to communicate with the network.  These are operators who want a single transport and protocol for both configuration data and streaming operational data. Sound impossible?  Well, we\u2019re already doing it today.TCP Dial-OutOur first dial-out protocol was also the simplest# plain old TCP.  Open up a raw TCP socket on your collector and the router will complete the standard three-way handshake and start pushing telemetry data across the session.  No fancy programming libraries are required on the collector \u2013 in python it\u2019s a simple matter of a \u201cbind\u201d to the port.  TCP dial-out inherits all the goodness of TCP (reliable delivery, fragmentation, re-ordering, etc) without having to invent a new protocol or define new mechanisms.  It\u2019s a great place to start if you\u2019re configuring MDT for the first time.gRPC Dial-OutOne of TCP\u2019s great strengths is its simplicity.  But TCP by itself lacks higher-level functions that can enable more secure and sophisticated communication between the router and the collector.  For that, we turned to gRPC.gRPC is an open source communication framework built on top of HTTP/2.  It was originally designed by Google to enable efficient, accurate and low-latency communication between clients and servers.  It has many functions beyond those required by MDT.One of the main reasons that people enable gRPC dial-out is that gRPC allows you to do authentication and encryption via TLS.  If you\u2019re worried about sending operational data in the clear and/or you want to protect your collector with certificate-based authentication, enable gRPC with TLS.Another bonus is that gRPC handles pesky details around async communications and the associated file descriptor handling. So you might actually find it easier to use than TCP as you scale to multiple routers.gRPC is not quite as trivial from a protocol perspective, but one of its strengths is the plethora of idiomatic client libraries in multiple programming languages.  Go, Python, Ruby, Java, C developers \u2013 grab your gRPC library from github and you\u2019ll be juggling gRPC sessions like a pro.gRPC Dial-InIn addition to secure and efficient transport, gRPC provides bidirectional streaming and connection multiplexing.  This means that you can \u201cdial-in\u201d to a router, push down new configs (including telemetry subscription configs) and have operational data streamed back \u2013 all within a single, unified channel, all using the same underlying data models.  Cisco IOS XR has supported configuration via gRPC since 6.0.0 and dial-in telemetry over gRPC since 6.1.1.Since the collector \u201cdials-in\u201d to the router, there\u2019s no need to specify each MDT destination in the configuration.  Just enable the gRPC service on the router, connect your client, and dynamically enable the telemetry subscription you want.Of course, like all the other methods, there are trade-offs. A dial-in subscription is transient.  If you lose it, the client (the collector) is responsible for re-establishing it.  You will also have to think more carefully about how you want to do load-balancing.Decisions, DecisionsSo what transport should you use for MDT?  Here\u2019s a few quick heuristics#  If you\u2019re looking for a quick and simple solution for a single router and collector, try TCP dial-out.  It\u2019s simple to configure, there are no new protocols to learn, and you won\u2019t have to worry about opening up inbound connections.  If you need encryption or you need help scaling out to many devices, take a look at gRPC dial-out.  If you\u2019re already using gRPC for configuration, consider gRPC dial-in.As you deploy MDT, you may find that your transport needs change or evolve.  No problem.  The most important thing to remember is that the push mechanism for telemetry data remains exactly the same, dial-in or dial-out, TCP or gRPC.  No matter what you choose, you\u2019ll get the same data, in the same data model, at the same speed.  That\u2019s the beauty of Model-Driven Telemetry.", "url": "https://xrdocs.github.io/telemetry/blogs/2017-01-20-model-driven-telemetry-dial-in-or-dial-out/", "tags": "cisco, MDT, telemetry", "title": "Model-Driven Telemetry: Dial-In or Dial-Out ?", "author": "Shelly Cadora"}, "tutorials-2017-08-03-introduction-to-the-wan-automation-engine-wae-design-user-interface": {"content": "     On This Page  Overview  Navigation of the WAE Design User Interface          Property Tables\u00a0      The Network Plot\u00a0      The Visualization Toolbar      Layouts and the Plot Options Menu      Simulation and Identifying the Simulation Mode        Conclusion  OverviewWAE Design is a planning tool for design, engineering, and capacity planning of IP/MPLS networks. This tutorial will examine some key features of the WAE Design user interface.  Note#      When WAE collects from the network, the output of the collection process is a network model which is often referred to as a plan file. The network model is then used by WAE applications such as WAE Design.    The network model used in this tutorial is from the WAE Design samples directory# us_wan_l1.txt    If you don\u2019t have the WAE Design application, see the tutorial Using dCloud to Access the WAN Automation Engine Demos.    If using dCloud, use the US East datacenter and launch the demo for \u201cWAE Live\u201d. The WAE Design application will be on the workstation desktop.  Navigation of the WAE Design User InterfaceThis section describes how to navigate the WAE Design user interface.Property Tables\u00a0Property Tables display collected and simulated information of objects in the network model. Select a row in a table and right-click to open a context menu. Common tasks usually involve opening the Properties menu at the top to edit information about the object, deleting or duplicating the object or filtering to related objects.Note# In WAE when looking at an interface, the traffic and utilization values are referring to egress traffic and utilization of the interface. There are many tables and columns that are not shown by default. Tables can easily be shown or hidden as needed by right-clicking on any table header and selecting Show/Hide Tables. Each table also has a large set of display columns which can also be shown or hidden by right-clicking the column header and selecting Show/Hide Columns.Advanced filter features allow the user to pinpoint specific objects in a table using the Filter button. In addition, objects can easily be sorted by clicking on the column header. Summary statistics for each column can be obtained by right-clicking on the column header.\u00a0The Network Plot\u00a0The Network Plot shows a visual representation of the network topology and interface utilizations.Most of the visualization options are selectable in the Visualization Toolbar directly above the Network Plot.Typically, nodes can be grouped into user defined Sites. Sites can also be grouped in user defined Parent Sites. Note that the node/site/parent site mapping is not layout specific, it applies for all layouts. Layouts are described in more detail later. If you right-click on an object in the plot, you will open the objects\u2019 context menu. However, if you right-click an empty area of the plot as shown on the right, you will open the plot context menu which provides options such as menus for creating new objects, recovering simulated failures, a copy plot feature that copies an image of the current plot to the clipboard, an Arrange menu for aligning elements in the plot and a shortcut to bring up the Plot Options menu.Warning! WAE Design does not have \u201cUndo\u201d or \u201cRedo\u201d capabilities. If you move nodes/sites or accidently delete an object from the model, you cannot go back. It is recommended that you frequently save the plan file.The Visualization ToolbarMost of the important aspects of the Visualization Toolbar are shown from left to right in the following animated gif.  L3/L1 toggle button enables quick transition from the DWDM L1 topology to the L3 topology.  The Traffic View selection can display the difference between the measured and simulated utilizations of the network. The Worst Case and Failure Impact views are populated using the Simulation Analysis tool described in another tutorial.  There are buttons to zoom, drag and fit the network plot.  In large networks, the various circuits can network can look complicated. You can select objects and set the opacity of the background objects to make a selection stand out.  The Arrange menu can also be launched which provides options for arranging sites and nodes.  The colors on the links represent the utilization value. These color thresholds can be configured.Layouts and the Plot Options MenuIn the properties menu for Sites and Nodes, there are schematic (X, Y) and geographic (longitude and latitude) coordinates. This determines the positon of these elements on the Network Plot. You can click and drag a node or site to change its position or use the Arrange menu to align and position the nodes or sites.  Note#      The geographic coordinates as well as node/site/parent site mappings apply to all layouts    There is no \u201cundo\u201d functionality  Layouts are used to present different views of the network. The layout drop-down allows you to quickly change between the defined layouts. Layouts can be created, modified, duplicated or deleted using the Edit Layouts option.A layout has a PlotLayoutType that can either be \u2018Design\u2019 or \u2018Weathermap\u2019. The difference is Weathermap layouts allow you to click and drag to bend circuits for clarity.The Plot Options menu enables custom settings that are applied to the current selected layout. The Plot Options menu is accessed by right clicking an empty area of the network plot and selecting \u201cPlot Options\u201d. The following examples from the Plot Options menu can be applied to a layout.            Plot Options Tab      Options                  General Options      Schematic vs Geographic# Schematic layouts use the X,Y positioning. Geographic will use the longitude and latitude positioning using either an outline or detailed background map.              Design Colors      Set the utilization threshold colors that appear in the plot              Design Circuits      Set the width of the circuits. Apply text such as name, IGP metric, IP address, utilization percentage. Group parallel circuits              Layer 1      Set the width of the L1 Links. Apply text such as name, number of L1 circuit paths, distance or delay. Show L1 waypoints and utilizations. Show the layer 1 topology in the background of the layer 3 topology and show the layer 3 topology in the background of the L1 view.      Simulation and Identifying the Simulation ModeWhen making changes to the plan file, you may not want to have WAE Design resimulate the network after every change. If you want to make multiple changes to the network and resimulate at a later time, uncheck the Auto resimulate button. When you are finished making all the changes select the Play button when you want to run a simulation.When running a simulation, it\u2019s important to understand what simulation mode you are currently in. (Simulation modes will be described in another tutorial). The current simulation mode is shown at the bottom of the WAE Design application below the Property Tables.ConclusionThis tutorial covered the basics of the WAE Design user interface. Please check out our other tutorials to explore additional features and capabilities of WAE.", "url": "https://xrdocs.github.io/automation/tutorials/2017-08-03-introduction-to-the-wan-automation-engine-wae-design-user-interface/", "tags": "cisco, WAE, Automation, Design, Capacity Planning", "title": "Introduction to the WAN Automation Engine (WAE) Design User Interface", "author": "Josh Peters"}, "techdocs-techdocs-placeholder": {"content": "Techdocs Placeholder", "url": "https://xrdocs.github.io/application-hosting/techdocs/techdocs_placeholder/", "title": "Techdocs_placeholder", "tags": ""}, "blogs-2018-05-01-anatomy-of-a-network-app-xr-auditor": {"content": "     On This Page  Introduction  User Story  IOS-XR architecture          Enter xr-auditor        The Build Environment  Building the Application  Transferring the app to the router  Running the auditor app          Dump Auditor Version      Install the App      List generated XML files      Deconstructing the XML content      Uninstall the app      Verbose Debugging      Troubleshooting#  Gathering logs        Support for Active/Standby RP systems  IntroductionThis application enables periodic auditing of the linux shells in the IOS-XR container-based architecture by running individual python applications in each individual environment in IOS-XR (across Active-Standby HA systems), i.e.#    \u00a0      XR-LXC    ADMIN-LXC    HOST  \u00a0   Functionally, the individual python applications#  \u00a0      Collect local data based on a YAML based user-config provided during the build process    Store accummulated data in the form of XML that is strictly validated against a user-defined XML schema.    Send the accummulated XML data periodically to an external server over SSH where it may be easily processed and visualized using any tools that can consume the XML schema and the data.  \u00a0  Further, the application supports#     \u00a0      Installation# on a High-Availability (Active/Standby RP) system through a single command.    A clean uninstallation  across the entire system through a single command.    Troubleshooting#   Dump filesystem view - The ability to view the entire system\u2019s affected (user-defined in YAML file) system across active/standby RPs using a single command.    Troubleshooting#   Gather debug Data - The ability to collect generated logs from all the environments (Active/Standby XR LXC, Admin LXC, HOST) and create a single tar ball using a single command.  \u00a0    No SMUs needed, leverages the native app-hosting architecture in IOS-XR and the internal SSH-based access between different parts of the IOS-XR architecture - namely, XR-LXC, Admin-LXC and HOST of the active and/or Standby RPs to easily manage movement of data, logs and apps across the system.\u00a0The complete code can be found here#  https#//github.com/akshshar/xr-auditorUser Story(Click to Expand)\u00a0  \u00a0  \u00a0IOS-XR architectureFor a quick refresher on the IOS-XR container based architecture, see the figure below#  \u00a0  \u00a0 .\u00a0  \u00a0IOS-XR AAA support vs LinuxAs shown above, access to the linux shells (in blue inside the containers) and the underlying shells is protected through XR AAA authentication and authorization.IOS-XR AAA also supports accounting which sends logs to a remote TACACS/RADIUS server to log what an authenticated and authorized user is upto on the XR interface.While IOS-XR supports the 3 A\u2019s of AAA (Authentication, Authorization and Accounting),  Linux supports only 2 of them# Authentication and authorization.Usually accounting is handled through separate tools such as auditd, snoopy etc. We showcase the usage of snoopy with IOS-XR here#  https#//github.com/akshshar/snoopy-xrIOS-XR Telemetry support vs LinuxSimilarly, IOS-XR also supports sending structured operational data (modeled using Yang models) over transports such as gRPC, TCP and UDP to external receivers that can process the data - You can learn more about IOS-XR telemetry here#  https#//xrdocs.github.io/telemetry/Further, Linux doesn\u2019t really have a telemetry system by default - there are variety of solutions available that can provide structured data for various individual applications and files on the system, but none of them support a clean one step installation, collection and troubleshooting capabilities across container based architecture as shown above.Enter xr-auditorThis is where xr-auditor shines. It allows a user to specify their collection requirements through YAML files, build the application into single binary and deploy the auditors in each domain(container) of the system in a couple of steps.xr-auditor is installed using a single binary generated out of the code in this git repo using pyinstaller. More details below. The installation involves running the binary on the XR-LXC shell of the Active RP#\u00a0  \u00a0 .\u00a0  \u00a0Once the install is triggered, individual cron jobs and apps are set up in the different domains as shown below to start sending collected data periodically to a remote server (identified in the SERVER_CONFIG in userfiles/auditor.cfg.yml) securely over SSH#\u00a0  \u00a0\u00a0  \u00a0The Build EnvironmentAll you need to build the application is a linux environment with python 2.7 installed.To make things simpler, there is a vagrant setup already included with the code. We will use the vagrant setup to build and test our application against IOS-XRv64 on our laptops before we run it on physical hardware (NCS5500)#The vagrant setup looks something like this#  If you\u2019re not familiar with vagrant and associated workflows I would suggest first going through the following tutorials on xrdocs before continuing (these tutorials will also show how to gain access to the IOS-XR vagrant box if you don\u2019t already have it)#      XR toolbox, Part 1 # IOS-XR Vagrant Quick Start    XR Toolbox, Part 2 # Bootstrap XR configuration with Vagrant    XR Toolbox, Part 3 # App Development Topology .  \u00a0  \u00a0Building the Application\u00a0  \u00a0      Step 1# Clone the xr-auditor git repo#    AKSHSHAR-M-33WP# akshshar$ git clone https#//github.com/akshshar/xr-auditor.gitCloning into 'xr-auditor'...remote# Counting objects# 502, done.remote# Compressing objects# 100% (23/23), done.remote# Total 502 (delta 12), reused 4 (delta 1), pack-reused 478Receiving objects# 100% (502/502), 8.92 MiB | 4.19 MiB/s, done.Resolving deltas# 100% (317/317), done.AKSHSHAR-M-33WP# akshshar$ AKSHSHAR-M-33WP# akshshar$ cd xr-auditor/AKSHSHAR-M-33WP#xr-auditor akshshar$ lsREADME.md\t\tcleanup.sh\t\tcron\t\t\trequirements.txt\tuserfilesbuild_app.sh\t\tcore\t\t\timages\t\t\tspecs\t\t\tvagrantAKSHSHAR-M-33WP#xr-auditor akshshar$       \u00a0  \u00a0      Step 2# Drop into the vagrant directory and spin up the vagrant topology (shown above)#          Note#  Make sure you\u2019ve gone through the tutorial#  XR toolbox, Part 1 # IOS-XR Vagrant Quick Start and already have the IOS-XRv vagrant box on your system#      AKSHSHAR-M-33WP#~ akshshar$ vagrant box listIOS-XRv            (virtualbox, 0)AKSHSHAR-M-33WP#~ akshshar$               Now, in the vagrant directory, issue a vagrant up#     AKSHSHAR-M-33WP#vagrant akshshar$ vagrant up Bringing machine 'rtr' up with 'virtualbox' provider... Bringing machine 'devbox' up with 'virtualbox' provider... ==&gt; rtr# Importing base box 'IOS-XRv'... ==&gt; rtr# Matching MAC address for NAT networking... ==&gt; rtr# Setting the name of the VM# vagrant_rtr_1525415374584_85170 ==&gt; rtr# Clearing any previously set network interfaces... ==&gt; rtr# Preparing network interfaces based on configuration...     rtr# Adapter 1# nat     rtr# Adapter 2# intnet ==&gt; rtr# Forwarding ports...     rtr# 57722 (guest) =&gt; 2222 (host) (adapter 1)     rtr# 22 (guest) =&gt; 2223 (host) (adapter 1) ==&gt; rtr# Running 'pre-boot' VM customizations... ==&gt; rtr# Booting VM...             .......             devbox# Removing insecure key from the guest if it's present... devbox# Key inserted! Disconnecting and reconnecting using new SSH key...  ==&gt; devbox# Machine booted and ready! ==&gt; devbox# Checking for guest additions in VM... ==&gt; devbox# Configuring and enabling network interfaces... ==&gt; devbox# Mounting shared folders...     devbox# /vagrant =&gt; /Users/akshshar/xr-auditor/vagrant         ==&gt; rtr# Machine 'rtr' has a post `vagrant up` message. This is a message ==&gt; rtr# from the creator of the Vagrantfile, and not from Vagrant itself# ==&gt; rtr#  ==&gt; rtr#  ==&gt; rtr#     Welcome to the IOS XRv (64-bit) VirtualBox. ==&gt; rtr#     To connect to the XR Linux shell, use# 'vagrant ssh'. ==&gt; rtr#     To ssh to the XR Console, use# 'vagrant port' (vagrant version &gt; 1.8) ==&gt; rtr#     to determine the port that maps to guestport 22, ==&gt; rtr#     then# 'ssh vagrant@localhost -p &lt;forwarded port&gt;' ==&gt; rtr#  ==&gt; rtr#     IMPORTANT#  READ CAREFULLY ==&gt; rtr#     The Software is subject to and governed by the terms and conditions ==&gt; rtr#     of the End User License Agreement and the Supplemental End User ==&gt; rtr#     License Agreement accompanying the product, made available at the ==&gt; rtr#     time of your order, or posted on the Cisco website at ==&gt; rtr#     www.cisco.com/go/terms (collectively, the 'Agreement'). ==&gt; rtr#     As set forth more fully in the Agreement, use of the Software is ==&gt; rtr#     strictly limited to internal use in a non-production environment ==&gt; rtr#     solely for demonstration and evaluation purposes. Downloading, ==&gt; rtr#     installing, or using the Software constitutes acceptance of the ==&gt; rtr#     Agreement, and you are binding yourself and the business entity ==&gt; rtr#     that you represent to the Agreement. If you do not agree to all ==&gt; rtr#     of the terms of the Agreement, then Cisco is unwilling to license ==&gt; rtr#     the Software to you and (a) you may not download, install or use the ==&gt; rtr#     Software, and (b) you may return the Software as more fully set forth ==&gt; rtr#     in the Agreement. AKSHSHAR-M-33WP#vagrant akshshar$         Once you see the above message, the devices should have booted up. You can check the status using vagrant status     AKSHSHAR-M-33WP#vagrant akshshar$ vagrant status Current machine states# rtr                       running (virtualbox) devbox                    running (virtualbox) This environment represents multiple VMs. The VMs are all listed above with their current state. For more information about a specific VM, run `vagrant status NAME`. AKSHSHAR-M-33WP#vagrant akshshar$           \u00a0  \u00a0      Step 3#  Note down the ports used for SSH (port 22) by the rtr and by devbox#    AKSHSHAR-M-33WP#vagrant akshshar$ vagrant port rtrThe forwarded ports for the machine are listed below. Please note thatthese values may differ from values configured in the Vagrantfile if theprovider supports automatic port collision detection and resolution.     22 (guest) =&gt; 2223 (host)  57722 (guest) =&gt; 2222 (host)AKSHSHAR-M-33WP#vagrant akshshar$ AKSHSHAR-M-33WP#vagrant akshshar$ AKSHSHAR-M-33WP#vagrant akshshar$ vagrant port devboxThe forwarded ports for the machine are listed below. Please note thatthese values may differ from values configured in the Vagrantfile if theprovider supports automatic port collision detection and resolution.     22 (guest) =&gt; 2200 (host) AKSHSHAR-M-33WP#vagrant akshshar$  AKSHSHAR-M-33WP#vagrant akshshar$       \u00a0  \u00a0      Step 4#  SSH into the vagrant box (either by using vagrant ssh devbox or by using the port discovered above (2200 for devbox)# ssh -p 2200 vagrant@localhost)#          Password is vagrant        AKSHSHAR-M-33WP#vagrant akshshar$ ssh -p 2200 vagrant@localhostvagrant@localhost's password# Welcome to Ubuntu 16.04.4 LTS (GNU/Linux 4.4.0-87-generic x86_64)* Documentation#  https#//help.ubuntu.com* Management#     https#//landscape.canonical.com* Support#        https#//ubuntu.com/advantage0 packages can be updated.0 updates are security updates.    Last login# Fri May  4 10#41#50 2018 from 10.0.2.2vagrant@vagrant#~$ vagrant@vagrant#~$             \u00a0    Now again clone the xr-auditor app so that you have the application code available for build inside the devbox environment#    vagrant@vagrant#~$ git clone https#//github.com/akshshar/xr-auditor.gitCloning into 'xr-auditor'...remote# Counting objects# 390, done.remote# Compressing objects# 100% (185/185), done.remote# Total 390 (delta 252), reused 333 (delta 195), pack-reused 0Receiving objects# 100% (390/390), 7.56 MiB | 3.51 MiB/s, done.Resolving deltas# 100% (252/252), done.Checking connectivity... done.vagrant@vagrant#~$ cd xr-auditor/vagrant@vagrant#~/xr-auditor$           \u00a0  \u00a0      Step 5#   Create a new ssh-key pair for your devbox environment (if you see see the earlier image), the devbox will serve as the remote server to which the router sends the collected XML data.          For password-less operation, the way we make this work is#                        Create an ssh-key pair on the server (devbox) .                          Add the public key of the pair to the devbox (server)\u2019s  ~/.ssh/authorized_keys file .                          Package the private key as part of the app during the build process and transfer to the router .                    The app on the router then uses the private key to ssh and transfer files to the server (devbox) without requiring a password.        Following the above steps on devbox#                  Create the ssh-key pair#        vagrant@vagrant#~/xr-auditor$ ssh-keygen -t rsaGenerating public/private rsa key pair.Enter file in which to save the key (/home/vagrant/.ssh/id_rsa)# Enter passphrase (empty for no passphrase)# Enter same passphrase again# Your identification has been saved in /home/vagrant/.ssh/id_rsa.Your public key has been saved in /home/vagrant/.ssh/id_rsa.pub.The key fingerprint is#SHA256#nUQqNANDpVUjwJLZ+7LrFY4go/y+yBcc+ProRqYejF8 vagrant@vagrantThe key's randomart image is#+---[RSA 2048]----+|   *=+B.o .      ||  + o= + +       ||  ..... . .      || . ..  . o .     ||o + ... S o      ||== =.o..         ||*+. Eoo          ||o+=o..           ||+*=*+.           |+----[SHA256]-----+vagrant@vagrant#~/xr-auditor$                             Add the public key to authorized_keys#        vagrant@vagrant#~/xr-auditor$ vagrant@vagrant#~/xr-auditor$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys vagrant@vagrant#~/xr-auditor$                             Copy the private key to the folder userfiles/ in the xr-auditor directory#        vagrant@vagrant#~/xr-auditor$ vagrant@vagrant#~/xr-auditor$ cp ~/.ssh/id_rsa userfiles/id_rsa_server vagrant@vagrant#~/xr-auditor$                 \u00a0  \u00a0                  Step 6#  Edit the appropriate settings in the userfiles/auditor.cfg.yml file to match the environment you are building for. This file encapsulates information about the router, the server to which the data will be sent, the installation directories for the app and the compliance data that the app must collect. Follow the instructions specified in the yml file to fill everything out#            Step 7#  Now you\u2019re all ready to build the app. Eventually a single binary will be created as part of the build process  and this app will be called auditor.    This app internally will consist of the following file structure#    auditor  |  |--- userfiles  |          |  |          |---  audit.cfg.yml  |          |   |          |---  compliance.xsd  |          |  |          |---  id_rsa_server  |  |  |--- xr  |    |  |    |--- audit_xr.bin  |    |         |  |    |         |--- userfiles  |    |         |        |  |    |         |        |--- audit.cfg.yml  |    |         |        |  |    |         |        |--- compliance.xsd  |    |         |        |  |    |         |        |--- id_rsa_server  |    |         |  |    |         |  |    |         |--- audit_xr.py  |    |   |    |--- audit_xr.cron  |      |  |  |--- admin  |    |  |    |--- audit_admin.bin  |    |         |  |    |         |--- userfiles  |    |         |        |  |    |         |        |--- audit.cfg.yml  |    |         |        |  |    |         |        |--- compliance.xsd  |    |         |        |  |    |         |        |--- id_rsa_server  |    |         |  |    |         |  |    |         |--- audit_admin.py  |    |   |    |--- audit_admin.cron  |      |  |  |--- host  |    |  |    |--- audit_host.bin  |    |         |  |    |         |--- userfiles  |    |         |        |  |    |         |        |--- audit.cfg.yml  |    |         |        |  |    |         |        |--- compliance.xsd  |    |         |        |  |    |         |        |--- id_rsa_server  |    |         |  |    |         |  |    |         |--- audit_host.py  |    |   |    |--- audit_host.cron  |      |--- collector  |    |  |    |---collector.bin  |    |         |  |    |         |--- userfiles  |    |         |        |  |    |         |        |--- audit.cfg.yml  |    |         |        |  |    |         |        |--- compliance.xsd  |    |         |        |  |    |         |        |--- id_rsa_server  |    |         |  |    |         |  |    |         |--- collector.py  |    |   |    |--- collector.cron  |                 To build the app, at the root of the git repo, issue the following command#  (The build_app.sh shell script will automatically install the required dependencies, including pyinstaller, inside the devbox)      vagrant@vagrant#~/xr-auditor$   vagrant@vagrant#~/xr-auditor$ sudo -E ./build_app.sh        +++ which ./build_app.sh  ++ dirname ./build_app.sh  + SCRIPT_PATH=.  + apt-get install -y git python-pip  Reading package lists... Done  Building dependency tree         Reading state information... Done  git is already the newest version (1#2.7.4-0ubuntu1.3).  python-pip is already the newest version (8.1.1-2ubuntu0.4).  0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.  + cd .  + echo       + [[ '' == '' ]]  + pip install --upgrade pip==9.0.3    ....       + pyinstaller ./specs/xr.spec  20 INFO# PyInstaller# 3.3.1  20 INFO# Python# 2.7.12  21 INFO# Platform# Linux-4.4.0-87-generic-x86_64-with-Ubuntu-16.04-xenial  25 INFO# UPX is not available.  26 INFO# Extending PYTHONPATH with paths  ['/home/vagrant/xr-auditor/core', '/home/cisco/audit_xr_linux/specs']  26 INFO# checking Analysis  30 INFO# Appending 'datas' from .spec  31 INFO# checking PYZ  34 INFO# checking PKG  34 INFO# Bootloader /usr/local/lib/python2.7/dist-packages/PyInstaller/bootloader/Linux-64bit/run  35 INFO# checking EXE  + pyinstaller ./specs/admin.spec  20 INFO# PyInstaller# 3.3.1  21 INFO# Python# 2.7.12  21 INFO# Platform# Linux-4.4.0-87-generic-x86_64-with-Ubuntu-16.04-xenial  24 INFO# UPX is not available.  26 INFO# Extending PYTHONPATH with paths  ['/home/vagrant/xr-auditor/core', '/home/cisco/audit_xr_linux/specs']  26 INFO# checking Analysis  30 INFO# Appending 'datas' from .spec  30 INFO# checking PYZ  33 INFO# checking PKG  33 INFO# Bootloader /usr/local/lib/python2.7/dist-packages/PyInstaller/bootloader/Linux-64bit/run  34 INFO# checking EXE  + pyinstaller ./specs/host.spec  20 INFO# PyInstaller# 3.3.1  20 INFO# Python# 2.7.12  21 INFO# Platform# Linux-4.4.0-87-generic-x86_64-with-Ubuntu-16.04-xenial  24 INFO# UPX is not available.  25 INFO# Extending PYTHONPATH with paths  ['/home/vagrant/xr-auditor/core', '/home/cisco/audit_xr_linux/specs']  25 INFO# checking Analysis       .....           67 INFO# running Analysis out00-Analysis.toc 81 INFO# Caching module hooks...   83 INFO# Analyzing core/auditor.py 1855 INFO# Processing pre-safe import module hook   _xmlplus 1996 INFO# Processing pre-find module path hook   distutils 2168 INFO# Loading module hooks...  2169 INFO# Loading module hook ~hook-distutils.py~... 2170 INFO# Loading module hook ~hook-xml.py~... 2171 INFO# Loading module hook ~hook-lxml.etree.py~... 2178 INFO# Loading module hook ~hook-httplib.py~... 2179 INFO# Loading module hook ~hook-encodings.py~... 2500 INFO# Looking for ctypes DLLs 2557 INFO# Analyzing run-time hooks ... 2563 INFO# Looking for dynamic libraries 2702 INFO# Looking for eggs 2702 INFO# Python library not in binary dependencies. Doing additional searching... 2722 INFO# Using Python library /usr/lib/x86_64-linux-gnu/libpython2.7.so.1.0 2724 INFO# Warnings written to /home/vagrant/xr-auditor/build/auditor/warnauditor.txt 2736 INFO# Graph cross-reference written to /home/vagrant/xr-auditor/build/auditor/xref-auditor.html 2771 INFO# Appending 'datas' from .spec 2773 INFO# checking PYZ 2776 INFO# checking PKG 2776 INFO# Building because /home/vagrant/xr-auditor/core/auditor.py changed 2777 INFO# Building PKG (CArchive) out00-PKG.pkg 6099 INFO# Building PKG (CArchive) out00-PKG.pkg completed successfully. 6110 INFO# Bootloader /usr/local/lib/python2.7/dist-packages/PyInstaller/bootloader/Linux-64bit/run 6111 INFO# checking EXE 6113 INFO# Rebuilding out00-EXE.toc because pkg is more recent 6114 INFO# Building EXE from out00-EXE.toc 6119 INFO# Appending archive to ELF section in EXE /home/vagrant/xr-auditor/dist/auditor 6172 INFO# Building EXE from out00-EXE.toc completed successfully. vagrant@vagrant#~/xr-auditor$        At the end of the build, you will see the auditor binary appear inside a dist/ directory at the root of the git repo#    vagrant@vagrant#~/xr-auditor$ ls -lrt dist/total 61672-rwxr-xr-x 1 root root  7046744 May  4 10#43 audit_xr.bin-rwxr-xr-x 1 root root  7046848 May  4 10#43 audit_admin.bin-rwxr-xr-x 1 root root  7046616 May  4 10#43 audit_host.bin-rwxr-xr-x 1 root root  7049952 May  4 10#43 collector.bin-rwxr-xr-x 1 root root 34949880 May  4 10#49 auditorvagrant@vagrant#~/xr-auditor$       Transferring the app to the routerYou will need the ssh credentials for your IOS-XR router to transfer the generated app to its /misc/scratch directory (also called disk0#.  In our vagrant setup, the credentials are vagrant/vagrant.Note, 2223 is the port used by the vagrant IOS-XRv instance for its SSH session (See vagrant port output from earlier)vagrant@vagrant#~/xr-auditor$ scp -P 2223 dist/auditor vagrant@10.0.2.2#/misc/scratch/vagrant@10.0.2.2's password# auditor  Running the auditor appYou can easily run the following steps over SSH itself (in fact Ansible Playbooks will be used for this purpose, explained in the /ansible directory README.For now, let\u2019s jump into the router and manually try out the options available#  ssh is triggered from your laptop or the host on which vagrant is runningAKSHSHAR-M-33WP#vagrant akshshar$ AKSHSHAR-M-33WP#vagrant akshshar$ ssh -p 2223 vagrant@localhostvagrant@localhost's password# RP/0/RP0/CPU0#rtr#RP/0/RP0/CPU0#rtr#RP/0/RP0/CPU0#rtr#RP/0/RP0/CPU0#rtr#View the options availableJump into the bash shell in the IOS-XRv instance and use the -h option for the auditor app#RP/0/RP0/CPU0#rtr#RP/0/RP0/CPU0#rtr#RP/0/RP0/CPU0#rtr#bashFri May  4 15#28#45.654 UTC[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$xr-vm_node0_RP0_CPU0#~]$/misc/scratch/auditor -husage# auditor [-h] [-v] [-i] [-u] [-c] [-l] [-o TARFILE_OUTPUT_DIR] [-d]optional arguments#  -h, --help            show this help message and exit  -v, --version         Display Current version of the Auditor app and exit  -i, --install         Install the required artifacts (audit apps, collectors                        and cron jobs) to default locations or to those                        specified in auditor.cfg.yml  -u, --uninstall       Uninstall all the artifacts from the system based on                        auditor.cfg.yml settings  -c, --clean-xml       Remove old XML files from the system  -l, --list-files      List all the audit related files (apps, cron jobs, xml                        files) currently on the system  -o TARFILE_OUTPUT_DIR, --output-logs-to-dir TARFILE_OUTPUT_DIR                        Specify the directory to use to collect the collated                        logs from all nodes on the system  -d, --debug           Enable verbose logging[xr-vm_node0_RP0_CPU0#~]$Dump Auditor VersionUse the -v option#RP/0/RP0/CPU0#rtr#RP/0/RP0/CPU0#rtr#bashFri May  4 15#25#52.977 UTC[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$/misc/scratch/auditor -vv1.0.0[xr-vm_node0_RP0_CPU0#~]$Install the AppUse the -i option to install the apps and cron jobs#[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$/misc/scratch/auditor -i2018-05-04 15#26#37,536 - DebugZTPLogger - INFO - Using root-lr user specified in auditor.cfg.yml, Username# vagrant2018-05-04 15#26#37,545 - DebugZTPLogger - INFO - XR LXC audit app successfully copied2018-05-04 15#26#37,550 - DebugZTPLogger - INFO - XR LXC audit cron job successfully set up2018-05-04 15#26#40,012 - DebugZTPLogger - INFO - Admin LXC audit app successfully copied2018-05-04 15#26#42,791 - DebugZTPLogger - INFO - Admin LXC audit cron file successfully copied and activated2018-05-04 15#26#46,506 - DebugZTPLogger - INFO - HOST audit app successfully copied2018-05-04 15#26#50,851 - DebugZTPLogger - INFO - Host audit cron file successfully copied and activated2018-05-04 15#26#50,863 - DebugZTPLogger - INFO - Collector app successfully copied2018-05-04 15#26#50,868 - DebugZTPLogger - INFO - Collector cron job successfully set up in XR LXC2018-05-04 15#26#50,868 - DebugZTPLogger - INFO - Successfully set up artifacts, IOS-XR Linux auditing is now ON[xr-vm_node0_RP0_CPU0#~]$The locations where the apps are installed and where the XML files get dumped are all defined in userfiles/auditor.cfg.yml. View the INSTALL_CONFIG section of the yml file#These locations are used by the auditor app to install the audit_xr.bin, collector.bin, audit_host.bin and audit_admin.bin apps in the right directory and by the individual apps to determine where to generate and store the XML outputs.The cron jobs get installed in /etc/cron.d of each location (XR, admin, host).Use the -l option with the auditor app to dump the current state of all the relevant filesystems across active and standby RPs,  as defined by the userfiles/auditor.cfg.yml file #[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$/misc/scratch/auditor -l2018-05-04 16#03#28,841 - DebugZTPLogger - INFO - Using root-lr user specified in auditor.cfg.yml, Username# vagrant2018-05-04 16#03#28,841 - DebugZTPLogger - INFO - ####################################################                       ACTIVE-RP XR                #####################################################2018-05-04 16#03#28,841 - DebugZTPLogger - INFO - ###### App Directory ######2018-05-04 16#03#28,846 - DebugZTPLogger - INFO -  /misc/scratch#total 48172drwxr-xr-x 2 root root     4096 Apr 24  2017 corelrwxrwxrwx 1 root root       12 Apr 24  2017 config -&gt; /misc/configdrwx------ 2 root root     4096 Apr 24  2017 clihistorydrwxr-xr-x 2 root root     4096 Apr 24  2017 crypto-rw-r--r-- 1 root root     1549 May  4 06#32 status_filedrwxr-xr-x 8 root root     4096 May  4 06#32 ztpdrwxr-xr-x 2 root root     4096 May  4 07#27 nvgen_traces-rwxr-xr-x 1 root root 34949880 May  4 10#49 auditor-rw-r--r-- 1 root root      798 May  4 10#50 auditor_collated_logs.tar.gz-rwx------ 1 root root  7049952 May  4 15#26 collector.bin-rwx------ 1 root root  7046744 May  4 15#26 audit_xr.bin-rwx------ 1 root root     1675 May  4 16#03 id_rsa-rw-r--r-- 1 root root   240786 May  4 16#03 tpa.log2018-05-04 16#03#28,846 - DebugZTPLogger - INFO - ###### Cron directory ######2018-05-04 16#03#28,851 - DebugZTPLogger - INFO -  /etc/cron.d#total 12-rw-r--r-- 1 root root 73 Apr 24  2017 logrotate.conf-rw-r--r-- 1 root root 86 May  4 15#26 audit_cron_xr_2018-05-04_15-26-37-rw-r--r-- 1 root root 87 May  4 15#26 audit_cron_collector_2018-05-04_15-26-502018-05-04 16#03#28,851 - DebugZTPLogger - INFO - ###### XML Output Directory ######2018-05-04 16#03#28,855 - DebugZTPLogger - INFO -  /misc/app_host#total 84drwx------ 2 root root 16384 Apr 24  2017 lost+founddrwxr-xr-x 5 root root  4096 Apr 24  2017 etcdrwxrwxr-x 2 root sudo  4096 Apr 24  2017 scratchdrwx-----x 9 root root  4096 Apr 24  2017 dockerdrwxr-xr-x 5 root root  4096 Apr 24  2017 app_reposrw-rw---- 1 root root     0 May  4 06#31 docker.sock-rw-r--r-- 1 root root  8111 May  4 16#03 HOST.xml-rw-r--r-- 1 root root  7908 May  4 16#03 ADMIN-LXC.xml-rw-r--r-- 1 root root 23798 May  4 16#03 compliance_audit_rtr_11_1_1_10.xml-rw-r--r-- 1 root root  8264 May  4 16#03 XR-LXC.xml2018-05-04 16#03#28,855 - DebugZTPLogger - INFO - ####################################################                       ACTIVE-RP COLLECTOR                #####################################################2018-05-04 16#03#28,856 - DebugZTPLogger - INFO - ###### App Directory ######2018-05-04 16#03#28,860 - DebugZTPLogger - INFO -  /misc/scratch#total 48172drwxr-xr-x 2 root root     4096 Apr 24  2017 corelrwxrwxrwx 1 root root       12 Apr 24  2017 config -&gt; /misc/configdrwx------ 2 root root     4096 Apr 24  2017 clihistorydrwxr-xr-x 2 root root     4096 Apr 24  2017 crypto-rw-r--r-- 1 root root     1549 May  4 06#32 status_filedrwxr-xr-x 8 root root     4096 May  4 06#32 ztpdrwxr-xr-x 2 root root     4096 May  4 07#27 nvgen_traces-rwxr-xr-x 1 root root 34949880 May  4 10#49 auditor-rw-r--r-- 1 root root      798 May  4 10#50 auditor_collated_logs.tar.gz-rwx------ 1 root root  7049952 May  4 15#26 collector.bin-rwx------ 1 root root  7046744 May  4 15#26 audit_xr.bin-rwx------ 1 root root     1675 May  4 16#03 id_rsa-rw-r--r-- 1 root root   240786 May  4 16#03 tpa.log2018-05-04 16#03#28,860 - DebugZTPLogger - INFO - ###### Cron directory ######2018-05-04 16#03#28,866 - DebugZTPLogger - INFO -  /etc/cron.d#total 12-rw-r--r-- 1 root root 73 Apr 24  2017 logrotate.conf-rw-r--r-- 1 root root 86 May  4 15#26 audit_cron_xr_2018-05-04_15-26-37-rw-r--r-- 1 root root 87 May  4 15#26 audit_cron_collector_2018-05-04_15-26-502018-05-04 16#03#28,866 - DebugZTPLogger - INFO - ###### XML Output Directory ######2018-05-04 16#03#28,872 - DebugZTPLogger - INFO -  /misc/app_host#total 84drwx------ 2 root root 16384 Apr 24  2017 lost+founddrwxr-xr-x 5 root root  4096 Apr 24  2017 etcdrwxrwxr-x 2 root sudo  4096 Apr 24  2017 scratchdrwx-----x 9 root root  4096 Apr 24  2017 dockerdrwxr-xr-x 5 root root  4096 Apr 24  2017 app_reposrw-rw---- 1 root root     0 May  4 06#31 docker.sock-rw-r--r-- 1 root root  8111 May  4 16#03 HOST.xml-rw-r--r-- 1 root root  7908 May  4 16#03 ADMIN-LXC.xml-rw-r--r-- 1 root root 23798 May  4 16#03 compliance_audit_rtr_11_1_1_10.xml-rw-r--r-- 1 root root  8264 May  4 16#03 XR-LXC.xml2018-05-04 16#03#28,872 - DebugZTPLogger - INFO - ####################################################                       ACTIVE-RP ADMIN                #####################################################2018-05-04 16#03#28,872 - DebugZTPLogger - INFO - ###### App Directory ######2018-05-04 16#03#29,460 - DebugZTPLogger - INFO -  /misc/scratch#total 7164drwxr-xr-x 2 root root    4096 Apr 24  2017 coredrwxr-xr-x 2 root root    4096 Apr 24  2017 shelf_mgr_pds-rw-r--r-- 1 root root     579 May  4 06#31 card_specific_install--wxr-s--- 1 root root   11974 May  4 06#31 calvados_log_tacacsd_0_0.out--wxr-sr-- 1 root root    1822 May  4 06#31 calvados_log_instagt_log_0_0.out--wxr-Sr-- 1 root root    3388 May  4 06#31 calvados_log_vmm_0_0.out--wxr-sr-x 1 root root   28112 May  4 06#33 calvados_log_confd_helper_0_0.out-rwx------ 1 root root 7046848 May  4 15#26 audit_admin.bin-rw-r--r-- 1 root root    7908 May  4 16#03 ADMIN-LXC.xml--wxr-Sr-x 1 root root  211763 May  4 16#03 calvados_log_aaad_0_0.out2018-05-04 16#03#29,460 - DebugZTPLogger - INFO - ###### Cron directory ######2018-05-04 16#03#30,075 - DebugZTPLogger - INFO -  /etc/cron.d#total 8-rw-r--r-- 1 root root 73 Apr 24  2017 logrotate.conf-rw-r--r-- 1 root root 89 May  4 15#26 audit_cron_admin_2018-05-04_15-26-402018-05-04 16#03#30,076 - DebugZTPLogger - INFO - ###### XML Output Directory ######2018-05-04 16#03#30,639 - DebugZTPLogger - INFO -  /misc/scratch#total 7168drwxr-xr-x 2 root root    4096 Apr 24  2017 coredrwxr-xr-x 2 root root    4096 Apr 24  2017 shelf_mgr_pds-rw-r--r-- 1 root root     579 May  4 06#31 card_specific_install--wxr-s--- 1 root root   11974 May  4 06#31 calvados_log_tacacsd_0_0.out--wxr-sr-- 1 root root    1822 May  4 06#31 calvados_log_instagt_log_0_0.out--wxr-Sr-- 1 root root    3388 May  4 06#31 calvados_log_vmm_0_0.out--wxr-sr-x 1 root root   28112 May  4 06#33 calvados_log_confd_helper_0_0.out-rwx------ 1 root root 7046848 May  4 15#26 audit_admin.bin-rw-r--r-- 1 root root    7908 May  4 16#03 ADMIN-LXC.xml--wxr-Sr-x 1 root root  215191 May  4 16#03 calvados_log_aaad_0_0.out2018-05-04 16#03#30,640 - DebugZTPLogger - INFO - ####################################################                       ACTIVE-RP HOST                #####################################################2018-05-04 16#03#30,640 - DebugZTPLogger - INFO - ###### App Directory ######2018-05-04 16#03#31,334 - DebugZTPLogger - INFO -  /misc/scratch#total 6888drwxr-xr-x 2 root root    4096 Apr 24  2017 core-rwx------ 1 root root 7046616 May  4 15#26 audit_host.bin2018-05-04 16#03#31,334 - DebugZTPLogger - INFO - ###### Cron directory ######2018-05-04 16#03#32,063 - DebugZTPLogger - INFO -  /etc/cron.d#total 8-rw-r--r-- 1 root root 73 Apr 24  2017 logrotate.conf-rw-r--r-- 1 root root 88 May  4 15#26 audit_cron_host_2018-05-04_15-26-462018-05-04 16#03#32,064 - DebugZTPLogger - INFO - ###### XML Output Directory ######2018-05-04 16#03#32,788 - DebugZTPLogger - INFO -  /misc/app_host#total 84drwx------ 2 root root 16384 Apr 24  2017 lost+founddrwxr-xr-x 5 root root  4096 Apr 24  2017 etcdrwxrwxr-x 2 root sudo  4096 Apr 24  2017 scratchdrwx-----x 9 root root  4096 Apr 24  2017 dockerdrwxr-xr-x 5 root root  4096 Apr 24  2017 app_reposrw-rw---- 1 root root     0 May  4 06#31 docker.sock-rw-r--r-- 1 root root  8111 May  4 16#03 HOST.xml-rw-r--r-- 1 root root  7908 May  4 16#03 ADMIN-LXC.xml-rw-r--r-- 1 root root 23798 May  4 16#03 compliance_audit_rtr_11_1_1_10.xml-rw-r--r-- 1 root root  8264 May  4 16#03 XR-LXC.xml[xr-vm_node0_RP0_CPU0#~]$List generated XML filesYou will see the generated XML files in the directories specified in the userfiles/auditor.cfg.yml files as explained in the previous section. The recommendation is to set the output_xml_dir for both XR and collector to /misc/app_host to view all the XML files in one location, but it is not mandatory.[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$ls -lrt /misc/app_host/total 84drwx------ 2 root root 16384 Apr 24  2017 lost+founddrwxr-xr-x 5 root root  4096 Apr 24  2017 etcdrwxrwxr-x 2 root sudo  4096 Apr 24  2017 scratchdrwx-----x 9 root root  4096 Apr 24  2017 dockerdrwxr-xr-x 5 root root  4096 Apr 24  2017 app_reposrw-rw---- 1 root root     0 May  4 06#31 docker.sock-rw-r--r-- 1 root root  7908 May  4 16#05 ADMIN-LXC.xml-rw-r--r-- 1 root root  8111 May  4 16#05 HOST.xml-rw-r--r-- 1 root root 23799 May  4 16#05 compliance_audit_rtr_11_1_1_10.xml-rw-r--r-- 1 root root  8264 May  4 16#05 XR-LXC.xml[xr-vm_node0_RP0_CPU0#~]$Here,-rw-r--r-- 1 root root  7908 May  4 16#05 ADMIN-LXC.xml  is generated by audit_admin.bin running in the Admin LXC-rw-r--r-- 1 root root  8111 May  4 16#05 HOST.xml is generated by audit_host.bin running in the Host shell-rw-r--r-- 1 root root  8264 May  4 16#05 XR-LXC.xml is generated by audit_xr.bin running in the XR shell-rw-r--r-- 1 root root 23799 May  4 16#05 compliance_audit_rtr_11_1_1_10.xml is generated by the collector app running in the XR shell.Deconstructing the XML contentAs specified earlier, the XML content generated by the collector app is transferred over SSH to the remote server, based on the SERVER_CONFIG settings in userfiles/auditor.cfg.yml#So log back into devbox(server) and drop into the directory that you specified as REMOTE_DIRECTORY in userfiles/auditor.cfg.yml.    # Specify the remote directory on the server    # where the compliance XML file should be copied    REMOTE_DIRECTORY# ~/home/vagrant~In this case, it is set to /home/vagrant so checking there#AKSHSHAR-M-33WP#vagrant akshshar$ AKSHSHAR-M-33WP#vagrant akshshar$ vagrant ssh devboxvagrant@127.0.0.1's password# Welcome to Ubuntu 16.04.4 LTS (GNU/Linux 4.4.0-87-generic x86_64) * Documentation#  https#//help.ubuntu.com * Management#     https#//landscape.canonical.com * Support#        https#//ubuntu.com/advantage0 packages can be updated.0 updates are security updates.Last login# Fri May  4 16#13#51 2018 from 10.0.2.2vagrant@vagrant#~$ vagrant@vagrant#~$ vagrant@vagrant#~$ ls -lrt /misc/appls# cannot access '/misc/app'# No such file or directoryvagrant@vagrant#~$ ls -lrt /home/vagrant/total 28drwxrwxr-x 10 vagrant vagrant  4096 May  4 10#42 xr-auditor-rw-rw-r--  1 vagrant vagrant 23799 May  4 16#14 compliance_audit_rtr_11_1_1_10.xmlvagrant@vagrant#~$ vagrant@vagrant#~$   Great! We see the xml file appear on the server, transmitted by the collector app.Let\u2019s dump the content#vagrant@vagrant#~$ cat compliance_audit_rtr_11_1_1_10.xml &lt;?xml version=~1.0~ encoding=~utf-8~?&gt;&lt;COMPLIANCE-DUMP xmlns#xsi=~http#//www.w3.org/2001/XMLSchema-instance~ version=~1.0.0~ xsi#noNamespaceSchemaLocation=~compliance.xsd~&gt;\t&lt;GENERAL&gt;\t\t&lt;PRODUCT&gt;XRV-P-L--CH&lt;/PRODUCT&gt;\t\t&lt;VENDOR&gt;Cisco&lt;/VENDOR&gt;\t\t&lt;IPADDR&gt;11.1.1.10/24&lt;/IPADDR&gt;\t\t&lt;HOST&gt;rtr&lt;/HOST&gt;\t\t&lt;VERSION&gt;6.1.2&lt;/VERSION&gt;\t\t&lt;DATE&gt;20180504-16#14 UTC&lt;/DATE&gt;\t\t&lt;OS&gt;IOS-XR&lt;/OS&gt;\t&lt;/GENERAL&gt;\t&lt;INTEGRITY-SET&gt;\t\t&lt;INTEGRITY domain=~XR-LXC~&gt;\t\t\t&lt;FILES&gt;\t\t\t\t&lt;FILE&gt;\t\t\t\t\t&lt;CONTENT&gt;[~#\\t$OpenBSD# sshd_config,v 1.80 2008/07/02 02#24#18 djm Exp $~, ~# This is the sshd server system-wide configuration file.  See~, ~# sshd_config(5) for more information.~, ~# This sshd was compiled with PATH=/usr/bin#/bin#/usr/sbin#/sbin~, ~# The strategy used for options in the default sshd_config shipped with~, ~# OpenSSH is to specify options with their default value where~, ~# possible, but leave them commented.  Uncommented options change a~, ~# default value.~, ~#Port 22~, ~AddressFamily inet~, ~#ListenAddress 0.0.0.0~, ~#ListenAddress ##~, ~# Disable legacy (protocol version 1) support in the server for new~, ~# installations. In future the default will change to require explicit~, ~# activation of protocol 1~, ~Protocol 2~, ~# HostKey for protocol version 1~, ~#HostKey /etc/ssh/ssh_host_key~, ~# HostKeys for protocol version 2~, ~#HostKey /etc/ssh/ssh_host_rsa_key~, ~#HostKey /etc/ssh/ssh_host_dsa_key~, ~# Lifetime and size of ephemeral version 1 server key~, ~#KeyRegenerationInterval 1h~, ~#ServerKeyBits 1024~, ~# Logging~, ~# obsoletes QuietMode and FascistLogging~, ~#SyslogFacility AUTH~, ~#LogLevel INFO~, ~# Authentication#~, ~#LoginGraceTime 2m~, ~PermitRootLogin yes~, ~#StrictModes yes~, ~#MaxAuthTries 6~, ~#MaxSessions 10~, ~#RSAAuthentication yes~, ~#PubkeyAuthentication yes~, ~#AuthorizedKeysFile\\t.ssh/authorized_keys~, ~# For this to work you will also need host keys in /etc/ssh/ssh_known_hosts~, ~#RhostsRSAAuthentication no~, ~# similar for protocol version 2~, ~#HostbasedAuthentication no~, ~# Change to yes if you don't trust ~/.ssh/known_hosts for~, ~# RhostsRSAAuthentication and HostbasedAuthentication~, ~#IgnoreUserKnownHosts no~, ~# Don't read the user's ~/.rhosts and ~/.shosts files~, ~#IgnoreRhosts yes~, ~# To disable tunneled clear text passwords, change to no here!~, ~#PasswordAuthentication yes~, ~PermitEmptyPasswords yes~, ~# Change to no to disable s/key passwords~, ~#ChallengeResponseAuthentication yes~, ~# Kerberos options~, ~#KerberosAuthentication no~, ~#KerberosOrLocalPasswd yes~, ~#KerberosTicketCleanup yes~, ~#KerberosGetAFSToken no~, ~# GSSAPI options~, ~#GSSAPIAuthentication no~, ~#GSSAPICleanupCredentials yes~, ~# Set this to 'yes' to enable PAM authentication, account processing,~, ~# and session processing. If this is enabled, PAM authentication will~, ~# be allowed through the ChallengeResponseAuthentication and~, ~# PasswordAuthentication.  Depending on your PAM configuration,~, ~# PAM authentication via ChallengeResponseAuthentication may bypass~, ~# the setting of \\~PermitRootLogin without-password\\~.~, ~# If you just want the PAM account and session checks to run without~, ~# PAM authentication, then enable this but set PasswordAuthentication~, ~# and ChallengeResponseAuthentication to 'no'.~, ~#UsePAM no~, ~#AllowAgentForwarding yes~, ~#AllowTcpForwarding yes~, ~#GatewayPorts no~, ~#X11Forwarding no~, ~#X11DisplayOffset 10~, ~#X11UseLocalhost yes~, ~#PrintMotd yes~, ~#PrintLastLog yes~, ~#TCPKeepAlive yes~, ~#UseLogin no~, ~UsePrivilegeSeparation no~, ~#PermitUserEnvironment no~, ~Compression no~, ~ClientAliveInterval 15~, ~ClientAliveCountMax 4~, ~UseDNS no~, ~#PidFile /var/run/sshd.pid~, ~#MaxStartups 10~, ~#PermitTunnel no~, ~#ChrootDirectory none~, ~# no default banner path~, ~#Banner none~, ~# override default of no subsystems~, ~Subsystem\\tsftp\\t/usr/lib64/openssh/sftp-server~, ~# Example of overriding settings on a per-user basis~, ~#Match User anoncvs~, ~#\\tX11Forwarding no~, ~#\\tAllowTcpForwarding no~, ~#\\tForceCommand cvs server~]&lt;/CONTENT&gt;\t\t\t\t\t&lt;CHECKSUM&gt;97884b5c2cb2b75022c4b440ddc4245a&lt;/CHECKSUM&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -la&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;-rwxr-xr-x 1 root root 3275 Apr 24  2017 /etc/ssh/sshd_config&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/etc/ssh/sshd_config&lt;/NAME&gt;\t\t\t\t&lt;/FILE&gt;\t\t\t\t&lt;FILE&gt;\t\t\t\t\t&lt;CONTENT&gt;[~root#x#0#0#root#/root#/bin/sh~, ~daemon#x#1#1#daemon#/usr/sbin#/bin/sh~, ~bin#x#2#2#bin#/bin#/bin/sh~, ~sys#x#3#3#sys#/dev#/bin/sh~, ~sync#x#4#65534#sync#/bin#/bin/sync~, ~games#x#5#60#games#/usr/games#/bin/sh~, ~man#x#6#12#man#/var/cache/man#/bin/sh~, ~lp#x#7#7#lp#/var/spool/lpd#/bin/sh~, ~mail#x#8#8#mail#/var/mail#/bin/sh~, ~news#x#9#9#news#/var/spool/news#/bin/sh~, ~uucp#x#10#10#uucp#/var/spool/uucp#/bin/sh~, ~proxy#x#13#13#proxy#/bin#/bin/sh~, ~www-data#x#33#33#www-data#/var/www#/bin/sh~, ~backup#x#34#34#backup#/var/backups#/bin/sh~, ~list#x#38#38#Mailing List Manager#/var/list#/bin/sh~, ~irc#x#39#39#ircd#/var/run/ircd#/bin/sh~, ~gnats#x#41#41#Gnats Bug-Reporting System (admin)#/var/lib/gnats#/bin/sh~, ~nobody#x#65534#65534#nobody#/nonexistent#/bin/sh~, ~messagebus#x#999#998##/var/lib/dbus#/bin/false~, ~rpc#x#998#996##/#/bin/false~, ~sshd#x#997#995##/var/run/sshd#/bin/false~, ~vagrant#x#1000#1009##/home/vagrant#/bin/sh~]&lt;/CONTENT&gt;\t\t\t\t\t&lt;CHECKSUM&gt;0cabf9f93101d6876bba590e48bfda5e&lt;/CHECKSUM&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -la&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;-rw-r--r-- 1 root root 874 Apr 24  2017 /etc/passwd&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/etc/passwd&lt;/NAME&gt;\t\t\t\t&lt;/FILE&gt;\t\t\t\t&lt;FILE&gt;\t\t\t\t\t&lt;CHECKSUM&gt;7ea587858977ef205c6a7419463359f7&lt;/CHECKSUM&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -la&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;lrwxrwxrwx 1 root root 7 Apr 24  2017 /usr/bin/python -&amp;gt; python2&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/usr/bin/python&lt;/NAME&gt;\t\t\t\t&lt;/FILE&gt;\t\t\t\t&lt;FILE&gt;\t\t\t\t\t&lt;CONTENT&gt;[~# Defaults for dhcp initscript~, ~# sourced by /etc/init.d/dhcp-server~, ~# installed at /etc/default/dhcp-server by the maintainer scripts~, ~# On what interfaces should the DHCP server (dhcpd) serve DHCP requests?~, ~#       Separate multiple interfaces with spaces, e.g. \\~eth0 eth1\\~.~, ~INTERFACES=\\~\\~~]&lt;/CONTENT&gt;\t\t\t\t\t&lt;CHECKSUM&gt;1c905007d96a8b16c58454b6da8cfd86&lt;/CHECKSUM&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -lhrt&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;-rw-r--r-- 1 root root 290 Apr 24  2017 /etc/default/dhcp-server&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/etc/default/dhcp-server&lt;/NAME&gt;\t\t\t\t&lt;/FILE&gt;\t\t\t&lt;/FILES&gt;\t\t\t&lt;DIRECTORIES&gt;\t\t\t\t&lt;DIRECTORY&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -ld&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;drwxr-xr-x 3 root root 20480 Apr 24  2017 /usr/bin&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/usr/bin&lt;/NAME&gt;\t\t\t\t&lt;/DIRECTORY&gt;\t\t\t\t&lt;DIRECTORY&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -lrt&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;total 8-rwx------ 1 root root   0 Apr 24  2017 log.txt-rwx------ 1 root root  13 Apr 24  2017 card_instances.txt-rw-r--r-- 1 root root 218 Apr 24  2017 cmdline-rw-r--r-- 1 root root   0 May  4 16#13 test.txt&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;touch test.txt&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/root&lt;/NAME&gt;\t\t\t\t&lt;/DIRECTORY&gt;\t\t\t\t&lt;DIRECTORY&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -ld&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;drwxr-xr-x 7 root root 4096 May  4 15#26 /misc/scratch&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/misc/scratch&lt;/NAME&gt;\t\t\t\t&lt;/DIRECTORY&gt;\t\t\t\t&lt;DIRECTORY&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -ld&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;drwxr-xr-x 7 root root 4096 May  4 16#03 /misc/app_host&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/misc/app_host&lt;/NAME&gt;\t\t\t\t&lt;/DIRECTORY&gt;\t\t\t\t&lt;DIRECTORY&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -ld&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;drwxr-xr-x 57 root root 4096 May  4 06#32 /etc&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/etc&lt;/NAME&gt;\t\t\t\t&lt;/DIRECTORY&gt;\t\t\t\t&lt;DIRECTORY&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -ld&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;drwxr-xr-x 34 root root 4096 May  4 10#52 /&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/&lt;/NAME&gt;\t\t\t\t&lt;/DIRECTORY&gt;\t\t\t&lt;/DIRECTORIES&gt;\t\t&lt;/INTEGRITY&gt;\t\t&lt;INTEGRITY domain=~ADMIN-LXC~&gt;\t\t\t&lt;FILES&gt;\t\t\t\t&lt;FILE&gt;\t\t\t\t\t&lt;CONTENT&gt;[~#\\t$OpenBSD# sshd_config,v 1.80 2008/07/02 02#24#18 djm Exp $~, ~# This is the sshd server system-wide configuration file.  See~, ~# sshd_config(5) for more information.~, ~# This sshd was compiled with PATH=/usr/bin#/bin#/usr/sbin#/sbin~, ~# The strategy used for options in the default sshd_config shipped with~, ~# OpenSSH is to specify options with their default value where~, ~# possible, but leave them commented.  Uncommented options change a~, ~# default value.~, ~#Port 22~, ~AddressFamily inet~, ~#ListenAddress 0.0.0.0~, ~#ListenAddress ##~, ~# Disable legacy (protocol version 1) support in the server for new~, ~# installations. In future the default will change to require explicit~, ~# activation of protocol 1~, ~Protocol 2~, ~# HostKey for protocol version 1~, ~#HostKey /etc/ssh/ssh_host_key~, ~# HostKeys for protocol version 2~, ~#HostKey /etc/ssh/ssh_host_rsa_key~, ~#HostKey /etc/ssh/ssh_host_dsa_key~, ~# Lifetime and size of ephemeral version 1 server key~, ~#KeyRegenerationInterval 1h~, ~#ServerKeyBits 1024~, ~# Logging~, ~# obsoletes QuietMode and FascistLogging~, ~#SyslogFacility AUTH~, ~#LogLevel INFO~, ~# Authentication#~, ~#LoginGraceTime 2m~, ~PermitRootLogin yes~, ~#StrictModes yes~, ~#MaxAuthTries 6~, ~#MaxSessions 10~, ~#RSAAuthentication yes~, ~#PubkeyAuthentication yes~, ~#AuthorizedKeysFile\\t.ssh/authorized_keys~, ~# For this to work you will also need host keys in /etc/ssh/ssh_known_hosts~, ~#RhostsRSAAuthentication no~, ~# similar for protocol version 2~, ~#HostbasedAuthentication no~, ~# Change to yes if you don't trust ~/.ssh/known_hosts for~, ~# RhostsRSAAuthentication and HostbasedAuthentication~, ~#IgnoreUserKnownHosts no~, ~# Don't read the user's ~/.rhosts and ~/.shosts files~, ~#IgnoreRhosts yes~, ~# To disable tunneled clear text passwords, change to no here!~, ~#PasswordAuthentication yes~, ~PermitEmptyPasswords yes~, ~# Change to no to disable s/key passwords~, ~#ChallengeResponseAuthentication yes~, ~# Kerberos options~, ~#KerberosAuthentication no~, ~#KerberosOrLocalPasswd yes~, ~#KerberosTicketCleanup yes~, ~#KerberosGetAFSToken no~, ~# GSSAPI options~, ~#GSSAPIAuthentication no~, ~#GSSAPICleanupCredentials yes~, ~# Set this to 'yes' to enable PAM authentication, account processing,~, ~# and session processing. If this is enabled, PAM authentication will~, ~# be allowed through the ChallengeResponseAuthentication and~, ~# PasswordAuthentication.  Depending on your PAM configuration,~, ~# PAM authentication via ChallengeResponseAuthentication may bypass~, ~# the setting of \\~PermitRootLogin without-password\\~.~, ~# If you just want the PAM account and session checks to run without~, ~# PAM authentication, then enable this but set PasswordAuthentication~, ~# and ChallengeResponseAuthentication to 'no'.~, ~#UsePAM no~, ~#AllowAgentForwarding yes~, ~#AllowTcpForwarding yes~, ~#GatewayPorts no~, ~#X11Forwarding no~, ~#X11DisplayOffset 10~, ~#X11UseLocalhost yes~, ~#PrintMotd yes~, ~#PrintLastLog yes~, ~#TCPKeepAlive yes~, ~#UseLogin no~, ~UsePrivilegeSeparation no~, ~#PermitUserEnvironment no~, ~Compression no~, ~ClientAliveInterval 15~, ~ClientAliveCountMax 4~, ~UseDNS no~, ~#PidFile /var/run/sshd.pid~, ~#MaxStartups 10~, ~#PermitTunnel no~, ~#ChrootDirectory none~, ~# no default banner path~, ~#Banner none~, ~# override default of no subsystems~, ~Subsystem\\tsftp\\t/usr/lib64/openssh/sftp-server~, ~# Example of overriding settings on a per-user basis~, ~#Match User anoncvs~, ~#\\tX11Forwarding no~, ~#\\tAllowTcpForwarding no~, ~#\\tForceCommand cvs server~]&lt;/CONTENT&gt;\t\t\t\t\t&lt;CHECKSUM&gt;97884b5c2cb2b75022c4b440ddc4245a&lt;/CHECKSUM&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -la&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;-rwxr-xr-x 1 root root 3275 Apr 24  2017 /etc/ssh/sshd_config&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/etc/ssh/sshd_config&lt;/NAME&gt;\t\t\t\t&lt;/FILE&gt;\t\t\t\t&lt;FILE&gt;\t\t\t\t\t&lt;CONTENT&gt;[~root#x#0#0#root#/root#/bin/sh~, ~daemon#x#1#1#daemon#/usr/sbin#/bin/sh~, ~bin#x#2#2#bin#/bin#/bin/sh~, ~sys#x#3#3#sys#/dev#/bin/sh~, ~sync#x#4#65534#sync#/bin#/bin/sync~, ~games#x#5#60#games#/usr/games#/bin/sh~, ~man#x#6#12#man#/var/cache/man#/bin/sh~, ~lp#x#7#7#lp#/var/spool/lpd#/bin/sh~, ~mail#x#8#8#mail#/var/mail#/bin/sh~, ~news#x#9#9#news#/var/spool/news#/bin/sh~, ~uucp#x#10#10#uucp#/var/spool/uucp#/bin/sh~, ~proxy#x#13#13#proxy#/bin#/bin/sh~, ~www-data#x#33#33#www-data#/var/www#/bin/sh~, ~backup#x#34#34#backup#/var/backups#/bin/sh~, ~list#x#38#38#Mailing List Manager#/var/list#/bin/sh~, ~irc#x#39#39#ircd#/var/run/ircd#/bin/sh~, ~gnats#x#41#41#Gnats Bug-Reporting System (admin)#/var/lib/gnats#/bin/sh~, ~nobody#x#65534#65534#nobody#/nonexistent#/bin/sh~, ~messagebus#x#999#998##/var/lib/dbus#/bin/false~, ~rpc#x#998#996##/#/bin/false~, ~sshd#x#997#995##/var/run/sshd#/bin/false~]&lt;/CONTENT&gt;\t\t\t\t\t&lt;CHECKSUM&gt;591fb16f798d29aa9dab2db5557ff4f8&lt;/CHECKSUM&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -la&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;-rw-r--r-- 1 root root 831 Apr 24  2017 /etc/passwd&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/etc/passwd&lt;/NAME&gt;\t\t\t\t&lt;/FILE&gt;\t\t\t\t&lt;FILE&gt;\t\t\t\t\t&lt;CHECKSUM&gt;7ea587858977ef205c6a7419463359f7&lt;/CHECKSUM&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -la&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;lrwxrwxrwx 1 root root 7 Apr 24  2017 /usr/bin/python -&amp;gt; python2&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/usr/bin/python&lt;/NAME&gt;\t\t\t\t&lt;/FILE&gt;\t\t\t\t&lt;FILE&gt;\t\t\t\t\t&lt;CONTENT&gt;[~# Defaults for dhcp initscript~, ~# sourced by /etc/init.d/dhcp-server~, ~# installed at /etc/default/dhcp-server by the maintainer scripts~, ~# On what interfaces should the DHCP server (dhcpd) serve DHCP requests?~, ~#       Separate multiple interfaces with spaces, e.g. \\~eth0 eth1\\~.~, ~INTERFACES=\\~\\~~]&lt;/CONTENT&gt;\t\t\t\t\t&lt;CHECKSUM&gt;1c905007d96a8b16c58454b6da8cfd86&lt;/CHECKSUM&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -lhrt&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;-rw-r--r-- 1 root root 290 Apr 24  2017 /etc/default/dhcp-server&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/etc/default/dhcp-server&lt;/NAME&gt;\t\t\t\t&lt;/FILE&gt;\t\t\t&lt;/FILES&gt;\t\t\t&lt;DIRECTORIES&gt;\t\t\t\t&lt;DIRECTORY&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -ld&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;drwxr-sr-x 3 root root 20480 Apr 24  2017 /usr/bin&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/usr/bin&lt;/NAME&gt;\t\t\t\t&lt;/DIRECTORY&gt;\t\t\t\t&lt;DIRECTORY&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -lrt&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;total 4-rwx------ 1 root root   0 Apr 24  2017 calv_setup_ldpath.log-rw-r--r-- 1 root root 227 Apr 24  2017 cmdline-rw-r--r-- 1 root root   0 May  4 16#14 test.txt&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;touch test.txt&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/root&lt;/NAME&gt;\t\t\t\t&lt;/DIRECTORY&gt;\t\t\t\t&lt;DIRECTORY&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -ld&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;drwxr-xr-x 4 root root 4096 May  4 15#27 /misc/scratch&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/misc/scratch&lt;/NAME&gt;\t\t\t\t&lt;/DIRECTORY&gt;\t\t\t\t&lt;DIRECTORY&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -ld&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/misc/app_host&lt;/NAME&gt;\t\t\t\t&lt;/DIRECTORY&gt;\t\t\t\t&lt;DIRECTORY&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -ld&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;drwxr-sr-x 55 root root 4096 May  4 06#32 /etc&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/etc&lt;/NAME&gt;\t\t\t\t&lt;/DIRECTORY&gt;\t\t\t\t&lt;DIRECTORY&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -ld&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;drwxr-sr-x 28 root root 4096 May  4 06#30 /&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/&lt;/NAME&gt;\t\t\t\t&lt;/DIRECTORY&gt;\t\t\t&lt;/DIRECTORIES&gt;\t\t&lt;/INTEGRITY&gt;\t\t&lt;INTEGRITY domain=~HOST~&gt;\t\t\t&lt;FILES&gt;\t\t\t\t&lt;FILE&gt;\t\t\t\t\t&lt;CONTENT&gt;[~#\\t$OpenBSD# sshd_config,v 1.80 2008/07/02 02#24#18 djm Exp $~, ~# This is the sshd server system-wide configuration file.  See~, ~# sshd_config(5) for more information.~, ~# This sshd was compiled with PATH=/usr/bin#/bin#/usr/sbin#/sbin~, ~# The strategy used for options in the default sshd_config shipped with~, ~# OpenSSH is to specify options with their default value where~, ~# possible, but leave them commented.  Uncommented options change a~, ~# default value.~, ~#Port 22~, ~AddressFamily inet~, ~#ListenAddress 0.0.0.0~, ~#ListenAddress ##~, ~# Disable legacy (protocol version 1) support in the server for new~, ~# installations. In future the default will change to require explicit~, ~# activation of protocol 1~, ~Protocol 2~, ~# HostKey for protocol version 1~, ~#HostKey /etc/ssh/ssh_host_key~, ~# HostKeys for protocol version 2~, ~#HostKey /etc/ssh/ssh_host_rsa_key~, ~#HostKey /etc/ssh/ssh_host_dsa_key~, ~# Lifetime and size of ephemeral version 1 server key~, ~#KeyRegenerationInterval 1h~, ~#ServerKeyBits 1024~, ~# Logging~, ~# obsoletes QuietMode and FascistLogging~, ~#SyslogFacility AUTH~, ~#LogLevel INFO~, ~# Authentication#~, ~#LoginGraceTime 2m~, ~PermitRootLogin yes~, ~#StrictModes yes~, ~#MaxAuthTries 6~, ~#MaxSessions 10~, ~#RSAAuthentication yes~, ~#PubkeyAuthentication yes~, ~#AuthorizedKeysFile\\t.ssh/authorized_keys~, ~# For this to work you will also need host keys in /etc/ssh/ssh_known_hosts~, ~#RhostsRSAAuthentication no~, ~# similar for protocol version 2~, ~#HostbasedAuthentication no~, ~# Change to yes if you don't trust ~/.ssh/known_hosts for~, ~# RhostsRSAAuthentication and HostbasedAuthentication~, ~#IgnoreUserKnownHosts no~, ~# Don't read the user's ~/.rhosts and ~/.shosts files~, ~#IgnoreRhosts yes~, ~# To disable tunneled clear text passwords, change to no here!~, ~#PasswordAuthentication yes~, ~PermitEmptyPasswords yes~, ~# Change to no to disable s/key passwords~, ~#ChallengeResponseAuthentication yes~, ~# Kerberos options~, ~#KerberosAuthentication no~, ~#KerberosOrLocalPasswd yes~, ~#KerberosTicketCleanup yes~, ~#KerberosGetAFSToken no~, ~# GSSAPI options~, ~#GSSAPIAuthentication no~, ~#GSSAPICleanupCredentials yes~, ~# Set this to 'yes' to enable PAM authentication, account processing,~, ~# and session processing. If this is enabled, PAM authentication will~, ~# be allowed through the ChallengeResponseAuthentication and~, ~# PasswordAuthentication.  Depending on your PAM configuration,~, ~# PAM authentication via ChallengeResponseAuthentication may bypass~, ~# the setting of \\~PermitRootLogin without-password\\~.~, ~# If you just want the PAM account and session checks to run without~, ~# PAM authentication, then enable this but set PasswordAuthentication~, ~# and ChallengeResponseAuthentication to 'no'.~, ~#UsePAM no~, ~#AllowAgentForwarding yes~, ~#AllowTcpForwarding yes~, ~#GatewayPorts no~, ~#X11Forwarding no~, ~#X11DisplayOffset 10~, ~#X11UseLocalhost yes~, ~#PrintMotd yes~, ~#PrintLastLog yes~, ~#TCPKeepAlive yes~, ~#UseLogin no~, ~UsePrivilegeSeparation no~, ~#PermitUserEnvironment no~, ~Compression no~, ~ClientAliveInterval 15~, ~ClientAliveCountMax 4~, ~UseDNS no~, ~#PidFile /var/run/sshd.pid~, ~#MaxStartups 10~, ~#PermitTunnel no~, ~#ChrootDirectory none~, ~# no default banner path~, ~#Banner none~, ~# override default of no subsystems~, ~Subsystem\\tsftp\\t/usr/lib64/openssh/sftp-server~, ~# Example of overriding settings on a per-user basis~, ~#Match User anoncvs~, ~#\\tX11Forwarding no~, ~#\\tAllowTcpForwarding no~, ~#\\tForceCommand cvs server~, ~#~, ~# Permit access from calvados and XR to host~, ~#~, ~Match Address 10.11.12.*~, ~PermitRootLogin yes~, ~#~, ~# Permit access from host to calvados and XR~, ~#~, ~Match Address 10.0.2.*~, ~PermitRootLogin yes~]&lt;/CONTENT&gt;\t\t\t\t\t&lt;CHECKSUM&gt;5b4a5d15629e9a81e16d64f8a7f2e873&lt;/CHECKSUM&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -la&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;-rwxr-xr-x 1 root root 3466 Apr 24  2017 /etc/ssh/sshd_config&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/etc/ssh/sshd_config&lt;/NAME&gt;\t\t\t\t&lt;/FILE&gt;\t\t\t\t&lt;FILE&gt;\t\t\t\t\t&lt;CONTENT&gt;[~root#x#0#0#root#/root#/bin/sh~, ~daemon#x#1#1#daemon#/usr/sbin#/bin/sh~, ~bin#x#2#2#bin#/bin#/bin/sh~, ~sys#x#3#3#sys#/dev#/bin/sh~, ~sync#x#4#65534#sync#/bin#/bin/sync~, ~games#x#5#60#games#/usr/games#/bin/sh~, ~man#x#6#12#man#/var/cache/man#/bin/sh~, ~lp#x#7#7#lp#/var/spool/lpd#/bin/sh~, ~mail#x#8#8#mail#/var/mail#/bin/sh~, ~news#x#9#9#news#/var/spool/news#/bin/sh~, ~uucp#x#10#10#uucp#/var/spool/uucp#/bin/sh~, ~proxy#x#13#13#proxy#/bin#/bin/sh~, ~www-data#x#33#33#www-data#/var/www#/bin/sh~, ~backup#x#34#34#backup#/var/backups#/bin/sh~, ~list#x#38#38#Mailing List Manager#/var/list#/bin/sh~, ~irc#x#39#39#ircd#/var/run/ircd#/bin/sh~, ~gnats#x#41#41#Gnats Bug-Reporting System (admin)#/var/lib/gnats#/bin/sh~, ~nobody#x#65534#65534#nobody#/nonexistent#/bin/sh~, ~messagebus#x#999#998##/var/lib/dbus#/bin/false~, ~rpc#x#998#996##/#/bin/false~, ~sshd#x#997#995##/var/run/sshd#/bin/false~]&lt;/CONTENT&gt;\t\t\t\t\t&lt;CHECKSUM&gt;591fb16f798d29aa9dab2db5557ff4f8&lt;/CHECKSUM&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -la&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;-rw-r--r-- 1 root root 831 Apr 24  2017 /etc/passwd&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/etc/passwd&lt;/NAME&gt;\t\t\t\t&lt;/FILE&gt;\t\t\t\t&lt;FILE&gt;\t\t\t\t\t&lt;CHECKSUM&gt;7ea587858977ef205c6a7419463359f7&lt;/CHECKSUM&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -la&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;lrwxrwxrwx 1 root root 7 Apr 24  2017 /usr/bin/python -&amp;gt; python2&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/usr/bin/python&lt;/NAME&gt;\t\t\t\t&lt;/FILE&gt;\t\t\t\t&lt;FILE&gt;\t\t\t\t\t&lt;CONTENT&gt;[~# Defaults for dhcp initscript~, ~# sourced by /etc/init.d/dhcp-server~, ~# installed at /etc/default/dhcp-server by the maintainer scripts~, ~# On what interfaces should the DHCP server (dhcpd) serve DHCP requests?~, ~#       Separate multiple interfaces with spaces, e.g. \\~eth0 eth1\\~.~, ~INTERFACES=\\~\\~~]&lt;/CONTENT&gt;\t\t\t\t\t&lt;CHECKSUM&gt;1c905007d96a8b16c58454b6da8cfd86&lt;/CHECKSUM&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -lhrt&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;-rw-r--r-- 1 root root 290 Apr 24  2017 /etc/default/dhcp-server&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/etc/default/dhcp-server&lt;/NAME&gt;\t\t\t\t&lt;/FILE&gt;\t\t\t&lt;/FILES&gt;\t\t\t&lt;DIRECTORIES&gt;\t\t\t\t&lt;DIRECTORY&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -ld&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;drwxr-sr-x 3 root root 20480 Apr 24  2017 /usr/bin&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/usr/bin&lt;/NAME&gt;\t\t\t\t&lt;/DIRECTORY&gt;\t\t\t\t&lt;DIRECTORY&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -lrt&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;total 4-rw-r--r-- 1 root root 97 Apr 24  2017 cmdline-rw-r--r-- 1 root root  0 May  4 16#14 test.txt&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;touch test.txt&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/root&lt;/NAME&gt;\t\t\t\t&lt;/DIRECTORY&gt;\t\t\t\t&lt;DIRECTORY&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -ld&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;drwxr-xr-x 3 root root 4096 May  4 15#26 /misc/scratch&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/misc/scratch&lt;/NAME&gt;\t\t\t\t&lt;/DIRECTORY&gt;\t\t\t\t&lt;DIRECTORY&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -ld&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;drwxr-xr-x 7 root root 4096 May  4 16#03 /misc/app_host&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/misc/app_host&lt;/NAME&gt;\t\t\t\t&lt;/DIRECTORY&gt;\t\t\t\t&lt;DIRECTORY&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -ld&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;drwxr-sr-x 56 root root 4096 May  4 06#29 /etc&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/etc&lt;/NAME&gt;\t\t\t\t&lt;/DIRECTORY&gt;\t\t\t\t&lt;DIRECTORY&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -ld&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;drwxr-sr-x 27 root root 4096 May  4 06#29 /&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/&lt;/NAME&gt;\t\t\t\t&lt;/DIRECTORY&gt;\t\t\t&lt;/DIRECTORIES&gt;\t\t&lt;/INTEGRITY&gt;\t&lt;/INTEGRITY-SET&gt;&lt;/COMPLIANCE-DUMP&gt;vagrant@vagrant#~$ Excellent, how does one read this data?The Basic structure is defined based on the XML schema userfiles/compliance.xsd in the git repo.  NOTE# The XML file will only be generated by the apps if the xml content validates successfully against the compliance.xsd file. So if you\u2019re receiveing XML content from the collector app, then you can be rest assured that it is already validated based on the schema.If we deconstruct parts of the XML data, we can see the basic structure starts with the  tag and the version of the auditor app (remember we used the `-v` option with the app earlier?) as an attribute#&lt;COMPLIANCE-DUMP xmlns#xsi=~http#//www.w3.org/2001/XMLSchema-instance~ version=~1.0.0~ xsi#noNamespaceSchemaLocation=~compliance.xsd~&gt;....The next set of higher level tags are#  &lt;GENERAL&amp;gt;  &lt;COMPLIANCE-DUMP xmlns#xsi=~http#//www.w3.org/2001/XMLSchema-instance~ version=~1.0.0~ xsi#noNamespaceSchemaLocation=~compliance.xsd~&gt;  &lt;GENERAL&gt;\t\t&lt;PRODUCT&gt;XRV-P-L--CH&lt;/PRODUCT&gt;\t\t&lt;VENDOR&gt;Cisco&lt;/VENDOR&gt;\t\t&lt;IPADDR&gt;11.1.1.10/24&lt;/IPADDR&gt;\t\t&lt;HOST&gt;rtr&lt;/HOST&gt;\t\t&lt;VERSION&gt;6.1.2&lt;/VERSION&gt;\t\t&lt;DATE&gt;20180504-16#14 UTC&lt;/DATE&gt;\t\t&lt;OS&gt;IOS-XR&lt;/OS&gt;\t&lt;/GENERAL&gt;The &lt;GENERAL&gt; data is used to collect relevant information from the router config and oper state in order to uniquely identify the router that produced this XML content.  &lt;INTEGRITY-SET&amp;gt;This is the actual compliance/audit data being collected by the apps from the individual Linux shells. It can be seen from the snippets below, that the integrity set consists of three sections identified by the domain which can be XR-LXC, ADMIN-LXC or HOST.Within each domain, there are a list of &lt;FILES&gt; each of which can be subjected to a list of commands along with content, checksum outputs. Further, there is a section called &lt;DIRECTORIES&gt; which is very similar to the &lt;FILES&gt; section and also contains a list of directories with the outputs of a list of commands on each directory.\t&lt;INTEGRITY-SET&gt;\t\t&lt;INTEGRITY domain=~XR-LXC~&gt;\t\t\t&lt;FILES&gt;\t\t\t\t&lt;FILE&gt;\t\t\t\t\t&lt;CONTENT&gt;[~#\\t$OpenBSD# sshd_config,v 1.80 2008/07/02 02#24#18 djm Exp $~, ~# This is the sshd server system-wide configuration file.  See~, ~# sshd_config(5) for more information.~, ~# This sshd was compiled with                  ......       ~UsePrivilegeSeparation no~, ~#PermitUserEnvironment no~, ~Compression no~, ~ClientAliveInterval 15~, ~ClientAliveCountMax 4~, ~UseDNS no~, ~#PidFile /var/run/sshd.pid~, ~#MaxStartups 10~, ~#PermitTunnel no~, ~#ChrootDirectory none~, ~# no default banner path~, ~#Banner none~, ~# override default of no subsystems~, ~Subsystem\\tsftp\\t/usr/lib64/openssh/sftp-server~, ~# Example of overriding settings on a per-user basis~, ~#Match User anoncvs~, ~#\\tX11Forwarding no~, ~#\\tAllowTcpForwarding no~, ~#\\tForceCommand cvs server~]&lt;/CONTENT&gt;\t\t\t\t\t&lt;CHECKSUM&gt;97884b5c2cb2b75022c4b440ddc4245a&lt;/CHECKSUM&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -la&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;-rwxr-xr-x 1 root root 3275 Apr 24  2017 /etc/ssh/sshd_config&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/etc/ssh/sshd_config&lt;/NAME&gt;\t\t\t\t&lt;/FILE&gt;                             .....              &lt;/FILES&gt;      &lt;DIRECTORIES&gt;\t\t\t\t&lt;DIRECTORY&gt;\t\t\t\t\t&lt;CMD-LIST&gt;\t\t\t\t\t\t&lt;CMD&gt;\t\t\t\t\t\t\t&lt;REQUEST&gt;ls -ld&lt;/REQUEST&gt;\t\t\t\t\t\t\t&lt;RESPONSE&gt;drwxr-xr-x 3 root root 20480 Apr 24  2017 /usr/bin&lt;/RESPONSE&gt;\t\t\t\t\t\t&lt;/CMD&gt;\t\t\t\t\t&lt;/CMD-LIST&gt;\t\t\t\t\t&lt;NAME&gt;/usr/bin&lt;/NAME&gt;\t\t\t\t&lt;/DIRECTORY&gt;\t\t\t\t&lt;DIRECTORY&gt;      ....      \t\t\t\t&lt;/DIRECTORY&gt;\t\t\t&lt;/DIRECTORIES&gt;\t\t&lt;/INTEGRITY&gt;\t\t&lt;INTEGRITY domain=~ADMIN-LXC~&gt;\t\t\t&lt;FILES&gt;\t\t\t\t&lt;FILE&gt;                        ....                \t\t\t&lt;/DIRECTORIES&gt;\t\t&lt;/INTEGRITY&gt;\t\t&lt;INTEGRITY domain=~HOST~&gt;\t\t\t&lt;FILES&gt;\t\t\t\t&lt;FILE&gt;\t\t                  \u00a0\u00a0\u00a0  So, where are the commands and the list of files and directories defined?? This is part of the userfiles/auditor.cfg.yml file as well. Jump to the COMPLIANCE_CONFIG section and you will see a YAML specification as shown below#   .\u00a0\u00a0\u00a0Uninstall the appTo uninstall everything that the auditor app installs and to return back to the clean original state, use -u option.To clean up the generated XML files along with the apps and cronjobs, add the `-c\u2019 option to the command#RP/0/RP0/CPU0#rtr#bashFri May  4 16#43#25.437 UTC[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$/misc/scratch/auditor -u -c2018-05-04 16#43#39,234 - DebugZTPLogger - INFO - Using root-lr user specified in auditor.cfg.yml, Username# vagrant2018-05-04 16#43#40,388 - DebugZTPLogger - INFO - Successfully removed xr audit app from XR LXC# audit_xr.bin2018-05-04 16#43#40,389 - DebugZTPLogger - INFO - Successfully cleaned up XR audit cron jobs2018-05-04 16#43#42,714 - DebugZTPLogger - INFO - Successfully removed audit app from Admin LXC# audit_admin.bin2018-05-04 16#43#43,868 - DebugZTPLogger - INFO - Successfully cleaned up admin audit cron jobs2018-05-04 16#43#47,888 - DebugZTPLogger - INFO - Successfully removed audit app from HOST# audit_host.bin2018-05-04 16#43#49,271 - DebugZTPLogger - INFO - Successfully cleaned up host audit cron jobs2018-05-04 16#43#50,388 - DebugZTPLogger - INFO - Successfully removed Collector audit app from XR LXC# collector.bin2018-05-04 16#43#50,388 - DebugZTPLogger - INFO - Successfully cleaned up collector audit cron jobs2018-05-04 16#43#50,388 - DebugZTPLogger - INFO - Starting cleanup of accumulated xml files as requested on Active-RP2018-05-04 16#44#20,471 - DebugZTPLogger - INFO - Cleaned up xml files on Active-RP XR LXC2018-05-04 16#44#26,199 - DebugZTPLogger - INFO - Cleaned up xml files on Active-RP Admin LXC2018-05-04 16#44#26,200 - DebugZTPLogger - INFO - Successfully uninstalled artifacts, IOS-XR Linux auditing is now OFF[xr-vm_node0_RP0_CPU0#~]$You can issue a /misc/scratch/auditor -l again to check that all the relevant directories got cleaned up.Verbose DebuggingAll the options support verbose debugging, use the -d flag if you\u2019d like to peak into what\u2019s happening behind the scenes when the auditor app installs or uninstalls individual apps and cron jobs.For example, if we use the -d flag during the installation process, we get#[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$/misc/scratch/auditor -i -d2018-05-04 16#49#08,511 - DebugZTPLogger - INFO - Using root-lr user specified in auditor.cfg.yml, Username# vagrant2018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/xr2018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/userfiles2018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/lib2018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/include2018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/host2018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/collector2018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/admin2018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/termios.so2018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/resource.so2018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/readline.so2018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/pyexpat.so2018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/lxml.etree.so2018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/libz.so.12018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/libz-a147dcb0.so.1.2.32018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/libtinfo.so.52018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/libssl.so.1.0.02018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/libreadline.so.62018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/libpython2.7.so.1.02018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/libffi.so.62018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/libexpat.so.12018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/libcrypto.so.1.0.02018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/libbz2.so.1.02018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/bz2.so2018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/_ssl.so2018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/_multibytecodec.so2018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/_json.so2018-05-04 16#49#08,512 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/_hashlib.so2018-05-04 16#49#08,513 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/_ctypes.so2018-05-04 16#49#08,513 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/_codecs_tw.so2018-05-04 16#49#08,513 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/_codecs_kr.so2018-05-04 16#49#08,513 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/_codecs_jp.so2018-05-04 16#49#08,513 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/_codecs_iso2022.so2018-05-04 16#49#08,513 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/_codecs_hk.so2018-05-04 16#49#08,513 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/_codecs_cn.so2018-05-04 16#49#08,513 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/xr/audit_xr.cron2018-05-04 16#49#08,513 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/xr/audit_xr.bin2018-05-04 16#49#08,513 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/userfiles/id_rsa_server2018-05-04 16#49#08,514 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/userfiles/compliance.xsd2018-05-04 16#49#08,514 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/userfiles/auditor.cfg.yml2018-05-04 16#49#08,514 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/lib/python2.72018-05-04 16#49#08,514 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/lib/python2.7/config-x86_64-linux-gnu2018-05-04 16#49#08,514 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/lib/python2.7/config-x86_64-linux-gnu/Makefile2018-05-04 16#49#08,514 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/include/python2.72018-05-04 16#49#08,514 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/include/python2.7/pyconfig.h2018-05-04 16#49#08,514 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/host/audit_host.cron2018-05-04 16#49#08,514 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/host/audit_host.bin2018-05-04 16#49#08,514 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/collector/collector.cron2018-05-04 16#49#08,514 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/collector/collector.bin2018-05-04 16#49#08,514 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/admin/audit_admin.cron2018-05-04 16#49#08,514 - DebugZTPLogger - DEBUG - /tmp/_MEIMqQ1ge/admin/audit_admin.bin2018-05-04 16#49#08,514 - DebugZTPLogger - DEBUG - bash cmd being run# ls /misc/scratch/2018-05-04 16#49#08,521 - DebugZTPLogger - DEBUG - output# auditorauditor_collated_logs.tar.gzclihistoryconfigcorecryptoid_rsanvgen_tracesstatus_filetpa.logztp2018-05-04 16#49#08,521 - DebugZTPLogger - DEBUG - error# 2018-05-04 16#49#08,529 - DebugZTPLogger - INFO - XR LXC audit app successfully copied2018-05-04 16#49#08,531 - DebugZTPLogger - DEBUG - bash cmd being run# chmod 0644 /etc/cron.d/audit_cron_xr_2018-05-04_16-49-082018-05-04 16#49#08,537 - DebugZTPLogger - DEBUG - output# 2018-05-04 16#49#08,537 - DebugZTPLogger - DEBUG - error# 2018-05-04 16#49#08,537 - DebugZTPLogger - INFO - XR LXC audit cron job successfully set up2018-05-04 16#49#08,537 - DebugZTPLogger - DEBUG - Received bash cmd# ls /misc/scratch to run in shell of active RP's admin LXC2018-05-04 16#49#08,537 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run ssh root@192.0.0.1 ls /misc/scratch~2018-05-04 16#49#09,093 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run ssh root@192.0.0.1 ls /misc/scratch', 'Fri May  4  16#49#08.992 UTC', 'calvados_log_aaad_0_0.out', 'calvados_log_confd_helper_0_0.out', 'calvados_log_instagt_log_0_0.out', 'calvados_log_tacacsd_0_0.out', 'calvados_log_vmm_0_0.out', 'card_specific_install', 'core', 'shelf_mgr_pds', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#09,094 - DebugZTPLogger - DEBUG - Inside active_adminscp2018-05-04 16#49#09,094 - DebugZTPLogger - DEBUG - Received scp request to transfer file from XR LXC to admin LXC2018-05-04 16#49#09,094 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run scp root@192.0.0.4#/tmp/_MEIMqQ1ge/./admin/audit_admin.bin /misc/scratch/audit_aadscp_audit_admin.bin~2018-05-04 16#49#09,727 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run scp root@192.0.0.4#/tmp/_MEIMqQ1ge/./admin/audit_admin.bin /misc/scratch/audit_aadscp_audit_admin.bin', 'Fri May  4  16#49#09.545 UTC', 'audit_admin.bin                                 0%    0     0.0KB/s   --#-- ETA', 'audit_admin.bin                               100% 6882KB   6.7MB/s   00#00', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#09,727 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run scp /misc/scratch/audit_aadscp_audit_admin.bin root@192.0.0.1#/misc/scratch/audit_admin.bin~2018-05-04 16#49#10,379 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run scp /misc/scratch/audit_aadscp_audit_admin.bin root@192.0.0.1#/misc/scratch/audit_admin.bin', 'Fri May  4  16#49#10.200 UTC', 'audit_aadscp_audit_admin.bin                    0%    0     0.0KB/s   --#-- ETA', 'audit_aadscp_audit_admin.bin                  100% 6882KB   6.7MB/s   00#00', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#10,380 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run rm -f /misc/scratch/audit_aadscp_audit_admin.bin~2018-05-04 16#49#11,056 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run rm -f /misc/scratch/audit_aadscp_audit_admin.bin', 'Fri May  4  16#49#10.991 UTC', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#11,056 - DebugZTPLogger - INFO - Admin LXC audit app successfully copied2018-05-04 16#49#11,057 - DebugZTPLogger - DEBUG - ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run scp /misc/scratch/audit_aadscp_audit_admin.bin root@192.0.0.1#/misc/scratch/audit_admin.bin', 'Fri May  4  16#49#10.200 UTC', 'audit_aadscp_audit_admin.bin                    0%    0     0.0KB/s   --#-- ETA', 'audit_aadscp_audit_admin.bin                  100% 6882KB   6.7MB/s   00#00', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#11,057 - DebugZTPLogger - DEBUG - Received bash cmd# rm -f /etc/cron.d/audit_cron_admin_* to run in shell of active RP's admin LXC2018-05-04 16#49#11,057 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run ssh root@192.0.0.1 rm -f /etc/cron.d/audit_cron_admin_*~2018-05-04 16#49#11,624 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run ssh root@192.0.0.1 rm -f /etc/cron.d/audit_cron_admin_*', 'Fri May  4  16#49#11.509 UTC', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#11,625 - DebugZTPLogger - DEBUG - Received bash cmd# ls /etc/cron.d/ to run in shell of active RP's admin LXC2018-05-04 16#49#11,625 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run ssh root@192.0.0.1 ls /etc/cron.d/~2018-05-04 16#49#12,199 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run ssh root@192.0.0.1 ls /etc/cron.d/', 'Fri May  4  16#49#12.950 UTC', 'logrotate.conf', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#12,200 - DebugZTPLogger - DEBUG - bash cmd being run# chmod 0644 /misc/app_host/audit_cron_admin_2018-05-04_16-49-112018-05-04 16#49#12,205 - DebugZTPLogger - DEBUG - output# 2018-05-04 16#49#12,205 - DebugZTPLogger - DEBUG - error# 2018-05-04 16#49#12,205 - DebugZTPLogger - DEBUG - Inside active_adminscp2018-05-04 16#49#12,205 - DebugZTPLogger - DEBUG - Received scp request to transfer file from XR LXC to admin LXC2018-05-04 16#49#12,205 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run scp root@192.0.0.4#/misc/app_host/audit_cron_admin_2018-05-04_16-49-11 /misc/scratch/audit_aadscp_audit_cron_admin_2018-05-04_16-49-11~2018-05-04 16#49#12,822 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run scp root@192.0.0.4#/misc/app_host/audit_cron_admin_2018-05-04_16-49-11 /misc/scratch/audit_aadscp_audit_cron_admin_2018-05-04_16-49-11', 'Fri May  4  16#49#12.660 UTC', 'audit_cron_admin_2018-05-04_16-49-11            0%    0     0.0KB/s   --#-- ETA', 'audit_cron_admin_2018-05-04_16-49-11          100%   89     0.1KB/s   00#00', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#12,822 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run scp /misc/scratch/audit_aadscp_audit_cron_admin_2018-05-04_16-49-11 root@192.0.0.1#/etc/cron.d/audit_cron_admin_2018-05-04_16-49-11~2018-05-04 16#49#13,381 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run scp /misc/scratch/audit_aadscp_audit_cron_admin_2018-05-04_16-49-11 root@192.0.0.1#/etc/cron.d/audit_cron_admin_2018-05-04_16-49-11', 'Fri May  4  16#49#13.275 UTC', 'audit_aadscp_audit_cron_admin_2018-05-04_16-4   0%    0     0.0KB/s   --#-- ETA', 'audit_aadscp_audit_cron_admin_2018-05-04_16-4 100%   89     0.1KB/s   00#00', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#13,381 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run rm -f /misc/scratch/audit_aadscp_audit_cron_admin_2018-05-04_16-49-11~2018-05-04 16#49#13,935 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run rm -f /misc/scratch/audit_aadscp_audit_cron_admin_2018-05-04_16-49-11', 'Fri May  4  16#49#13.887 UTC', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#13,935 - DebugZTPLogger - INFO - Admin LXC audit cron file successfully copied and activated2018-05-04 16#49#13,935 - DebugZTPLogger - DEBUG - ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run scp /misc/scratch/audit_aadscp_audit_cron_admin_2018-05-04_16-49-11 root@192.0.0.1#/etc/cron.d/audit_cron_admin_2018-05-04_16-49-11', 'Fri May  4  16#49#13.275 UTC', 'audit_aadscp_audit_cron_admin_2018-05-04_16-4   0%    0     0.0KB/s   --#-- ETA', 'audit_aadscp_audit_cron_admin_2018-05-04_16-4 100%   89     0.1KB/s   00#00', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#13,935 - DebugZTPLogger - DEBUG - Received host command request# ~ls /misc/scratch~2018-05-04 16#49#13,936 - DebugZTPLogger - DEBUG - Received bash cmd# ssh root@10.0.2.16 ls /misc/scratch to run in shell of active RP's admin LXC2018-05-04 16#49#13,936 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run ssh root@192.0.0.1 ssh root@10.0.2.16 ls /misc/scratch~2018-05-04 16#49#14,610 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run ssh root@192.0.0.1 ssh root@10.0.2.16 ls /misc/scratch', 'Fri May  4  16#49#14.390 UTC', 'core', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#14,610 - DebugZTPLogger - DEBUG - Received scp request to transfer file from XR LXC to host shell2018-05-04 16#49#14,611 - DebugZTPLogger - DEBUG - Inside active_adminscp2018-05-04 16#49#14,611 - DebugZTPLogger - DEBUG - Received scp request to transfer file from XR LXC to admin LXC2018-05-04 16#49#14,611 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run scp root@192.0.0.4#/tmp/_MEIMqQ1ge/./host//audit_host.bin /misc/scratch/audit_aadscp_audit_host.bin~2018-05-04 16#49#15,388 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run scp root@192.0.0.4#/tmp/_MEIMqQ1ge/./host//audit_host.bin /misc/scratch/audit_aadscp_audit_host.bin', 'Fri May  4  16#49#15.990 UTC', 'audit_host.bin                                  0%    0     0.0KB/s   --#-- ETA', 'audit_host.bin                                100% 6881KB   6.7MB/s   00#00', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#15,389 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run scp /misc/scratch/audit_aadscp_audit_host.bin root@192.0.0.1#/misc/scratch/audit_ahscp_audit_host.bin~2018-05-04 16#49#16,006 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run scp /misc/scratch/audit_aadscp_audit_host.bin root@192.0.0.1#/misc/scratch/audit_ahscp_audit_host.bin', 'Fri May  4  16#49#15.846 UTC', 'audit_aadscp_audit_host.bin                     0%    0     0.0KB/s   --#-- ETA', 'audit_aadscp_audit_host.bin                   100% 6881KB   6.7MB/s   00#00', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#16,006 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run rm -f /misc/scratch/audit_aadscp_audit_host.bin~2018-05-04 16#49#16,596 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run rm -f /misc/scratch/audit_aadscp_audit_host.bin', 'Fri May  4  16#49#16.538 UTC', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#16,596 - DebugZTPLogger - DEBUG - Received bash cmd# scp /misc/scratch/audit_ahscp_audit_host.bin root@10.0.2.16#/misc/scratch/audit_host.bin to run in shell of active RP's admin LXC2018-05-04 16#49#16,597 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run ssh root@192.0.0.1 scp /misc/scratch/audit_ahscp_audit_host.bin root@10.0.2.16#/misc/scratch/audit_host.bin~2018-05-04 16#49#17,321 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run ssh root@192.0.0.1 scp /misc/scratch/audit_ahscp_audit_host.bin root@10.0.2.16#/misc/scratch/audit_host.bin', 'Fri May  4  16#49#17.810 UTC', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#17,321 - DebugZTPLogger - DEBUG - Received bash cmd# rm -f /misc/scratch/audit_ahscp_audit_host.bin to run in shell of active RP's admin LXC2018-05-04 16#49#17,322 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run ssh root@192.0.0.1 rm -f /misc/scratch/audit_ahscp_audit_host.bin~2018-05-04 16#49#17,949 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run ssh root@192.0.0.1 rm -f /misc/scratch/audit_ahscp_audit_host.bin', 'Fri May  4  16#49#17.841 UTC', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#17,949 - DebugZTPLogger - INFO - HOST audit app successfully copied2018-05-04 16#49#17,949 - DebugZTPLogger - DEBUG - ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run ssh root@192.0.0.1 scp /misc/scratch/audit_ahscp_audit_host.bin root@10.0.2.16#/misc/scratch/audit_host.bin', 'Fri May  4  16#49#17.810 UTC', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#17,949 - DebugZTPLogger - DEBUG - Received host command request# ~rm -f /etc/cron.d/audit_cron_host_*~2018-05-04 16#49#17,949 - DebugZTPLogger - DEBUG - Received bash cmd# ssh root@10.0.2.16 rm -f /etc/cron.d/audit_cron_host_* to run in shell of active RP's admin LXC2018-05-04 16#49#17,949 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run ssh root@192.0.0.1 ssh root@10.0.2.16 rm -f /etc/cron.d/audit_cron_host_*~2018-05-04 16#49#18,628 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run ssh root@192.0.0.1 ssh root@10.0.2.16 rm -f /etc/cron.d/audit_cron_host_*', 'Fri May  4  16#49#18.414 UTC', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#18,628 - DebugZTPLogger - DEBUG - Received host command request# ~ls /etc/cron.d/~2018-05-04 16#49#18,628 - DebugZTPLogger - DEBUG - Received bash cmd# ssh root@10.0.2.16 ls /etc/cron.d/ to run in shell of active RP's admin LXC2018-05-04 16#49#18,629 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run ssh root@192.0.0.1 ssh root@10.0.2.16 ls /etc/cron.d/~2018-05-04 16#49#19,290 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run ssh root@192.0.0.1 ssh root@10.0.2.16 ls /etc/cron.d/', 'Fri May  4  16#49#19.900 UTC', 'logrotate.conf', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#19,290 - DebugZTPLogger - DEBUG - bash cmd being run# chmod 0644 /misc/app_host/audit_cron_host_2018-05-04_16-49-172018-05-04 16#49#19,295 - DebugZTPLogger - DEBUG - output# 2018-05-04 16#49#19,295 - DebugZTPLogger - DEBUG - error# 2018-05-04 16#49#19,295 - DebugZTPLogger - DEBUG - Received scp request to transfer file from XR LXC to host shell2018-05-04 16#49#19,295 - DebugZTPLogger - DEBUG - Inside active_adminscp2018-05-04 16#49#19,295 - DebugZTPLogger - DEBUG - Received scp request to transfer file from XR LXC to admin LXC2018-05-04 16#49#19,295 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run scp root@192.0.0.4#/misc/app_host/audit_cron_host_2018-05-04_16-49-17 /misc/scratch/audit_aadscp_audit_cron_host_2018-05-04_16-49-17~2018-05-04 16#49#19,902 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run scp root@192.0.0.4#/misc/app_host/audit_cron_host_2018-05-04_16-49-17 /misc/scratch/audit_aadscp_audit_cron_host_2018-05-04_16-49-17', 'Fri May  4  16#49#19.753 UTC', 'audit_cron_host_2018-05-04_16-49-17             0%    0     0.0KB/s   --#-- ETA', 'audit_cron_host_2018-05-04_16-49-17           100%   88     0.1KB/s   00#00', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#19,903 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run scp /misc/scratch/audit_aadscp_audit_cron_host_2018-05-04_16-49-17 root@192.0.0.1#/misc/scratch/audit_ahscp_audit_cron_host_2018-05-04_16-49-17~2018-05-04 16#49#20,500 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run scp /misc/scratch/audit_aadscp_audit_cron_host_2018-05-04_16-49-17 root@192.0.0.1#/misc/scratch/audit_ahscp_audit_cron_host_2018-05-04_16-49-17', 'Fri May  4  16#49#20.389 UTC', 'audit_aadscp_audit_cron_host_2018-05-04_16-49   0%    0     0.0KB/s   --#-- ETA', 'audit_aadscp_audit_cron_host_2018-05-04_16-49 100%   88     0.1KB/s   00#00', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#20,500 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run rm -f /misc/scratch/audit_aadscp_audit_cron_host_2018-05-04_16-49-17~2018-05-04 16#49#21,032 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run rm -f /misc/scratch/audit_aadscp_audit_cron_host_2018-05-04_16-49-17', 'Fri May  4  16#49#20.991 UTC', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#21,033 - DebugZTPLogger - DEBUG - Received bash cmd# scp /misc/scratch/audit_ahscp_audit_cron_host_2018-05-04_16-49-17 root@10.0.2.16#/etc/cron.d/audit_cron_host_2018-05-04_16-49-17 to run in shell of active RP's admin LXC2018-05-04 16#49#21,033 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run ssh root@192.0.0.1 scp /misc/scratch/audit_ahscp_audit_cron_host_2018-05-04_16-49-17 root@10.0.2.16#/etc/cron.d/audit_cron_host_2018-05-04_16-49-17~2018-05-04 16#49#21,693 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run ssh root@192.0.0.1 scp /misc/scratch/audit_ahscp_audit_cron_host_2018-05-04_16-49-17 root@10.0.2.16#/etc/cron.d/audit_cron_host_2018-05-04_16-49-17', 'Fri May  4  16#49#21.488 UTC', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#21,694 - DebugZTPLogger - DEBUG - Received bash cmd# rm -f /misc/scratch/audit_ahscp_audit_cron_host_2018-05-04_16-49-17 to run in shell of active RP's admin LXC2018-05-04 16#49#21,694 - DebugZTPLogger - DEBUG - Received admin exec command request# ~run ssh root@192.0.0.1 rm -f /misc/scratch/audit_ahscp_audit_cron_host_2018-05-04_16-49-17~2018-05-04 16#49#22,283 - DebugZTPLogger - DEBUG - Exec command output is ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run ssh root@192.0.0.1 rm -f /misc/scratch/audit_ahscp_audit_cron_host_2018-05-04_16-49-17', 'Fri May  4  16#49#22.174 UTC', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#22,283 - DebugZTPLogger - INFO - Host audit cron file successfully copied and activated2018-05-04 16#49#22,284 - DebugZTPLogger - DEBUG - ['vagrant connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0', '\\x1b[?7hsysadmin-vm#0_RP0# run ssh root@192.0.0.1 scp /misc/scratch/audit_ahscp_audit_cron_host_2018-05-04_16-49-17 root@10.0.2.16#/etc/cron.d/audit_cron_host_2018-05-04_16-49-17', 'Fri May  4  16#49#21.488 UTC', 'sysadmin-vm#0_RP0#']2018-05-04 16#49#22,285 - DebugZTPLogger - DEBUG - bash cmd being run# ls /misc/scratch2018-05-04 16#49#22,304 - DebugZTPLogger - DEBUG - output# audit_xr.binauditorauditor_collated_logs.tar.gzclihistoryconfigcorecryptoid_rsanvgen_tracesstatus_filetpa.logztp2018-05-04 16#49#22,304 - DebugZTPLogger - DEBUG - error# 2018-05-04 16#49#22,312 - DebugZTPLogger - INFO - Collector app successfully copied2018-05-04 16#49#22,313 - DebugZTPLogger - DEBUG - bash cmd being run# chmod 0644 /etc/cron.d/audit_cron_collector_2018-05-04_16-49-222018-05-04 16#49#22,318 - DebugZTPLogger - DEBUG - output# 2018-05-04 16#49#22,318 - DebugZTPLogger - DEBUG - error# 2018-05-04 16#49#22,319 - DebugZTPLogger - INFO - Collector cron job successfully set up in XR LXC2018-05-04 16#49#22,319 - DebugZTPLogger - INFO - Successfully set up artifacts, IOS-XR Linux auditing is now ON[xr-vm_node0_RP0_CPU0#~]$Troubleshooting#  Gathering logsIn case something goes wrong and a particular app or cron job does not behave properly, it is advisable to collect logs from all the domains into a single tar ball.This is made easy by the -o &lt;tarfile_output_dir&gt; option which allows a user to quickly gather the logs from all domains (Active and Standby RP) and create a tarfile called  auditor_collated_logs.tar.gz for you.[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$/misc/scratch/auditor -o /misc/scratch/2018-05-04 16#53#34,073 - DebugZTPLogger - INFO - Using root-lr user specified in auditor.cfg.yml, Username# vagrant2018-05-04 16#53#34,079 - DebugZTPLogger - INFO - Successfully saved audit logs for Active XR LXC to /misc/scratch/auditor_collected_logs/ACTIVE-XR-LXC.audit.log2018-05-04 16#53#35,906 - DebugZTPLogger - INFO - Successfully copied audit logs from Active Admin LXC to Active XR LXC at /misc/scratch/auditor_collected_logs/ACTIVE-ADMIN-LXC.audit.log2018-05-04 16#53#38,967 - DebugZTPLogger - INFO - Successfully copied audit logs from Active HOST to Active XR LXC at /misc/scratch/auditor_collected_logs/ACTIVE-HOST.audit.log2018-05-04 16#53#39,001 - DebugZTPLogger - INFO - Audit logs tarfile created at# /misc/scratch//auditor_collated_logs.tar.gz[xr-vm_node0_RP0_CPU0#~]$The log tar ball will then be available to copy from the router directory to another location for inspection and troubleshooting.[xr-vm_node0_RP0_CPU0#~]$ls -lrt /misc/scratch/auditor_collated_logs.tar.gz -rw-r--r-- 1 root root 28019 May  4 16#53 /misc/scratch/auditor_collated_logs.tar.gz[xr-vm_node0_RP0_CPU0#~]$Support for Active/Standby RP systemsAs mentioned earlier, the app supports active/standby systems as well. To demonstate see the outputs from an NCS5508 device with an active/standby RP to see how the application installs components on both the RPs#NCS-5500 router running IOS-XR 6.1.31#RP/0/RP0/CPU0#rtr#show version Sat May  5 00#43#20.533 UTCCisco IOS XR Software, Version 6.1.31Copyright (c) 2013-2016 by Cisco Systems, Inc.Build Information# Built By     # radharan Built On     # Wed May 24 02#15#20 PDT 2017 Build Host   # iox-lnx-049 Workspace    # /san2/production/6.1.31/ncs5500/workspace Version      # 6.1.31 Location     # /opt/cisco/XR/packages/cisco NCS-5500 () processor System uptime is 2 days, 17 hours, 47 minutesRP/0/RP0/CPU0#rtr#Active and Standby RPs are present and in the High-Availability State#RP/0/RP0/CPU0#rtr#show redundancy summary Sat May  5 00#43#28.737 UTC    Active Node    Standby Node    -----------    ------------     0/RP0/CPU0      0/RP1/CPU0 (Node Ready, NSR#Not Configured)RP/0/RP0/CPU0#rtr#RP/0/RP0/CPU0#rtr#Follow the same process as shown earlier#  Set up userfiles/auditor.cfg.yml appropriately with ROUTER_CONFIG and SERVER_CONFIG sections and transfer the app to the router.  In this case, I have set up the auditor.cfg.yml ROUTER_CONFIG such that the OUTGOING_INTERFACE is unset. This forces the app to use the mgmt port ip by default. I do this so that when I force a switchover to happen, it becomes easy to distinguish on the server that is receiving the XML data that there is switch from the active to standby based on the name of the compliance file generated.When you run the installation of the app, you will see logs indicating that components were installed on the standby RP as well#[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$/misc/scratch/auditor -i2018-05-05 00#45#58,971 - DebugZTPLogger - INFO - Using root-lr user specified in auditor.cfg.yml, Username# vagrant2018-05-05 00#46#00,588 - DebugZTPLogger - INFO - XR LXC audit app successfully copied2018-05-05 00#46#00,595 - DebugZTPLogger - INFO - XR LXC audit cron job successfully set up2018-05-05 00#46#14,238 - DebugZTPLogger - INFO - Admin LXC audit app successfully copied2018-05-05 00#46#23,931 - DebugZTPLogger - INFO - Admin LXC audit cron file successfully copied and activated2018-05-05 00#46#39,428 - DebugZTPLogger - INFO - HOST audit app successfully copied2018-05-05 00#46#52,978 - DebugZTPLogger - INFO - Host audit cron file successfully copied and activated2018-05-05 00#46#54,534 - DebugZTPLogger - INFO - Collector app successfully copied2018-05-05 00#46#54,540 - DebugZTPLogger - INFO - Collector cron job successfully set up in XR LXC2018-05-05 00#46#54,964 - DebugZTPLogger - INFO - Standby XR LXC auditor app successfully copied2018-05-05 00#46#56,634 - DebugZTPLogger - INFO - Standby XR LXC audit app successfully copied2018-05-05 00#46#56,958 - DebugZTPLogger - INFO - Standby XR LXC audit cron file successfully copied and activated2018-05-05 00#47#09,404 - DebugZTPLogger - INFO - Standby Admin LXC audit app successfully copied2018-05-05 00#47#20,155 - DebugZTPLogger - INFO - Standby Admin LXC audit cron file successfully copied and activated2018-05-05 00#47#36,755 - DebugZTPLogger - INFO - Standby HOST audit app successfully copied2018-05-05 00#47#50,351 - DebugZTPLogger - INFO - Standby host audit cron file successfully copied and activated2018-05-05 00#47#52,011 - DebugZTPLogger - INFO - Standby XR LXC Collector app successfully copied2018-05-05 00#47#52,335 - DebugZTPLogger - INFO - Standby XR LXC collector cron file successfully copied and activated2018-05-05 00#47#52,336 - DebugZTPLogger - INFO - Successfully set up artifacts, IOS-XR Linux auditing is now ON[xr-vm_node0_RP0_CPU0#~]$On my connected server, I see the compliance file appear just like the vagrant scenario#cisco@dhcpserver#~$ cisco@dhcpserver#~$ ls -lrt ~/compliance_audit*-rw-rw-r-- 1 cisco cisco 24629 May  4 00#56 /home/cisco/compliance_audit_rtr_11_11_11_42.xmlcisco@dhcpserver#~$ Now let\u2019s force a switchover to happen on the router#RP/0/RP0/CPU0#rtr#redundancy switchover Sat May  5 00#53#38.742 UTCProceed with switchover 0/RP0/CPU0 -&gt; 0/RP1/CPU0? [confirm]RP/0/RP1/CPU0#May  5 00#53#39.486 # rmf_svr[328]# %HA-REDCON-4-FAILOVER_REQUESTED # failover has been requested by operator, waiting to initiate Initiating switch-over.RP/0/RP0/CPU0#rtr#[00#53#44.034] Sending KILL signal to ds..[00#53#44.034] Sending KILL signal to processmgr..PM disconnect successStopping OpenBSD Secure Shell server# sshdinitctl# Unknown instance# Stopping system message bus# dbus.Libvirt not initialized for container instanceStopping system log daemon...0Stopping internet superserver# xinetd.Now let\u2019s wait on the server for about 2-3 minutes, and we should see a new compliance file show up#cisco@dhcpserver#~$ cisco@dhcpserver#~$ cisco@dhcpserver#~$ ls -lrt ~/compliance_audit*-rw-rw-r-- 1 cisco cisco 24629 May  4 00#57 /home/cisco/compliance_audit_rtr_11_11_11_42.xmlcisco@dhcpserver#~$ cisco@dhcpserver#~$ cisco@dhcpserver#~$ ls -lrt ~/compliance_audit*-rw-rw-r-- 1 cisco cisco 24629 May  4 00#57 /home/cisco/compliance_audit_rtr_11_11_11_42.xml-rw-rw-r-- 1 cisco cisco 24373 May  4 00#59 /home/cisco/compliance_audit_rtr_11_11_11_41.xmlcisco@dhcpserver#~$ Perfect! Within 2 minutes, we have the auditor apps on the standby RP sending us the required compliance data!", "url": "https://xrdocs.github.io/application-hosting/blogs/2018-05-01-anatomy-of-a-network-app-xr-auditor/", "tags": "vagrant, iosxr, cisco, linux, security, audit, cron, python, pyinstaller, application", "title": "Anatomy of a Network App:   &quot;xr-auditor&quot;", "author": "Akshat Sharma"}, "tutorials-2017-09-25-using-service-layer-apis-with-vagrant-iosxr": {"content": "     IOS-XR Service Layer APIs  Introduction  Clone the development topology          Understand the Vagrantfile        GRPC/Python environment (devbox)          Use our Vagrant box      Build your own?        Clone the Object Model Code into Devbox  Bring up the Router  Check connectivity from the devbox  Run the python unit-tests  Writing your own Python-GRPC client  IntroductionIf you\u2019ve haven\u2019t played around with the vagrant IOS-XR box yet, now might be a good time to take a look at the following tutorials and get your environment set up#      Generate API Key# Generate an API Key using your CCO (cisco.com) ID to download the Vagrant box for IOS-XR with SL-API support.        Vagrant IOS-XR Quick Start# Use the downloaded box and learn how to boot it on your laptop and play with a couple of sample topologies.        Bootstrap XR Configuration with Vagrant (optional)# Learn how a simple shell provisioner can be used to apply a configuration on boot with a Vagrant IOS-XR box.  Once you have everything set up, you should be able to see the IOS-XRv vagrant box in the vagrant box list command#  AKSHSHAR-M-K0DS#~ akshshar$ vagrant box list  IOS-XRv (virtualbox, 0)  AKSHSHAR-M-K0DS#~ akshshar$ This tutorial is meant to get you up and running with an environment to play with the Service Layer APIs on IOS-XR. An introduction to these APIs can be found here#  https#//xrdocs.github.io/cisco-service-layer/tutorials/service-layer-intro/To get more details on the APIs, check out the API-Docs section#  https#//xrdocs.github.io/cisco-service-layer/apidocs/In this tutorial we set up a GRPC/python environment that may be used to build your own python client to interact with the SL APIs.A go client binary is also included as part of the \u201cservice-layer-objmodel\u201d code itself at the following link# (You will also find a quick-start go client code located there)  https#//github.com/cisco-service-layer/service-layer-objmodel/tree/master/grpc/go/src/tutorialClone the development topologyWe\u2019ll use a simple Vagrant topology as shown below#Clone the vagrant-examples repo to get started#AKSHSHAR-M-K0DS#~ akshshar$ git clone https#//github.com/cisco-service-layer/vagrant-examples.gitCloning into 'vagrant-examples'...remote# Counting objects# 78, done.remote# Compressing objects# 100% (42/42), done.remote# Total 78 (delta 13), reused 78 (delta 13), pack-reused 0Unpacking objects# 100% (78/78), done.Checking connectivity... done.AKSHSHAR-M-K0DS#~ akshshar$ AKSHSHAR-M-K0DS#~ akshshar$cd vagrant-examples/iosxr-grpc-setup/ AKSHSHAR-M-K0DS#iosxr-grpc-setup akshshar$ AKSHSHAR-M-K0DS#iosxr-grpc-setup akshshar$ lsVagrantfile\tconfigs\t\tscripts AKSHSHAR-M-K0DS#iosxr-grpc-setup akshshar$  Understand the VagrantfileThe Vagrantfile located under vagrant-examples/iosxr-grpc-setup/ is shown in its entirety below#      Notice the port forwarding enabled for the rtr node (IOS-XR) which corresponds to the grpcserver port (57344) configured as part of the bootstrap script. This makes the port accessible    on the management port (nat network for Vagrant).        Further, eth1 of the devbox is connected to GigabitEthernet0/0/0/0 of the IOS-XR vagrant node,making the grpc server available on this path as well.  Vagrant.configure(2) do |config|     config.vm.define ~rtr~ do |node|      node.vm.box =  ~thinxr-aug3~      node.vm.network ~forwarded_port~, guest# 57344, host# 57344       # gig0/0/0 connected to ~link1~      # auto_config is not supported for XR, set to false      node.vm.network #private_network, virtualbox__intnet# ~link1~, auto_config# false      #Source a config file and apply it to XR      node.vm.provision ~file~, source# ~configs/rtr_config~, destination# ~/home/vagrant/rtr_config~      node.vm.provision ~shell~ do |s|          s.path =  ~scripts/apply_config.sh~          s.args = [~/home/vagrant/rtr_config~]      end    end     config.vm.define ~devbox~ do |node|      node.vm.box =  ~ciscoxr/grpc-ubuntu-14.04~      # eth1 connected to link1      # auto_config is supported for an ubuntu instance      node.vm.network #private_network, virtualbox__intnet# ~link1~, ip# ~11.1.1.20~    endendThe following configuration is applied to the IOS-XR instance on boot#(located @  vagrant-examples/iosxr-grpc-setup/configs/rtr_config)!! XR configuration!interface GigabitEthernet0/0/0/0ip address 11.1.1.10/24no shutdown!grpc   port 57344  address-family ipv4  service-layer!!endThis configuration is in addition to a dhcp client configured on the MgmtEth0/RP0/CPU0/0 port and a user with credentials# username/password = vagrant/vagrant. These are set up in the vagrant box by default.GRPC/Python environment (devbox)Use our Vagrant boxYou\u2019ll need a few dependencies installed to construct your own grpc python client. To make things easier we\u2019ve already created an ubuntu-14.04 vagrant box with everything installed.If you notice in the above Vagrantfile, we specify a name for a special Vagrant box# config.vm.define ~devbox~ do |node|      node.vm.box =  ~ciscoxr/grpc-ubuntu-14.04~      # eth1 connected to link1ciscoxr/grpc-ubuntu-14.04 is up on Atlas for your convenience and you can include it in your Vagrantfiles as shown above.To bring up the devbox, simply issue a \u201cvagrant up devbox\u201d inside the cloned directory#AKSHSHAR-M-K0DS#iosxr-grpc-setup akshshar$ pwd/Users/akshshar/vagrant-examples/iosxr-grpc-setupAKSHSHAR-M-K0DS#iosxr-grpc-setup akshshar$ AKSHSHAR-M-K0DS#iosxr-grpc-setup akshshar$ lsVagrantfile\tconfigs\t\tscriptsAKSHSHAR-M-K0DS#iosxr-grpc-setup akshshar$ vagrant up devbox Bringing machine 'devbox' up with 'virtualbox' provider...==&gt; devbox# Importing base box 'ciscoxr/grpc-ubuntu-14.04'...----------------------- snip output --------------------------Hop into the devbox once up#vagrant ssh devboxAll dependencies should be installed already#vagrant@vagrant-ubuntu-trusty-64#~$ protoc --versionlibprotoc 3.0.0vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ pip show grpcio ---Name# grpcioVersion# 0.13.1 Location# /usr/local/lib/python2.7/dist-packagesRequires# six, enum34, futures, protobufvagrant@vagrant-ubuntu-trusty-64#~$ Build your own?If you\u2019d much rather build your own devbox environment, then let\u2019s use a pristine Ubuntu 14.04box. Make the following change in the Vagrantfile# config.vm.define ~devbox~ do |node|      node.vm.box =  ~ubuntu/trusty64~      # eth1 connected to link1You will need the following steps#  Bring up the devbox first#AKSHSHAR-M-K0DS#iosxr-grpc-setup akshshar$ pwd/Users/akshshar/vagrant-examples/iosxr-grpc-setupAKSHSHAR-M-K0DS#iosxr-grpc-setup akshshar$ AKSHSHAR-M-K0DS#iosxr-grpc-setup akshshar$ lsVagrantfile\tconfigs\t\tscriptsAKSHSHAR-M-K0DS#iosxr-grpc-setup akshshar$ vagrant up devbox Bringing machine 'devbox' up with 'virtualbox' provider...==&gt; devbox# Importing base box 'ciscoxr/grpc-ubuntu-14.04'...----------------------- snip output --------------------------  Hop into the devboxvagrant ssh devbox  Install basic dependencies#sudo apt-get updatesudo apt-get -y install autoconf automake libtool curl make g++ unzip git python-pip python-dev   Clone and build google protobuf#git clone https#//github.com/google/protobuf.git ~/protobufcd ~/protobuf/./autogen.sh./configuremakesudo make installsudo ldconfig  Clone and build grpcgit clone https#//github.com/grpc/grpc.git ~/grpccd ~/grpc/git submodule update --initmakesudo make install  Install the python grpc package and other dependenciessudo pip install six grpcio=='0.13.1' py2-ipaddress=='3.4'That\u2019s it! You\u2019re now ready to launch the router and test things out.Clone the Object Model Code into DevboxBy now, you should have your devbox up and running with the dependencies installed.Clone the Object Model code#The following command must be run inside the devboxgit clone https#//github.com/cisco-service-layer/service-layer-objmodel.git ~/service-layer-objmodelBring up the RouterOn your laptop, bring up the router connected to the devbox#AKSHSHAR-M-K0DS#iosxr-grpc-setup akshshar$ pwd /Users/akshshar/vagrant-examples/iosxr-grpc-setup AKSHSHAR-M-K0DS#iosxr-grpc-setup akshshar$ lsVagrantfile\tconfigs\t\tscriptsAKSHSHAR-M-K0DS#iosxr-grpc-setup akshshar$ vagrant up rtr Bringing machine 'rtr' up with 'virtualbox' provider...==&gt; rtr# Importing base box 'IOS-XRv'...----------------------- snip output --------------------------Check connectivity from the devboxOnce the router is up, you should be able to issue vagrant status to see both nodes running on your laptop#AKSHSHAR-M-K0DS#iosxr-grpc-setup akshshar$ pwd/Users/akshshar/vagrant-examples/iosxr-grpc-setupAKSHSHAR-M-K0DS#iosxr-grpc-setup akshshar$ AKSHSHAR-M-K0DS#iosxr-grpc-setup akshshar$ vagrant statusCurrent machine states#rtr                       running (virtualbox)devbox                    running (virtualbox)This environment represents multiple VMs. The VMs are all listedabove with their current state. For more information about a specificVM, run `vagrant status NAME`.AKSHSHAR-M-K0DS#iosxr-grpc-setup akshshar$ Jump into the devbox to see that#vagrant ssh devbox      You\u2019re able to ping the directly connected interface of the router (Gig0/0/0/0 at 11.1.1.10)#    vagrant@vagrant-ubuntu-trusty-64#~$ ping 11.1.1.10PING 11.1.1.10 (11.1.1.10) 56(84) bytes of data.64 bytes from 11.1.1.10# icmp_seq=1 ttl=255 time=1.48 ms64 bytes from 11.1.1.10# icmp_seq=2 ttl=255 time=2.12 ms64 bytes from 11.1.1.10# icmp_seq=3 ttl=255 time=2.49 ms            You\u2019re able to connect to port 57344 (opened up by the grpc server) on the router#          Via Gig0/0/0/0        vagrant@vagrant-ubuntu-trusty-64#~$ telnet 11.1.1.10 57344Trying 11.1.1.10...Connected to 11.1.1.10.Escape character is '^]'.                 Via MgmtEth0/RP0/CPU0/0           vagrant@vagrant-ubuntu-trusty-64#~$ telnet 10.0.2.2 57344Trying 10.0.2.2...Connected to 10.0.2.2.Escape character is '^]'.         Perfect! You\u2019re now all set to try out the python grpc client code.Run the python unit-testsStill inside the devbox, set the SERVER_IP and SERVER_PORT variables#You have two options#  If you wish to use the Management Network, then SERVER_IP=10.0.2.2  If you wish to use the Gig0/0/0/0 Network, then SERVER_IP=11.1.1.10For example, if we use the Management Network#vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ export SERVER_IP=10.0.2.2vagrant@vagrant-ubuntu-trusty-64#~$ export SERVER_PORT=57344vagrant@vagrant-ubuntu-trusty-64#~$ Now, run the python unit-tests to verify that everything is fine#cd ~/service-layer-objmodel/grpc/python/src/python -m unittest -v tests.test_lindt  You will see a slew of messages pass by on the screen, as the unit-tests program routes into the router using the Service Layer APIs#  D0808 12#23#28.989076624    1983 ev_posix.c#101]             Using polling engine# polltest_000_global_init (tests.test_lindt.TestSuite_000_Global) ... Waiting to hear from Global event...Server Version 0.0.0Global Event Notification Received! Waiting for events...oktest_001_get_globals (tests.test_lindt.TestSuite_000_Global) ... Max VRF Name Len     # 33Max Iface Name Len   # 64Max Paths per Entry  # 128Max Prim per Entry   # 64Max Bckup per Entry  # 64Max Labels per Entry # 3Min Prim Path-id     # 1Max Prim Path-id     # 64Min Bckup Path-id    # 65Max Bckup Path-id    # 128Max Remote Bckup Addr# 2oktest_000_get_globals (tests.test_lindt.TestSuite_001_Route_IPv4) ... Max v4 VRF Reg Per VRF Msg # 512Max v4 Routes per Route Msg# 1024oktest_001_vrf_registration_add (tests.test_lindt.TestSuite_001_Route_IPv4) ... oktest_002_route_add (tests.test_lindt.TestSuite_001_Route_IPv4) ... oktest_003_00_route_update (tests.test_lindt.TestSuite_001_Route_IPv4) ... oktest_003_01_route_update_nhlfe_connected (tests.test_lindt.TestSuite_001_Route_IPv4) ... oktest_003_02_route_update_nhlfe_ecmp (tests.test_lindt.TestSuite_001_Route_IPv4) ... oktest_003_03_route_update_nhlfe_non_connected (tests.test_lindt.TestSuite_001_Route_IPv4) ... oktest_003_04_route_update_route_connected (tests.test_lindt.TestSuite_001_Route_IPv4) ... oktest_003_05_route_update_route_ecmp (tests.test_lindt.TestSuite_001_Route_IPv4) ... ok------------------------- snip output --------------------------------------------------------------------------------------------------Ran 139 tests in 22.700sOKWriting your own Python-GRPC clientYou now have a development environment up and running on your laptop.To understand how to build your own python-grpc client to interact with Service Layer APIs, head over to API-Docs section where you can find more in-depth information on the available Services, Messsages and Error codes#  https#//xrdocs.github.io/cisco-service-layer/apidocs/index.html", "url": "https://xrdocs.github.io/cisco-service-layer/tutorials/2017-09-25-using-service-layer-apis-with-vagrant-iosxr/", "tags": "vagrant, iosxr, cisco, grpc, service-layer", "title": "Using Service Layer APIs with Vagrant IOS-XR", "author": "Akshat Sharma"}, "tutorials-2016-08-06-introduction-to-rpm": {"content": "     IOS-XR and RPM package manager  Introduction  XR Packages Installation  XR Package Structure  Packages Installation from the Shell  Analyzing Package Using Linux  IntroductionWith IOS XR 6.0, the Package Installation Envelope (PIE) format has been discarded in favor of the RPM Package Manager (RPM) format. This move aligns IOS XR 6.0  and above more closely with RPM-based Linux distribution like Red Hat or Centos. RPM is a free software project and is released under GPL. Briefly, RPMs contain the following elements#  CPIO archive# Contains the absolute path of all the package\u2019s files;  Metadata# Contains the package dependencies;  Scriptlets# Scripts that perform pre and post (un)installation tasks;The Metadata is a XML file that helps determine and resolve package dependencies, to facilitate dependencies resolution the metadata is used to poulate a small database located in /var/lib/rpm that can be queried using tools like YUM or RPM.A Software Maintenance Update (SMU) will be published in the form of tape archive (tar) format. The SMU will contain the following files#  A Readme.txt file describing the content of the SMU;  One or more RPMs;  A Package-mdata.txt that contains a MD5 checksum of all the packages in the tar file;XR Packages InstallationWithin IOS-XR, two new CLI commands have been introduced that complement the existing ones# \u201cinstall update\u201d and \u201cinstall upgrade\u201d, described Table 1. These new commands require an external packages repository accessible through FTP/SFTP/SCP/TFTP or HTTP.            Command      Description              install update source       When no package is specified, update latest SMUs of all installed packages.              install upgrade source  version       Upgrade the base image to the specified version. All installed packages are upgraded to same release as the base package.      RP/0/RP0/CPU0#pwa-rtr#install update source ?   WORD  Enter source directory for the package(s)            Example#           sftp#//user@server/directory/          scp#//user@server/directory/          ftp#//user@server/directory/          tftp#//server/directory/          http#//server/directory/In the example below the k9sec package is installed using the \u201cinstall update\u201d command. After initiating the command, you can issue a \u201cshow install request\u201d to monitor the status of the package installation.RP/0/RP0/CPU0#pwa-rtr#install update source http#//192.168.122.1#8080/xrv9k xrv9k-k9secSat Feb 13 17#18#59.981 UTC++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++Update in progress...Scheme # httpHostname # 192.168.122.1#8080Collecting software state..Update packages #    xrv9k-k9secFetching .... xrv9k-k9sec-1.0.0.0-r600.x86_64.rpm-6.0.0Adding packages    xrv9k-k9sec-1.0.0.0-r600.x86_64.rpm-6.0.0Feb 13 17#19#08 Install operation 22 started by root#install add source /misc/disk1/install_tmp_staging_area/6.0.0 xrv9k-k9sec-1.0.0.0-r600.x86_64.rpm-6.0.0Feb 13 17#19#09 Install operation will continue in the backgroundFeb 13 17#19#12 Install operation 20 finished successfullyInstall add operation successfulActivating xrv9k-k9sec-1.0.0.0-r600Feb 13 17#19#14 Install operation 23 started by root#  install activate pkg xrv9k-k9sec-1.0.0.0-r600Feb 13 17#19#14 Package list#Feb 13 17#19#14     xrv9k-k9sec-1.0.0.0-r600Feb 13 17#19#16 Install operation will continue in the background RP/0/RP0/CPU0#pwa-rtr#  This product contains cryptographic features and is subject to UnitedStates and local country laws governing import, export, transfer anduse. Delivery of Cisco cryptographic products does not imply third-partyauthority to import, export, distribute or use encryption. Importers,exporters, distributors and users are responsible for compliance withU.S. and local country laws. By using this product you agree to complywith applicable laws and regulations. If you are unable to comply withU.S. and local laws, return this product immediately.A summary of U.S. laws governing Cisco cryptographic products may befound at#http#//www.cisco.com/wwl/export/crypto/tool/stqrg.htmlIf you require further assistance please contact us by sending email toexport@cisco.com.Feb 13 17#20#12 Install operation 21 finished successfullyAll the install commands log their progress. You can enter \u201cshow install log\u201d to review the installation log file. This command is useful for identifying the reason for any failure.RP/0/RP0/CPU0#pwa-rtr#show install log 21Tue Feb 23 17#54#00.961 UTCFeb 23 17#51#14 Install operation 21 started by root#      install activate pkg xrv9k-k9sec-1.0.0.0-r600Feb 23 17#51#14 Package list#Feb 23 17#51#14     xrv9k-k9sec-1.0.0.0-r600Feb 23 17#51#15 Action 1# install prepare action startedFeb 23 17#51#17 Install operation will continue in the backgroundFeb 23 17#51#17 The prepared software is set to be activated with process restartFeb 23 17#51#18 Start preparing software for local installationFeb 23 17#51#19 Action 1# install prepare action finished successfullyFeb 23 17#51#20 Action 2# install activate action startedFeb 23 17#51#20 The software will be activated with process restartFeb 23 17#51#22 Activating XR packagesFeb 23 17#51#58 0 processes affected at node 0/RP0/CPU0Feb 23 17#52#10 Action 2# install activate action finished successfullyFeb 23 17#52#11 Install operation 21 finished successfullyFeb 23 17#52#11 Ending operation 21Install add operation successfulXR Package StructureWhen you enter the Shell of the control plane (accessed by typing \u201cbash\u201d or \u201crun\u201d from the CLI) you are in a full Bash shell environment of the XR container with all the traditional Linux tools at your fingertips. (You can return to the IOS XR CLI by typing \u201cexit\u201d).Since all IOS XR packages used the RPM format, we will use the Linux rpm utility to inspect their content. The \u201c-q\u201d switch used below is used to query the installed packages database and the \u201c-i\u201d switch display the general information contained in the metadata of the RPM package.RP/0/RP0/CPU0#pwa-rtr#runWed Dec  2 03#04#32.231 UTC [xr-vm_node0_RP0_CPU0#~]$rpm -qi xrv9k-k9secName        # xrv9k-k9sec        Relocations# /opt/cisco/XR/packages/xrv9k-k9sec-1.0.0.0-r600Version     # 1.0.0.0                           Vendor# (none)Release     # r600                          Build Date# Thu Dec 24 08#46#14 2015Install Date# Fri Mar  4 12#18#15 2016      Build Host# iox-lnx-009Group       # IOS-XR                        Source RPM# xrv9k-k9sec-1.0.0.0-r600.src.rpmSize        # 8616918                License# Copyright (c) 2015 Cisco Systems Inc. All rights reserved.Signature   # (none)Packager    # alnguyenSummary     # Bundle package for iosxr-securityArchitecture# x86_64Description #Bundle package for iosxr-securityBuild workspace# /auto/srcarchive16/production/6.0.0/xrv9k/workspaceWe can also use RPM utilities to query the requirement of the package (\u201c-R\u201d switch), this information is also in the RPM metadata and is crucial for dependency checking. In the example below, the k9sec package depends on three packages, each of them within a certain version range.[xr-vm_node0_RP0_CPU0#~]$rpm -qR xrv9k-k9sec/bin/sh/bin/sh/bin/sh/bin/shxrv9k-iosxr-fwding &gt;= 1.0.0.0xrv9k-iosxr-fwding &lt; 2.0.0.0xrv9k-iosxr-infra &gt;= 1.0.0.0xrv9k-iosxr-infra &lt; 2.0.0.0xrv9k-iosxr-os &gt;= 1.0.0.0xrv9k-iosxr-os &lt; 2.0.0.0All the Cisco packages are in a separate group named IOS-XR. With the \u201c\u2014queryformat\u201d switch we specify the type of field we want to display and how we want to display them. The following command will query all the installed packages and display their groups and names we use the utility grep to filter the output and only display the package belonging to the IOS XR group. Enter the following command to query all the packages from that group#[xr-vm_node0_RP0_CPU0#~]$rpm -qa --queryformat '%{group}   %{name}\\n' | grep IOS-XRIOS-XR   xrv9k-spirit-bootIOS-XR   xrv9k-iosxr-routingIOS-XR   xrv9k-iosxr-fwdingIOS-XR   xrv9k-iosxr-infraIOS-XR   xrv9k-baseIOS-XR   xrv9k-bgpIOS-XR   xrv9k-common-pd-fib IOS-XR   xrv9k-fwdingIOS-XR   xrv9k-gcp-fwdingIOS-XR   xrv9k-gdplaneIOS-XR   xrv9k-iosxr-osIOS-XR   xrv9k-os-supportIOS-XR   xrv9k-k9secIOS-XR   xrv9k-mgblWith the Help of standard Linux tools we can review the full history of installed IOS-XR packages#[xr-vm_node0_RP0_CPU0#~]$rpm -qa --queryformat '%{installtime} %{group} %{name}-%{version}-%{release} %{installtime#date}\\n' | grep IOS-XR | sort -nr | sed -e 's/^[0-9]*\\ IOS-XR\\ //'xrv9k-mgbl-2.0.0.0-r600 Fri Mar  4 12#33#59 2016xrv9k-k9sec-1.0.0.0-r600 Fri Mar  4 12#18#15 2016xrv9k-os-support-1.0.0.0-r600 Fri Jan 29 02#04#37 2016xrv9k-iosxr-os-1.0.0.0-r600 Fri Jan 29 02#04#35 2016xrv9k-gdplane-1.0.0.0-r600 Fri Jan 29 02#04#33 2016xrv9k-gcp-fwding-1.0.0.0-r600 Fri Jan 29 02#04#33 2016xrv9k-fwding-1.0.0.0-r600 Fri Jan 29 02#04#32 2016xrv9k-common-pd-fib-1.0.0.0-r600 Fri Jan 29 02#04#32 2016xrv9k-bgp-1.0.0.0-r600 Fri Jan 29 02#04#31 2016xrv9k-base-1.0.0.0-r600 Fri Jan 29 02#04#31 2016xrv9k-iosxr-infra-1.0.0.0-r600 Fri Jan 29 02#04#27 2016xrv9k-iosxr-fwding-2.0.0.0-r600 Fri Jan 29 02#04#25 2016xrv9k-spirit-boot-1.0.0.0-r600 Fri Jan 29 02#04#24 2016xrv9k-iosxr-routing-1.0.0.0-r600 Fri Jan 29 02#04#24 2016With the \u201c\u2014requires\u201d switch we can query the RPM database and display the version of installed packages that are fulfilling the dependency of another package. Using the following command we learn which packages requires xrv9k-iosxr-routing to be present in the system#[xr-vm_node0_RP0_CPU0#~]$rpm -q --whatrequires xrv9k-iosxr-routingxrv9k-iosxr-fwding-2.0.0.0-r600.x86_64xrv9k-bgp-1.0.0.0-r600.x86_64xrv9k-mgbl-2.0.0.0-r600.x86_64With following command we get the version of the package that provides the xrv9k-iosxr-routing functionality#[xr-vm_node0_RP0_CPU0#~]$rpm -q --whatprovides xrv9k-iosxr-routing  xrv9k-iosxr-routing-1.0.0.0-r600.x86_64Packages Installation from the ShellYou can use the install commands inside the Linux shell of the IOS-XR container to install packages using a shell script.[xr-vm_node0_RP0_CPU0#~]$#install update source http#//192.168.122.1#8080/xrv9k xrv9k-eigrp++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++Update in progress...Scheme # httpHostname # 192.168.122.1#8080Collecting software state..Update packages #\txrv9k-eigrpFetching .... xrv9k-eigrp-1.0.0.0-r600.x86_64.rpm-6.0.0Adding packages \txrv9k-eigrp-1.0.0.0-r600.x86_64.rpm-6.0.0Mar 10 22#40#38 Install operation 24 started by root# install add source /misc/disk1/install_tmp_staging_area/6.0.0 xrv9k-eigrp-1.0.0.0-r600.x86_64.rpm-6.0.0 Mar 10 22#40#40 Install operation will continue in the backgroundMar 10 22#40#43 Install operation 24 finished successfullyInstall add operation successfulActivating xrv9k-eigrp-1.0.0.0-r600Mar 10 22#40#45 Install operation 30 started by root#  install activate pkg xrv9k-eigrp-1.0.0.0-r600 Mar 10 22#40#45 Package list#Mar 10 22#40#45     xrv9k-eigrp-1.0.0.0-r600Mar 10 22#40#48 Install operation will continue in the backgroundMar 10 22#40#43 Install operation 24 finished successfullyInstall add operation successfulActivating xrv9k-eigrp-1.0.0.0-r600Mar 10 22#40#45 Install operation 25 started by root#  install activate pkg xrv9k-eigrp-1.0.0.0-r600 Mar 10 22#40#45 Package list#Mar 10 22#40#45     xrv9k-eigrp-1.0.0.0-r600Mar 10 22#40#48 Install operation will continue in the backgroundMar 10 22#41#49 Install operation 25 finished successfullyAnalyzing Package Using LinuxAny Linux distribution installed with the RPM utilities allows you to look at the content of packages, this is very useful to analyze dependencies and verify package integrity outside of the router. In this example we use the \u201c-l\u201d switch to display the full path of all the files inside the package.NOTE# Notice the extra -p switch used to query uninstalled packages.cisco@compute#~$ cd ~/web_server/xrv9k/cisco@compute#~/web_server/xrv9k$ rpm -qpl xrv9k-k9sec-1.0.0.0-r600.x86_64.rpm-6.0.0//opt/opt/cisco/opt/cisco/XR/opt/cisco/XR/packages/opt/cisco/XR/packages/xrv9k-k9sec-1.0.0.0-r600/opt/cisco/XR/packages/xrv9k-k9sec-1.0.0.0-r600/all/opt/cisco/XR/packages/xrv9k-k9sec-1.0.0.0-r600/all/etc/opt/cisco/XR/packages/xrv9k-k9sec-1.0.0.0-r600/all/etc/compat-mdata&lt;SNIP&gt;cisco@compute#~/web_server/xrv9k$ rpm -qpR xrv9k-k9sec-1.0.0.0-r600.x86_64.rpm-6.0.0/bin/sh/bin/sh/bin/sh/bin/shxrv9k-iosxr-fwding &gt;= 2.0.0.0xrv9k-iosxr-fwding &lt; 3.0.0.0xrv9k-iosxr-infra &gt;= 1.0.0.0xrv9k-iosxr-infra &lt; 2.0.0.0xrv9k-iosxr-os &gt;= 1.0.0.0xrv9k-iosxr-os &lt; 2.0.0.0NOTE# Run these RPM utilities off-box on any Linux system that has the RPM utility installed. Experiment with some of the RPM commands to create your own dependency management tool for XR packages.\u2014", "url": "https://xrdocs.github.io/software-management/tutorials/2016-08-06-introduction-to-rpm/", "tags": "iosxr, linux, rpm, yum", "title": "IOS-XR and RPM Package Manager", "author": "Patrick Warichet"}, "tutorials-2017-08-14-validate-the-intent-of-network-config-changes": {"content": "     Validate the intent of network config changes  Introduction  Prerequisites  Setup the topology  Copy the public credential file from the routers  Compile the example  Run the example  A few pointers on the code  IntroductionThe goal of this tutorial is not only to demonstrate how to config an IOS XR device using the gRPC framework and OpenConfig YANG models, but also validate the changes by subscribing to a telemetry stream from the device.We will use a gRPC library for Cisco IOS XR written in Go to#1) Submit network config changes to the devices using OpenConfig YANG models.2) Request the running configuration on the targets to validate the change submitted was actually applied.3) Subscribe to a telemetry stream to track status changes.In this oportunity, we will setup a BGP session between two devices with gRPC and leverage Streaming Telemetry (gRPC as well) to track BGP Neighbor status.This tutorial assumes that you have gone through the previous gRPC tutorial. If you haven\u2019t checked it out, then you can do so here#  Programming IOS-XR with gRPC and GoPrerequisitesWe will use this Vagrantfile to setup and run the topology as shown below#This time, we will automate the installation of Go and basic configuration of the routers to enable connectivity between them and the Ubuntu VM.To make this possible, we will use all the files in this folder. You need to have Vagrant and VirtualBox installed.Request access to the IOS XRv Vagrant box by filling up the form here. This example was run with IOS XR version 6.1.2.Setup the topologyYou can either manually download the files in this folder or clone the repo# git clone https#//github.com/nleiva/xrgrpc.git.If you cloned the repo, you need to drill down to the files# cd xrgrpc/example/configvalidate4. Either if you did this or downloaded the files to another folder, you simply need to run vagrant up where the files are.This process might take several minutes, so feel free to multitask.Copy the public credential file from the routersIn order to establish secure gRPC connections, we need to get this file from the target.Login to the first router (password# vagrant) and copy the content of ems.pem.ssh -p 2223 vagrant@localhostbash cat /misc/config/grpc/ems.pemexitExit the router and login to the Ubuntu VM to update the following file in the repo with the contents copied.vagrant ssh vm-1vim $GOPATH/src/github.com/nleiva/xrgrpc/example/configvalidate4/ems1.pemexitRepeat this process for the second router. Notice the destination port and destination files are different.ssh -p 2202 vagrant@localhostbash cat /misc/config/grpc/ems.pemexitvagrant ssh vm-1vim $GOPATH/src/github.com/nleiva/xrgrpc/example/configvalidate4/ems2.pemexitYou can verify the port to use with vagrant port &lt;vm name&gt; before running ssh -p &lt;port no&gt;Compile the exampleLogin to the Ubuntu VM, go to the example location and compile.vagrant ssh vm-1cd $GOPATH/src/github.com/nleiva/xrgrpc/example/configvalidate4go buildThat\u2019s it! We are all set to run the example.Run the exampleOn the same folder, you just need to do a ./configvalidate4.$ go build$ ./configvalidate4******************************************************************************************Config merged on 192.0.2.2#57344 -&gt; Request ID# 1000, Response ID# 1000Config merged on 192.0.2.3#57344 -&gt; Request ID# 1000, Response ID# 1000******************************************************************************************BGP Config from 192.0.2.2#57344{ ~openconfig-bgp#bgp~# {  ~global~# {   ~config~# {    ~as~# 64512,    ~router-id~# ~203.0.113.2~   },   ~afi-safis~# {    ~afi-safi~# [     {      ~afi-safi-name~# ~openconfig-bgp-types#ipv4-unicast~,      ~config~# {       ~afi-safi-name~# ~openconfig-bgp-types#ipv4-unicast~,       ~enabled~# true      }     }    ]   }  },  ~neighbors~# {   ~neighbor~# [    {     ~neighbor-address~# ~203.0.113.3~,     ~config~# {      ~neighbor-address~# ~203.0.113.3~,      ~peer-as~# 64512,      ~description~# ~iBGP session~     },     ~afi-safis~# {      ~afi-safi~# [       {        ~afi-safi-name~# ~openconfig-bgp-types#ipv4-unicast~,        ~config~# {         ~afi-safi-name~# ~openconfig-bgp-types#ipv4-unicast~,         ~enabled~# true        }       }      ]     }    }   ]  } }}******************************************************************************************Telemetry from 192.0.2.2#57344------------------------------------- Time 07#51#55PM -------------------------------------BGP Neighbor; IP# 203.0.113.3, ASN# 64512, State bgp-st-active------------------------------------- Time 07#51#57PM -------------------------------------BGP Neighbor; IP# 203.0.113.3, ASN# 64512, State bgp-st-idle------------------------------------- Time 07#51#59PM -------------------------------------BGP Neighbor; IP# 203.0.113.3, ASN# 64512, State bgp-st-idle------------------------------------- Time 07#52#01PM -------------------------------------BGP Neighbor; IP# 203.0.113.3, ASN# 64512, State bgp-st-opensent------------------------------------- Time 07#52#03PM -------------------------------------BGP Neighbor; IP# 203.0.113.3, ASN# 64512, State bgp-st-estab------------------------------------- Time 07#52#05PM -------------------------------------BGP Neighbor; IP# 203.0.113.3, ASN# 64512, State bgp-st-estab^CManually cancelled the session to 192.0.2.2#57344\u2026Wait!, what did just happend?..1) We applied a BGP neighbor config to routers 192.0.2.2 and 192.0.2.3, using a template based on the BGP OpenConfig model# bgpoctemplate4.json.{ ~openconfig-bgp#bgp~# {   ~global~# {    ~config~# {     ~as~# {{.LocalAs}},     ~router-id~# ~{{.LocalAddress}}~    }   },   ~neighbors~# {    ~neighbor~# [     {      ~neighbor-address~# ~{{.NeighborAddress}}~,      ~config~# {       ~neighbor-address~# ~{{.NeighborAddress}}~,       ~peer-as~# {{.PeerAs}},       ~description~# ~{{.Description}}~      }&lt;snip&gt;Config merged on 192.0.2.2#57344 -&gt; Request ID# 1000, Response ID# 1000Config merged on 192.0.2.3#57344 -&gt; Request ID# 1000, Response ID# 10002) We request the running configuration on one of the targets to validate it was actually applied.BGP Config from 192.0.2.2#57344{ ~openconfig-bgp#bgp~# {  ~global~# {   ~config~# {    ~as~# 64512,    ~router-id~# ~203.0.113.2~   },   ~afi-safis~# {    ~afi-safi~# [     {      ~afi-safi-name~# ~openconfig-bgp-types#ipv4-unicast~,      ~config~# {       ~afi-safi-name~# ~openconfig-bgp-types#ipv4-unicast~,       ~enabled~# true&lt;snip&gt;3) We subscribed to BGP neighbor telemetry stream to track status changes every two seconds. You can see how the session went from active, idle and opensent to established.Telemetry from 192.0.2.2#57344------------------------------------- Time 07#51#55PM -------------------------------------BGP Neighbor; IP# 203.0.113.3, ASN# 64512, State bgp-st-active------------------------------------- Time 07#51#57PM -------------------------------------BGP Neighbor; IP# 203.0.113.3, ASN# 64512, State bgp-st-idle------------------------------------- Time 07#51#59PM -------------------------------------BGP Neighbor; IP# 203.0.113.3, ASN# 64512, State bgp-st-idle------------------------------------- Time 07#52#01PM -------------------------------------BGP Neighbor; IP# 203.0.113.3, ASN# 64512, State bgp-st-opensent------------------------------------- Time 07#52#03PM -------------------------------------BGP Neighbor; IP# 203.0.113.3, ASN# 64512, State bgp-st-estab------------------------------------- Time 07#52#05PM -------------------------------------BGP Neighbor; IP# 203.0.113.3, ASN# 64512, State bgp-st-estabA few pointers on the codeWe will document a complete walk-through in a following tutorial. Well, if you are impatient like me, you can take a look at other examples documented in the repo in the meantime.In this example we basically did six things.1) Manually specify target parameters. We increased the timeout on router1 to be able to listen to the telemetry stream. Remember, we are only using a single connection per device for all the RPC calls.router1, err #= xr.BuildRouter(\txr.WithUsername(~vagrant~),\txr.WithPassword(~vagrant~),\txr.WithHost(~192.0.2.2#57344~),\txr.WithCert(~ems1.pem~),\txr.WithTimeout(60),)if err != nil {\tlog.Fatalf(~Target parameters for router1 are incorrect# %s~, err)}2) Define BGP parameters for each device.neighbor1 #= &amp;NeighborConfig{\tLocalAs#         64512,\tPeerAs#          64512,\tDescription#     ~iBGP session~,\tNeighborAddress# ~203.0.113.3~,\tLocalAddress#    ~203.0.113.2~,}3) Connect to both routers.conn1, ctx1, err #= xr.Connect(*router1)if err != nil {\tlog.Fatalf(~Could not setup a client connection to %s, %v~, router1.Host, err)}defer conn1.Close()conn2, ctx2, err #= xr.Connect(*router2)if err != nil {\tlog.Fatalf(~Could not setup a client connection to %s, %v~, router2.Host, err)}4) Apply the configs to the routers.ri, err #= xr.MergeConfig(ctx1, conn1, buf1.String(), id)if err != nil {\tlog.Fatalf(~Failed to config %s# %v\\n~, router1.Host, err)} else {\tfmt.Println(line)\tfmt.Printf(~\\nConfig merged on %s -&gt; Request ID# %v, Response ID# %v\\n\\n~, router1.Host, id, ri)}5) Get the BGP config from router1.id++output, err #= xr.GetConfig(ctx1, conn1, ~{\\~openconfig-bgp#bgp\\~# [null]}~, id)if err != nil {\tlog.Fatalf(~Could not get the config from %s, %v~, router1.Host, err)}fmt.Printf(~\\nBGP Config from %s\\n\\n~, router1.Host)fmt.Printf(~\\n%s\\n~, output)6) Subscribe to the telemetry stream and parse the output.id++ch, ech, err #= xr.GetSubscription(ctx1, conn1, p, id, e)if err != nil {\tlog.Fatalf(~Could not setup Telemetry Subscription# %v\\n~, err)}&lt;snip&gt;\trasn #= nbr.GetRemoteAs()\tstate #= nbr.GetConnectionState()\traddr #= nbr.GetConnectionRemoteAddress().GetIpv4Address()\t// Debug#\t// fmt.Printf(~\\n\\n%v\\n\\n\\n~, hex.Dump(content))\tfmt.Printf(~BGP Neighbor; IP# %v, ASN# %v, State %s \\n\\n~, raddr, rasn, state)Simple, isn\u2019t it?.This concludes this tutorial/example. Stay tuned for more!.Some useful links below#  Part 1# Programming IOS-XR with gRPC and Go  gRPC Getting Started  gRPC and GPB for Networking Engineers", "url": "https://xrdocs.github.io/programmability/tutorials/2017-08-14-validate-the-intent-of-network-config-changes/", "tags": "vagrant, iosxr, IOS XR, gRPC, protobuf, OpenConfig, GPB, Streaming Telemetry, BGP, VirtualBox, Ubuntu", "title": "Validate the intent of network config changes", "author": "Nicolas Leiva"}, "tutorials-2017-08-23-multilayer-planning-with-the-wan-automation-engine": {"content": "     On This Page  Overview  Discovery of the DWDM Topology  Multilayer Planning in WAE Design          Example# Visualize the Multilayer Topology      Example# Simulate the Impact of a Fiber Cut      Example# Modeling DWDM Circuit Paths and Protection Schemes                  Simulate Optical Restoration          Simulate 1+1 Protection                    Example# Multilayer Optimizations for Segment Routing Policies                  Optimize a SR Policy for Latency and Avoidance          Optimize SR Policies for Multilayer Disjointness                    Example# Capacity Planning Optimization                  Capacity Planning Optimization Create Parallel Circuits          Capacity Planning Optimization New Adjacencies (with Optical Bypass)          Capacity Planning Optimization LAG Augmentation                          LAG Augmentation and L1 Circuit Activation                                            OverviewThe WAE network model includes the multivendor devices that participate in the IGP (OSPF or IS-IS) and can be extended to include the DWDM topology. Using the WAE Design application or WAE APIs, you can use the model to simulate \u201cwhat if\u201d scenarios and optimize paths for L3 and L1 domains. The purpose of this tutorial is to demonstrate the multilayer capabilities of WAE.  Note#      The network model used in this tutorial is from the WAE Design samples directory# us_wan_L1.txt    If you don\u2019t have the WAE Design application, see the tutorial Using dCloud to Access the WAN Automation Engine Demos.    If using dCloud, use the US East datacenter and launch the demo for \u201cWAE Live\u201d. The WAE Design application will be on the workstation desktop.  Discovery of the DWDM TopologyThe goal in multilayer discovery is to augment the WAE model of the IGP with the DWDM topology. For Cisco optical, the layer 1 topology discovery and mapping between the L1 circuit path and the L3 adjacency is automatic; WAE can interface through CTC to the NCS 2K running 10.6.2 or later to discover the DWDM topology and L3-L1 mapping if LMP is configured on both the NCS 2K and IOS-XR. In IOS-XR, an example of the LMP configuration is shown below#RP/0/RP0/CPU0#Napoli-5#show run lmpMon Aug 21 19#31#21.657 CETlmpgmpls optical-uni  ...  controller dwdm0/6/0/20/0   neighbor Battipaglia   neighbor link-id ipv4 unicast 20.20.20.60   neighbor interface-id unnumbered 2130707466   link-id ipv4 unicast 20.20.20.50  !  ...  neighbor Battipaglia   ipcc routed   router-id ipv4 unicast 10.58.244.11  !  router-id ipv4 unicast 10.58.244.50!!RP/0/RP0/CPU0#Napoli-5#show run int hundredGigE 0/6/0/20/0Mon Aug 21 19#31#38.179 CETinterface HundredGigE0/6/0/20/0  description Core Link to Salerno - bundle member  bundle id 2 mode active  cdp  transceiver permit pid all! RP/0/RP0/CPU0#Napoli-5#show run controller dwdm 0/6/0/20/0Mon Aug 21 19#31#59.844 CETcontroller dwdm0/6/0/20/0  g709 enable  g709 fec high-gain-sd-fec  wavelength 50GHz-Grid frequency 19315  admin-state in-service!For third party optical vendors, typically WAE will use the vendor specific NMS for the topology details and populate a vendor agnostic YANG model. Third-party interfaces for L1 vendors require a WAE function pack. Please contact your Cisco sales representative for details.Multilayer Planning in WAE DesignWAE Design has visualization, simulation and optimization tools and capabilities for multilayer planning scenarios. This section will cover a few of these scenarios by example. You can follow the examples using the us_wan_L1.txt plan file located in the WAE Design samples directory.Example# Visualize the Multilayer Topology  Open us_wan_L1.txt and make sure you have the network plot set to the Simulated Traffic view.  Currently you are looking at the layer 3 topology. View the layer 1 topology by selecting the L3/L1 toggle button in the upper left corner of the Design application.  From the layouts menu, select the layout \u201cJoint\u201d to see a layout that was setup to see the L3 and L1 views in the same plot.  See the settings for this layout by right clicking an empty area of the plot and selecting Plot Options. Then toggle to the Layer 1 tab to see available options.  In this plot, you can also open any site to see the contained L1 and L3 nodes.Another useful tip is the ability to select background objects in the network plot. To enable this setting, go to View -&gt; Preferences and check the box that says \u201cEnable Selection of Background Objects\u201d.Example# Simulate the Impact of a Fiber CutThe primary purpose of WAE including the layer 1 information is to understand the impact to the layer 3 topology.  Using us_wan_L1.txt ensure you have the network plot set to the Simulated Traffic view.  Highlight a layer 3 circuit, toggle to the L1 view and observe the associated layer 1 circuit  Click an empty area of the plot remove the highlights for the selections  Right-click a layer 1 link and select Fail  Observe the impact of the failure in the L1 and L3 views  Right-click and empty area of the plot and select Recover and select the L1 link.Example# Modeling DWDM Circuit Paths and Protection SchemesIn the previous example, failing a L1 link simulated the impact to the layer 3 topology. In WAE, layer 3 circuits are mapped to layer 1 circuits, and layer 1 circuits can have circuit paths. In this example, you will use circuit paths to simulate optical restoration and 1+1 protection scenarios.In WAE, L1 links have properties for distance, delay, loss, metric, feasibility metric, reserved L1 circuit paths, maximum L1 circuit paths and waypoint information. This information helps determine the path of the L1 circuit (which can have a feasibility limit). The colors on the L1 links represent the utilization, which is the number of active and operational circuit paths routed through the L1 link divided by the maximum allowable.Simulate Optical Restoration  Using us_wan_L1.txt ensure you have the network plot set to the Simulated Traffic view.  In the L1 view, right-click on the L1 link between SLC and KCY and select Filter to L1 Circuits Through L1 Links.  In the L1 Circuits table, identify and select the L1 circuit between CHI and SEA  Right-click an empty area of the plot and select New -&gt; Layer 1 -&gt; L1 Circuit Paths  For the 1 selected L1 circuit, set the path option to 2 Uncheck the Standby box.  In the L1 Circuits table, identify and select the L1 circuit between CHI and SEA then right-click on the L1 link between SLC and KCY and select Fail  Observe the dashed line for this circuit. This failure simulation shows path option 1 becoming non-operational and path option 2 becoming operational.  Right-click and empty area of the plot and select Recover and select the L1 link.Simulate 1+1 Protection  Using us_wan_L1.txt ensure you have the network plot set to the Simulated Traffic view.  In the L1 view, right-click on the L1 link between SLC and KCY and select Filter to L1 Circuits Through L1 Links.  In the L1 Circuits table, identify and select the L1 circuit between CHI and SEA  Right-click the circuit and select Filter to L1 Circuit Paths.  Open the Properties menu for the L1 circuit path with path option 2. (This was added in the previous example)  Set the checkbox for Standby and ensure the checkbox for Active is also checked.  To modify the path, select Insert After and set site SLC to Exclude.  Select OK to exit the properties menu  In the L1 Circuits table, identify and select the L1 circuit between CHI and SEA then right-click on the L1 link between SLC and KCY and select Fail  Observe the circuit path change for this circuit. This failure simulation shows path option 1 becoming non-operational and path option 2, which was already established becoming operational.  Right-click and empty area of the plot and select Recover and select the L1 link.In this example, you changed the L1 circuit path manually to be partially disjoint from the other. In WAE Design version 7, there is an optimization tool to compute disjoint L1 circuit paths.Example# Multilayer Optimizations for Segment Routing PoliciesIf the layer 3 and layer 1 topologies are included in the model, you can take advantage of the WAE optimization tools for Segment Routing Policies.Optimize a SR Policy for Latency and AvoidanceThis example will use the WAE SR-TE optimization tool.  Right-click an empty area of the plot and select New -&gt; LSPs -&gt; LSP  In the LSP Properties menu, set the type to SR, set the source to er1.sea and set the destination to be er1.atl. Click OK.  Observe the path of the SR policy.  Next optimize the SR policy by selecting Tools -&gt; SR-TE Optimization  In the SR-TE Optimization menu, set Minimize Path Metric to Delay and ensure Avoid Nodes is set to None. Click OK.  Observe the optimized path of the SR policy in the new plan file.  If you want the lowest latency SR policy that avoids nodes in site KCY, first highlight the site KCY, right-click and select Filter to Contained Nodes.  In the Nodes table, highlight the selected nodes.  Select Tools -&gt; SR-TE Optimization. In the SR-TE Optimization menu, set Minimize Path Metric to Delay and set Avoid Nodes to \u201cSelected in Table\u201d. Click OK.  Observe the optimized path of the SR policy in the new plan file.In this example, the avoidance criteria is referring to L3 nodes. In WAE Design version 7, you can also select avoidance criteria for L1 Nodes and L1 Links.Optimize SR Policies for Multilayer DisjointnessIn this example, you will use WAE to compute paths for SR policies that are disjoint for the L3 and L1 topologies.  Close any open plan files and do not save changes. Open the plan file us_wan_L1.txt. It should be in the original state in which you started this tutorial.  Right-click an empty area of the plot and select New -&gt; LSPs -&gt; LSP  In the LSP Properties menu, set the following parameters#          Type# SR      Source# er1.sjc      Destination# er1.kcy.      In the Advanced tab set Disjoint Group to any string such as \u2018group1\u2019.      Click OK.        Right-click on the LSP in the LSPs table and select Duplicate  Select the LSPs in the LSPs table, right-click an empty area of the plot and select New -&gt; LSPs -&gt; LSP Paths. Leave the defaults and click OK.  Select Tools -&gt; LSP Disjoint Path Optimization.  In the LSP Disjoint Path Optimization menu, set the following options#          Disjoint Routing Selection# Create Disjoint Paths between LSPs in Disjoint Groups.      Priorities# set L1 Links to 1      Click OK.        Observe in the new plan file that the SR policies are disjoint at L3 and L1.Example# Capacity Planning OptimizationWAE has a tool called Capacity Planning Optimization that attempts to get below a simulated utilization threshold by upgrading the capacity in some way. This section will show some of the options of the tool and the results.Before you start this section, do the following tasks.  Close any open plan files and do not save changes. Open the plan file us_wan_L1.txt. It should be in the original state in which you started this tutorial.  Right-click an empty area of the plot and select New -&gt; Demands -&gt; Demand  In the Demand Properties menu set the following options#          Name# Can be any string such as \u2018new_customer\u2019      Source# er1.sea      Destination# er1.atl      Traffic# 700 (Mbps)      Capacity Planning Optimization Create Parallel Circuits  Select Tools -&gt; Capacity Planning Optimization  In the Capacity Planning Optimization menu, select the following options#          Maximum Interface Utilization# 80      Capacity Increment# 1000      Upgrade Existing Circuits# Create Parallel Circuits      Create New Adjacencies# Restrict New Adjacencies between Nodes None      Select OK      The result should look similar to the picture on the right.Capacity Planning Optimization New Adjacencies (with Optical Bypass)Ensure the plan file us_wan_L1.txt is selected.This example will examine a case where you can only add new adjacencies between core nodes. First, select only the core nodes in the Nodes table.  Select Tools -&gt; Capacity Planning Optimization  In the Capacity Planning Optimization menu, select the following options#          Maximum Interface Utilization# 80      Capacity Increment# 1000      Upgrade Existing Circuits# (Ignore)      Create New Adjacencies# Restrict New Adjacencies between Nodes Selected in Table (22/33)      In the Layer 1 tab, select the checkbox Create L1 Circuits      Select OK      The result should look similar to the picture on the right.Capacity Planning Optimization LAG AugmentationEnsure the plan file us_wan_L1.txt is selectedThis time you will see what happens if you can only augment existing LAG members.  Select Tools -&gt; Capacity Planning Optimization  In the Capacity Planning Optimization menu, select the following options#          Maximum Interface Utilization# 80      Capacity Increment# 1000      Check the box Use Capacity of Existing LAG Members      Upgrade Existing Circuits# Create Port Circuits (LAGs)      Create New Adjacencies# Restrict New Adjacencies between Nodes None      In the Layer 1 tab, select the checkbox Create L1 Circuits      Select OK      The result should look similar to the picture on the right. Notice the upgraded links are larger. This is because the capacity of the L3 adjacency is larger as new members have been added to the LAG.In this example, if you examine the Ports table you will see the ports have different capacities which doesn\u2019t make a lot of sense. In a real network WAE can discover the ports that are not being used. Selecting the checkbox Use Capacity of Existing LAG Members will use the ports that are not associated with port circuits.LAG Augmentation and L1 Circuit ActivationIn WAE 7 EFT, the ability to use the WAE Design application to deploy changes to the network for the LAG augmentation use case has been demonstrated. The testbed involved the NCS 2000 running 10.6.2 or later and the ASR 9000 running IOS-XR. The L3 LAG augmentation was performed using the Cisco Network Services Orchestrator and the L1 circuit activation uses CTC.At this time, we are not planning to use WAE Design to deploy new L3 circuits to the network. WAE does expose APIs which can be leveraged to compute optimized paths and deployed to the network using other management and orchestration tools.", "url": "https://xrdocs.github.io/automation/tutorials/2017-08-23-multilayer-planning-with-the-wan-automation-engine/", "tags": "cisco, WAE, Design, Capacity Planning, Multilayer", "title": "Multilayer Planning with the WAN Automation Engine", "author": "Josh Peters"}, "blogs-2018-03-08-enabling-ios-xr-on-third-party-network-hardware": {"content": "     On This Page  Background  \u201cLayers\u201d of the Network Stack  How we enabled IOS-XR on whitebox hardware          The Decision Stages      Putting it all together      Deployment models        What does the integration look like?          Assessing the platform Integration        Where do we go from here?  BackgroundWith the recent announcement that IOS-XR will now be available on a curated set of third party network hardware, let\u2019s dive a little deeper into technical details of the integration. In this ongoing series of technical blogs, we\u2019ve demonstrated how IOS-XR with model driven APIs at every layer of the stack enables us to easily integrate with a wide variety of community tools and protocols.This time I\u2019d like to explain what it takes to enable a Network Operating System (NOS) on whitebox hardware and showcase how IOS-XR  with suitable abstractions at the platform integration layer enabled us to port it to select OCP-compliant hardware for the Service Provider Access market.In the video below - we show IOS-XR running on OCP compliant hardware, installed and brought up using ONIE and seamlessly integrated with the platform\u2019s capabilities#\u00a0\u00a0Before we discuss details, let\u2019s review the various layers of a generic network stack. In case of IOS-XR, these layers have evolved over time to accommodate different networks with varied software and operational requirements.\u201cLayers\u201d of the Network StackNetwork disaggregation is generally understood to be a \u201cdecoupling\u201d of the network hardware and software. However, we\u2019ve seen a lot of use cases typically associated with network disaggregation being solved by exposing APIs at different layers within the software stack. Over time this has led to a further \u201cdisaggregation\u201d within the software stack into multiple layers.Thus, today when we break down a network device, its constituent parts look something like#      Network Software# Consisting of various layers#                  Platform Integration Layer# Typically consists of kernel and/or user-land drivers for devices such as fans, leds, sensors etc. The integration of these device specific drivers with the higher layers of the software stack happens at this layer. It this layer that allows a software stack to extract information (e.g. temperature) from sensors and influence component state (e.g. fan speed).                    Hardware Abstraction Layer# This layer interacts with the ASIC SDK (provided by the ASIC vendor) and handles programming of the data plane based on RIB state, or LSD (label switch database) state etc.                    Network Infrastructure/Service Adaptation Layer#  Typically consists of components such as the RIB, Label Switch database, BFD, network interface handler and APIs on for higher layers/agents.                    Network Application/Protocol Layer#  This layer contains protocols (BGP, ISIS, OSPF etc.) and features such as L2VPN, L3VPN etc.                    Manageability Layer# This layer exposes command line interface (CLI)  for features and protocols in the network application layer along with model-driven APIs for use with automation tools.                  Networking Hardware# Consists of the ASIC that handles forwarding decisions and provides hooks (through the ASIC SDK) to help program route lookup tables in the hardware. The system components such as fans, sensors and optics make up the rest of this layer.  The figure below (click to expand) shows how IOS-XR\u2019s architecture maps to these layers#In this blog, we\u2019ll focus primarily on the layers that lie at the interface of the network software and the hardware i.e. the integration of IOS-XR with platform sensors, optics and the use of OCP technologies (such as ONL modules and onlpdump) to enable it.How we enabled IOS-XR on whitebox hardwareThere are four primary steps to enable a NOS on third-party hardware#The Decision Stages1. Select the HardwareThis may seem obvious but is an  important first step to ensure smooth portability of the vendor software on third party network hardware.   Since we are using OCP-compliant hardware, we get to utilize the ONL driver code/modules on github.Ultimately when selecting a NOS, integrators look for hardware with a mix of#  Ports - the required density of (typically) 100G ports  ASIC capabilities - A lot of the features one can eventually support depend on the capabilities of the underlying ASICThere are a number of hardware platforms that are already OCP-compliant and several others that are still under review.In this blog we describe integration with one of the hardware platforms we selected based on our customer requirements# the  Edgecore-AS7816-64x, 100GBE platform that provides line-rate L2 and L3 forwarding across 64 x QSFP28 ports.2. Integrate with the PlatformThe term \u201cPlatform\u201d here refers to hardware components such as Fans, Power modules, Optics, Sensors etc. The goal is to use available drivers for these hardware components and integrate them with a platform abstraction layer inside the NOS.This integration stage requires the following steps#      Port ONL modules for selected hardware into the NOS#The ONL modules for the various OCP-compliant and OCP-inspired hardware platforms are available on Github in the opencomputeproject github org.    For example, under the packages directory browse to the platforms/accton/x86-64/x86-64-accton-as7816-64x/modules/builds directory#        What you see are the kernel modules for the device x86-64-accton-as7816-64x that may be ported into a kernel of choice to expose the functionality of the devices\u2019s cpld (complex programmable logic device), fans, leds and power modules.    In Jan,2018 the optics support was shifted to the Open optical monitoring(oom) project - common across platforms and available on Github here.  If you're still looking for the optics kernel modules however, you will need to check out an older git hash for OpenNetworkLinux#  b77d4dde8ea9855843b634a3d41be7b2dedc2dd3 - the last one before the OOM change. Here you will find the sfp.c source code still intact#  https#//github.com/opencomputeproject/OpenNetworkLinux/blob/b77d4dde8ea9855843b634a3d41be7b2dedc2dd3/packages/platforms/accton/x86-64/x86-64-accton-as7816-64x/modules/builds/x86-64-accton-as7816-64x-sfp.c        Platform Abstraction inside the NOS#The Platform abstraction layer helps abstract the underlying capabilities of the hardware sensors, fans, optics and power modules and exposes an API north-bound to integrate with higher layer of the NOS.    The technique through which the underlying capabilities of the hardware are exposed to the platform abstraction layer depends on the type of hardware in play - the presence of a BMC (Baseboard management controller) may imply that the NOS leverages something like OpenBMC, whereas an absence of a BMC may imply that ONLP (ONL platform library) would instead serve this purpose.    There are two main ways to expose the underlying hardware\u2019s capabilities to the platform abstraction layer# using platform libraries such as ONLP (Open Network Linux Platform) or using OpenBMC (if available) for hardware with a BMC (Baseboard Management Controller).    The ONL platform library (ONLP) is an abstraction layer used to  inventory, manage, and monitor all devices inside the system (fans, power supplies, LEDs, SFP/SFP+/QSFP, temperature sensors, etc.).    Keep in mind that ONLP is not really needed if you\u2019re willing to write your own hooks that manage the capabilities exposed by the kernel modules. But since it\u2019s already available on Github, integrating ONLP and its application layer daemon (onlpdump) could make parts of the integration easier.    To give you a gist of the pieces involved, ONLP consists of two layers#          The \u201capplication to platform\u201d APIs that can be found here#        https#//github.com/opencomputeproject/OpenNetworkLinux/tree/master/packages/base/any/onlp/src/onlp/module/inc/onlp                        The \u201cplatform to hardware\u201d APIs found here#                   https#//github.com/opencomputeproject/OpenNetworkLinux/tree/master/packages/base/any/onlp/src/onlp/module/inc/onlp/platformi        with hardware specific hooks implemented in hardware platform  specific directories#        https#//github.com/opencomputeproject/OpenNetworkLinux/tree/master/packages/platforms/accton/x86-64/x86-64-accton-as7816-64x/onlp/builds/src/module/src            \u00a0  \u00a0  We will show how IOS-XR already contains a platform abstraction layer that allows it to hook up with ONLP and integrate with the underlying platform.3. Integrate the ASIC SDKWhile the OEM vendor provides the APIs/modules  that expose functionality of the platform components such as fans, psu modules, leds and sfps, The ASIC SDK comes from the ASIC vendor. For example, Edgecore-AS7816-64x platform uses the Broadcom Tomahawk II (56970) ASIC.Broadcom provides an Open API on top of their SDK called OpenNSL for integration with a Hardware Abstraction Layer (HAL) in the NOS.4. Provide a NOS installer for a bootloader such as ONIEOnce you\u2019ve built a NOS capable of running on the selected hardware, you need some way for the device to install and boot the NOS. ONIE may be the available bootloader for the system. It is very well documented and details can be found here#  https#//opencomputeproject.github.io/onie/To build an ONIE-compatible installer, follow the instructions in the developer section#  https#//opencomputeproject.github.io/onie/developers/demo_os.htmlIOS-XR NOS image is packaged up into an ONIE-compatible NOS installer called iosxrwb-k9.amd64.installer. This installer is then fetched and installed using ONIE on the whitebox hardware.Putting it all togetherLet\u2019s summarize the decision stages described above. The different touch points (Platform Integration and ASIC-SDK integration) in play are showcased below#\u00a0\u00a0\u00a0\u00a0The BSP contains the ONL modules for the platform, compiled into the kernel. Typically, the NOS  (IOS-XR) contains the Platform Abstraction Layer to integrate the platform either by using ONLP APIs or directly reading from the sysfs paths exposed by the installed kernel modules.The Optics Abstraction layer integrates with the optics device-driver/kernel-module for the platform and handle Optics in the NOS inventory directly. In the future, we can look at hooking up the OOM (open optical monitoring) layer with the optics abstraction layer for more enhanced functionality.The ASIC SDK API hooks up to a HAL (Hardware Adaptation Layer) that would in turn provide north bound APIs to the NOS layers such as FIB for route or label programming.Deployment modelsThe deployment models for a NOS are a function of how an integrator views the software being deployed on whitebox hardware#      As a complete Software Stack#  In this scenario, the NOS vendor includes a Linux distribution (rootfs and kernel) within the NOS image along with all the platform modules and any ASIC SDK that may be required.        As an application on Linux# In this scenario, the integrator is expected to run the network stack as an application on top of a Linux distribution (rootfs and kernel) of choice. The platform modules and any ASIC SDK required must be installed by the integrator. The Vendor NOS still contains all the abstraction layers to work with the modules installed by the integrator.  Native#This deployment model is used when the vendor NOS (IOS-XR) is viewed as \u201ca complete Software Stack\u201d responsible for the Linux distribution(rootfs and the Kernel) as well as the protocol stack capabilities.IOS-XR is packaged up into an ONIE-compatible installer and is brought up on the system natively. This installed NOS contains all the kernel modules necessary to work with the platform and the ASIC in question.Container (Docker, LXC etc.)This deployment model is used when the vendor NOS (IOS-XR) is viewed as an \u201capplication\u201d on top of a custom OS and is responsible only for the abstraction layers and the protocol stack capabilities. The Linux distribution(rootfs and kernel) running natively on the platform is installed and set up by the integrator.As shown above, IOS-XR is packaged into a container image (Docker, LXC etc.) and published into a either a private or a reachable repository (Docker registry for example). The network operator can then pull and load the container image directly onto the custom OS using the installed container daemon or through a combination with configuration management tools like Ansible, Puppet, Chef etc.What does the integration look like?So, the burning question# What does the integration of IOS-XR on OCP hardware actually look like?.Since I have an Edgecore-AS7816-64X lying around, let\u2019s begin by setting up a DHCP server to respond with a default-url option and a web server with the ONIE-compatible NOS installer for IOS-XR.The relevant ISC-DHCP server config snippet is shown below#host AS7816-64X {  hardware ethernet a8#2b#b5#87#9f#f4;  fixed-address 172.30.0.60;  next-server 172.30.0.22;  option default-url = ~http#//172.30.0.22/AS7816-64X/iosxrwb-k9.amd64.installer~;  if exists user-class and option user-class = ~exr-config~ {    filename = ~http#//172.30.0.22/AS7816-64X/scripts/as7816-64x_nso_ztp.py~;  }}Notice the yellow highlighted default-url pointing to the ONIE-compatible NOS installer for IOS-XR# iosxrwb-k9.amd64.installer.This is the native deployment model described in the previous section. The installer contains the complete Software Stack replete with the kernel modules that help integrate with the platform and the ASIC. Further it contains a Wind River Linux (WRL) distribution (rootfs and kernel).Let\u2019s attempt to fetch and install this image by rebooting the network device.NOTE# If there is a NOS already installed on the device, then the NOS might have options to force the device to boot into ONIE mode directly. If it does not, make sure you select the ONIE loader when the relevant screen pops up upon reboot.Once selected, the ONIE loader looks something like#As is evident, I begin by selecting the Uninstall OS option first. This will force the device to erase internal mass storage devices and remove the existing NOS, before rebooting and attempting a fresh install through ONIE.Upon reboot, the Install OS option should automatically get selected, thereby triggering the download of the ONIE-compatible installer image of IOS-XR based on DHCP interactions with the dhcp server#Info# Attempting file#//dev/sda3/onie-installer-x86_64.bin ...Info# Attempting file#//dev/sda3/onie-installer ...Info# Attempting file#//dev/sda3/onie-installer.bin ...Info# Attempting http#//172.30.0.22/AS7816-64X/iosxrwb-k9.amd64.installer ...ONIE# Executing installer# http#//172.30.0.22/AS7816-64X/iosxrwb-k9.amd64.installerinstaller# computing checksum of original archiveinstaller# checksum is OKinstaller# extracting pad1+0 records in1+0 records out512 bytes (512B) copied, 0.000014 seconds, 34.9MB/sinstaller# copying file before resetting padinstaller# resetting pad1+0 records in1+0 records out512 bytes (512B) copied, 0.000012 seconds, 40.7MB/sinstaller# extracting shar into /tmp/sfx-dFtTrainstaller# invoking installer xrinstaller.shFound installer tmpfs on /tmp/sfx-dFtTra (/tmp) using opts rw,noatimeUnpacking ONL installer files...Extracting from /tmp/sfx-dFtTra/onie-installer.zip# iosxrwb-k9.iso ...Archive#  /tmp/sfx-dFtTra/onie-installer.zip  inflating# iosxrwb-k9.isoExtracting initrd to /tmp/sfx-dFtTra/initrd-F3ONm5Awesome! The default-url option set up on the dhcp server allowed ONIE to pick up the url for the NOS installer and start expanding and booting it.The next step is ZTP -  enabling IOS-XR on the whitebox platform automatically ensures that capabilities such as ZTP become available for use.If you haven\u2019t heard about ZTP yet, hop over to these great tutorials and blogs on xrdocs#  https#//xrdocs.github.io/software-management/tutorials/2016-08-26-working-with-ztp/https#//xrdocs.github.io/software-management/blogs/2017-09-21-ios-xr-ztp-learning-through-packet-captures/Notice the red-marked filename field in the DHCP server config shown earlier. This field is utilized during the ZTP phase to return a custom python script called as7816-64x_nso_ztp.py to execute on IOS-XR once it comes up.  The captured reply from the DHCP server is shown below - notice the returned filename, in line with the server configuration.  TIME# 2018-03-11 06#12#10.692    IP# 172.30.0.25 (0#50#56#b7#50#d3) &gt; 172.30.0.60 (a8#2b#b5#87#9f#f4)    OP# 2 (BOOTPREPLY) HTYPE# 1 (Ethernet)  HLEN# 6  HOPS# 0   XID# a8e9d54c  SECS# 0 FLAGS# 0CIADDR# 0.0.0.0YIADDR# 172.30.0.60SIADDR# 172.30.0.22GIADDR# 0.0.0.0CHADDR# a8#2b#b5#87#9f#f4#00#00#00#00#00#00#00#00#00#00 SNAME# . FNAME# http#//172.30.0.22/AS7816-64X/scripts/as7816-64x_nso_ztp.pyOPTION#  53 (  1) DHCP message type         5 (DHCPACK)OPTION#  54 (  4) Server identifier         172.30.0.25OPTION#  51 (  4) IP address leasetime      86400 (24h)OPTION#   1 (  4) Subnet mask               255.255.255.0OPTION#   3 (  4) Routers                   172.30.0.1OPTION#   6 (  4) DNS server                172.30.0.25OPTION#  12 ( 10) Host name                 AS7816-64XOPTION# 114 ( 56) URL                       687474703a2f2f31 http#//1\t\t\t\t\t    37322e33302e302e 72.30.0.\t\t\t\t\t    32322f4153373831 22/AS781\t\t\t\t\t    362d3634582f696f 6-64X/io\t\t\t\t\t    73787277622d6b39 sxrwb-k9\t\t\t\t\t    2e616d6436342e69 .amd64.i\t\t\t\t\t    6e7374616c6c6572 nstaller                 OPTION#  28 (  4) Broadcast address         172.30.0.255OPTION#  15 ( 11) Domainname                cisco.local---------------------------------------------------------------------------This script is set up to configure an admin user on the system and apply a configuration that enables basic features such as ISIS, LACP etc.In the end, we are presented with a familiar login prompt if we connect to the box over SSH#cisco@server#~/$ ssh cisco@172.30.0.61The authenticity of host '172.30.0.61 (172.30.0.61)' can't be established.RSA key fingerprint is 45#cb#02#4a#b7#c9#05#ff#6d#74#26#b8#c0#0d#9c#e5.Are you sure you want to continue connecting (yes/no)? yesWarning# Permanently added '172.30.0.61' (RSA) to the list of known hosts.Password#RP/0/RP0/CPU0#leaf3#RP/0/RP0/CPU0#leaf3#RP/0/RP0/CPU0#leaf3#show versionFri Mar  2 10#15#33.919 UTCCisco IOS XR Software, Version 6.5.1.04ICopyright (c) 2013-2018 by Cisco Systems, Inc.Build Information# Built By     # balsup Built On     # Fri Mar  2 02#04#10 PST 2018 Build Host   # vxr-slurm-124 Workspace    # /nobackup/balsup/release Version      # 6.5.1.04I Location     # /opt/cisco/XR/packages/Accton_as7816_64x () processorSystem uptime is 19 minutesRP/0/RP0/CPU0#leaf3#RP/0/RP0/CPU0#leaf3#And there you have it - IOS-XR running on an OCP compliant platform.Assessing the platform IntegrationAs mentioned earlier, platform integration involves hooking up the abstraction layers (platform, optics) within IOS-XR to the capabilities exposed by the kernel modules available from the ONL repository while also enabling onlpdump [optional] in the linux user-space.To begin with, let\u2019s look at the kernel modules installed on the system#      Platform Kernel modules (from ONL repo)#     RP/0/RP0/CPU0#leaf3# RP/0/RP0/CPU0#leaf3#bash Fri Mar  2 10#35#30.755 UTC [leaf3#~]$ [leaf3#~]$ [leaf3#~]$ lsmod | grep accton x86_64_accton_as7816_64x_sfp    14621  0 x86_64_accton_as7816_64x_psu     3322  0 x86_64_accton_as7816_64x_leds     5564  0 x86_64_accton_as7816_64x_fan     6715  0 accton_i2c_cpld         9016  3 x86_64_accton_as7816_64x_leds,x86_64_accton_as7816_64x_psu,x86_64_accton_as7816_64x_sfp i2c_core               29699  12 igb,at24,lm75,i2c_i801,i2c_mux,ym2651y,i2c_algo_bit,x86_64_accton_as7816_64x_fan,x86_64_accton_as7816_64x_psu,x86_64_accton_as7816_64x_sfp,i2c_mux_pca954x,accton_i2c_cpld [leaf3#~]$      Now let\u2019s compare some of the outputs from IOS-XR and onlpdump on the same system to see how they match up#Fan Speeds#      IOS-XR CLI#    RP/0/RP0/CPU0#leaf3#admin show environment fanFri Mar  2 10#44#14.704 UTC=====================================\t\t\tFan speed (rpm)Location     FRU Type           FAN_0-------------------------------------0/FT0        7816-FN-BK         13800   0/FT1        7816-FN-BK         14100   0/FT2        7816-FN-BK         14000   0/FT3        7816-FN-BK         13800   0/PM0        7816-FN-BK         10800   0/PM1        7816-FN-BK          8096   RP/0/RP0/CPU0#leaf3#RP/0/RP0/CPU0#leaf3#            Onlpdump Output#    RP/0/RP0/CPU0#leaf3#bashFri Mar  2 10#44#23.913 UTC[leaf3#~]$[leaf3#~]$ /opt/cisco/hostos/bin/onlpdump | grep -A8 'fan @ [1-4]'   fan @ 1 = {       Description# Chassis Fan - 1       Status# 0x00000009 [ PRESENT,F2B ]       Caps#   0x00000038 [ SET_PERCENTAGE,GET_RPM,GET_PERCENTAGE ]       RPM#    13800       Per#    54       Model#  NULL       SN#     NULL   }   fan @ 2 = {       Description# Chassis Fan - 2       Status# 0x00000009 [ PRESENT,F2B ]       Caps#   0x00000038 [ SET_PERCENTAGE,GET_RPM,GET_PERCENTAGE ]       RPM#    14100       Per#    55       Model#  NULL       SN#     NULL   }   fan @ 3 = {       Description# Chassis Fan - 3       Status# 0x00000009 [ PRESENT,F2B ]       Caps#   0x00000038 [ SET_PERCENTAGE,GET_RPM,GET_PERCENTAGE ]       RPM#    14000       Per#    54       Model#  NULL       SN#     NULL   }   fan @ 4 = {       Description# Chassis Fan - 4       Status# 0x00000009 [ PRESENT,F2B ]       Caps#   0x00000038 [ SET_PERCENTAGE,GET_RPM,GET_PERCENTAGE ]       RPM#    13800       Per#    54       Model#  NULL       SN#     NULL   }[leaf3#~]$      Temperature Checks#      IOS-XR CLI#    RP/0/RP0/CPU0#leaf3#admin show environment temperatures location 0/RP0Fri Mar  2 10#49#07.667 UTC================================================================================Location  TEMPERATURE                 Value   Crit Major Minor Minor Major  Crit          Sensor                    (deg C)   (Lo) (Lo)  (Lo)  (Hi)  (Hi)   (Hi)--------------------------------------------------------------------------------0/RP0                ! CPU Core                       67      0     0     0    45    55    60        ! ChassisThermalSensor 1         48      0     0     0    45    55    60        ! ChassisThermalSensor 2         54      0     0     0    45    55    60          ChassisThermalSensor 3         36      0     0     0    45    55    60          ChassisThermalSensor 4         39      0     0     0    45    55    60          ChassisThermalSensor 5         44      0     0     0    45    55    60          ChassisThermalSensor 6         41      0     0     0    45    55    60          NP1                            64    -10    -5     0   105   110   115          NP2                            63    -10    -5     0   105   110   115          NP3                            63    -10    -5     0   105   110   115          NP4                            64    -10    -5     0   105   110   115          NP5                            64    -10    -5     0   105   110   115          NP6                            64    -10    -5     0   105   110   115          NP7                            63    -10    -5     0   105   110   115          NP8                            63    -10    -5     0   105   110   115RP/0/RP0/CPU0#leaf3#            Onlpdump Output#    RP/0/RP0/CPU0#leaf3#RP/0/RP0/CPU0#leaf3#bashFri Mar  2 10#49#15.746 UTC[leaf3#~]$[leaf3#~]$[leaf3#~]$ /opt/cisco/hostos/bin/onlpdump | grep -A10 thermal   thermal @ 1 = {       Description# CPU Core       Status# 0x00000001 [ PRESENT ]       Caps#   0x0000000f [ GET_TEMPERATURE,GET_WARNING_THRESHOLD,GET_ERROR_THRESHOLD,GET_SHUTDOWN_THRESHOLD ]       Temperature# 64000       thresholds = {           Warning# 45000           Error# 55000           Shutdown# 60000       }   }   thermal @ 2 = {       Description# Chassis Thermal Sensor 1       Status# 0x00000001 [ PRESENT ]       Caps#   0x0000000f [ GET_TEMPERATURE,GET_WARNING_THRESHOLD,GET_ERROR_THRESHOLD,GET_SHUTDOWN_THRESHOLD ]       Temperature# 48500       thresholds = {           Warning# 45000           Error# 55000           Shutdown# 60000       }   }   thermal @ 3 = {       Description# Chassis Thermal Sensor 2       Status# 0x00000001 [ PRESENT ]       Caps#   0x0000000f [ GET_TEMPERATURE,GET_WARNING_THRESHOLD,GET_ERROR_THRESHOLD,GET_SHUTDOWN_THRESHOLD ]       Temperature# 54000       thresholds = {           Warning# 45000           Error# 55000           Shutdown# 60000       }   }   thermal @ 4 = {       Description# Chassis Thermal Sensor 3       Status# 0x00000001 [ PRESENT ]       Caps#   0x0000000f [ GET_TEMPERATURE,GET_WARNING_THRESHOLD,GET_ERROR_THRESHOLD,GET_SHUTDOWN_THRESHOLD ]       Temperature# 36000       thresholds = {           Warning# 45000           Error# 55000           Shutdown# 60000       }   }   thermal @ 5 = {       Description# Chassis Thermal Sensor 4       Status# 0x00000001 [ PRESENT ]       Caps#   0x0000000f [ GET_TEMPERATURE,GET_WARNING_THRESHOLD,GET_ERROR_THRESHOLD,GET_SHUTDOWN_THRESHOLD ]       Temperature# 39500       thresholds = {           Warning# 45000           Error# 55000           Shutdown# 60000       }   }   thermal @ 6 = {       Description# Chassis Thermal Sensor 5       Status# 0x00000001 [ PRESENT ]       Caps#   0x0000000f [ GET_TEMPERATURE,GET_WARNING_THRESHOLD,GET_ERROR_THRESHOLD,GET_SHUTDOWN_THRESHOLD ]       Temperature# 44500       thresholds = {           Warning# 45000           Error# 55000           Shutdown# 60000       }   }   thermal @ 7 = {       Description# Chassis Thermal Sensor 6       Status# 0x00000001 [ PRESENT ]       Caps#   0x0000000f [ GET_TEMPERATURE,GET_WARNING_THRESHOLD,GET_ERROR_THRESHOLD,GET_SHUTDOWN_THRESHOLD ]       Temperature# 41000       thresholds = {           Warning# 45000           Error# 55000           Shutdown# 60000       }   }--       thermal @ 8 = {           Description# PSU-1 Thermal Sensor 1           Status# 0x00000001 [ PRESENT ]           Caps#   0x0000000f [ GET_TEMPERATURE,GET_WARNING_THRESHOLD,GET_ERROR_THRESHOLD,GET_SHUTDOWN_THRESHOLD ]           Temperature# 40000           thresholds = {               Warning# 45000               Error# 55000               Shutdown# 60000           }       }--       thermal @ 9 = {           Description# PSU-2 Thermal Sensor 1           Status# 0x00000001 [ PRESENT ]           Caps#   0x0000000f [ GET_TEMPERATURE,GET_WARNING_THRESHOLD,GET_ERROR_THRESHOLD,GET_SHUTDOWN_THRESHOLD ]           Temperature# 33000           thresholds = {               Warning# 45000               Error# 55000               Shutdown# 60000           }       }[leaf3#~]$      Similarly, Optics#      IOS-XR CLI#    RP/0/RP0/CPU0#leaf3#show  inventoryFri Mar  2 11#06#16.559 UTCNAME# ~0/RP0~, DESCR# ~Accton-as7816-64x Route processor~PID# 7816-64X-O-AC-F   , VID# v01, SN# 664X1735002NAME# ~HundredGigE0/0/0/0~, DESCR# ~Cisco QSFP28 100G AOC Pluggable Optics Module~PID# QSFP-100G-AOC10M  , VID# V01, SN# FIW211303CS-ANAME# ~HundredGigE0/0/0/1~, DESCR# ~Cisco QSFP28 100G AOC Pluggable Optics Module~PID# QSFP-100G-AOC10M  , VID# V01, SN# FIW211303Z9-ANAME# ~HundredGigE0/0/0/62~, DESCR# ~Cisco QSFP28 100G SR4 Pluggable Optics Module~PID# QSFP-100G-SR4-S   , VID# V01, SN# AVF1940G0VMNAME# ~HundredGigE0/0/0/63~, DESCR# ~Cisco QSFP28 100G SR4 Pluggable Optics Module~PID# QSFP-100G-SR4-S   , VID# V01, SN# AVF1941G0DK            Onlpdump Output#    RP/0/RP0/CPU0#leaf3#bashFri Mar  2 11#06#21.072 UTC[leaf3#~]$[leaf3#~]$ /opt/cisco/hostos/bin/onlpdump | grep sfp[leaf3#~]$ /opt/cisco/hostos/bin/onlpdump -S | grep -v NONEPort  Type            Media   Status  Len    Vendor            Model             S/N             ----  --------------  ------  ------  -----  ----------------  ----------------  ----------------   0  100G-AOC        Fiber           10m    CISCO-FINISAR     FCBN425QE1C10-C1  FIW211303CS-A      1  100G-AOC        Fiber           10m    CISCO-FINISAR     FCBN425QE1C10-C1  FIW211303Z9-A     62  100GBASE-SR4    Fiber                  CISCO-AVAGO       AFBR-89CDDZ-CS1   AVF1940G0VM       63  100GBASE-SR4    Fiber                  CISCO-AVAGO       AFBR-89CDDZ-CS1   AVF1941G0DK     [leaf3#~]$      and so on\u2026.The combination of ONLP and IOS-XR\u2019s platform integration resembles IOS-XR\u2019s integration with Cisco Hardware such as the NCS5500 or NCS5000 series.Where do we go from here?In future blogs, we intend to have a deeper discussion on the underlying technology we used in our integration and show how some of IOS-XR\u2019s carrier grade features behave on OCP-compliant hardware (Spoiler Alert!# pretty well \ud83d\ude00).", "url": "https://xrdocs.github.io/cloud-scale-networking/blogs/2018-03-08-enabling-ios-xr-on-third-party-network-hardware/", "tags": "IOS-XR, Cisco, OCP, ONL, Platform, Broadcom, Edgecore, Accton, OFA, Service-Layer, API, access, service-provider, journey-to-the-web", "title": "Enabling IOS-XR on Third-Party Network Hardware", "author": "Akshat Sharma"}, "tutorials-2016-12-23-streaming-bgp-route-and-neighbor-counts-with-mdt": {"content": "     Streaming BGP Stats with MDT  BGP Performance Indicators          Number of BGP Routes      Number of BGP Neighbors        BGP Performance IndicatorsThe number of BGP routes and neighbor at any given time can be good, high-level indicators of network health.  Being able to stream those numbers periodically is a good use of model-driven telemetry (MDT) but the associated YANG models are large and can be intimidating, so this tutorial shows how to drill down for these specific stats.Number of BGP RoutesFor CLI fans, the information that I was looking for is often found in the output of \u201cshow route ipv4 summary\u201d#RP/0/RP0/CPU0#SunC#show route ipv4 summaryFri Dec 23 16#48#59.988 UTCRoute Source                     Routes     Backup     Deleted     Memory(bytes)local                            3          0          0           720connected                        2          1          0           720static                           1          0          0           240dagr                             0          0          0           0bgp 1                            5          1          0           1440isis 1                           1          1          0           480Total                            12         3          0           3600RP/0/RP0/CPU0#SunC#This data is included in the IOS XR native YANG model called \u201cCisco-IOS-XR-ip-rib-ipv4-oper.yang\u201d.  Now, there is a ton of stuff in that YANG model, including all of the prefixes in the RIB.  That\u2019s too much. I just want the summary statistics for BGP routes.  So I needed to filter down to a very specific tree path.  Using pyang to present a tree view of the model, here is the desired path#$ pyang -f tree Cisco-IOS-XR-ip-rib-ipv4-oper.yang --tree-path rib/vrfs/vrf/afs/af/safs/saf/ip-rib-route-table-names/ip-rib-route-table-name/protocol/bgp/as/informationmodule# Cisco-IOS-XR-ip-rib-ipv4-oper   +--ro rib      +--ro vrfs         +--ro vrf* [vrf-name]            +--ro afs               +--ro af* [af-name]                  +--ro safs                     +--ro saf* [saf-name]                        +--ro ip-rib-route-table-names                           +--ro ip-rib-route-table-name* [route-table-name]                              +--ro protocol                                 +--ro bgp                                    +--ro as* [as]                                       +--ro information                                          +--ro protocol-names?                string                                          +--ro instance?                      string                                          +--ro version?                       uint32                                          +--ro redistribution-client-count?   uint32                                          +--ro protocol-clients-count?        uint32                                          +--ro routes-counts?                 uint32                                          +--ro active-routes-count?           uint32                                          +--ro deleted-routes-count?          uint32                                          +--ro paths-count?                   uint32                                          +--ro protocol-route-memory?         uint32$If you did a NETCONF  operation on this subtree, the data would be returned encoded in XML like this#&lt;?xml version=~1.0~?&gt;&lt;rpc-reply message-id=~urn#uuid#7aa4d7d8-4638-40ed-bb87-93b1403e0baa~ xmlns#nc=~urn#ietf#params#xml#ns#netconf#base#1.0~ xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~&gt; &lt;data&gt;  &lt;rib xmlns=~http#//cisco.com/ns/yang/Cisco-IOS-XR-ip-rib-ipv4-oper~&gt;   &lt;vrfs&gt;    &lt;vrf&gt;     &lt;vrf-name&gt;default&lt;/vrf-name&gt;     &lt;afs&gt;      &lt;af&gt;       &lt;af-name&gt;IPv4&lt;/af-name&gt;       &lt;safs&gt;        &lt;saf&gt;         &lt;saf-name&gt;Unicast&lt;/saf-name&gt;         &lt;ip-rib-route-table-names&gt;          &lt;ip-rib-route-table-name&gt;           &lt;route-table-name&gt;default&lt;/route-table-name&gt;           &lt;protocol&gt;            &lt;bgp&gt;             &lt;as&gt;              &lt;as&gt;1&lt;/as&gt;              &lt;information&gt;               &lt;protocol-names&gt;bgp&lt;/protocol-names&gt;               &lt;instance&gt;1&lt;/instance&gt;               &lt;version&gt;0&lt;/version&gt;               &lt;redistribution-client-count&gt;0&lt;/redistribution-client-count&gt;               &lt;protocol-clients-count&gt;1&lt;/protocol-clients-count&gt;               &lt;routes-counts&gt;6&lt;/routes-counts&gt;               &lt;active-routes-count&gt;5&lt;/active-routes-count&gt;               &lt;deleted-routes-count&gt;0&lt;/deleted-routes-count&gt;               &lt;paths-count&gt;6&lt;/paths-count&gt;               &lt;protocol-route-memory&gt;1440&lt;/protocol-route-memory&gt;               &lt;backup-routes-count&gt;1&lt;/backup-routes-count&gt;              &lt;/information&gt;             &lt;/as&gt;            &lt;/bgp&gt;           &lt;/protocol&gt;          &lt;/ip-rib-route-table-name&gt;         &lt;/ip-rib-route-table-names&gt;        &lt;/saf&gt;       &lt;/safs&gt;      &lt;/af&gt;     &lt;/afs&gt;    &lt;/vrf&gt;   &lt;/vrfs&gt;  &lt;/rib&gt; &lt;/data&gt;&lt;/rpc-reply&gt;To get this same data encoded in Google Protocol Buffers and streamed using MDT, just configure a sensor-path as follows#telemetry model-driven  sensor-group SGroup1   sensor-path Cisco-IOS-XR-ip-rib-ipv4-oper#rib/vrfs/vrf/afs/af/safs/saf/ip-rib-route-table-names/ip-rib-route-table-name/protocol/bgp/as/informationNotice that the subtree filter (everything after Cisco-IOS-XR-ip-rib-ipv4-oper# in the sensor-path) is exactly the same as the argument I passed to the \u2013tree-path filter in pyang.  That\u2019s a handy tip for constructing sensor-paths in general!Number of BGP NeighborsFor BGP neighbor counts, the model you want is Cisco-IOS-XR-ipv4-bgp-oper.yang.  Again, this is a very juicy model, so it\u2019s best to winnow it down to the nearest subtree#$ pyang -f tree Cisco-IOS-XR-ipv4-bgp-oper.yang --tree-path bgp/instances/instance/instance-active/default-vrf/process-info/globalmodule# Cisco-IOS-XR-ipv4-bgp-oper   +--ro bgp      +--ro instances         +--ro instance* [instance-name]            +--ro instance-active               +--ro default-vrf                  +--ro process-info                     +--ro global                        +--ro process-instance-node?                string                        +--ro restart-count?                        uint32                        +--ro path-attributes-entry-count?          uint32                        +--ro path-attribute-memory?                uint32                        +--ro as-path-entry-count?                  uint32                        +--ro as-path-entries-memory?               uint32                        +--ro community-entry-count?                uint32                        +--ro community-memory?                     uint32                        +--ro extended-community-entry-count?       uint32                        +--ro extended-community-memory?            uint32                        +--ro pe-distinguisher-label-entry-count?   uint32                        +--ro pe-distinguisher-label-memory?        uint32                        +--ro pta-entry-count?                      uint32                        +--ro pta-memory?                           uint32                        +--ro ribrnh-entry-count?                   uint32                        +--ro ribrnh-memory?                        uint32                        +--ro ppmp-entry-count?                     uint32                        +--ro ppmp-memory?                          uint32                        +--ro route-reflectors?                     uint32                        +--ro route-reflector-memory?               uint32                        +--ro nexthop-count?                        uint32                        +--ro nexthop-memory?                       uint32                        +--ro local-as?                             uint32                        +--ro total-vrf-count?                      uint32                        +--ro neighbors-count-total?                uint32                        +--ro established-neighbors-count-total?    uint32                        +--ro sn-num-non-dflt-vrf-nbrs?             uint32                        +--ro sn-num-non-dflt-vrf-nbrs-estab?       uint32                        +--ro pool-size*                            uint32                        +--ro pool-alloc-count*                     uint32                        +--ro pool-free-count*                      uint32                        +--ro msg-log-pool-size*                    uint32                        +--ro msg-log-pool-alloc-count*             uint32                        +--ro msg-log-pool-free-count*              uint32Depending on whether you\u2019re interested in all neighbors or just neighbors in the established state, you can grab neighbors-count-total or established-neighbors-count-total from that list.To get that data via MDT,  configure the sensor path like this#telemetry model-driven  sensor-group SGroup1   sensor-path Cisco-IOS-XR-ipv4-bgp-oper#bgp/instances/instance/instance-active/default-vrf/process-infoThe hardest part of MDT is often just figuring out which YANG model and subtree has the data you need.  Once you\u2019ve got that, the configuration is pretty trivial.  Hopefully these two examples will get you started.", "url": "https://xrdocs.github.io/telemetry/tutorials/2016-12-23-streaming-bgp-route-and-neighbor-counts-with-mdt/", "tags": "iosxr, bgp, yang, mdt, telemetry", "title": "Streaming BGP Route and Neighbor Counts with MDT", "author": "Shelly Cadora"}, "tutorials-2017-09-26-use-case-openbmp-controller-using-service-layer-apis": {"content": "     On This Page  Basic Premise  Architecture  Running the demo          Pre-requisites      Steps      Starting the Controller      Starting the SL-API (route-shuttle) client        Basic PremiseTo gain control over the BGP RIB tables, all the routes learnt by the router under scrutiny will be dropped by a route policy. The Adj-in-Rib is learnt over BMP by the controller, is manipulated and then fed back over Service Layer APIs in IOS-XR (or equivalent RIB API in case of other vendors).ArchitectureRunning the demoThe basic steps are as follows#Pre-requisitesVagrant#      Have Vagrant and Virtualbox installed        To be able to work with Ubuntu 16.04 box (used for the Quagga instance) in the Vagrantfile,       the recommended versions for Vagrant and Virtualbox are#             cisco@host#~$ VBoxManage -v     5.1.22r115126     cisco@host#~$ vagrant -v     Vagrant 1.9.7     cisco@host#~$       The issue is described here#  https#//github.com/hashicorp/vagrant/issues/7155         Make sure you have access to an SL-API enabled IOS-XR vagrant box. If you don\u2019t have it get access to the IOS-XR vagrant box (version = 6.1.2+) by following this tutorial#  IOS-XR Vagrant Quickstart  StepsNote# You will need atleast 15G free RAM to run the vagrant topology.  The vagrant topology consists of four nodes as shown in the figure below#  Clone the git repository#git clone https#//github.com/akshshar/openbmp-controller.git  cd into the vagrant/ directory and clone the Service Layer API repository into the directorycisco@host#~/$ cd openbmp-controller/vagrantcisco@host#~/openbmp-controller/vagrant$ git clone https#//github.com/cisco-service-layer/service-layer-objmodelCloning into 'service-layer-objmodel'...Username for 'https#//github.com'# akshsharPassword for 'https#//akshshar@github.com'# remote# Counting objects# 229, done.remote# Total 229 (delta 0), reused 0 (delta 0), pack-reused 229Receiving objects# 100% (229/229), 5.03 MiB | 2.57 MiB/s, done.Resolving deltas# 100% (106/106), done.Checking connectivity... done.cisco@host#~/openbmp-controller/vagrant$   Copy the lib/ folder from the root of this repository into the vagrant foldercisco@host#~/openbmp-controller/vagrant$ cp -r ../lib/ lib/cisco@host#~/openbmp-controller/vagrant$ lscompose  configs  daemon.json  lib  scripts  Vagrantfilecisco@host#~/openbmp-controller/vagrant$  If you\u2019re behind a proxy, set the proxy variables as shown, the vagrant provisioning scripts will use them appropriately.export http_proxy=~http#//proxy-server#80~export https_proxy=~https#//proxy-server#80~  Now issue a vagrant up and go get a coffee #). This will take some time.cisco@host#~/openbmp-controller/vagrant$ vagrant destroy --force; vagrant up==&gt; devbox# Forcing shutdown of VM...==&gt; devbox# Destroying VM and associated drives...==&gt; rtr3# Forcing shutdown of VM...==&gt; rtr3# Destroying VM and associated drives...==&gt; rtr2# Forcing shutdown of VM...==&gt; rtr2# Destroying VM and associated drives...==&gt; rtr1# Forcing shutdown of VM...==&gt; rtr1# Destroying VM and associated drives...Bringing machine 'rtr1' up with 'virtualbox' provider...Bringing machine 'rtr2' up with 'virtualbox' provider...Bringing machine 'rtr3' up with 'virtualbox' provider...Bringing machine 'devbox' up with 'virtualbox' provider...Once the environment is up and running, ssh into rtr1 to view the BGP and BMP neighbors#RP/0/RP0/CPU0#rtr1#show  bgp summary Wed Jul 26 01#46#35.642 UTCBGP router identifier 1.1.1.1, local AS number 65000BGP generic scan interval 60 secsNon-stop routing is enabledBGP table state# ActiveTable ID# 0xe0000000   RD version# 12BGP main routing table version 12BGP NSR Initial initsync version 2 (Reached)BGP NSR/ISSU Sync-Group versions 0/0BGP scan interval 60 secsBGP is operating in STANDALONE mode.Process       RcvTblVer   bRIB/RIB   LabelVer  ImportVer  SendTblVer  StandbyVerSpeaker              12         12         12         12          12           0Neighbor        Spk    AS MsgRcvd MsgSent   TblVer  InQ OutQ  Up/Down  St/PfxRcd2.2.2.2           0 65000      35      37       12    0    0 00#29#39          011.1.1.20         0 65001      35      33       12    0    0 00#28#09          6RP/0/RP0/CPU0#rtr1#show  bgp bmp summary  Wed Jul 26 01#49#36.948 UTCID   Host                 Port     State   Time        NBRs 1   12.1.1.20            5000     ESTAB   00#22#57    2   RP/0/RP0/CPU0#rtr1#Great! Now hop over to the devbox and view the running containers (you should see 4 of them)#  openbmp_aio # All-in-one docker contains that contains an openbmp collector, mysql dB and a Kafka Bus.  redis#  A redis database to temporarily store the RIB and neighbor information.  controller#  The controller contains code from this repository and performs route-policy and path-selection before pushing the local RIB back into the kafka bus.  rshuttle# The route-shuttle container that contains code from route-shuttle library (https#//github.com/akshshar/route-shuttle) withan an openbmp client to convert the incoming stream of routes from Redis or Kafka into a stream for the Service Layer API in IOS-XR.cisco@host#~/openbmp-controller/vagrant$ vagrant ssh devboxWelcome to Ubuntu 16.04.2 LTS (GNU/Linux 4.4.0-81-generic x86_64) * Documentation#  https#//help.ubuntu.com * Management#     https#//landscape.canonical.com * Support#        https#//ubuntu.com/advantage43 packages can be updated.24 updates are security updates.Last login# Wed Jul 26 01#51#16 2017 from 10.0.2.2vagrant@vagrant#~$ docker psCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                                                                                              NAMESf408c46e6047        openbmp/aio         ~/usr/sbin/run_all...~   2 hours ago         Up 2 hours          0.0.0.0#2181-&gt;2181/tcp, 0.0.0.0#3306-&gt;3306/tcp, 0.0.0.0#5000-&gt;5000/tcp, 0.0.0.0#8001-&gt;8001/tcp, 0.0.0.0#9092-&gt;9092/tcp, 9999/tcp   openbmp_aioea4270c3dba6        controller#latest   ~/bin/bash~              2 hours ago         Up 2 hours                                                                                                                                             controller35dc15073b61        redis               ~docker-entrypoint...~   2 hours ago         Up 2 hours          0.0.0.0#6379-&gt;6379/tcp                                                                                                             redisribaa4923d9ff81        grpcio#latest       ~/bin/bash~              2 hours ago         Up 2 hours                                                                                                                                             rshuttle                                  Starting the ControllerOn the devbox, exec into the controller container and start the \u201copenbmp controller\u201d. You should see a stream of routes pouring in if you select the \u201cverbose\u201d (-v) knob.vagrant@vagrant#~$ vagrant@vagrant#~$ docker exec -it controller bashroot@controller#/# root@controller#/# root@controller#/# cd data/lib/root@controller#/data/lib# python consumer.py -husage# consumer.py [-h] -r REDIS_HOST -b BOOTSTRAP_SERVER [-v]optional arguments#  -h, --help            show this help message and exit  -r REDIS_HOST, --redis-host REDIS_HOST                        Specify the Redis Server IP  -b BOOTSTRAP_SERVER, --bootstrap-server BOOTSTRAP_SERVER                        Specify hostname of the kafka cluster  -v, --verbose         Enable verbose loggingroot@controller#/data/lib# python consumer.py -r 12.1.1.20 -b 12.1.1.20 -v INFO#root#Starting verbose debuggingDEBUG#root#Connecting to Kafka to receive router messagesINFO#root#Connecting to Kafka to receive peer messagesDEBUG#root#Connecting to Kafka to receive prefix messagesINFO#root#Received Redis eventINFO#root#Received Redis eventINFO#root#Received Redis eventDEBUG#root#Received an AdjInRib eventINFO#root#Received Redis eventINFO#root#Received Redis eventINFO#root#Received Redis eventINFO#root#Received Redis eventDEBUG#root#% openbmp.parsed.router [0] reached end at offset 0DEBUG#root#% openbmp.parsed.peer [0] reached end at offset 0DEBUG#root#% openbmp.parsed.unicast_prefix [0] reached end at offset 0DEBUG#root#% openbmp.parsed.router [1] reached end at offset 0DEBUG#root#% openbmp.parsed.router [2] reached end at offset 0DEBUG#root#Received Message (2017-07-26 01#50#50.236257) # ROUTER(V# 1.6)DEBUG#root#[    {        ~hash~# ~7fbf77c12967d9101d4383e10cfb1cb2~,         ~name~# ~rtr2~,         ~seq~# 0,         ~init_data~# ~~, Starting the SL-API (route-shuttle) clientOnce the controller has started, open up another shell into devbox and start the sl-api (route-shuttle) client. Currently it is hardcoded to use the rtr1 hash and query both Redis and Kafka to get a stream of routes. The router hash will be queried via Redis directly in upcoming changes to the route-shuttle code.The openbmp client and plugin for route-shuttle will convert the incoming stream of routes from Redis and Kafka into a route batch for the XR RIB over GRPC#cisco@host#~/openbmp-controller/vagrant$ vagrant ssh devboxWelcome to Ubuntu 16.04.2 LTS (GNU/Linux 4.4.0-81-generic x86_64) * Documentation#  https#//help.ubuntu.com * Management#     https#//landscape.canonical.com * Support#        https#//ubuntu.com/advantage43 packages can be updated.24 updates are security updates.Last login# Wed Jul 26 01#50#11 2017 from 10.0.2.2vagrant@vagrant#~$ docker exec -it rshuttle bashroot@rshuttle#/# cd /data/route-shuttle/root@rshuttle#/data/route-shuttle# python openbmp-client.py -husage# openbmp-client.py [-h] -i SERVER_IP -p SERVER_PORT -b BOOTSTRAP_SERVER                         -r REDIS_HOST [-v]optional arguments#  -h, --help            show this help message and exit  -i SERVER_IP, --server-ip SERVER_IP                        Specify the IOS-XR GRPC server IP address  -p SERVER_PORT, --server-port SERVER_PORT                        Specify the IOS-XR GRPC server port  -b BOOTSTRAP_SERVER, --bootstrap-server BOOTSTRAP_SERVER                        Specify hostname of the kafka cluster  -r REDIS_HOST, --redis-host REDIS_HOST                        Specify the redis server host  -v, --verbose         Enable verbose loggingroot@rshuttle#/data/route-shuttle# python openbmp-client.py -i 12.1.1.10 -p 57777 -b 12.1.1.20 -r 12.1.1.20 -vINFO#root#Starting verbose debuggingINFO#root#Using GRPC Server IP(12.1.1.10) Port(57777)DEBUG#root#Global thread spawnedDEBUG#root#Received event from GRPC serverDEBUG#root#Server Returned 0x501, Version 0.0.0DEBUG#root#Successfully Initialized, connection established!DEBUG#root#Max VRF Name Len     # 33DEBUG#root#Max Iface Name Len   # 64DEBUG#root#Max Paths per Entry  # 128DEBUG#root#Max Prim per Entry   # 64DEBUG#root#Max Bckup per Entry  # 64DEBUG#root#Max Labels per Entry # 3DEBUG#root#Min Prim Path-id     # 1DEBUG#root#Max Prim Path-id     # 64DEBUG#root#Min Bckup Path-id    # 65DEBUG#root#Max Bckup Path-id    # 128DEBUG#root#Max Remote Bckup Addr# 2DEBUG#root#VRF SL_REGOP_REGISTER Success!DEBUG#root#VRF SL_REGOP_EOF Success!DEBUG#root#{'paths'# {}, 'prefix_len'# 24, 'prefix'# '10.0.2.0/24', 'family'# 2, 'network'# '10.0.2.0'}DEBUG#root#{'paths'# {}, 'prefix_len'# 24, 'prefix'# '11.1.1.0/24', 'family'# 2, 'network'# '11.1.1.0'}DEBUG#root#{'paths'# {}, 'prefix_len'# 24, 'prefix'# '20.1.1.0/24', 'family'# 2, 'network'# '20.1.1.0'}DEBUG#root#{'paths'# {}, 'prefix_len'# 24, 'prefix'# '20.1.2.0/24', 'family'# 2, 'network'# '20.1.2.0'}DEBUG#root#{'paths'# {}, 'prefix_len'# 24, 'prefix'# '20.1.3.0/24', 'family'# 2, 'network'# '20.1.3.0'}DEBUG#root#{'paths'# {}, 'prefix_len'# 24, 'prefix'# '20.1.4.0/24', 'family'# 2, 'network'# '20.1.4.0'}DEBUG#root#{'paths'# {'nexthop'# '2.2.2.2', 'event'# 'add', 'family'# 2, 'admin_distance'# 200}, 'prefix_len'# 24, 'prefix'# '100.1.1.0/24', 'family'# 2, 'network'# '100.1.1.0'}DEBUG#root#{'paths'# {'nexthop'# '2.2.2.2', 'event'# 'add', 'family'# 2, 'admin_distance'# 200}, 'prefix_len'# 24, 'prefix'# '100.2.1.0/24', 'family'# 2, 'network'# '100.2.1.0'}Once the SL-API client starts running, you should be able to check the default VRF route table to see the application routes being pumped incisco@host#~/openbmp-controller/vagrant$ ssh -p 2223 vagrant@localhostPassword# RP/0/RP0/CPU0#rtr1#show routeWed Jul 26 03#26#02.671 UTCCodes# C - connected, S - static, R - RIP, B - BGP, (&gt;) - Diversion path       D - EIGRP, EX - EIGRP external, O - OSPF, IA - OSPF inter area       N1 - OSPF NSSA external type 1, N2 - OSPF NSSA external type 2       E1 - OSPF external type 1, E2 - OSPF external type 2, E - EGP       i - ISIS, L1 - IS-IS level-1, L2 - IS-IS level-2       ia - IS-IS inter area, su - IS-IS summary null, * - candidate default       U - per-user static route, o - ODR, L - local, G  - DAGR, l - LISP       A - access/subscriber, a - Application route       M - mobile route, r - RPL, t - Traffic Engineering, (!) - FRR Backup pathGateway of last resort is 10.0.2.2 to network 0.0.0.0S   0.0.0.0/0 [1/0] via 10.0.2.2, 02#18#14, MgmtEth0/RP0/CPU0/0L    1.1.1.1/32 is directly connected, 02#16#08, Loopback0O    2.2.2.2/32 [110/2] via 10.1.1.20, 02#09#11, GigabitEthernet0/0/0/0L    6.6.6.6/32 is directly connected, 02#16#08, Loopback1C    10.0.2.0/24 is directly connected, 02#18#14, MgmtEth0/RP0/CPU0/0L    10.0.2.15/32 is directly connected, 02#18#14, MgmtEth0/RP0/CPU0/0C    10.1.1.0/24 is directly connected, 02#16#08, GigabitEthernet0/0/0/0L    10.1.1.10/32 is directly connected, 02#16#08, GigabitEthernet0/0/0/0C    11.1.1.0/24 is directly connected, 02#16#08, GigabitEthernet0/0/0/1L    11.1.1.10/32 is directly connected, 02#16#08, GigabitEthernet0/0/0/1C    12.1.1.0/24 is directly connected, 02#16#08, GigabitEthernet0/0/0/2L    12.1.1.10/32 is directly connected, 02#16#08, GigabitEthernet0/0/0/2B    20.1.1.0/24 [20/0] via 11.1.1.20, 02#07#35B    20.1.2.0/24 [20/0] via 11.1.1.20, 02#07#35B    20.1.3.0/24 [20/0] via 11.1.1.20, 02#07#35B    20.1.4.0/24 [20/0] via 11.1.1.20, 02#07#35a    100.1.1.0/24 [200/0] via 2.2.2.2, 01#34#10a    100.2.1.0/24 [200/0] via 2.2.2.2, 01#34#10a    100.3.1.0/24 [200/0] via 2.2.2.2, 01#34#10a    100.4.1.0/24 [200/0] via 2.2.2.2, 01#34#10a    100.5.1.0/24 [200/0] via 2.2.2.2, 01#34#10a    100.6.1.0/24 [200/0] via 2.2.2.2, 01#34#10a    100.7.1.0/24 [200/0] via 2.2.2.2, 01#34#10a    100.8.1.0/24 [200/0] via 2.2.2.2, 01#34#10a    100.9.1.0/24 [200/0] via 2.2.2.2, 01#34#10a    100.10.1.0/24 [200/0] via 2.2.2.2, 01#34#10a    100.11.1.0/24 [200/0] via 2.2.2.2, 01#34#10a    200.1.1.0/24 [200/0] via 2.2.2.2, 01#34#10a    200.2.1.0/24 [200/0] via 2.2.2.2, 01#34#10a    200.3.1.0/24 [200/0] via 2.2.2.2, 01#34#10a    200.4.1.0/24 [200/0] via 2.2.2.2, 01#34#10a    200.5.1.0/24 [200/0] via 2.2.2.2, 01#34#10a    200.6.1.0/24 [200/0] via 2.2.2.2, 01#34#10a    200.7.1.0/24 [200/0] via 2.2.2.2, 01#34#10a    200.8.1.0/24 [200/0] via 2.2.2.2, 01#34#10a    200.9.1.0/24 [200/0] via 2.2.2.2, 01#34#10RP/0/RP0/CPU0#rtr1#With this setup running, play around by changing routes being injected by rtr2 to see how the application routes follow the events. Further, try to vary routepolicy.py and pathselection.py files to see how easily the incoming routes can be manipulated based on BGP path attributes.", "url": "https://xrdocs.github.io/cisco-service-layer/tutorials/2017-09-26-use-case-openbmp-controller-using-service-layer-apis/", "tags": "vagrant, iosxr, cisco, linux, use case, use-case, bmp, controller, service-layer, grpc", "title": "Use Case: OpenBMP Controller using Service Layer APIs", "author": "Akshat Sharma"}, "blogs-2016-06-28-xr-app-hosting-architecture-quick-look": {"content": "If you&#8217;ve been following the set of tutorials in the XR toolbox series#  XR Toolbox SeriesYou might have noticed that we haven&#8217;t actually delved into the internal architecture of IOS-XR. While there are several upcoming documents that will shed light on the deep internal workings of IOS-XR, I thought I&#8217;ll take a  quick stab at the internals for the uninitiated.This is what the internal software architecture and plumbing, replete with the containers, network namespaces and XR interfaces, looks like#Alright, back up. The above figure seems pretty daunting to understand, so let&#8217;s try to deconstruct it#  At the bottom of the figure, in gray, we have the host (hypervisor) linux environment. This is a 64-bit linux kernel running the Windriver linux 7 (WRL7) distribution. The rest of the components run as containers (LXCs) on top of the host.  In green, we see the container called the XR Control plane LXC (or XR LXC). This runs a Windriver Linux 7 (WRL7) environment as well and contains the XR control plane and the XR linux environment#  Inside the XR control plane LXC, if we zoom in further, the XR control plane processes are represented distinctly in blue as shown below. This is where the XR routing protocols like BGP, OSPF etc. run. The XR CLI presented to the user is also one of the processes.      See the gray box inside the XR control plane LXC ? This is the XR linux shell.    P.S. This is what you drop into when you issue a  vagrant ssh [*].Another way to get into the XR linux shell is by issuing a bash command in XR CLI.    The XR linux shell that the user interacts with is really the global-vrf network namespace inside the control plane container. This corresponds to the global/default-vrf in IOS-XR.        Only the interfaces in global/default vrf in XR appear in the XR linux shell today when you issue an ifconfig#    RP/0/RP0/CPU0#rtr1#RP/0/RP0/CPU0#rtr1#RP/0/RP0/CPU0#rtr1#show  ip int brSun Jul 17 11#52#15.049 UTC   Interface                      IP-Address      Status          Protocol Vrf-NameLoopback0                      1.1.1.1         Up              Up       default GigabitEthernet0/0/0/0         10.1.1.10       Up              Up       default GigabitEthernet0/0/0/1         11.1.1.10       Up              Up       default MgmtEth0/RP0/CPU0/0            10.0.2.15       Up              Up       default RP/0/RP0/CPU0#rtr1#RP/0/RP0/CPU0#rtr1#RP/0/RP0/CPU0#rtr1#bash    Sun Jul 17 11#52#22.904 UTC[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$ifconfigGi0_0_0_0 Link encap#Ethernet  HWaddr 08#00#27#e0#7f#bb            inet addr#10.1.1.10  Mask#255.255.255.0          inet6 addr# fe80##a00#27ff#fee0#7fbb/64 Scope#Link          UP RUNNING NOARP MULTICAST  MTU#1514  Metric#1          RX packets#0 errors#0 dropped#0 overruns#0 frame#0          TX packets#546 errors#0 dropped#3 overruns#0 carrier#1          collisions#0 txqueuelen#1000           RX bytes#0 (0.0 B)  TX bytes#49092 (47.9 KiB)Gi0_0_0_1 Link encap#Ethernet  HWaddr 08#00#27#26#ca#9c            inet addr#11.1.1.10  Mask#255.255.255.0          inet6 addr# fe80##a00#27ff#fe26#ca9c/64 Scope#Link          UP RUNNING NOARP MULTICAST  MTU#1514  Metric#1          RX packets#0 errors#0 dropped#0 overruns#0 frame#0          TX packets#547 errors#0 dropped#3 overruns#0 carrier#1          collisions#0 txqueuelen#1000           RX bytes#0 (0.0 B)  TX bytes#49182 (48.0 KiB)Mg0_RP0_CPU0_0 Link encap#Ethernet  HWaddr 08#00#27#ab#bf#0d            inet addr#10.0.2.15  Mask#255.255.255.0          inet6 addr# fe80##a00#27ff#feab#bf0d/64 Scope#Link          UP RUNNING NOARP MULTICAST  MTU#1514  Metric#1          RX packets#210942 errors#0 dropped#0 overruns#0 frame#0          TX packets#84664 errors#0 dropped#0 overruns#0 carrier#1          collisions#0 txqueuelen#1000           RX bytes#313575212 (299.0 MiB)  TX bytes#4784245 (4.5 MiB)---------------------------------- snip output -----------------------------------------        Any Linux application hosted in this environment shares the process space with XR, and we refer to it as a native application.    The FIB is programmed by the XR control plane exclusively. The global-vrf network namespace only sees a couple of routes by default#                  A default route pointing to XR FIB. This way any packet with an unknown destination is handed-over by a linux application to XR for routing. This is achieved through a special interface called fwdintf as shown in the figure above.                    Routes in the subnet of the Management Interface#  Mgmt0/RP0/CPU0. The management subnet is local to the global-vrf network namespace.              To view these routes, simply issue an ip route in the XR linux shell#    AKSHSHAR-M-K0DS#native-app-bootstrap akshshar$ vagrant ssh rtr xr-vm_node0_RP0_CPU0#~$ xr-vm_node0_RP0_CPU0#~$ xr-vm_node0_RP0_CPU0#~$ ip route default dev fwdintf  scope link  src 10.0.2.15 10.0.2.0/24 dev Mg0_RP0_CPU0_0  proto kernel  scope link  src 10.0.2.15 xr-vm_node0_RP0_CPU0#~$ xr-vm_node0_RP0_CPU0#~$     However if we configure loopback 1 in XR, a new route appears in the XR linux environment#    RP/0/RP0/CPU0#rtr1#RP/0/RP0/CPU0#rtr1#conf tSun Jul 17 11#59#33.014 UTCRP/0/RP0/CPU0#rtr1(config)#RP/0/RP0/CPU0#rtr1(config)#int loopback 1RP/0/RP0/CPU0#rtr1(config-if)#ip addr 6.6.6.6/32RP/0/RP0/CPU0#rtr1(config-if)#commitSun Jul 17 11#59#49.970 UTCRP/0/RP0/CPU0#rtr1(config-if)#RP/0/RP0/CPU0#rtr1#RP/0/RP0/CPU0#rtr1#bash                               Sun Jul 17 11#59#58.941 UTC[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$ip routedefault dev fwdintf  scope link  src 10.0.2.15 6.6.6.6 dev fwd_ew  scope link  src 10.0.2.1510.0.2.0/24 dev Mg0_RP0_CPU0_0  proto kernel  scope link  src 10.0.2.15 [xr-vm_node0_RP0_CPU0#~]$    This is what we call the east-west route. Loopback1 is treated as a special remote interface from the perspective of the XR linux shell. It does not appear in ifconfig like the other interfaces. This way an application sitting inside the global-vrf network namespace can talk to XR on the same box by simply pointing to loopback1.        Finally, if you followed the Bring your own Container (LXC) App, you&#8217;ll notice that in the XML file meant to launch the lxc, we share the global-vrf network namespace with the container; specifically, in this section#    Create LXC SPEC XML File    This makes the architecture work seamlessly for native and container applications. An LXC app has the same view of the world, the same routes and the same XR interfaces to take advantage of, as any native application with the shared global-vrf namespace.            You&#8217;ll also notice my awkward rendering for a linux app#        Notice the TPA IP ? This stands for Third Party App IP address.    The purpose of the TPA IP is simple. Set a src-hint for linux applications, so that originating traffic from the applications (native or LXC) could be tied to the loopback IP or any reachable IP of XR.    This approach mimics how routing protocols like to identify routers in complex topologies# through router-IDs. With the TPA IP, application traffic can be consumed, for example, across an OSPF topology just by relying on XR&#8217;s capability to distribute the loopback IP address selected as the src-hint.    We go into further detail here# Set the src-hint for Application traffic  That pretty much wraps it up. Remember, XR handles the routing and applications use only a subset of the routing table to piggy-back on XR for reachability!", "url": "https://xrdocs.github.io/application-hosting/blogs/2016-06-28-xr-app-hosting-architecture-quick-look/", "tags": "iosxr, cisco, architecture, xr toolbox", "title": "XR App-hosting architecture: Quick Look!", "author": "Akshat Sharma"}, "tutorials-2016-10-03-pipeline-to-text-tutorial": {"content": "     Using Pipeline  Using Pipeline          Preparing the Router      Getting Pipeline      Pipeline.conf      Configuring the Input Stage for TCP Dial-Out      Configuring the Output Stage for Text File      Running Pipeline      Seeing the Data      Why Did We Do That Again?        Using PipelineIn an earlier blog, I introduced Pipeline, a multi-function telemetry collection service written in Go.  In this tutorial, I\u2019ll cover how to set up Pipeline for the simplest of tasks#  ingesting telemetry data over TCP and writing it to a file as a JSON object.Preparing the RouterThis tutorial assumes that you\u2019ve already configured your router for model-driven telemetry (MDT) with TCP dial-out using the instructions in this tutorial. The IP address and port that you specify in the destination-group in the router config should match the IP address and port on which Pipeline is listening.Getting PipelinePipeline is available from github.Pipeline.confThe pipeline.conf file contains all the configuration necessary to get Pipeline running.  In many cases, the default pipeline.conf can be used with little or no modification.The pipeline configuration is divided up into sections.  Each section is delineated by an arbitrary name enclosed in square brackets.  Each section defines either an input stage (\u201cstage = xport_input\u201d) or an output stage (\u201cstage = export_output\u201d).  Other parameters in the section tell Pipeline what to listen for (in the case of an input stage) or how to output the data (for an output stage).The easiest way to understand this is to look at a simple example.Configuring the Input Stage for TCP Dial-OutLet\u2019s take a look at the TCP dial-out section in the default pipeline.conf.scadora@darcy#~/bigmuddy-network-telemetry-pipeline$ grep -A20 ~Example of a TCP dialout~ pipeline.conf# Example of a TCP dialout (router connects to pipeline over TCP)#[testbed]stage = xport_input## Module type, the type dictates the rest of the options in the section.# TCP can only be used as xport_iinput currently. UDP works similarly.#type = tcp## Supported encapsulation is 'st' for streaming telemetry header. This# is the header used to carry streaming telemetry payload in TCP and UDP.#encap = st## TCP option dictating which binding to listen on. Can be a host name# or address and port, or just port.#listen = #5432This [testbed] section shown above will work \u201cas is\u201d for MDT with TCP dial-out.  If you want to change the port that Pipeline listens on to something other than \u201c5432\u201d, you can edit this section of the pipeline.conf.  Otherwise, we\u2019re good to go for the input stage.Configuring the Output Stage for Text FileTo dump the received data to a file, we need a \u201ctap\u201d stage in Pipeline.  The default pipeline.conf file comes with a tap stage section called [inspector] as you can see below.scadora@darcy#~/bigmuddy-network-telemetry-pipeline$ grep -A20 ~Example of a tap stage~ pipeline.conf# Example of a tap stage; dump content to file, or at least count messages#[inspector]stage = xport_output## Module type# tap is only supported in xport_output stage currently.#type = tap## File to dump decoded messages#file = /data/dump.txt## encoding = json#This [inspector] section shown above will work \u201cas is\u201d for dumping data to a file.  If you want to change the file that Pipeline writes to (default is /data/dump.txt) or write with a different encoding (default is JSON), you can edit this section of the pipeline.conf.  Otherwise, we\u2019re good to go for the output stage as well.Running PipelineRunning pipeline is trivial.  Just execute the binary in the bin directory.  Pipeline will use the pipeline.conf file by default.scadora@darcy#~/bigmuddy-network-telemetry-pipeline$ bin/pipeline &amp;[1] 21975scadora@darcy#~/bigmuddy-network-telemetry-pipeline$ Startup pipelineLoad config from [pipeline.conf], logging in [pipeline.log]Wait for ^C to shutdownscadora@darcy#~/bigmuddy-network-telemetry-pipeline$Seeing the DataAssuming your router is properly configured, the router should initiate the TCP session to Pipeline and stream the data specified in the sensor-group configuration.  To see the data as it comes in, use the Linux \u201ctail\u201d utility on the file that the [inspector] stage was configured to write to.scadora@darcy#~/bigmuddy-network-telemetry-pipeline$ tail -f dump.txt------- 2017-04-03 20#37#06.763244782 -0700 PDT -------Summary# GPB(common) Message [172.30.8.53#15457(SunC)/Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters msg len# 5984]{    ~Source~# ~172.30.8.53#15457~,    ~Telemetry~# {        ~node_id_str~# ~SunC~,        ~subscription_id_str~# ~Sub1~,        ~encoding_path~# ~Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters~,        ~collection_id~# 712163,        ~collection_start_time~# 1491277026499,        ~msg_timestamp~# 1491277026499,        ~collection_end_time~# 1491277026507    },    ~Rows~# [        {               ~Timestamp~# 1491277026506,            ~Keys~# {                ~interface-name~# ~MgmtEth0/RP0/CPU0/0~            },            ~Content~# {                ~applique~# 0,                ~availability-flag~# 0,                ~broadcast-packets-received~# 65679,                ~broadcast-packets-sent~# 0,                ~bytes-received~# 272894774,                ~bytes-sent~# 20829696017,                ~carrier-transitions~# 1,                &lt;output snipped for brevity&gt;Why Did We Do That Again?To leverage the real power of telemetry, you need to get the data into an analytics stack like InfluxDB or Prometheus\u2026or to multiple consumers via a pub/sub mechanism like Kafka.  Pipeline can do all that and I\u2019ll show you how in future tutorials.But having the power to dump encoded telemetry data into a text file does come in handy, especially when you\u2019re setting up telemetry and Pipeline for the first time.  The tap output module gives you a quick and easy way to validate that the router is sending the data you think it should be sending.  Once that\u2019s settled, it\u2019s a simple matter of configuring a different output module to send the data some place really useful.Give Pipeline a try and let us know what you think!", "url": "https://xrdocs.github.io/telemetry/tutorials/2016-10-03-pipeline-to-text-tutorial/", "tags": "iosxr, MDT, telemetry, pipeline", "title": "Using Pipeline: TCP to textfile", "author": "Shelly Cadora"}, "tutorials-ncs5500-urpf": {"content": "     Understanding NCS5500 Resources  S01E07 NCS5500 URPF Configuration and Impact on Scale          Previously on \u201cUnderstanding NCS5500 Resources\u201d      Definition      URPF relevancy      NCS5500 Implementation      Configuration and impact on base systems (no eTCAM)      Configuration and impact on scale Jericho systems (with eTCAM)      Configuration and impact on scale Jericho+ systems (with NG eTCAM)      Verification      Conclusion        S01E07 NCS5500 URPF Configuration and Impact on ScalePreviously on \u201cUnderstanding NCS5500 Resources\u201dIn previous posts, we presented#  the different routers and line cards in NCS5500 portfolio  we explained how IPv4 prefixes are sorted in LEM, LPM and eTCAM  we covered how IPv6 prefixes are stored in the same databases.  we demonstrated in a video how we can handle a full IPv4 and IPv6 Internet view on \u201cBase\u201d systems and line cards (i.e. without external TCAM, only using the LEM and LPM internal to the forwarding ASIC)  in the fifth post, we continued with a new video where we demonstrated the very high scale we can reach on Jericho-based systems when using an external TCAM  last post, we introduced systems based on the Jericho+ forwarding ASIC and we detailed the routing distribution between the different memories and the scale they can achieve.In this new episode, we will cover the impact of activating URPF on the NCS5500 routers.DefinitionURPF stands for Unicast Reverse Path Forwarding.Defintion from the CCO website#\u201cThis security feature works by enabling a router to verify the reachability of the source address in packets being forwarded. This capability can limit the appearance of spoofed addresses on a network. If the source IP address is not valid, the packet is discarded.Unicast RPF in strict mode, the packet must be received on the interface that the router would use to forward the return packet.Unicast RPF in loose mode, the source address must appear in the routing table.\u201dIt\u2019s a feature configured at the interface level.URPF relevancyRegardless of the Forwarding ASIC (Qumran-MX, Jericho or Jericho+), the NCS5500 only supports URPF in loose mode.Configuring URPF comes at a cost in term of scale on some of the NCS5500 family members. It will be detailed extensively in this article. That\u2019s why it\u2019s important to understand what are the benefits of enabling this feature.As explained in the definition section above, the loose mode simply verify that source addresses of the packets received are in of the routable space. To bypass this \u201cprotection\u201d, it\u2019s fairly easy for an attacker to pick source addresses inside existing routes when forging the packet instead of totally random addresses.We invite the operators to check how much traffic is currently dropped by the URPF loose mode if they have it enabled on production routers.Example# to check this on an ASR9000#RP/0/RP0/CPU0#Router#show cef drops | i RPF drops  RPF drops            packets #               0  RPF drops            packets #               0  RPF drops            packets #               0  RPF drops            packets #               0  RPF drops            packets #               0  RPF drops            packets #               0  RPF drops            packets #               0  RPF drops            packets #               0  RPF drops            packets #           50065  RPF drops            packets #               0  RPF drops            packets #            1262  RPF drops            packets #         3627918  RPF drops            packets #            1262  -- SNIP --And compare these figures to the packet count per interface to understand how much traffic it represents. The impact it could have on route scale and the protection efficiency it offers need to be put in perspective before deciding if it is worth enabling URPF.Now said, some other very good reasons to enable URPF loose mode exist. For example, it\u2019s a mandatory brick of a Source-based Remotely Triggered Black Hole architecture (S-RTBH).NCS5500 ImplementationWe don\u2019t support URPF strict mode and we have no plans to add it in the future on NCS5500. URPF loose mode is available on NCS5500 since IOS XR 6.2.2 for IPv4 and IPv6. The feature is supported on Jericho and Jericho+ systems, with or without eTCAM.The configuration implies the deactivation of some profiles, different on \u201cbase\u201d and \u201cscale\u201d systems. After this preliminary operation, the configuration is applied at the interface level.Deactivating URPF on an interface implies to do it for both IPv4 and IPv6.Allow-self-ping is the default mode and allow-default is not supported.Configuration and impact on base systems (no eTCAM)On \u201cbase\u201d systems (without external TCAM)#Since URPF requires two accesses to the LEM (lookup for source address then for destination address in the packet header), we have to disable the optimizations present by default or after a configuration#hw-module fib ipv4 scale host-optimized-disablehw-module fib ipv6 scale internet-optimized-disableNote# depending on the IOS XR version, the options could be different and actually could be the opposite of \u201cdisable\u201d, be attentive at what is availabe in the CLI.With the optimization disabled and after the line cards / system reload, we have now#Important# with such mode, it will no longer be possible to handle a full internet view (v4+v6 or v4-only).The configuration can now be applied on the interfaces#hw-module fib ipv4 scale host-optimized-disablehw-module fib ipv6 scale internet-optimized-disable!interface HundredGigE0/7/0/0 ipv4 address 192.168.1.1 255.255.255.252 ipv4 verify unicast source reachable-via any ipv6 verify unicast source reachable-via any ipv6 address 2001#10#1##1/64Configuration and impact on scale Jericho systems (with eTCAM)Now, let\u2019s consider the scale systems and line cards with Jericho ASICs#The eTCAM is a 80bit memory and in normal condition we use it in two blocks of 40 bits to double the capacity. The first access being performed on the first half and the second access in the pipeline being done on the second half.With URPF, we need these two accesses to check source and destination, it\u2019s no longer possible to use the double capacity mode# it needs to be disabled.RP/0/RP0/CPU0#NCS5508-632(config)#hw-module tcam fib ipv4 scaledisableRP/0/RP0/CPU0#NCS5508-632(config)#commitThe impact on scale is significative since we lost 1M out of the 2M of the eTCAM capacity.Let\u2019s check with a large routing table (internet v4 + internet v6 + 435k host routes) what is the impact#RP/0/RP0/CPU0#5508-6.3.2#sh bgp sumBGP router identifier 1.1.1.1, local AS number 100BGP generic scan interval 60 secsNon-stop routing is enabledBGP table state# ActiveTable ID# 0xe0000000   RD version# 1720749BGP main routing table version 1720749BGP NSR Initial initsync version 634456 (Reached)BGP NSR/ISSU Sync-Group versions 1720749/0BGP scan interval 60 secs BGP is operating in STANDALONE mode.  Process       RcvTblVer   bRIB/RIB   LabelVer  ImportVer  SendTblVer  StandbyVerSpeaker         1720749    1720749    1720749    1720749     1720749     1720749 Neighbor        Spk    AS MsgRcvd MsgSent   TblVer  InQ OutQ  Up/Down  St/PfxRcd192.168.100.151   0  1000  706753  307270  1720749    0    0     5w0d     655487192.168.100.152   0 45896  707144  307270  1720749    0    0     5w0d     656126192.168.100.153   0  7018  705342  307270  1720749    0    0     5w0d     654330192.168.100.154   0  1836  709963  307270  1720749    0    0     5w0d     658948192.168.100.155   0 50300  687217  307270  1720749    0    0     5w0d     636208192.168.100.156   0 50304  708316  307270  1720749    0    0     5w0d     657301192.168.100.157   0 57381  708322  307270  1720749    0    0     5w0d     657307192.168.100.158   0  4608  728503  812358  1720749    0    0     5w0d     677487192.168.100.159   0  4777  717228  307270  1720749    0    0     5w0d     666213192.168.100.160   0 37989  339686  307270  1720749    0    0     5w0d     288706192.168.100.161   0  3549  705390  307270  1720749    0    0     5w0d     654376192.168.100.163   0  8757  683499  307270  1720749    0    0     5w0d     632483192.168.100.164   0  3257  705671  307270  1720749    0    0     5w0d     654661192.168.100.166   0 10051 1186443  217145  1720749    0    0 00#28#05    1186410 RP/0/RP0/CPU0#5508-6.3.2#sh dpa resource iproute loc 0/7/CPU0 ~iproute~ DPA Table (Id# 24, Scope# Global)--------------------------------------------------IPv4 Prefix len distributionPrefix   Actual            Capacity    Prefix   Actual            Capacity/0       3                 20           /1       0                 20/2       0                 20           /3       0                 20/4       3                 20           /5       0                 20/6       0                 20           /7       0                 20/8       16                20           /9       14                20/10      37                204          /11      107               409/12      288               818          /13      557               1636/14      1071              3275         /15      1909              5732/16      13572             42381        /17      8005              25387/18      14055             42585        /19      25974             86603/20      40443             127348       /21      45082             141679/22      83722             231968       /23      71750             207173/24      395142            1105590      /25      2085              4299/26      3362              4504         /27      5736              3275/28      15909             2866         /29      17377             6961/30      42508             2866         /31      112               204/32      435868            20                          NPU ID# NPU-0           NPU-1           NPU-2           NPU-3                          In Use# 1224707         1224707         1224707         1224707                 Create Requests                           Total# 1224713         1224713         1224713         1224713                         Success# 1224713         1224713         1224713         1224713                 Delete Requests                           Total# 6               6               6               6                         Success# 6               6               6               6                 Update Requests                           Total# 341539          341539          341539          341539                         Success# 341538          341538          341538          341538                    EOD Requests                           Total# 0               0               0               0                         Success# 0               0               0               0                          Errors                     HW Failures# 0               0               0               0                Resolve Failures# 0               0               0               0                 No memory in DB# 0               0               0               0                 Not found in DB# 0               0               0               0                    Exists in DB# 0               0               0               0 RP/0/RP0/CPU0#5508-6.3.2#sh contr npu resources lem loc 0/7/CPU0HW Resource Information    Name                            # lem OOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP -- Current Usage    NPU-0        Total In-Use                # 467163   (59 %)        iproute                     # 435868   (55 %)        ip6route                    # 31304    (4 %)        mplslabel                   # 0        (0 %)-- SNIP -- RP/0/RP0/CPU0#5508-6.3.2#sh contr npu resources lpm loc 0/7/CPU0HW Resource Information    Name                            # lpm OOR Information    NPU-0        Estimated Max Entries       # 530552        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP --Current Usage    NPU-0        Total In-Use                # 5235     (1 %)        iproute                     # 0        (0 %)        ip6route                    # 5219     (1 %)        ipmcroute                   # 0        (0 %)-- SNIP -- RP/0/RP0/CPU0#5508-6.3.2#sh contr npu resources exttcamipv4 loc 0/7/CPU0HW Resource Information    Name                            # ext_tcam_ipv4 OOR Information    NPU-0        Estimated Max Entries       # 2048000        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP -- Current Usage    NPU-0        Total In-Use                # 788839   (39 %)        iproute                     # 788839   (39 %)        ipmcroute                   # 0        (0 %)-- SNIP -- RP/0/RP0/CPU0#5508-6.3.2#So we have 13 times Internet (coming from actual internet full views provided by different customers) and a lot of host routes (435k). In a Jericho + eTCAM card, before enabling URPF it occupies#  LEM# 59%  LPM# 1%  eTCAM# 39%Let\u2019s now remove the double capacity mode and configure the URPF on interfacesRP/0/RP0/CPU0#5508-6.3.2#sh run | i hw-mBuilding configuration...RP/0/RP0/CPU0#5508-6.3.2#sh run int hu 0/7/0/0interface HundredGigE0/7/0/0cdpipv4 address 192.168.1.1 255.255.255.252ipv6 address 2001#10#1##1/64load-interval 30flow ipv4 monitor fmm sampler fsm1 ingress!RP/0/RP0/CPU0#5508-6.3.2#confRP/0/RP0/CPU0#5508-6.3.2(config)#hw-module tcam fib ipv4 scaledisableIn order to activate this new scale, you must manually reload the chassis/all line cardsRP/0/RP0/CPU0#5508-6.3.2(config)#commitRP/0/RP0/CPU0#5508-6.3.2(config)#endRP/0/RP0/CPU0#5508-6.3.2#adminroot connected from 127.0.0.1 using console on 5500-6.3.2sysadmin-vm#0_RP0# hw-module location 0/7 reloadReload hardware module ? [no,yes] yesresult Card graceful reload request on 0/7 succeeded.sysadmin-vm#0_RP0# exitRP/0/RP0/CPU0#5508-6.3.2#confRP/0/RP0/CPU0#5508-6.3.2(config)#int hu 0/7/0/0RP/0/RP0/CPU0#5508-6.3.2(config-if)# ipv4 verify unicast source reachable-via anyRP/0/RP0/CPU0#5508-6.3.2(config-if)# ipv6 verify unicast source reachable-via anyRP/0/RP0/CPU0#5508-6.3.2(config-if)#commitRP/0/RP0/CPU0#5508-6.3.2(config-if)#endRP/0/RP0/CPU0#5508-6.3.2#RP/0/RP0/CPU0#5508-6.3.2#sh run | i hw-mBuilding configuration...hw-module tcam fib ipv4 scaledisableRP/0/RP0/CPU0#5508-6.3.2#sh run int hu 0/7/0/0interface HundredGigE0/7/0/0cdpipv4 address 192.168.1.1 255.255.255.252ipv4 verify unicast source reachable-via anyipv6 verify unicast source reachable-via anyipv6 address 2001#10#1##1/64load-interval 30flow ipv4 monitor fmm sampler fsm1 ingress! RP/0/RP0/CPU0#5508-6.3.2#sh contr npu resources lem loc 0/7/CPU0HW Resource Information    Name                            # lem OOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP -- Current Usage    NPU-0        Total In-Use                # 467173   (59 %)        iproute                     # 435868   (55 %)        ip6route                    # 31304    (4 %)        mplslabel                   # 0        (0 %)-- SNIP --RP/0/RP0/CPU0#5508-6.3.2#sh contr npu resources lpm loc 0/7/CPU0HW Resource Information    Name                            # lpm OOR Information    NPU-0        Estimated Max Entries       # 171722        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP --Current Usage    NPU-0        Total In-Use                # 5234     (3 %)        iproute                     # 0        (0 %)        ip6route                    # 5218     (3 %)        ipmcroute                   # 0        (0 %)-- SNIP --RP/0/RP0/CPU0#5508-6.3.2#sh contr npu resources exttcamipv4 loc 0/7/CPU0HW Resource Information    Name                            # ext_tcam_ipv4 OOR Information    NPU-0        Estimated Max Entries       # 1024000        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green-- SNIP --Current Usage    NPU-0        Total In-Use                # 788839   (77 %)        iproute                     # 788839   (77 %)        ipmcroute                   # 0        (0 %)-- SNIP --RP/0/RP0/CPU0#5508-6.3.2#With URPF configured (and dual capacity mode disabled) and the same very large table we have#  LEM# 59%  LPM# 3%  eTCAM# 77%In conclusion of this demo, enabling URPF implies the deactivation of the dual capacity mode and reduces by half the eTCAM memory. Nevertheless, routes are also stored in LEM and LPM. A very large internet table can still fit in the system, even if the room for growth is reduced.Configuration and impact on scale Jericho+ systems (with NG eTCAM)The Jericho+ w/ eTCAM systems don\u2019t need to disable the dual capacity mode to enable URPF.The same configuration than above can be re-used (except the hw-module commands).The impact on scale is not null but is signficantly less than it was on the Jericho-based systems. Since the J+/eTCAM systems are qualified for 4M entries which is much less than its actual capacity, the 25% impact doesn\u2019t change the officially supported numbers# with URPF enabled we still support 4M routes in eTCAM.VerificationPackets dropped by URPF can be counted at the NPU level with#RP/0/RP0/CPU0#NCS5508-6.3.2#show contr npu stats traps-all instance 0 location 0/7/CPU0 | inc RpfRxTrapUcLooseRpfFail                          0    84   0x54        32035   0         0        RxTrapUcStrictRpfFail                         0    137  0x89        32035   0         0   ConclusionURPF loose mode can be configured on all NCS5500 systems. On Jericho w/ eTCAM, the impact is significative but we demonstrated we still support a very large public table and a lot of host routes. On Jericho+ w/ eTCAM, URPF doesn\u2019t affect the supported scale of 4M entries.", "url": "https://xrdocs.github.io/cloud-scale-networking/tutorials/ncs5500-urpf/", "tags": "ncs5500, urpf, iosxr, internet, scale", "title": "NCS5500 URPF: Configuration and Impact on Scale", "author": "Nicolas Fevrier"}, "blogs-2018-02-25-internet-traffic-trends": {"content": "     On This Page  Introduction  Unicast Video Growth          Broadcast Video History      Video on Demand      Video over IP      Over the Top IP Video        Producers and Consumers          Content Providers      Caching and Content Delivery Networks      Eyeball Networks        Efficient Unicast Video Delivery          What is Network Efficiency?      Role of Internet Peering      Localized Peering      Service Provider Unicast Delivery Headend      Express Peering Fabrics        IntroductionOver the last five years Internet traffic has been driven by one dominant source, unicast Internet video. The rise in Internet video has its roots in how user viewing habits have changed as unicast video delivery became more viable as an alternative to broadcast or multicast delivery. The capacity requirements of modern video delivery require rethinking networks to make the most efficient use of resources at all layers. This two-part blog series will first cover how video delivery has evolved to bring us where we are today. The second part will cover network architecture and technology to help improve network efficiency to deal with the rising tide of unicast video.Unicast Video GrowthBroadcast Video HistoryTelevision video delivery for many years followed the same path blazed by radio before it, broadcasting a single program over the air at a specific time to anyone within range of the signal. Cable networks were built in the 70s and 80s, with the promise of delivering a wider variety of content to subscribers not subject to the same impairments as over the air (OTA) broadcasts, while eliminating the use of antennas. A physical medium like coaxial cable exhibits similar properties as transmission through the air as electrical signals are replicated across branches in the medium. The original primitive cable networks were still analog end to end and built for broadcast delivery of all video to every user. Satellite video delivery worked in much the same way, simply broadcasting all signals and requiring the end device tune to the channel at a specific analog frequency and the user tune in to watch at a specific time of day. In the 1980s and 1990s, TV viewers could always cite the exact day and time of their favorite programs. While broadcast video has limitations on flexibility for users, it has the ultimate efficiency when it comes to network resources as the signal is broadcast once to all users once at the origin.Broadcast Video DeliveryVideo on DemandVideo on Demand, or VoD, originated in the late 1980s and rose to prominence in the 1990s as a way to deliver video content to users on their time, not tied to a broadcast schedule. Viewers could now select what they wanted to view and have it be delivered to them immediately. It took the reduction in cost of the base infrastructure components, mainly storage and compute, to make a service like VoD a reality. VoD was also seen as a way to further monetize the cable network and challenge the huge video rental business that existed during those times with Pay Per View (PPV) content.VoD delivery used two different methods for delivery back in its original form, push or pull. In the push method, content was delivered via broadcast to a single or all subscribers and stored locally on a device such as a set-top box, for viewing later. The pull method streamed the content to the subscriber device from a remote server on user demand. In the end, the pull method easily won out due to the much larger variety of content available and less costly end user device. In order to support a single user viewing content destined for only their device, it required dedicating analog spectrum for the channel. It was still broadcast to a number of users, but encrypted such that only the paying subscriber could view it. Even though it was still analog broadcast at the lowest level, the content was unicast to a specific subscriber by consuming resources for a single video stream destined to a single viewer. VoD fundamentally changed users viewing habits and also introduced the first unicast video delivery.Video over IPService providers who built out wireline networks using DSL and Ethernet technology, network infrastructure types not having a native analog video delivery method, looked at IP as the higher layer protocol to deliver video content to users. These networks were deployed to take advantage of multicast, a subset of the broadcast capability inherent in Ethernet, and standardized for IP in RFC 1112. IP multicast improves network efficiency by implementing frame replication in the network devices, combined with a set of control-plane protocols to create optimized distribution trees. In its simplest form IP multicast replicates a broadcast network, sending all channels to all users (dense mode), and some providers used this method. However, to improve network efficiency it is now most common for end devices to use protocols like IGMP (v4) and MLD (v6) so optimized multicast trees are built. This type of multicast IP delivery is known as IPTV and is implemented in North America by networks such as AT&amp;T UVerse and Google Fiber.}Multicast Video Delivery\u00a0Supporting VoD on these networks requires delivering video over IP. Similar mechanisms can be used as analog networks, using a specific multicast address for the subscriber stream. However, instead of simulating a unicast stream using a more complex multicast process, streaming the content as a to a unicast IP address assigned to a device is much simpler and supported a wider range of devices, even across networks that do not support native multicast delivery. Today more and more content on wireline networks is delivered using unicast IP, even on traditional cable networks, due to its flexibility and the ability to serve content to a variety of end user devices from a single content source. The flexibility and ease of delivery using unicast IP has superceded the inefficiencies of delivering duplicate content over the same network resources.}Unicast Video DeliveryOver the Top IP VideoThe unicast video content described above has typically been contained within a service provider network. As the Internet has grown and bandwidth to end users increased, video content from alternative sources emerged. Broadband Internet became more widely available in the mid 2000s and with it came user-generated video providers like YouTube along with traditional media rental companies like Netflix embracing streaming video for rental delivery. These Internet content providers deliver video \u201cover the top\u201d (OTT) of service provider networks since the origin and destination are applications controlled by the content provider. The growth of OTT Internet video has continued to climb rapidly over the last decade along with IP video in general. IP video accounted for 73% of all Internet traffic in 2016, and by 2021 will account for 82% of all Internet traffic. The most rapid increase is in over the top Internet video, shown in the graph below from the Cisco VNI.It is not only on-demand content driving OTT growth, streaming of traditional broadcast video like sports to mobile devices, tablets, smart TVs, and additional endpoints is increasing in popularity. The last few years have seen a number of new services delivering traditional linear (live) TV using OTT IP delivery. Over the top video is by nature unicast, as each stream is simply sent on demand when a user clicks \u201cplay.\u201d Since there is little efficiency in sending a single stream to each user, it causes tremendous strain on network resources. It is however a trend that is unlikely to change, so new methods need to be employed to improve network efficiency and build networks to handle increasing video traffic demands.Producers and ConsumersContent ProvidersContent providers are those who originate video streams. A content source could also be a service provider providing video content to its own subscriber base, or an OTT Internet video source. A content provider may not be the original origin of the content, but is simply a means to deliver the content to the end user. dCaching and Content Delivery NetworksCaching is the process of storing content locally to serve to users instead of utilizing network resources to retrieve the content each time the content is accessed. Caching of Internet content became popular with the rise of the Internet in the late 1990s with open-source software such as Squid and commercial products like Cacheflow and Cisco WAAS. Called \u201ctransparent\u201d caches, they intercept content without the source or destination having knowledge of the caching. The content in those days was mainly primitive static content, but with the high cost of bandwidth, it was still sometimes beneficial to cache content. Transparent caches have evolved into systems today targeted at OTT providers, and use more sophisticated techniques to cache video content from any source. However, with the rise of end to end encryption use, transparent caches are no longer a realistic option for serving content closer to users.Content Delivery Networks (CDN) have been around for many years now, with the first major CDN Akamai going live in 1999. The aim of a CDN is to place content closer to end users by distributing caching servers closer to end users. CDNs such as Akamai, Limelight, and Fastly host and deliver a variety of content from their customers. In addition to more generic CDNs, content owners have built their own CDNs to deliver their own content. Examples of dedicated CDNs include the Netflix OpenConnect network and Google Global Cache network. Most new streaming video providers utilize a distributed CDN to deliver content. Each CDN uses proprietary mechanisms for request routing and content delivery, so providers must use analysis to determine which ones are the most optimal for their network.Eyeball NetworksWireless and wireline service providers providing the last mile Internet connection to end users are commonly known as \u201cEyeball\u201d networks, because the all content must pass through those networks for end users to view it. Around the world, and especially in North America, consolidation of service providers have left relatively few Eyeball networks serving a large number of subscribers.Efficient Unicast Video DeliveryWhat is Network Efficiency?Network efficiency in this context refers to minimizing the cost and consumption of network resources such as physical fiber, wavelengths,and IP interfaces to deliver unicast video content to end users. The equation to delivering video traffic efficiently is to create a network model reducing the distance, network hops, and network layer transitions between the content provider and content consumer while maintaining statistical multiplexing through aggregation where beneficial.Role of Internet PeeringInternet Peering is the exchange of traffic between two providers. Peering originated at third party carrier-neutral facilities known as Internet Exchange Points (IXP), with the exchange providing a public fabric to interconnect service providers. Due to consolidation and the dominant traffic type being video, the Internet has evolved from most content flowing through a Tier-1 Internet provider via transit connections to one of direct traffic exchange between content providers and eyeball networks. The majority of Internet video traffic today is exchanged via private network interconnection (PNI) between content providers and eyeball networks. The concept has been coined the \u201cFlattening of the Internet\u201d as the traditional hierarchical traffic flow between ISPs is eliminated. Traditional large IXPs still act as meet-me points for many providers, facilitating both public and private interconnection, but improving network efficiency demands traffic take shorter paths.Localized PeeringReducing the distance and network hops between where unicast video packets enter your network and exit to the consumer is a key priority for service providers in reducing network cost. Each pass through an optical transponder or router interface adds additional cost to the transit path, especially on long-haul paths from traditional large IXPs to subscriber regions. The aforementioned rise in video traffic demands peering move closer to the edges of the network to serve wireline broadband subscribers along with high-bandwidth 5G mobile users. Content providers have invested heavily in their own networks as well as distributed caches serving content from any network location with Internet access. Third party co-location providers have begun building more regional locations supporting PNI between content distributors and the end subscribers on the SP network. This leads to a localized peering option for SPs and content providers, greatly reducing the distance and hops across the network. As more traffic shifts to becoming locally delivered building additional regional or metro peering locations becomes important to ensure less reliance on longer paths during failures.Localized Peering\u00a0Service Provider Unicast Delivery HeadendAs mentioned, service providers are seeing growth not only in OTT unicast video delivery, but also delivery for their own video services. Most service providers have deployed their own internal CDNs to provide unicast video content to their subscribers and migrate VoD off legacy analog systems onto an all-IP infrastructure. The same efficiency tools for dealing with off-net content from peers applies to on-net video services. There may be efficiencies gained in placing SP content servers in the same facilities as other content peers, aggregating all content traffic in a single location for efficient delivery to end users.Express Peering FabricsSee how Express Peering Fabrics can help drive efficiency into service providers networks in the next blog in this series.", "url": "https://xrdocs.github.io/design/blogs/2018-02-25-internet-traffic-trends/", "tags": "iosxr, Peering, Design", "title": "Internet Traffic Trends", "author": "Phil Bedard"}, "tutorials-2017-10-25-ncs1002-telemetry-deep-dive": {"content": "     NCS1002 Telemetry deep dive  Introduction  Sensor Paths for NCS1002  NCS1002 Telemetry configuration  NCS1002 telemetry data consumption  Conclusion  IntroductionThis tutorial continues the series of documents about automation of configuration of Cisco optical products. The purpose of this document is to give you a lot of details about Telemetry on NCS1002 (terminal device). The goal is not only to give you some information about valuable sensor paths for NCS1002, but also to provide all the pieces for you to start exploring Telemetry on NCS1002 right away.Model-driven Telemetry (MDT) provides a mechanism to stream data from an MDT-capable device to a destination(s). There are several core components of Streaming Telemetry you should know and understand#  \u201cSensor path\u201d. Describes the data you want your NCS1002 to stream to a collector (for example, OSNR values from your line ports)  \u201cTransport protocol\u201d. Describes the protocol you want to use to deliver to your collector/controller the information you selected with sensor-paths (for example, TCP)  \u201cEncoder\u201d. Describes the format of the data on the wire (for example, GPB)  \u201cInitialization of streaming session\u201d. Describes who initiates the streaming of data from the router towards the collector. Two possible options are# dial-in mode (the collector initiates a session to the router and subscribes to data to be streamed out) or dial-out mode (the router initiates a session to the destinations based on the subscription.)  \u201cSubscription\u201d. Binds everything together for the router to start streaming data on the configured intervals.There is no need to go in details about telemetry, as there are many different technical documents available in xrdocs-telemetry, and you can also find configuration information on cisco.com.Sensor Paths for NCS1002With this generic understanding of telemetry, let\u2019s now define sensor paths that could be valuable exactly for your optical deployments based on NCS1002. These paths provide valuable information about NCS1002 and that list should be pretty complete for you to start playing around and testing your optical DCI segments. Feel free to add or remove paths from the suggested list as well as optimize sample-interval timers according to your requirements.Here is a list of sensor paths for NCS1002 with some basic explanation and print screens from Grafana for better visibility#  Monitoring of CPU utilization# Cisco-IOS-XR-wdsysmon-fd-oper#system-monitoring/cpu-utilization.With this model you\u2019re able to get information about NCS1002 CPU load for 1-, 5- and 15-min intervals.  Monitoring of memory usage# Cisco-IOS-XR-nto-misc-oper#memory-summary/nodes/node/summaryThis model helps you to have information about NCS1002 free memory availability.  Alarms# Cisco-IOS-XR-alarmgr-server-oper#alarms/brief/brief-card/brief-locations/brief-location/active.This path gives you information about currently active alarms in NCS1002.Here is an example of text-based output for active alarms on an NCS1002 under testing. You can modify your existing tools (or develop new) to collect this information either directly from a TSDB (time-series database) like InfluxDB or from Kafka platform, depending on your design.Summary# GPB(common) Message [172.16.1.1#27939(rosco_1)/Cisco-IOS-XR-alarmgr-server-oper#alarms/brief/brief-card/brief-locations/brief-location/active msg len# 3150]{    ~Source~# ~172.16.1.1#27939~,    ~Telemetry~# {        ~node_id_str~# ~rosco_1~,        ~subscription_id_str~# ~optical~,        ~encoding_path~# ~Cisco-IOS-XR-alarmgr-server-oper#alarms/brief/brief-card/brief-locations/brief-location/active~,        ~collection_id~# 24180,        ~collection_start_time~# 1508635312850,        ~msg_timestamp~# 1508635312850,        ~collection_end_time~# 1508635312858    },    ~Rows~# [        {            ~Timestamp~# 1508635312856,            ~Keys~# {                ~node-id~# ~0/RP0/CPU0~            },            ~Content~# {                ~alarm-info_PIPELINE_EDIT~# [                    {                        ~clear-time~# ~-~,                        ~clear-timestamp~# 0,                        ~description~# ~Optics0/0/0/1 - Improper Removal~,                        ~group~# ~controller~,                        ~location~# ~0/0~,                        ~set-time~# ~09/12/2017 23#30#07 PDT~,                        ~set-timestamp~# 1505284207,                        ~severity~# ~critical~                    },       {                        ~clear-time~# ~-~,                        ~clear-timestamp~# 0,                        ~description~# ~One Or More FPDs Need Upgrade Or Not In Current State~,                        ~group~# ~fpd-infra~,                        ~location~# ~0/0~,                        ~set-time~# ~09/14/2017 01#28#05 PDT~,                        ~set-timestamp~# 1505377685,                        ~severity~# ~major~                    },                    {                        ~clear-time~# ~-~,                        ~clear-timestamp~# 0,                        ~description~# ~HundredGigECtrlr0/0/0/0 - Carrier Loss On The LAN~,                        ~group~# ~ethernet~,                        ~location~# ~0/0~,                        ~set-time~# ~09/22/2017 07#46#09 PDT~,                        ~set-timestamp~# 1506091569,                        ~severity~# ~major~                    },       {                        ~clear-time~# ~-~,                        ~clear-timestamp~# 0,                        ~description~# ~Optics0/0/0/20 - Optics High Laser Bias~,                        ~group~# ~controller~,                        ~location~# ~0/0~,                        ~set-time~# ~10/19/2017 10#46#23 PDT~,                        ~set-timestamp~# 1508435183,                        ~severity~# ~minor~                    }                ]            }        }    ]}  Chassis info# Cisco-IOS-XR-plat-chas-invmgr-oper#platform-inventory/racks/rack/attributes/basic-info.This path is useful to get information about the serial number and software version on NCS1002. You don\u2019t need to stream this data very often.Here is an example output of this path for the NCS1002 under testing#Summary# GPB(common) Message [172.16.1.1#27939(rosco_1)/Cisco-IOS-XR-plat-chas-invmgr-oper#platform-inventory/racks/rack/attributes/basic-info msg len# 471]{    ~Source~# ~172.16.1.1#27939~,    ~Telemetry~# {        ~node_id_str~# ~rosco_1~,        ~subscription_id_str~# ~optical~,        ~encoding_path~# ~Cisco-IOS-XR-plat-chas-invmgr-oper#platform-inventory/racks/rack/attributes/basic-info~,        ~collection_id~# 24175,        ~collection_start_time~# 1508635312221,        ~msg_timestamp~# 1508635312221,        ~collection_end_time~# 1508635312225    },    ~Rows~# [        {            ~Timestamp~# 1508635312223,            ~Keys~# {                ~name~# ~0~            },            ~Content~# {                ~description~# ~Network Convergence System 1002 20 QSFP28/QSFP+ slots~,                ~firmware-revision~# ~~,                ~hardware-revision~# ~V01~,                ~is-field-replaceable-unit~# ~true~,                ~model-name~# ~NCS1002-K9~,                ~name~# ~Rack 0~,                ~serial-number~# ~CAT1111A1AA~,                ~software-revision~# ~6.2.2\\n~,                ~vendor-type~# ~1.3.6.1.4.1.9.12.3.1.3.1786~            }        }    ]}  Pluggables info# Cisco-IOS-XR-plat-chas-invmgr-oper#platform-inventory/racks/rack/slots/slot/cards/card/port-slots/port-slot/portses/ports/hw-components/hw-component/attributes/basic-info.This path is useful to get information about the serial number and hardware revision details about pluggables inserted into the platform. You don\u2019t need to stream this data very often, but it might be valuable to collect information about installed pluggables on each platform for inventory.Here is a partial output of this path for the NCS1002 under testing#Summary# GPB(common) Message [172.16.1.1#41461(rosco_1)/Cisco-IOS-XR-plat-chas-invmgr-oper#platform-inventory/racks/rack/slots/slot/cards/card/port-slots/port-slot/portses/ports/hw-components/hw-component/attributes/basic-info msg len# 4611]{    ~Source~# ~172.16.1.1#41461~,    ~Telemetry~# {        ~node_id_str~# ~rosco_1~,        ~subscription_id_str~# ~100~,        ~encoding_path~# ~Cisco-IOS-XR-plat-chas-invmgr-oper#platform-inventory/racks/rack/slots/slot/cards/card/port-slots/port-slot/portses/ports/hw-components/hw-component/attributes/basic-info~,        ~collection_id~# 47,        ~collection_start_time~# 1508773513140,        ~msg_timestamp~# 1508773513140,        ~collection_end_time~# 1508773513441    },    ~Rows~# [        {            ~Timestamp~# 1508773513174,            ~Keys~# {                ~name_PIPELINE_EDIT~# [                    ~0~,                    ~1~,                    ~0~,                    ~17d0~,                    ~0~,                    ~0~                ]            },            ~Content~# {                ~description~# ~Cisco 100G QSFP28 LR4-S Pluggable Optics Module~,                ~firmware-revision~# ~~,                ~hardware-revision~# ~V01 ~,                ~is-field-replaceable-unit~# ~false~,                ~model-name~# ~QSFP-100G-LR4-S~,                ~name~# ~0/0-Optics0/0/0/0-IDPROM~,                ~serial-number~# ~FNS11111AA1     ~,                ~software-revision~# ~~,                ~vendor-type~# ~1.3.6.1.4.1.9.12.3.1.16.1~            }        },        {            ~Timestamp~# 1508773513203,            ~Keys~# {                ~name_PIPELINE_EDIT~# [                    ~0~,                    ~1~,                    ~0~,                    ~17d5~,                    ~0~,                    ~0~                ]            },            ~Content~# {                ~description~# ~Cisco CFP2 DWDM Pluggable Optics~,                ~firmware-revision~# ~~,                ~hardware-revision~# ~V02 ~,                ~is-field-replaceable-unit~# ~false~,                ~model-name~# ~ONS-CFP2-WDM~,                ~name~# ~0/0-Optics0/0/0/5-IDPROM~,                ~serial-number~# ~OVE1111111A~,                ~software-revision~# ~~,                ~vendor-type~# ~1.3.6.1.4.1.9.12.3.1.16.1~            }        }    ]}  Client Optics RX and TX power# Cisco-IOS-XR-controller-optics-oper#optics-oper/optics-ports/optics-port/optics-info.With this model you can get information about TX and RX power levels from each lane on each pluggable on the platform.  Client Optics Laser Bias Current# Cisco-IOS-XR-controller-optics-oper#optics-oper/optics-ports/optics-port/optics-info.With this model you can get information about average laser bias current from each lane on each pluggable on the platform.  Client Optics RX utilization# Cisco-IOS-XR-pmengine-oper#performance-management/ethernet/ethernet-ports/ethernet-port/ethernet-current/ethernet-second30/second30-ethers/second30-etherThis sensor-path gives you highly granular information about RX load on each client port.  Pre-FEC and Post-FEC information about NCS1002 line ports# Cisco-IOS-XR-pmengine-oper#performance-management/otu/otu-ports/otu-port/otu-current/otu-second30/otu-second30fecs/otu-second30fecAs it can be seen, you can get almost real time information about Pre-FEC BER on each line port. Data is taken from each 30 seconds interval (the shortest one on NCS1002). Post-FEC BER is expected to be zero on each port (and this can be seen on the graph).  Bit errors corrected and uncorrected words# Cisco-IOS-XR-pmengine-oper#performance-management/otu/otu-ports/otu-port/otu-current/otu-second30/otu-second30fecs/otu-second30fecYou can also look at FEC from error bits corrected value and uncorrected words, to have more granular information on how FEC BER is calculated. As with Post-FEC, expectation is that UC-Words number is equal to zero.  OTN errors on near-end and on far-end# Cisco-IOS-XR-pmengine-oper#performance-management/otu/otu-ports/otu-port/otu-current/otu-second30/otu-second30otns/otu-second30otnThis model gives information about different OTN parameters for each line port#  ES-NE/ES-FE (Error Seconds in the near end / far end)  ESR-NE/ESR-FE (Error Seconds Ratio on the near end / far end)  SES-NE/SES-FE (Severely error seconds in the near end / far end)  SESR-NE/SESR-FE (Severely error seconds ratio in the near end / far end)  BBE-NE/ BBE-FE (Background block errors in the near end / far end)      BBER-NE/ BBER-FE (Background block errors in the near end / far end)Other parameters, such as UAS (Unavailable seconds) and FC (Failure counts) can also be found there.    OPT and OPR for line ports# Cisco-IOS-XR-pmengine-oper#performance-management/optics/optics-ports/optics-port/optics-current/optics-second30/optics-second30-optics/optics-second30-opticYou can get almost real time information about OPT/OPR levels for each line port with this model. Information is taken from each 30 seconds interval.  CD / PMD / DGD / OSNR for line ports# Cisco-IOS-XR-pmengine-oper#performance-management/optics/optics-ports/optics-port/optics-current/optics-second30/optics-second30-optics/optics-second30-opticYou can get information about average (also, minimum and maximum, if you want) values for each 30-seconds interval for#  Chromatic Dispersion  Polarization Mode Dispersion  Differential Group Delay  Optical Signal to Noise ratioSensor paths listed here can help you with fast monitoring of different important optical parameters as well as platform itself. Let\u2019s have a look how to configure that.NCS1002 Telemetry configurationThere are many possible ways to configure a device to stream the data using telemetry. You can find a good explanation how to do it with CLI configuration [here] (https#//xrdocs.github.io/telemetry/tutorials/2016-07-21-configuring-model-driven-telemetry-mdt/) or you can configure Telemetry using YANG Development Kit (YDK), like hereLet me first show you an example configuration of models above using CLI. Telemetry configuration will be based on gRPC, Self-Describing GPB and Dial-out Mode. telemetry model-driven destination-group DGROUP1  address-family ipv4 1.1.1.1 port 5432   encoding self-describing-gpb   protocol grpc no-tls  !  address-family ipv4 10.30.110.38 port 5432   encoding self-describing-gpb   protocol grpc no-tls  ! ! sensor-group SGROUP1  sensor-path Cisco-IOS-XR-plat-chas-invmgr-oper#platform-inventory/racks/rack/attributes/basic-info  sensor-path Cisco-IOS-XR-plat-chas-invmgr-oper#platform-inventory/racks/rack/slots/slot/cards/card/port-   slots/port-slot/portses/ports/hw-components/hw-component/attributes/basic-info ! sensor-group SGROUP2  sensor-path Cisco-IOS-XR-wdsysmon-fd-oper#system-monitoring/cpu-utilization  sensor-path Cisco-IOS-XR-nto-misc-oper#memory-summary/nodes/node/summary  sensor-path Cisco-IOS-XR-alarmgr-server-oper#alarms/brief/brief-card/brief-locations/brief-location/active ! sensor-group SGROUP3  sensor-path Cisco-IOS-XR-controller-optics-oper-sub1#optics-oper/optics-ports/optics-port/optics-info  sensor-path Cisco-IOS-XR-pmengine-oper#performance-management/otu/otu-ports/otu-port/otu-current/otu-second30/otu-second30fecs/otu-second30fec  sensor-path Cisco-IOS-XR-pmengine-oper#performance-management/otu/otu-ports/otu-port/otu-current/otu-second30/otu-second30otns/otu-second30otn  sensor-path Cisco-IOS-XR-pmengine-oper#performance-management/ethernet/ethernet-ports/ethernet-port/ethernet-current/ethernet-second30/second30-ethers/second30-ether  sensor-path Cisco-IOS-XR-pmengine-oper#performance-management/optics/optics-ports/optics-port/optics-current/optics-second30/optics-second30-optics/optics-second30-optic ! subscription Sub1  sensor-group-id SGROUP1 sample-interval 1800000  destination-id DGROUP1 ! subscription Sub2  sensor-group-id SGROUP2 sample-interval 20000  destination-id DGROUP1 ! subscription Sub3  sensor-group-id SGROUP3 sample-interval 10000  destination-id DGROUP1 !MDT configuration using CLI is very straightforward and simple.More interesting and powerful way to configure telemetry on NCS1002 is through YDK. If you want to read more about YDK, a lot of details and information can be found here with hundreds of examples here. Let\u2019s briefly cover major parts of YDK for NCS1002 telemetry configuration for your convenience. For this example I will use native IOS-XR telemetry YANG model. Configuration is based on gRPC Dial-out with self-describing GPB model (the same as it was with CLI).Let\u2019s start with configuring destination address/port, encoding and transport protocol# destination_group = telemetry_model_driven.destination_groups.DestinationGroup()## the name of this destination groupdestination_group.destination_id = 'DGROUP'ipv4_destination = destination_group.ipv4_destinations.Ipv4Destination()## address and port of the server configurationipv4_destination.destination_port = 57500ipv4_destination.ipv4_address = 10.30.110.38## define encodingipv4_destination.encoding = xr_telemetry_model_driven_cfg.EncodeTypeEnum.self_describing_gpbprotocol = ipv4_destination.Protocol()## define the transport protocolprotocol.protocol = xr_telemetry_model_driven_cfg.ProtoTypeEnum.grpcprotocol.no_tls = 1ipv4_destination.protocol = protocoldestination_group.ipv4_destinations.ipv4_destination.append(ipv4_destination)telemetry_model_driven.destination_groups.destination_group.append(destination_group)After destination, encoding and transport configuration, let\u2019s configure a sensor-group with one sensor path# sensor_group = telemetry_model_driven.sensor_groups.SensorGroup()## the name of this sensor-groupsensor_group.sensor_group_identifier = 'SGROUP'sensor_group.enable = Empty()        ## define the path you want to be collectedsensor_path = sensor_group.sensor_paths.SensorPath()sensor_path.telemetry_sensor_path = 'Cisco-IOS-XR-nto-misc-oper#memory-summary/nodes/node/summary'sensor_group.sensor_paths.sensor_path.append(sensor_path)   telemetry_model_driven.sensor_groups.sensor_group.append(sensor_group)The final step is to define subscription and configure all together# subscription = telemetry_model_driven.subscriptions.Subscription()## name of the subscription groupsubscription.subscription_identifier = ~Sub1~sensor_profile = subscription.sensor_profiles.SensorProfile()## attach the sensor-groupsensor_profile.sensorgroupid = 'SGROUP1'## define the intervalsensor_profile.sample_interval = 20000subscription.sensor_profiles.sensor_profile.append(sensor_profile) sensor_profile = subscription.sensor_profiles.SensorProfile()## define destination group to be useddestination_profile = subscription.destination_profiles.DestinationProfile()destination_profile.destination_id = 'DGROUP1'destination_profile.enable = Empty()subscription.destination_profiles.destination_profile.append(destination_profile) telemetry_model_driven.subscriptions.subscription.append(subscription)That\u2019s it! The full version with all sensor paths and two destinations can be found here. You can also find there YDK configurations for few other modes, including configurations using OpenConfig models (feel free to modify them and use as you need!)NCS1002 telemetry data consumptionAt this step we defined the data we want to stream out of an NCS1002. We configured Model-Driven Telemetry with destination, encoding, transport and sampling details. The final step for our task will be to collect and process this data.There are several ways to achieve this and you\u2019re free to use any one that you like. For those of you who have just started looking into telemetry, there are several files at the end to help with faster adoption and testing of things described above.Steps you need to do have your collector up and running#      Clone/download \u201cpipeline\u201d on your server. Pipeline can be found here and the basic overview of pipeline is here        Download and install \u201cInfluxDB\u201d on your server. The link for download is here        Make sure \u201cpipeline\u201d streams data to \u201cInfluxDB\u201d. How to do this is here. And make sure you don\u2019t forget to create a database!        Install Grafana and add \u201cInfluxDB\u201d database. The link to Grafana is here or go to their github link  After these steps are done, you will need to install correct \u201cmetrics.json\u201d file that will contain descriptions of models described in this tutorial. For Grafana you will need to have a dashboard configured. As i mentioned above, these files are already prepared for you! You can get \u201cmetrics.json\u201d here and the dashboard for NCS1002 for Grafana can be found here.NCS1002 with IOS XR 6.2.2, YDK version 0.5.4, Grafana 4.2.0, InfluxDB v1.0.0 and Python 2.7 were used.ConclusionTelemetry is the modern way to get almost real-time information from your NCS1002 devices. In this tutorial, we covered valuable sensor paths for NCS1002, how to configure them with CLI and YDK and how to process. Try telemetry on NCS1002 today and stay tuned for our next updates. NCS1001 configuration automation tutorials are coming soon!", "url": "https://xrdocs.github.io/telemetry/tutorials/2017-10-25-ncs1002-telemetry-deep-dive/", "tags": "iosxr, NCS1002, Rosco, Telemetry, Visualization, monitoring", "title": "NCS1002 Telemetry deep dive", "author": "Viktor Osipchuk"}, "tutorials-2016-07-25-configuring-model-driven-telemetry-mdt-with-yang": {"content": "     Configuring MDT with OpenConfig YANG  Model-Driven Configuration for Model-Driven Telemetry  The Models  Get-Config  Edit-Config  Conclusion  Model-Driven Configuration for Model-Driven TelemetryIn an earlier tutorial, I wrote about how to configure MDT using CLI.  But if the router is using YANG models to structure the operational data it streams, shouldn\u2019t we also be able to use models to configure the telemetry feature itself?  The answer is yes!  In this tutorial, we\u2019ll look at the OpenConfig YANG model for telemetry and how to configure it.  I will use ncclient as a simple Python NETCONF client, but you can use whatever client you want.The ModelsLet\u2019s start with a quick look at the NETCONF capabilities list from IOS XR 6.1.1.  This bit of code#from ncclient import managerimport re    xr = manager.connect(host='10.30.111.9', port=830, username='cisco', password='cisco',\tallow_agent=False,\tlook_for_keys=False,\thostkey_verify=False,\tunknown_host_cb=True)for c in xr.server_capabilities#    model = re.search('module=([^&amp;]*telemetry[^&amp;]*)&amp;', c)    if model is not None#        print model.group(1)     \u2026tells us that there are two models for telemetry configuration#Script Output#openconfig-telemetryCisco-IOS-XR-telemetry-model-driven-cfgThe first model is the OpenConfig telemetry model and the second is the XR native telemetry model.  If you look at them in detail, you will notice that the native model closely follows the OpenConfig model, although the native model will let you do things that are supported by IOS XR but not defined by this version of OpenConfig (like disabling TLS or enabling dial-out).  In this tutorial, I\u2019ll focus on openconfig-telemetry, but you could do everything with Cisco-IOS-XR-telemetry-model-driven-cfg as well.The NETCONF &lt;get-schema&gt; operation will give you the contents of the schema but the full YANG output can be really verbose and overwhelming, so I\u2019ll pipe the output to the pyang utility for a compact tree view with the following bit of code#from subprocess import Popen, PIPE, STDOUToc = xr.get_schema('openconfig-telemetry')p = Popen(['pyang', '-f', 'tree'], stdout=PIPE, stdin=PIPE, stderr=PIPE) print(p.communicate(input=oc.data)[0])And voila#Script Output#module# openconfig-telemetry   +--rw telemetry-system      +--rw sensor-groups      |  +--rw sensor-group* [sensor-group-id]      |     +--rw sensor-group-id    -&gt; ../config/sensor-group-id      |     +--rw config      |     |  +--rw sensor-group-id?   string      |     +--ro state      |     |  +--ro sensor-group-id?   string      |     +--rw sensor-paths      |        +--rw sensor-path* [path]      |           +--rw path      -&gt; ../config/path      |           +--rw config      |           |  +--rw path?             string      |           |  +--rw exclude-filter?   string      |           +--ro state      |              +--ro path?             string      |              +--ro exclude-filter?   string      +--rw destination-groups      |  +--rw destination-group* [group-id]      |     +--rw group-id        -&gt; ../config/group-id      |     +--rw config      |     |  +--rw group-id?   string      |     +--ro state      |     |  +--ro group-id?   string      |     +--rw destinations      |        +--rw destination* [destination-address destination-port]      |           +--rw destination-address    -&gt; ../config/destination-address      |           +--rw destination-port       -&gt; ../config/destination-port      |           +--rw config      |           |  +--rw destination-address?    inet#ip-address      |           |  +--rw destination-port?       uint16      |           |  +--rw destination-protocol?   telemetry-stream-protocol      |           +--ro state      |              +--ro destination-address?    inet#ip-address      |              +--ro destination-port?       uint16      |              +--ro destination-protocol?   telemetry-stream-protocol      +--rw subscriptions         +--rw persistent         |  +--rw subscription* [subscription-id]         |     +--rw subscription-id       -&gt; ../config/subscription-id         |     +--rw config         |     |  +--rw subscription-id?          uint64         |     |  +--rw local-source-address?     inet#ip-address         |     |  +--rw originated-qos-marking?   inet#dscp         |     +--ro state         |     |  +--ro subscription-id?          uint64         |     |  +--ro local-source-address?     inet#ip-address         |     |  +--ro originated-qos-marking?   inet#dscp         |     +--rw sensor-profiles         |     |  +--rw sensor-profile* [sensor-group]         |     |     +--rw sensor-group    -&gt; ../config/sensor-group         |     |     +--rw config         |     |     |  +--rw sensor-group?         -&gt; /telemetry-system/sensor-groups/sensor-group/config/sensor-group-id         |     |     |  +--rw sample-interval?      uint64         |     |     |  +--rw heartbeat-interval?   uint64         |     |     |  +--rw suppress-redundant?   boolean         |     |     +--ro state         |     |        +--ro sensor-group?         -&gt; /telemetry-system/sensor-groups/sensor-group/config/sensor-group-id         |     |        +--ro sample-interval?      uint64         |     |        +--ro heartbeat-interval?   uint64         |     |        +--ro suppress-redundant?   boolean         |     +--rw destination-groups         |        +--rw destination-group* [group-id]         |           +--rw group-id    -&gt; ../config/group-id         |           +--rw config         |           |  +--rw group-id?   -&gt; ../../../../../../../destination-groups/destination-group/group-id         |           +--rw state         |              +--rw group-id?   -&gt; ../../../../../../../destination-groups/destination-group/group-id         +--rw dynamic            +--ro subscription* [subscription-id]               +--ro subscription-id    -&gt; ../state/subscription-id               +--ro state               |  +--ro subscription-id?          uint64               |  +--ro destination-address?      inet#ip-address               |  +--ro destination-port?         uint16               |  +--ro destination-protocol?     telemetry-stream-protocol               |  +--ro sample-interval?          uint64               |  +--ro heartbeat-interval?       uint64               |  +--ro suppress-redundant?       boolean               |  +--ro originated-qos-marking?   inet#dscp               +--ro sensor-paths                  +--ro sensor-path* [path]                     +--ro path     -&gt; ../state/path                     +--ro state                        +--ro path?             string                        +--ro exclude-filter?   stringYou can spend a lot of time understanding the intricacies of YANG and all the details, but all we really need to know for now is that the model has three major sections#  The destination-group tells the router where to send telemetry data and how. Only needed for dial-out configuration.  The sensor-group identifies a list of YANG models that the router should stream.  The subscription ties together the destination-group and the sensor-group.Let\u2019s see how this works in practice.Get-ConfigWe can use the openconfig-telemetry model to filter for the telemetry config with the ncclient get_config operation#filter = '''&lt;telemetry-system xmlns=~http#//openconfig.net/yang/telemetry~&gt;'''c = xr.get_config(source='running', filter=('subtree', filter))print(c)And here\u2019s what we get#Script Output#&lt;?xml version=~1.0~?&gt;&lt;rpc-reply message-id=~urn#uuid#939c718e-81ee-43ec-9733-565aa53fedb2~ xmlns#nc=~urn#ietf#params#xml#ns#netconf#base#1.0~ xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~&gt; &lt;data&gt;  &lt;telemetry-system xmlns=~http#//openconfig.net/yang/telemetry~&gt;   &lt;sensor-groups&gt;    &lt;sensor-group&gt;     &lt;sensor-group-id&gt;SGroup3&lt;/sensor-group-id&gt;     &lt;config&gt;      &lt;sensor-group-id&gt;SGroup3&lt;/sensor-group-id&gt;     &lt;/config&gt;     &lt;sensor-paths&gt;      &lt;sensor-path&gt;       &lt;path&gt;openconfig-interfaces#interfaces/interface&lt;/path&gt;       &lt;config&gt;        &lt;path&gt;openconfig-interfaces#interfaces/interface&lt;/path&gt;       &lt;/config&gt;      &lt;/sensor-path&gt;     &lt;/sensor-paths&gt;    &lt;/sensor-group&gt;   &lt;/sensor-groups&gt;   &lt;subscriptions&gt;    &lt;persistent&gt;     &lt;subscription&gt;      &lt;subscription-id&gt;Sub3&lt;/subscription-id&gt;      &lt;config&gt;       &lt;subscription-id&gt;Sub3&lt;/subscription-id&gt;      &lt;/config&gt;      &lt;sensor-profiles&gt;       &lt;sensor-profile&gt;        &lt;sensor-group&gt;SGroup3&lt;/sensor-group&gt;        &lt;config&gt;         &lt;sensor-group&gt;SGroup3&lt;/sensor-group&gt;         &lt;sample-interval&gt;30000&lt;/sample-interval&gt;        &lt;/config&gt;       &lt;/sensor-profile&gt;      &lt;/sensor-profiles&gt;     &lt;/subscription&gt;    &lt;/persistent&gt;   &lt;/subscriptions&gt;  &lt;/telemetry-system&gt; &lt;/data&gt;&lt;/rpc-reply&gt;So what does all that mean to the router?  It breaks down into three parts which you\u2019ll recall from the YANG model above#  The destination-group tells the router where to send telemetry data and how.  The absence of a destination-group in the output above alerts us to the fact that this is a dial-in configuration (the collector will initiate the session to the router).  The sensor-group identifies a list of YANG models that the router should stream.  In this case, the router has a sensor-group called \u201cSGroup3\u201d that will send interface statistics data from the OpenConfig Interfaces YANG model.  The subscription ties together the destination-group and the sensor-group.  This router has a subscription name \u201cSub3\u201d that will send the list of models in SGroup3 at an interval of 30 second (30000 milleseconds).If you read the earlier tutorial on configuring MDT with CLI, you might recognize this as the same as the gRPC dial-in configuration described there.  If you missed that thrilling installment, the XML above is the YANG equivalent of this CLI#CLI Output#telemetry model-driven sensor-group SGroup3  sensor-path openconfig-interfaces#interfaces/interface ! subscription Sub3  sensor-group-id SGroup3 sample-interval 30000 !  Edit-ConfigSo let\u2019s say we want to add a second model to SGroup3 (Cisco-IOS-XR-ipv4-arp-oper).  We can do that with the following NETCONF operations#edit_data = '''&lt;config&gt;&lt;telemetry-system xmlns=~http#//openconfig.net/yang/telemetry~&gt;   &lt;sensor-groups&gt;    &lt;sensor-group&gt;     &lt;sensor-group-id&gt;SGroup3&lt;/sensor-group-id&gt;     &lt;sensor-paths&gt;      &lt;sensor-path&gt;       &lt;config&gt;        &lt;path&gt;Cisco-IOS-XR-ipv4-arp-oper#arp/nodes/node/entries/entry&lt;/path&gt;       &lt;/config&gt;      &lt;/sensor-path&gt;     &lt;/sensor-paths&gt;    &lt;/sensor-group&gt;   &lt;/sensor-groups&gt;&lt;/config&gt;'''xr.edit_config(edit_data, target='candidate', format='xml')xr.commit()If we do a get-config operation again#c = xr.get_config(source='running', filter=('subtree', filter))print(c)\u2026 we\u2019ll see that SGroup3 has the new addition.Script Output#&lt;?xml version=~1.0~?&gt;&lt;rpc-reply message-id=~urn#uuid#abd0a7ee-5f06-4754-b2a3-dae6e3d797aa~ xmlns#nc=~urn#ietf#params#xml#ns#netconf#base#1.0~ xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~&gt; &lt;data&gt;  &lt;telemetry-system xmlns=~http#//openconfig.net/yang/telemetry~&gt;   &lt;sensor-groups&gt;    &lt;sensor-group&gt;     &lt;sensor-group-id&gt;SGroup3&lt;/sensor-group-id&gt;     &lt;config&gt;      &lt;sensor-group-id&gt;SGroup3&lt;/sensor-group-id&gt;     &lt;/config&gt;     &lt;sensor-paths&gt;      &lt;sensor-path&gt;       &lt;path&gt;openconfig-interfaces#interfaces/interface&lt;/path&gt;       &lt;config&gt;        &lt;path&gt;openconfig-interfaces#interfaces/interface&lt;/path&gt;       &lt;/config&gt;      &lt;/sensor-path&gt;      &lt;sensor-path&gt;       &lt;path&gt;Cisco-IOS-XR-ipv4-arp-oper#arp/nodes/node/entries/entry&lt;/path&gt;       &lt;config&gt;        &lt;path&gt;Cisco-IOS-XR-ipv4-arp-oper#arp/nodes/node/entries/entry&lt;/path&gt;       &lt;/config&gt;      &lt;/sensor-path&gt;     &lt;/sensor-paths&gt;    &lt;/sensor-group&gt;   &lt;/sensor-groups&gt;   &lt;subscriptions&gt;    &lt;persistent&gt;     &lt;subscription&gt;      &lt;subscription-id&gt;Sub3&lt;/subscription-id&gt;      &lt;config&gt;       &lt;subscription-id&gt;Sub3&lt;/subscription-id&gt;      &lt;/config&gt;      &lt;sensor-profiles&gt;       &lt;sensor-profile&gt;        &lt;sensor-group&gt;SGroup3&lt;/sensor-group&gt;        &lt;config&gt;         &lt;sensor-group&gt;SGroup3&lt;/sensor-group&gt;         &lt;sample-interval&gt;30000&lt;/sample-interval&gt;        &lt;/config&gt;       &lt;/sensor-profile&gt;      &lt;/sensor-profiles&gt;     &lt;/subscription&gt;    &lt;/persistent&gt;   &lt;/subscriptions&gt;  &lt;/telemetry-system&gt; &lt;/data&gt;&lt;/rpc-reply&gt;And if you need some CLI to reassure yourself that it worked, here it is#CLI Output#RP/0/RP0/CPU0#SunC#show run telemetry model-drivenMon Aug  8 20#09#57.149 UTCtelemetry model-driven sensor-group SGroup3  sensor-path openconfig-interfaces#interfaces/interface  sensor-path Cisco-IOS-XR-ipv4-arp-oper#arp/nodes/node/entries/entry ! subscription Sub3  sensor-group-id SGroup3 sample-interval 30000 !!ConclusionArmed with the examples in this blog and a understanding of the telemetry YANG model, you should now be able to use YANG configuration models to configure the router to stream YANG models with the operational data you want.  How\u2019s that for model-driven programmability?", "url": "https://xrdocs.github.io/telemetry/tutorials/2016-07-25-configuring-model-driven-telemetry-mdt-with-yang/", "tags": "iosxr, YANG, telemetry, MDT", "title": "Configuring Model-Driven Telemetry (MDT) with OpenConfig YANG", "author": "Shelly Cadora"}, "tutorials-2016-07-27-ipxe-deep-dive": {"content": "     IOS-XR# iPXE Deep Dive  Introduction          Topology        Boot Process  iPXE DHCPv4 Request  iPXE DHCPv6 Request  iPXE without Chainloading  DHCP Server Configuration          DHCPv4      DHCPv6      Dynamic Scripting - Embedding iPXE variables in URL        iPXE with Chainloading          iPXE Script        Conclusions  IntroductioniPXE is an open source boot firmware (licensed under the GNU GPL with some portions under GPL-compatible licenses). It is fully backward compatible with PXE but include several enhancement. The enhancement that are important for IOS-XR are the following#  Boot from a web server via HTTP  control the boot process with scripts  control the boot process with menus  DNS supportiPXE is included in the network card of the management interfaces only and support for iPXE boot is included in the system firmware (UEFI) of the NCS1K, NCS5k and NCS5500 series routers. All these systems are equipped with a UEFI 64-bits firmware (aka BIOS).iPXE can run on both IPv4 and IPv6 protocol but cannot use SLAAC for IPv6.iPXE enumerates all Ethernet interfaces net0, net1, net2, \u2026TopologyIn the following examples we will use a NCS-5001 router.  This device is equipped with 2 management interfaces but we will use only one of these two interfaces, It is recommended to place each interfaces in different subnet to facilitate the management process and improve redundancy.The following diagram show the topology used for all examples. Both the DHCP and HTTP server are on a different subnet than the NCS-5001.Boot ProcessThe IOS-XR 6.0 boot process is illustrated below, iPXE requires two external services, a DHCP server (e.g. isc-dhcpd) and a HTTP server (e.g. Apache)It is important to note that a different dhcp client will start at the end of the boot process. This second dhcp client will facilitate auto provisioning the system.By default all NCS series router boot from the local disk, there are 2 options to force the system to boot using iPXE# If the device is already booted you can issue the command \u201chw-module location  bootmedia network reload~ in admin mode to force the system to reboot in iPXE mode.RP/0/RP0/CPU0#ios#adminSun Apr 10 00#56#08.037 UTCroot connected from 127.0.0.1 using console on xr-vm_node0_RP0_CPU0sysadmin-vm#0_RP0# hw-module location all bootmedia network reloadSun Apr  10 00#56#24.167 UTCReload hardware module ? [no,yes] yesresult Card reload request on all succeeded.If the system is just being powered on, you can get to the device firmware by pressing &lt;ESC&gt; or &lt;DEL&gt; after it has completed the hardware diagnostic. You will be presented with the Boot selection menu. To force the device to boot using iPXE select the first entry \u201cUEFI# Built-in EFI IPXE\u201dOnce the option is selected, iPXE will initialize the management interfaces, display the features options that were included in the iPXE firmware and propose you to jump into the iPXE prompt by pressing &lt;CTRL&gt;BiPXE initialising devices...okiPXE 1.0.0+ (aa070) -- Open Source Network Boot Firmware -- http#//ipxe.orgFeatures# DNS HTTP TFTP VLAN EFI ISO9660 NBI MenuPress Ctrl-B to drop to iPXE shelliPXE&gt;When presented with the iPXE command line, you are in the iPXE environment, there are multiple commands that can be used for manual booting and for diagnosing problems. Commands can also be used as part of an iPXE script (see section iPXE with chain loading).You can use the help command to show a list of all available commands. Full documentation for each command is provided in the iPXE command reference http#//ipxe.org/cmd.iPXE DHCPv4 RequestAfter Initializing the management Interface Ethernet driver, iPXE will send a DHCP request, DHCP will send both an IPv6 and an IPv4 request, The capture below show the initial IPv4 DHCP request sent by the system.    Bootstrap Protocol        Message type# Boot Request (1)        Hardware type# Ethernet (0x01)        Hardware address length# 6        Hops# 0        Transaction ID# 0x20e69f64        Seconds elapsed# 4        Bootp flags# 0x8000 (Broadcast)            1... .... .... .... = Broadcast flag# Broadcast            .000 0000 0000 0000 = Reserved flags# 0x0000        Client IP address# 0.0.0.0 (0.0.0.0)        Your (client) IP address# 0.0.0.0 (0.0.0.0)        Next server IP address# 0.0.0.0 (0.0.0.0)        Relay agent IP address# 0.0.0.0 (0.0.0.0)        Client MAC address# 52#46#27#70#1a#67 (52#46#27#70#1a#67)        Client hardware address padding# 00000000000000000000        Server host name not given        Boot file name not given        Magic cookie# DHCP        Option# (53) DHCP Message Type            Length# 1            DHCP# Discover (1)        Option# (57) Maximum DHCP Message Size            Length# 2            Maximum DHCP Message Size# 1472        Option# (93) Client System Architecture            Length# 2            Client System Architecture# EFI x86-64 (9)        Option# (94) Client Network Device Interface            Length# 3            Major Version# 3            Minor Version# 10        Option# (60) Vendor class identifier            Length# 45            Vendor class identifier# PXEClient#Arch#00009#UNDI#003010#PID#NCS-5001        Option# (77) User Class Information            Length# 4            User Class identifier# iPXE        Option# (55) Parameter Request List            Length# 22            Parameter Request List Item# (1) Subnet Mask            Parameter Request List Item# (3) Router            Parameter Request List Item# (6) Domain Name Server            Parameter Request List Item# (7) Log Server            Parameter Request List Item# (12) Host Name            Parameter Request List Item# (15) Domain Name            Parameter Request List Item# (17) Root Path            Parameter Request List Item# (43) Vendor-Specific Information            Parameter Request List Item# (60) Vendor class identifier            Parameter Request List Item# (66) TFTP Server Name            Parameter Request List Item# (67) Bootfile name            Parameter Request List Item# (119) Domain Search            Parameter Request List Item# (128) PXE - undefined (vendor specific)            Parameter Request List Item# (129) PXE - undefined (vendor specific)            Parameter Request List Item# (130) PXE - undefined (vendor specific)            Parameter Request List Item# (131) PXE - undefined (vendor specific)            Parameter Request List Item# (132) PXE - undefined (vendor specific)            Parameter Request List Item# (133) PXE - undefined (vendor specific)            Parameter Request List Item# (134) PXE - undefined (vendor specific)            Parameter Request List Item# (135) PXE - undefined (vendor specific)            Parameter Request List Item# (175) Etherboot            Parameter Request List Item# (203) Unassigned        Option# (175) Etherboot            Length# 36    Value#2969895296,2248423659,50397184,385941796,16847617,19529985,654377248,    16848129,19267841        Option# (61) Client identifier            Length# 11            Hardware type# DUID (0xFF)            Client Identifier# 46#4f#43#31#39#34#37#52#31#34#33 (FOC1947R143)        Option# (97) UUID/GUID-based Client Identifier            Length# 17            Client Identifier (UUID)# 9ed138b2-dc55-42b6-9c56-2cf6f63921d9        Option# (255) End            Option End# 255iPXE includes a number of options in the initial IPv4 DHCP request, the relevant ones are highlightedOption 60# \u201cvendor-class-identifier\u201d Identify 4 elements separated by columns#1 The type of client# e.g.# PXEClient2 The architecture of The system (Arch)# e.g.# 00009 Identify an EFI system using a x86-64 CPU3 The Universal Network Driver Interface (UNDI)# e.g.# 003010 (first 3 octets identify the major version and last 3 octets identify the minor version)4 The Product Identifier (PID)# e.g.# NCS-5001Option 61# \u201cdhcp-client-identifier\u201d Identify the Serial Number of the systemOption 66 and 67# are used for TFTP, the first one request the TFTP server name while the second request the filenameOption 77# \u201cuser-class\u201d Identify the mode of the system# e.g.# iPXEOption 97# \u201cuuid\u201d Identify the Universally Unique Identifier a 128-bit value (not usable at this time)Option 128 - 135# Reserved for PXE boot variables but not in use.In is response the DHCP server will place the bootfile URI in option 67 \u201cfilename\u201d or \u201cbootfile-name\u201d e.g.#http#//172.30.0.22/ncs5k/6.0.0/ncs5k-mini-x.iso-6.0.0iPXE DHCPv6 Request    DHCPv6        Message type# Relay-forw (12)        Hopcount# 0        Link address# fd#30#12##1 (fd#30#12##1)        Peer address# fe80##c672#95ff#fea7#efc0 (fe80##c672#95ff#fea7#efc0)        Relay Message            Option# Relay Message (9)            Length# 88            Value# 011ac36d00010012000200000009464f4331393437523134...            DHCPv6                Message type# Solicit (1)                Transaction ID# 0x1ac36d                Client Identifier                    Option# Client Identifier (1)                    Length# 18                    Value# 000200000009464f43313934375231343300                    DUID# 000200000009464f43313934375231343300                    DUID Type# assigned by vendor based on Enterprise number (2)                    Enterprise ID# ciscoSystems (9)                    Identifier# 464f43313934375231343300 (FOC1947R143)                Identity Association for Non-temporary Address                    Option# Identity Association for Non-temporary Address (3)                    Length# 12                    Value# 1d4098ed0000000000000000                    IAID# 1d4098ed                    T1# 0                    T2# 0                Option Request                    Option# Option Request (6)                    Length# 8                    Value# 00170018003b003c                    Requested Option code# DNS recursive name server (23)                    Requested Option code# Domain Search List (24)                    Requested Option code# Bootfile URL(59)                    Requested Option code# Bootfile Prameters (60)                User Class                    Option# User Class (15)                    Length# 6                    Value# 000469505845 # ~iPXE~                Vendor Class                    Option# Vendor Class (16)                    Length# 14                    Value# 0000000900084e43532d35303031                    Enterprise ID# ciscoSystems (9)                    vendor-class-data# NCS-5001                Elapsed time                    Option# Elapsed time (8)                    Length# 2                    Value# 0000                    Elapsed-time# 0 ms        Interface-Id            Option# Interface-Id (18)            Length# 4            Value# 0000001d            Interface-ID# The initial DHCPv6 solicit has the relevant option highlightedOption 1# \u201cclient-identifier\u201d equivalent to DHCPv4 option 61 but with the following format#DUID Type# integer 16 e.g.# 0002 (assigned by vendor)Enterprise Id# integer 32 e.g.# 00000009 (Cisco Systems)Client Identifier# string e.g.# FOC1947R143Option 15# \u201cdhcp6.user-class\u201d equivalent to DHCPv4 option 77 but the first 2 Octets define the length of the stringOption 16# \u201cvendor-class-identifier\u201d equivalent to DHCPv4 option 60 but with the following format#Enterprise Id# integer 32 e.g.#00000009 (Cisco Systems)Length# integer 16Vendor# string e.g.# NCS-5001Option 59# \u201cdhcp6.bootfile-url\u201d equivalent to DHCPv4 option 67Option 60# \u201cdhcp6.bootfile-parameter\u201d  required to be present but not in use.The DHCPv6 server will include option 59 \u201cdhcp6.bootfile-url\u201d in its response containing the full URL of the boot image e.g.# [http#//[fd#30##172#30#0#22]/ncs5k/6.0.0/ncs5k-mini-x.iso-6.0.0] (http#//[fd#30##172#30#0#22]/ncs5k/6.0.0/ncs5k-mini-x.iso-6.0.0)iPXE without ChainloadingIn this first examples, iPXE features are not used but the usage is similar to PXE boot. In the following examples we will rely solely on the DHCP server configuration to provide the elements necessary to identify the boot ISO for the device.DHCP Server ConfigurationDHCPv4Using the options above we can configure isc-dhcpd to adequately provide the URI to boot the system, the common statements for the network and the pool are shown below########## Network 172.30.12.0/24 ################shared-network 172-30-12-0 {   subnet 172.30.12.0 netmask 255.255.255.0 {      option subnet-mask 255.255.255.0;      option broadcast-address 172.30.12.255;      option routers 172.30.12.1;      option domain-name-servers 172.30.0.25;      option domain-name ~cisco.local~;   }   ####### Pool #########        pool {           range 172.30.12.10 172.30.12.100;           next-server 172.30.0.22;           if exists user-class and option user-class = ~iPXE~ {              filename = ~http#//172.30.0.22/ncs5k-mini-4~;           } else if exists user-class and option user-class = ~exr-config~ {              filename = ~http#//172.30.0.22/scripts/ncs-ztp.sh~;           }In the example above option 77 is used to provide the bootfile to the system, the if-then-else statement is required to prevent the DHCP server to provide the (large) bootfile to the auto-configuration process. With this configuration all system in iPXE mode will receive a DHCP offer with identical bootfile URI.If we want to add more granularity to the process we can define a class and using option 60 to only target a specific product or a family of products using the PID embedded in the the request. in the match statement we first verify that the system is in iPXE mode by matching the beginning of the vendor-class-identifier \u201cPXEClient\u201d than we match the first 6 octets of the PID portion \u201cNCS-50\u201d, this will match all the NCS-5K routers (NCS-5001, NCS-5002, NCS-5011) and provide them the same bootfile URI, the \u201cif\u201d statement can be more specific to only match NCS-5001 product and additional \u201celse-if\u201d statement can be added to match other products.######### Class #########   class ~ncs-5k~ {      match if substring (option vendor-class-identifier, 0, 9) = ~PXEClient~;         if substring (option vendor-class-identifier, 37, 6) = ~NCS-50~ {            filename = ~http#//172.30.0.22/ncs5k-mini-3~;         }      }Granularity of the boot image can be even more specific, the traditional approach is to use the mac address with a host definition inside the pool, as illustrated below######## Hosts #########host ncs-5001-a {   hardware ethernet c4#72#95#a7#ef#c2;   if exists user-class and option user-class = ~iPXE~ {      filename = ~http#//172.30.0.22/ncs5k-mini-1~;   }   fixed-address 172.30.12.50;}Using the host statement we provide a fixed address which can be useful for DNS, we still need to verify that option 77 is set to iPXE in the request to only provide the bootfile when required. The disadvantage of using the mac-address is that it is not necessary know in advance and is not written on the packaging box if this is the initial bootup of the system, another approach would be to use the uuid (option 97) or the serial number embedded in option 61.######## Hosts #########host ncs-5001-b {   option dhcp-client-identifier ~FOC1947R144~;   if exists user-class and option user-class = ~iPXE~ {      filename = ~http#//172.30.0.22/ncs5k-mini-2~;   }   fixed-address 172.30.12.52;}Using the different options and the flexibility of the ISC dhcp server we can achieve various degrees of granularity for the system we want to iPXE boot, but using DHCP options does not scale and each change require to restart the DHCP service. It offers the advantage to be identical to PXE and is easy to do for small to medium size network.DHCPv6The ISC-DHCP service is mono stack, to support IPv6 a second instance of the service needs to be launched, both instances should use different configuration file. The common configuration statement for the DHCPv6 is as follow#shared-network FD-30-12 {   subnet6 fd#30#12##/64 {      # Range for clients      range6 fd#30#12##1024 fd#30#12##1124;      # Range for clients requesting a temporary address      range6 fd#30#12##/64 temporary;      # Additional options      option dhcp6.name-servers fd#30##172#30#0#25;      option dhcp6.domain-search ~cisco.local~;       if exists dhcp6.user-class and substring(option dhcp6.user-class, 2, 4) = ~iPXE~ {         option dhcp6.bootfile-url = ~http#//[fd#30##172#30#0#22]/ncs5k-mini-4~;      } else if exists dhcp6.user-class and substring(option dhcp6.user-class, 0, 10) = ~exr-config~ {         option dhcp6.bootfile-url = ~http#//[fd#30##172#30#0#22]/scripts/ncs-ztp.sh~;      }   }}The DHCP configuration for IPv6 is similar to IPv4, the first 2 octets of the user-class define the length of the string, so we need to use the substring() statement to match \u201ciPXE\u201d. Another difference is the square brackets used to represent the IPv6 address in isc-dhcp configuration file. iPXE cannot used SLAAC and you need to disable SLAAC on the first hop router and force statefull IPv6 address assignment on the segment. For reference here is a snippet of an Cisco IOS configuration. since the DHCP and HTTP server are on a different subnet a helper-address and a relay address have been configured for DHCPv4 and DHCPv6.interface GigabitEthernet2/0   description ** Management Network **   ip dhcp relay information trusted   ip address 172.30.12.1 255.255.255.0   ip helper-address 172.30.0.25   ip virtual-reassembly in   ipv6 address FD#30#12##1/64   ipv6 nd managed-config-flag   ipv6 nd other-config-flag   ipv6 nd router-preference High   ipv6 dhcp relay destination FD#30##172#30#0#25 GigabitEthernet1/0endIf there are no router present on the segment, you will have to launch the Router Advertisement Daemon (radvd) and force IPv6 routing on the DHCP server. An example of radvd.conf is as follow#interface eth1{   MinRtrAdvInterval 5;   MaxRtrAdvInterval 60;   AdvSendAdvert on;   AdvOtherConfigFlag on;   IgnoreIfMissing off;   prefix FD#30#12##/64 {   };};Granularity in identifying the boot image is similar to IPv4, A class that encompass all NCS-5K series can be defined as follow (ipv6 class support is available starting isc-dhcp-server 4.3.4)########## Class #########class ~ncs-5k~ {   match if exists vendor-class-identifier and substring(vendor-class-identifier, 6, 6) = ~NCS-50~;   if exists dhcp6.user-class and substring(option dhcp6.user-class, 2, 4) = ~iPXE~ {      filename = ~http#//[fd#30##172.30.0.22]/ncs5k-mini-3~;   }}Granularity to the host level can be achieve by using the serial number as identifier since the client sends the serial number as part of the client-id a simple solution is to match the complete hex data of the option.######## Hosts #########host ncs-5001-b {   host-identifier option dhcp6.client-id 00#02#00#00#00#09#46#4f#43#31#39#34#37#52#31#34#33#00;   if exists dhcp6.user-class and substring(option dhcp6.user-class, 2, 4) = ~iPXE~ {      option dhcp6.bootfile-url = ~http#//[fd#30##172#30#0#22]/ncs5k-mini-2~;   }   fixed-address6 fd#30#12##172.30.12.52;}Refer to the section iPXE DHCPv6 Request on how to decode the dhcp6.client-id or use xxd to translate it in ascii.cisco@galaxy-42$ echo ~00#02#00#00#00#09#46#4f#43#31#39#34#37#52#31#34#33~ | xxd -pe -r &amp;&amp; echo -e        FOC1947R143cisco@galaxy-42$ echo -n ~FOC1947R143~ | od -A n -t x1 | sed 's/^ /00#02#00#00#00#09#/' | sed 's/ /#/g'    00#02#00#00#00#09#46#4f#43#31#39#34#37#52#31#34#33Dynamic Scripting - Embedding iPXE variables in URLThe URL provided by the DHCP server does not have to be a static. For example, you could direct iPXE to boot from the URLhttp#//172.30.0.22/boot.php?mac=${net0/mac}&amp;product=${product#uristring}&amp;serial=${serial#uristring}Which would expand to a URL such ashttp#//172.30.0.22/boot.php?mac=c4#72#95#a7#ef#c0&amp;product=NCS5001&amp;serial=FOC1947R143The boot.php program running on the web server could dynamically generate a script based on the information provided in the URL. For example, boot.php could look up the serial number in a MySQL database to determine the correct target to boot from, and then dynamically generate a script such as&lt;?php   header ( ~Content-type# text/plain~ );   echo ~#!ipxe \\n~;   echo ~set myURL http#//172.30.0.22/Cisco/NCS/NCS5001/FOC1947R143 \\n~;   echo ~boot myURL \\n~;?&gt;iPXE with ChainloadingChainloading is the capability to jump from one boot statement to another. Using chainloading and the embedded scripting capability of iPXE we can have a very detail and complex selection mechanism for the boot image. In the following example we will use the boot file structure illustrated below and we will use the initial DHCP configuration described earlier but in place of providing the URI for an ISO the DHCP server will provide the URI to a iPXE boot script (boot.ipxe).The file boot.ipxe file is a script that will identify the correct image based on available iPXE variable, it starts with the \u201c!ipxe\u201d statement and include statement like chain isset, etc.. All the iPXE statements are documented in the iPXE command section open source boot firmwareThe script is evaluated top to bottom and works for both IPv4 and IPv6iPXE Script!ipxe # Global variables used by all other iPXE scriptschain --autofree boot.ipxe.cfg || # Boot &lt;boot-url&gt;/&lt;boot-dir&gt;/hostname-&lt;hostname&gt;.ipxe# if hostname DHCP variable is set and script is presentisset ${hostname} &amp;&amp; chain --replace --autofree ${boot-dir}hostname-${hostname}.ipxe || # Boot &lt;boot-url&gt;/&lt;boot-dir&gt;/uuid-&lt;UUID&gt;.ipxe# if SMBIOS UUID variable is set and script is present (not usable see CSCuz28164)isset ${uuid} &amp;&amp; chain --replace --autofree ${boot-dir}uuid-${uuid}.ipxe || # Boot &lt;boot-url&gt;/&lt;boot-dir&gt;/mac-010203040506.ipxe if script is presentchain --replace --autofree ${boot-dir}mac-${mac#hexraw}.ipxe || # Boot &lt;boot-url&gt;/&lt;boot-dir&gt;/serial-FOC1947R143.ipxe if script is presentisset ${serial} &amp;&amp; chain --replace --autofree ${boot-dir}serial-${serial}.ipxe || # Boot &lt;boot-url&gt;/&lt;boot-dir&gt;/pid-&lt;product&gt;.ipxe if script is presentisset ${product} &amp;&amp; chain --replace --autofree ${boot-dir}pid-${product}.ipxe ||# Boot &lt;boot-url&gt;/menu.ipxe script if all other options have been exhaustedchain --replace --autofree ${menu-url} ||chain --replace --autofree ${menu-url6} ||The first action of the script is to import a set of variables from boot.ipxe.cfg this will set ${boot-url} / ${boot-url6} and other variables.The script verify if a specific variable has been set either in the SMBIOS of the system or in the DHCP response from the server.If the variable has been set, the script attempts to jump to a secondary boot file. For example if the serial number is set \u201cisset ${serial}\u201d, the script will attempt to jump to the file /serial-FOC1947R144.ipxe if the file exists. If the file exist iPXE will start executing statement from this boot script. If the file does not exist the script continue to the next statement until it reaches the menu statement, the last statement of the list.Here is an example of a secondary boot script based on the serial number of the device, as you can see this script points to the last element of the chain# the ISO boot file.cisco@galaxy-42#/var/www/html/ipxe$ cat serial-FOC1947R143.ipxe#!ipxeechoecho Booting NCS5K Mini ISO 6.0.0 from ISO for ${initiator}chain --replace --autofree  ${boot-url}ncs5k-mini-x.iso-6.0.0 ||chain --replace --autofree  ${boot-url6}ncs5k-mini-x.iso-6.0.0Finally if all boot items have failed, the menu.ipxe script is executed and propose an interactive menu-driven list of boot options.Below is the example script for the boot menu, this example is adapted from https#//gist.github.com/robinsmidsrod/2234639Each menu items can be associated with a shortcut key and navigation between items is done using the up and down arrows, for xrv9k image we have to use the sanboot option, for NCS-5K and NCS-5500 device we use the boot keyword.boot.ipxe.cfg#!ipxe# Base URL used to resolve most resources# Should always end with a slashset boot-url http#//172.30.0.22/set boot-url6 http#//[fd#30##172#30#0#22]/# What URL to use when sanbooting# Should always end with a slashset sanboot-url http#//172.30.0.22/set sanboot-url6 http#//[fd#30##172#30#0#22]/# Relative directory to boot.ipxe used to# override boot script for specific clientsset boot-dir ipxe/# Absolute URL to the menu script, used by boot.ipxe# and commonly used at the end of simple override scripts# in ${boot-dir}.set menu-url ${boot-url}menu.ipxeset menu-url6 ${boot-url6}menu.ipxeset initiator ${product} - ${serial}boot.ipxe!ipxe# Variables are specified in boot.ipxe.cfg# Some menu defaultsset menu-timeout 30000set submenu-timeout ${menu-timeout}isset ${menu-default} || set menu-default exit###################### MAIN MENU #####################################startmenu iPXE boot menu for ${initiator}item --gap --             ------------------------- XRV9K Boot Menu ------------------------------item --key a sunstone-mini              Boot xrv9k Mini 6.0.0 ISOitem --key d sunstone-latest            Boot xrv9k Mini 6.1.1 ISO Latest builditem --key e sunstone-disk              Boot xrv9k from local diskitem --gap --             ------------------------ NCS5000 Boot Menu -----------------------------item --key f ncs5000-6.0.0              Boot ncs-5000 Mini 6.0.0 ISOitem --key g ncs5000-6.1.1              Boot ncs-5000 Mini 6.1.1 ISOitem --gap --             ------------------------ NCS5500 Boot Menu -----------------------------item --key h ncs5500-6.0.0              Boot ncs-5500 Mini 6.0.0 ISOitem --key i ncs5500-6.1.1              Boot ncs-5500 Mini 6.1.1. Latest ISOitem --gap --             ------------------------- Advanced options -----------------------------item --key j config                     Configure settingsitem shell                              Drop to iPXE shellitem reboot                             Reboot Systemitemitem --key x exit                       Exit iPXE and continue BIOS bootchoose --timeout ${menu-timeout} --default ${menu-default} selected || goto cancelset menu-timeout 0goto ${selected} #cancelecho You cancelled the menu, dropping you to a shell #shellecho Type 'exit' to get the back to the menushellset menu-timeout 0set submenu-timeout 0goto start #failedecho Booting failed, dropping to shellgoto shell #rebootreboot #exitexit    #configconfiggoto start #backset submenu-timeout 0clear submenu-defaultgoto start ############ MAIN MENU ITEMS ############ #sunstone-miniecho Booting XRV9K Mini 6.0.0 from ISO for ${initiator}sanboot ${sanboot-url}xrv9k-mini-x.iso-6.0.0 ||sanboot ${sanboot-url6}xrv9k-mini-x.iso-6.0.0 || goto failedgoto start #sunstone-latestecho Booting XRV9K Mini 6.1.1 latest developer release from ISO for ${initiator}sanboot ${sanboot-url}xrv9k-mini-latest.iso ||sanboot ${sanboot-url6}xrv9k-mini-latest.iso || goto failedgoto start #ncs5000-6.0.0echoecho Booting NCS-5K Mini ISO 6.0.0 from ISO for ${initiator}boot ${boot-url}ncs5000-mini.official ||boot ${boot-url6}ncs5000-mini.official || goto failedgoto start #ncs5000-6.1.1echoecho Booting NCS-5K Mini ISO 6.1.1 from ISO for ${initiator}boot ${boot-url}ncs5000-mini.latest ||boot ${boot-url6}ncs5000-mini.latest || goto failedgoto start #ncs5500-6.0.0echoecho Booting NCS-5500 Mini ISO 6.0.0 from ISO for ${initiator}boot ${boot-url}ncs5500-mini.official ||boot ${boot-url6}ncs5500-mini.official || goto failedgoto start #ncs5500-6.1.1echoecho Booting NCS-5500 Mini ISO 6.1.1 from ISO for ${initiator}boot ${boot-url}ncs5500-mini.latest ||boot ${boot-url6}ncs5500-mini.latest || goto failedgoto start #sunstone-diskecho Start XRV9K from disksanboot --no-describe --drive 0x80 || goto failed  goto startHere is a screenshots of the boot process with only the DHCPv6 service active and no valid boot file present.iPXE&gt; autoboot net0                                             &lt;- autoboot from the mgmt interface net0# c4#72#95#a7#ef#c0 using dh8900cc on PCI01#00.1 (open)  [Link#up, TX#108 TXE#0 RX#5188624 RXE#5186887]Configuring (net0 c4#72#95#a7#ef#c0).......... oknet0# fe80##c672#95ff#fea7#efc0/64net0# fd#30#12##1124/64 gw fe80##fa72#eaff#fe8b#ce80            &lt;- ipv6 statefull address assignment Filename# http#//[fd#30##172#30#0#22]/boot.ipxe                 &lt;- ipv6 boot URI from DHCPv6http#//[fd#30##172#30#0#22]/boot.ipxe... ok                     &lt;- boot script is downloaded /boot.ipxe.cfg... ok                                            &lt;- boot variable are chained/ipxe/uuid-03000200-0400-0500-0006-000700080009.ipxe... No such file or directory (http#//ipxe.org/2d0c618e)/ipxe/mac-c47295a7efc0.ipxe... No such file or directory (http#//ipxe.org/2d0c618e)/ipxe/serial-FOC1947R143.ipxe... No such file or directory (http#//ipxe.org/2d0c618e)/ipxe/pid-NCS-5001.ipxe... No such file or directory (http#//ipxe.org/2d0c618e)http#//172.30.0.22/menu.ipxe... Network unreachable (http#//ipxe.org/280a6090)http#//[fd#30##172#30#0#22]/menu.ipxe... ok                      &lt;- boot menu is executed                 iPXE boot menu for NCS-5001 - FOC1947R143 ------------------------- XRV9K Boot Menu ------------------------------ Boot xrv9k Mini 6.0.0 ISOBoot xrv9k Mini 6.1.1 ISO Latest buildBoot xrv9k from local disk------------------------ NCS5000 Boot Menu -----------------------------Boot ncs-5000 Mini 6.0.0 ISOBoot ncs-5000 Mini 6.1.1 ISO Latest build------------------------ NCS5500 Boot Menu -----------------------------Boot ncs-5500 Mini 6.0.0 ISOBoot ncs-5500 Mini 6.1.1 Latest build------------------------- Advanced options -----------------------------Configure settingsDrop to iPXE shellReboot System Exit iPXE and continue BIOS bootIf we select the entry \u201cBoot ncs-5000 Mini 6.0.0 ISO\u201d, the script will first attempt to boot using the IPv4 address, since our device did not receive a valid IPv4 address it will attempt to use the IPv6 address and start the NOS installation.Booting Skywarp Mini ISO 6.0.0 from ISO for NCS-5001 - FOC1947R143http#//172.30.0.22/ncs5000-mini.official... Network unreachable (http#//ipxe.org/280a6090)http#//[fd#30##172#30#0#22]/ncs5000-mini.official... okBooting iso-image@0x42e2cb000(835930112), bzImage@0x42e2f7000(4473806)ConclusionsiPXE offers a wide variety of configuration paradigm that can be used in large deployment, with its scripting capability, iPXE is independent of DHCP configuration and can achieve very good granularity based on model number, serial number, mac-address, host name, etc.Creation of boot file can be automated easily on the back-end side without restarting any services. On the HTTP server symbolic link can be used to move devices from one ISO to another without reconfiguration. with its backward compatibility with PXE and its low resources requirement, it is a very good alternative to ONIE.Future enhancement to the boot process including secure boot will bring even more security to the iPXE without using HTTPS.", "url": "https://xrdocs.github.io/software-management/tutorials/2016-07-27-ipxe-deep-dive/", "tags": "iosxr, cisco, iPXE", "title": "iPXE Deep Dive", "author": "Patrick Warichet"}, "blogs-2016-10-24-using-ztp-to-install-chef": {"content": "     Using ZTP to install chef  Introduction  Chef Infrastructure          Installing the Chef Server      Create a User and Organization      Installing and Setting up the Chef Workstation        Installing the client with ZTP and Bootsrap the node  Creating a simple recipe  IntroductionChef is an automation platform that \u201cturns infrastructure into code\u201d, allowing users to manage and deploy resources across multiple servers, or nodes. Chef allows users to create and download recipes (stored in cookbooks) to automate content, configuration and policies on these nodes.Chef is comprised of a Chef server, one or more workstations, and a number of nodes that are managed by the chef-client installed on each node. You can download the IOS-XR Chef client package from Chef and installed directly inside the control plane LXC of IOS-XR.Chef like Puppet (see my previous blog Using ZTP to install Puppet)Automated configuration management tools play a vital role in managing complex enterprise infrastructures. Amongst the many advantages, the ones pertinent to IOS-XR and network node in general are#Consistency# It makes it easier for configuration changes to meet compliance and security requirements. By automating repeated tasks (like applying a SMU), it allows network administrators to concentrate on more important stuff.Efficient change management#. Automated configuration management can remove delay when deploying new technologies, reducing the number of processes needed to manage change. Small change batches can be performed on a more regular basis.Availability# Automatated configuration management tool help quickly restore service. Rather than troubleshooting an issue by hand, a system can be reset to well known working status.Visibility# Configuration management tools include auditing and reporting capabilities, changes can be automatically logged in all relevant tracking systems.Chef InfrastructureChef requires the follwing components a server, one or more workastation and one or more nodes, The instruction below used Ubuntu Xenial for both the server and the workstation to mange the IOS-XR nodes.Installing the Chef ServerThe Chef server is the central place that govern interaction between all workstations and managed nodes. Changes made in the workstations are uploaded to the Chef server, which is then accessed by the chef-client and used to configure individual nodes.Installing Chef Server is easy as 1-2-3#1 Download the latest Chef Server for your favorite distro#Example for Ubuntu Xenial (Chef version 12.9.1)wget https#//packages.chef.io/stable/ubuntu/16.04/chef-server-core_12.9.1-1_amd64.deb2 Install the server#sudo dpkg -i chef-server-core_*.deb3 Run the chef-server-ctl command to start the Chef server services#sudo chef-server-ctl reconfigureCreate a User and Organization1 In order to link workstations and nodes to the Chef server, an administrator and an organization need to be created with associated RSA private keys. create a directory to store the keys#mkdir ~/chef-keys2 Create an administrator. Change username to your desired username, firstname and lastname to your first and last name, email to your email, password to a secure password, and username.pem to your username followed by .pem#sudo chef-server-ctl user-create username firstname lastname email password --filename ~/chef-keys/username.pem3 Create an organization. The shortname value should be a basic identifier for your organization with no spaces, whereas the fullname can be the full, proper name of the organization. The association_user value username refers to the username made in the step above#sudo chef-server-ctl org-create shortname fullname --association_user username --filename ~/chef-keys/shortname.pemWith the Chef server installed and the RSA keys generated, you can move on to configuring your workstation, where all major work will be performed for your Chef\u2019s nodes.Installing and Setting up the Chef WorkstationYour Chef workstation will be where you create and configure any recipes, cookbooks, attributes, and other changes made to your Chef configurations. Although this can be the same machine that host the server, it is recommended to keep the server and the workstation seperated.1 Download the latest Chef Development Kit#wget https#//packages.chef.io/stable/ubuntu/12.04/chefdk_0.19.6-1_amd64.deb2 Install ChefDK#sudo dpkg -i chefdk_*.deb3 Verify the components of the development kit#~$ chef verifyRunning verification for component 'berkshelf'Running verification for component 'test-kitchen'Running verification for component 'tk-policyfile-provisioner'Running verification for component 'chef-client'Running verification for component 'chef-dk'Running verification for component 'chef-provisioning'Running verification for component 'chefspec'Running verification for component 'generated-cookbooks-pass-chefspec'Running verification for component 'rubocop'Running verification for component 'fauxhai'Running verification for component 'knife-spork'Running verification for component 'kitchen-vagrant'Running verification for component 'package installation'Running verification for component 'openssl'Running verification for component 'inspec'Running verification for component 'delivery-cli'Running verification for component 'git'Running verification for component 'opscode-pushy-client'Running verification for component 'chef-sugar'.................---------------------------------------------Verification of component 'test-kitchen' succeeded.Verification of component 'chef-dk' succeeded.Verification of component 'chefspec' succeeded.Verification of component 'rubocop' succeeded.Verification of component 'knife-spork' succeeded.Verification of component 'openssl' succeeded.Verification of component 'delivery-cli' succeeded.Verification of component 'opscode-pushy-client' succeeded.Verification of component 'berkshelf' succeeded.Verification of component 'fauxhai' succeeded.Verification of component 'inspec' succeeded.Verification of component 'chef-sugar' succeeded.Verification of component 'tk-policyfile-provisioner' succeeded.Verification of component 'chef-provisioning' succeeded.Verification of component 'kitchen-vagrant' succeeded.Verification of component 'git' succeeded.Verification of component 'chef-client' succeeded.Verification of component 'package installation' succeeded.Verification of component 'generated-cookbooks-pass-chefspec' succeeded.4 Generate the chef-repo and add the RSA keys~$ chef generate repo chef-repo~$ cd chef-repo~/chef-repo$ mkdir .chef~/chef-repo$ scp user@chef-server#~/chef-keys/*.pem .chef/5 Generate knife.rbUsing your favorite text editor create a knife configuration file named knife.rb in to your ~/chef-repo/.chef folder.log_level                #infolog_location             STDOUTnode_name                'username'client_key               '/home/cisco/chef-repo/.chef/username.pem'validation_client_name   'shortname-validator'validation_key           '/home/cisco/chef-repo/.chef/shortname.pem'chef_server_url          'https#//chef-server/organizations/shortname'syntax_check_cache_path  '/home/cisco/chef-repo/.chef/syntax_check_cache'cookbook_path [ '/home/cisco/chef-repo/cookbooks' ]Replace username,shortname with the values used in the steps \u201cCreate a User and Organization\u201dMove uo to the chef-repo and copy the needed SSL certificates from the server#~/chef-repo/.chef$ cd ..~/chef-repo$ knife ssl fetchWARNING# Certificates from chef-cook will be fetched and placed in your trusted_certdirectory (~/chef-repo/.chef/trusted_certs).Knife has no means to verify these are the correct certificates. You shouldverify the authenticity of these certificates after downloading.Adding certificate for chef-cook in ~/chef-repo/.chef/trusted_certs/chef-cook.crtConfirm that knife.rb is set up correctly by running the client list#~/chef-repo$ knife client listciscolab-validatorThis command should output the validator name (ciscolab in our case).With both the server and a workstation configured, it is possible to bootstrap your first node.Installing the client with ZTP and Bootsrap the nodeUsing ZTP we can install the Chef client directly inside the control plane LXC of IOS-XR, here is a script example that will perform the installation during the initial bootup.#!/bin/bashYUM_REPO=~http#//172.30.0.22/packages/chef~YUM_CHEF=~/etc/yum/repos.d/chef.repo~CHEF_SRV=~chef-cook.cisco.local~DOMAIN=~cisco.local~DOMAIN_SRV=172.30.0.25HOSTNAME=~ncs-5001-c~MGMT_IP=~172.30.12.54 255.255.255.0~source ztp_helper.shfunction create_repo(){   # Create local repository file for chef   echo ~creating repo file in /etc/yum/repo.d~   echo ~### created by ztp $(date +~%b %d %H#%M#%S~) ###~ &gt; $YUM_CHEF   echo -ne ~[chef]\\nname=chef\\nenabled=1\\ngpgcheck=1\\n~ &gt;&gt; $YUM_CHEF   echo ~baseurl=$YUM_REPO~ &gt;&gt; $YUM_CHEF   echo ~gpgkey=$YUM_REPO/chef.asc~ &gt;&gt; $YUM_CHEF }function install_chef(){   # Install chef from local repository   echo ~installing chef from the local repo~   /usr/bin/yum clean all &gt; /dev/null   /usr/bin/yum update &gt; /dev/null   /usr/bin/yum install -y chef &gt; /dev/null}function setup_resolver(){  echo ~ setting up the resolver~  local resolver=/etc/resolv.conf  echo ~### created by ztp $(date +~%b %d %H#%M#%S~) ###~ &gt; $resolver  echo ~domain $DOMAIN~ &gt;&gt; $resolver  echo ~search $DOMAIN~ &gt;&gt; $resolver  echo ~nameserver $DOMAIN_SRV~ &gt;&gt; $resolver  }function set_hostname(){  echo ~setting up the device hostname~  xrapply_string_with_reason ~ztp chef install~ ~hostname $HOSTNAME\\n interface mgmtEth 0/RP0/CPU0/0\\n ipv4 address $MGMT_IP \\n~  /bin/hostname -f $HOSTNAME.$DOMAIN  echo $HOSTNAME &gt; /etc/hostname  }function start_services(){  echo ~starying services~  /etc/init.d/sshd_operns start  # Start chef client in daemon mode and schedule a run every 5 min  /usr/bin/chef-client -daemonize -i 300 -L /var/log/chef.log}### script startset_hostname;setup_resolver;create_repo;install_chef;start_services;exit 0On the workstation, we bootstrap the node using knife. It is important to note that the Chef client will run inside the Linux shell. Inside the Linux shell the default port for the ssh server is 57722 and ssh using the root user is disabled. Fortunatly IOS-XR root-lr users are not root when they ssh into the system (see my previous blog IOS-XR  Users and Groups). Since we need root access to bootstrap the client we have to use \u2013sudo and provide the user password.~$ knife bootstrap 172.30.12.54 --sudo -p 57722 -x admin -P cisco123 --node-name ncs-5001-cConnecting to 172.30.12.54172.30.12.54 knife sudo password# Enter your password# 172.30.12.54 172.30.12.54 -----&gt; Existing Chef installation detected172.30.12.54 Starting the first Chef Client run...172.30.12.54 Starting Chef Client, version 12.15.19172.30.12.54 [2016-11-02T23#09#51+00#00] WARN# [inet] no ip address on fwdintf172.30.12.54 Creating a new client identity for ncs-5001-c using the validator key.172.30.12.54 resolving cookbooks for run list# []172.30.12.54 Synchronizing Cookbooks#172.30.12.54 Installing Cookbook Gems#172.30.12.54 Compiling Cookbooks...172.30.12.54 [2016-11-02T23#09#53+00#00] WARN# Node ncs-5001-c has an empty run list.172.30.12.54 Converging 0 resources172.30.12.54 172.30.12.54 Running handlers#172.30.12.54 Running handlers complete172.30.12.54 Chef Client finished, 0/0 resources updated in 04 secondsknife node listncs-5001-cCreating a simple recipeWe use the command \u201cchef generate cookbook\u201d to configure our cookbook, once created, we change to the recipes folder and edit the default.rb recipe.~/chef-repo/cookbooks$ chef generate cookbook ios-xrGenerating cookbook ios-xr- Ensuring correct cookbook file content- Ensuring delivery configuration- Ensuring correct delivery build cookbook contentYour cookbook is ready. Type `cd ios-xr` to enter it.There are several commands you can run to get started locally developing and testing your cookbook.Type `delivery local --help` to see a full list.Why not start by writing a test? Tests for the default recipe are stored at#test/recipes/default_test.rbIf you'd prefer to dive right in, the default recipe can be found at#recipes/default.rbWe create a simple recipe that will create a file in the home directory of the user (/disk0# for IOS-XR)~/chef-repo/cookbooks$ cd ios-xr/recipes/~/chef-repo/cookbooks$ vi default.rb## Cookbook Name## ios-xr# Recipe## default## Copyright 2016, YOUR_COMPANY_NAME## All rights reserved - Do Not Redistribute#file ~#{ENV['HOME']}/chef.txt~ do  content 'Hello from Chef'endWe push the recipe to the Chef server and add it to the run list for the ncs-5001-c node~/chef-repo/cookbooks/ios-xr/recipes$ knife cookbook upload ios-xrUploading ios-xr         [0.1.0]Uploaded 1 cookbook.~/chef-repo/cookbooks/ios-xr$ knife node run_list set ncs-5001-c 'recipe[ios-xr##default]'ncs-5001-c#  run_list# recipe[ios-xr##default]The execution will occur within the interval configured (300 sec in our case), Here is what the logs look like#Starting Chef Client, version 12.15.19resolving cookbooks for run list# [~ios-xr##default~]Synchronizing Cookbooks#  - ios-xr (0.1.0)Installing Cookbook Gems#Compiling Cookbooks...Converging 1 resourcesRecipe# ios-xr##default  * file[/disk0#/chef.txt] action create    - create new file /disk0#/chef.txt    - update content in file /disk0#/chef.txt from none to ba4fda    --- /disk0#/chef.txt\t2016-11-09 22#04#29.356188978 +0000    +++ /disk0#/.chef-chef20161109-16571-14v6aep.txt\t2016-11-09 22#04#29.355188978 +0000    @@ -1 +1,2 @@    +Hello from ChefRunning handlers#Running handlers completeChef Client finished, 1/1 resources updated in 03 seconds", "url": "https://xrdocs.github.io/software-management/blogs/2016-10-24-using-ztp-to-install-chef/", "tags": "iosxr, cisco", "title": "Using ZTP to install Chef", "author": "Patrick Warichet"}, "blogs-2017-07-31-the-future-of-highly-available-networks": {"content": "     On This Page  Introduction  Defining Availability  Approaches to Availability          Network Level      Device Level                  The Complexity Problem                      New Heuristics          Solve for Network Availability First      Minimize Impact with Scale-Out Architectures      Manage Scale With Automation      Understand Your Failures      Automate Upgrades      Simplify Upgrades      Design Simple Failures      Drain Instead of Switchover      Return to A Known State      Protect Single Points of Failure        Conclusion  References And Further Reading  IntroductionNobody will dispute the importance of availability in today\u2019s service provider networks.  What is less obvious is how you achieve it. A network is a complex, dynamic system that must continually adapt to changing conditions. Some changes are normal, necessary and planned (e.g. software and hardware upgrades, configuration changes), while others are unplanned and unpredictable (e.g. software or hardware faults, human error).  This whitepaper discusses different approaches to availability in both cases and lays out current best practices which can be distilled into a few simple themes#      Solve for the Network First        Reduce Complexity        Automate Operations  Defining AvailabilityBefore diving into the mechanics of availability, it\u2019s worth considering what a highly available network means to you.  Tolerance for failure is driven by your SLAs.  Not every service requires the same kind of availability as high frequency trading or systems supporting hospitals.  So take some time to understand the availability requirements for your services across your network.  Many people assume that higher availability is always better.  This may result in over-engineering the network and introducing unneeded complexity and cost.Approaches to AvailabilityWhen planning for availability, network architects often consider two levels of availability strategies# device level and network level.  Getting the right balance between these levels is key to service availability in your network.Network LevelThe idea of building a reliable network from unreliable components is as old as the Internet itself. Originally designed for military survivability, the Internet assumes that nodes and links will fail.  Under such conditions, you can still deliver network availability through resilient protocols and well-designed architectures.On the protocol side, availability is improved by reducing both the Mean Time To Detection (MTTD) and the Mean Time To Repair (MTTR) of protocol failures.   For reducing MTTD, Bidirectional Forwarding Detection (BFD) and/or Ethernet OAM (802.3ah) are your best friends.  BFD operates at Layer 3 and EOAM at Layer 2, but both provide fast-failure detection that allows network protocols to begin convergence.Reducing MTTR involves multiple approaches, starting with optimizing protocol convergence after the failure has been detected.  Incremental SPF (iSPF) has long been used in IGPs to reduce the time it takes to recompute the best path.  Convergence can also be improved by installing a precomputed backup path in the routing table using BGP Protocol Independent Convergence (PIC) and Loop Free Alternative Fast ReRoute (LFA FRR).MPLS Traffic Engineering (TE) can also help reduce MTTR by giving you the ability to use links and nodes that are not necessarily in the shortest path.  By increasing the pool of available resources, TE helps ensure that the loss of one link or node results in the loss of only a small amount of total capacity.  When links or nodes fail, MPLS TE Fast Reroute (MPLS TE FRR) can locally repair LSPs while the headend re-establishes the end-to-end LSP with an impressive 50 millisecond failover time. Still, it\u2019s also worth remembering that FRR might be overkill for some services# not all SLAs actually require 50 millisecond failover.For these convergence optimizations and fast reroute technologies to work, the underlying architecture must support them.  Multiple paths are essential to delivering fault tolerance.  Well-designed architectures use redundant uplinks and multi-homing to avoid single points of failure.  In such architectures, fast failure detection and fast convergence optimizations together provide a good balance of minimizing packet loss while re-converging the control plane at a pace that doesn\u2019t destabilize the network.One of the main drawbacks with network-level availability mechanisms is that you either have to overprovision your network or accept that availability may be degraded during a failure.  After all, if a link or node fails and your backup paths don\u2019t have enough capacity, you will drop traffic.  Again, it\u2019s worth considering your SLAs.  Some temporary degradation may be acceptable and you could use QoS to ensure that lower priority traffic is dropped first, allowing you to provision just enough redundant capacity for high priority traffic in failure conditions.   In any event, be sure to weigh the higher capex costs of an overbuilt network against the lower operating costs of simpler hardware, software and network designs.  Many operators have found that the opex savings ultimately far outweighs the capex cost of network-level availability.Device LevelNetwork-level availability mechanisms are great for coping with unreliable components but, over the years, we\u2019ve also put a lot of work into making those individual networking devices more reliable, too. In the industry parlance, device-level availability often focuses on increasing the Mean Time Between Failure (MTBF) of the router and its components.  Following the paradigm of traditional hardware fault tolerance, device-level HA duplicates major components in the system (RPs, power supplies, fan trays) for 1+1 redundancy.  The duplicate components may load share in an Active-Active configuration (e.g. redundant power shelves in the CRS) or run in an Active-Standby configuration (e.g. Active-Standby RPs).As reassuring as backup power supplies and fans may be, straight-forward hardware redundancy doesn\u2019t cut it for complex components with significant software elements.  Take the route processor (RP), a complex bundle of hardware and software that is responsible for running the control plane and programming the data plane.  In the event of a failover, a standby RP cannot assume the duties of the active RP without either 1) re-building the state (re-establishing neighbor relationships, re-building routing tables, etc) or 2) having an exact, real-time copy of the active state.  The first takes time and the second has proven difficult to achieve in practice.One way to buy time is to separate the control plane and data plane by allowing the data plane to continue to forward traffic using the existing FIB even when the control plane on the RP is unavailable.  At Cisco, we call this Non-Stop Forwarding (NSF).  Modifications to higher-level protocols (BGP, ISIS, OSPF, LDP) allow a router to alert neighbors that a restart is in progress (\u201cGraceful Restart\u201d).  The NSF-aware neighbors will continue to maintain neighbor relationships and forwarding entries while the RP reboots and/or the standby RP transitions to active.  Stale FIB entries may cause sub-optimal routing or even black holes, but the effect is temporary and usually tolerable.  NSF may also impose additional CPU and memory requirements which increase the complexity and cost of the device.  Nevertheless, over years of industry hardening, NSF has matured into an effective technique for minimizing network downtime.Instead of buying time with NSF and Graceful Restart, IOS XR also supports Non-Stop-Routing (NSR).  With NSR, all the protocol state required to maintain peering state is precisely synchronized across the active and standby RPs.  When the active fails over, the standby can immediately take over the peering sessions.  Because the failure is handled internally, it is hidden from the outside world.  In practice, NSR is a very complex, resource-intensive operation that doesn\u2019t always result in the perfect state synchronization that is required.  And precisely because NSR \u201chides\u201d the failure of the RP from neighbors, troubleshooting can be very difficult if something goes wrong.Building on NSF and NSR, Cisco tackled the specific problem of planned outages by developing an upgrade process called In Service Software Upgrades (ISSU).  ISSU is a complex process that coordinates the standard RP failover with various other mechanisms to ensure that the line card stops forwarding for only as much time as it takes to re-program the hardware.  Under ideal conditions, the outage is less than 10 seconds.  However, in real networks, conditions are almost never ideal.  Like NSR, ISSU has proven difficult to achieve in practice for the entire industry.  Even when an in-service upgrade is possible, the operational overhead of understanding and troubleshooting ISSU\u2019s many stages and caveats often outweighs the value of keeping the node in service during the upgrade.The Complexity ProblemIn Normal Accidents, Charles Perrow introduced the now widely-accept idea that systems with interactive complexity and tight coupling are at higher risk for accidents and outages. It simply isn\u2019t possible for engineers to imagine, anticipate, plan for and prevent every possible interaction in the system.  Moreover, system designers have learned the hard way that, in practice, using redundancy to compensate for local failures often has the effect of increasing complexity which, in turn, causes the outage you were trying to avoid!  Given that a router with two-way active-standby redundancy is a complex, tightly coupled system, it is perhaps inevitable that successfully and reliably executing NSR and ISSU at service provider speeds and scale has proven challenging industry-wide.New HeuristicsAs daunting as availability can be, the solutions are relatively straightforward.  You don\u2019t need a lot of new features and functionality, but you may need to rethink your operations and architecture.Solve for Network Availability FirstGiven the unavoidable cost and complexity of device-level availability, it makes sense to focus your availability strategy on network-level availability mechanisms.  Fast detection, convergence and re-route in a redundant, multi-path topology will get you the most bang for the buck.Minimize Impact with Scale-Out ArchitecturesIf you\u2019re looking at your next-generation network architecture, it\u2019s worth considering emerging design patterns that can significantly improve availability.  Traditional, hierarchical network designs typically include an aggregation layer, where a small number of large devices with a large number of ports aggregate traffic from southbound layers in preparation for transit northbound.  These aggregation devices are commonly deployed in a 1+1 redundancy topology.From an availability perspective, the weak point is those aggregation boxes.  If one of those boxes go down, you\u2019ll lose half your network capacity.  That\u2019s a large blast radius.   Network-level availability mechanisms like fast-reroute and QoS may mitigate the impact to high priority services, but unless you have vast amount of excess capacity, your network will run in a degraded state.  Hence, those devices are prime candidates for dual RPs with NSF and NSR.  But we\u2019ve already seen that those strategies can introduce complexity and, consequently, reduce availability.Faced with new traffic patterns and scale requirements, pioneers in massively-scaled data center design developed a new design pattern that continues to find new applications outside the data center [1].  The spine-and-leaf topology replaces the large boxes in the aggregation layer with many smaller leafs and spines that can be scaled horizontally. Because the traffic is spread across more, smaller boxes in a spine-leaf topology, the loss of any single device has a much smaller blast radius.  Cisco\u2019s NCS 5500 product line is well aligned with this type of Clos-based fabric design as it moves to the core and beyond.Manage Scale With AutomationThe sheer numbers in fabric-based network architectures can be intimidating.  In the past, we\u2019ve often assumed that complexity (and therefore, failure) increases with the number of devices.  But as the design of large-scale data centers have shown, you can easily manage vast numbers of devices if you have sufficiently hardened automation.  On the IOS-XR side, we are committed to Model-Driven Programmability to enable complete automation to make the network full programmable through tools like Ansible and Cisco\u2019s Network Service Orchestrator (NSO).Understand Your FailuresKnowing what\u2019s failed in the past is essential to avoiding that failure in the future.  The world\u2019s largest web service providers routinely perform forensic analyses of past failures in order to improve design and operations [2].  It is also possible to automate the remediation of well-understood failures [3].Automate UpgradesMore than one forensic analysis has shown that 60 \u2013 90% of failures in the network are caused by having a human being in the loop# fat-fingering the configuration, killing the wrong process, applying the wrong software patch.  Maintenance operations are responsible for twice the number of failures as bugs.   Upgrades in particular are a magnet for these kinds of failure, as they are often complex, manual and multi-stage.When manual intervention is the cause of the problem, automation provides a way forward.  By automating and vigorously validating upgrade procedures, you can significantly improve device availability while reducing operational overhead.  This is the motivation for tools like the Cisco Software Manager which has been proven to reduce errors and improve availability.Simplify UpgradesWe can\u2019t just stop at automating the upgrade process.  Automating complex processes removes the human element, but as long as the complexity remains, so does the risk of \u201cnormal accidents.\u201d  After all, in the worst case, automation just provides you a way to do stupid things faster! To get the most out of automation, the upgrade process itself needs to be simplified.  The current state of the art for software installs and upgrades is the standard Linux model of package management.  Starting with IOS XR 6.0, all IOS XR packages use the RPM Package Manager (RPM) format, the first step in our upgrade simplification journey.Design Simple FailuresThe truth is that device failure is normal at scale.  Even if an individual device has the vaunted 5 9s availability, if you have 10,000 of those devices, you will have downtime every day of the year.  Instead of trying to avoid failures at all costs, embrace it!  Just make sure you embrace the right kind of failure.  Experience has taught us that simple, obvious failures with predictable consequences are easier to manage than complex, subtle failures with poorly understood consequences even when the simple failure has a larger \u201cblast radius.\u201dTake the case of a stateful switchover from the active to the standby RP.  There aren\u2019t many network operators who haven\u2019t been scarred by a planned or unplanned switchover that did not go as expected.  For whatever reason, the standby RP ends up in state that does not match the active RP\u2019s state when it went down.  Because device-level availability techniques like NSR try to \u201chide\u201d the failure from the outside world, it can be very difficult to diagnose and troubleshoot the underlying issue.   In many cases, the partial failure of the switchover is often worse than just having the router go away and come back.  A rebooting router is a well-understood event that can be handled by the control plane protocols.  On the other hand, a misbehaving RP in an unknown state is not well understood and may lead to much worse behavior than a temporary degradation.The RP example illustrates an emerging design principle# instead of trying to handle a large set of potential partial failures (e.g. different kinds of failed switchovers), group them into a common failure (router reset) that can be handled in a predictable way by the network.  The end result is a network that is simpler, more predictable and more reliable.Following this principle, many service providers have settled on simpler switchover techniques like NSF over the more complex stateful switchover of NSR.  Going a step further, some providers have deployed single-RP systems in multi-homed roles, forgoing the upside of switchover altogether in favor of a single, well-understood failure.  Of course, single-RP systems cost less, but this is absolutely not about capex.  Some customers will actually buy the redundant RP and leave it, powered off, in the chassis so they don\u2019t have to roll a truck in the event of a truly catastrophic RP failure.  The cost of the extra RP is trivial compared to the operational cost of detecting and fixing bad failovers.Drain Instead of SwitchoverIf you have a single RP system, you won\u2019t be doing a switchover for maintenance operations.  Operators who have pioneered this kind of deployment have developed a \u201cdrain-and-maintain\u201d strategy.  In this workflow, devices targeted for traffic-impacting maintenance will be drained of traffic in a controlled manner by shutting down links, lowering the preference of the link, or assigning an infinite cost to the link so routing neighbors will not select it.  Once the traffic has been redirected away from the router, the maintenance operation (such as software upgrade) can proceed.  When the maintenance is complete, links can be brought back into service.  This works well for redundant, transport-only nodes like LSRs and P routers.For drain-and-maintain to be successful, you have to first validate that there is sufficient excess capacity to carry the drained traffic while the device is offline.  Because of all the moving parts, automation is a key element of this strategy.  You will want an orchestration system to validate the excess capacity, choreograph the drain, maintenance, and undrain, and validate the return to the desired steady-state.Return to A Known StateIf a router reboot is to be a \u201cnormal failure\u201d in the network, the system needs to ensure that the router returns to a known state as quickly as possible.  For this to work, the router\u2019s \u201csource of truth\u201d (i.e. its configuration) needs to be stored off the box.  If the source of truth is on the router, the truth will be irretrievably lost if the router is wiped out.  With an off-box source of truth, you can iPXE-boot your router back to the known state with confidence.Protect Single Points of FailureRedundant, multi-homed topologies are the hallmarks of good network design, but it is not always possible to design out all the single points point of failure. Some common examples include#  Edge devices such as an LER or PE router may have single-attached customers.  End-users are typically single-homed to an edge device that may contain significant amounts of non-duplicated user state (e.g. BNG or CMTS).  Long-haul transport can be prohibitively expensive, increasing the likelihood that of an architecture that leverages single devices with a limited number of links.The first question to ask yourself is if there is any way to design redundancy into the network using new technologies.  For example, IOS XR supports Network Function Virtualization (NFV), allowing it to be deployed as a virtual PE (vPE). Deployed in a redundant pair, vPEs can provide edge customers with better network availability over the same physical link.If you can\u2019t eliminate it altogether, a single point of failure is also a good candidate for the spine-and-leaf fabric described above.  If a 2 RU node in the fabric fails, the blast radius is much smaller than if a 20-slot chassis fails.  Barring that, in-chassis hardware redundancy and switchover techniques like NSF may be considered.ConclusionDecades of experience have proven that network availability mechanisms provide simpler, more efficient, lower cost alternatives when the architecture supports them.  Beyond that, the frontier for availability is all about operations.  By automating workflows, particularly upgrades, you can eliminate the most common causes of failure in the first place.  Investing in operations may seem like an odd strategy for availability but the truth is that simple, automated networks are the most available networks of all.References And Further Reading[1] Introducing Data Center Fabric[2] Evolve or Die - High-Availability Design Principles Drawn from Google\u2019s Network Infrastructure[3] Making Facebook Self-HealingNormal Accidents# Living with High Risk Technologies (Updated). Princeton University Press, 1999, Charles Perrow.Site Reliability Engineering, O\u2019Reilly Media, April 2016, Betsy Beyer, Chris Jones, Jennifer Petoff, Niall Richard Murphy.", "url": "https://xrdocs.github.io/design/blogs/2017-07-31-the-future-of-highly-available-networks/", "tags": "iosxr, HA, ISSU", "title": "The Future of Highly Available Networks", "author": "Shelly Cadora"}, "tutorials-2017-04-12-on-box-telemetry-running-pipeline-and-kafka-on-ios-xr": {"content": "     Running Pipeline and Kafka on IOS-XR  Streaming Telemetry  What is on-box Telemetry?          Docker container to host Pipeline + Kafka      NCS5500/Vagrant On-Box Telemetry Setup      ASR9k On-Box Telemetry Setup        Docker image for Pipeline+Kafka  Building a Pipeline-kafka Docker image for IOS-XR          Clone Github repo      Understand the Dockerfile      Build the Docker image      Pull Docker image on the router        Launch the Docker container          Create a custom pipeline.conf        Testing the on-box Telemetry receiver          Query the local Kafka instance        Streaming TelemetryIf you haven\u2019t checked out the great set of tutorials from Shelly Cadora and team on the Telemetry page of xrdocs# https#//xrdocs.github.io/telemetry/tutorials, it\u2019s time to dive in.Streaming Telemetry in principle is tied to our need to evolve network device monitoring, above and beyond the capabilities that SNMP can provide.To get started, check out the following blogs#      The Limits of SNMP        Why you should care about Model Driven Telemetry        Introduction to pipeline  The running theme through the above set of blogs is clear# We need a consistent, model-driven method of exposing operational data from Network devices (read Yang Models# Openconfig, Vendor specific, and IETF)  and PUSH the data over industry accepted transport protocols like GRPC or plain TCP/UDP to external Telemetry receivers. This is where IOS-XR really excels.The move from pull (SNMP style) to a push-based model for gathering Telemetry data is crucial to understand. It allows operational data to be collected at higher rates and higher scale (been shown and tested to be nearly 100x more effective than SNMP).Consequently, there is greater focus on tools that can help consume this large amount of data off-box. There are a variety of tools (opensource and otherwise) available for big data consumption#  Apache Kafka, Prometheus, influxDB stack, SignalFX etc.A tool we recently open-sourced in this space with complete support for Model Driven Telemetry on IOS-XR (6.0.1+) that, as the name suggests, serves as a pipe/conduit between IOS-XR (over TCP, UDP or GRPC) on the input side and a whole host of tools (Kafka, influxDB, prometheus etc.) on the output side is called Pipeline. You can find it on Github. Find more about it here and here.What is on-box Telemetry?There is no one-size-fits-all technique for monitoring and managing network devices. There are a lot of network operators that will follow the typical approach# Set up the Model Driven Telemetry on IOS-XR and stream operational data to an external receiver or set of receivers. This is shown below. Pipeline as mentioned earlier, is used as a conduit to a set of tools like Kafka,prometheus etc.However, quite a few of our users have come and asked us if it\u2019s possible to have a telemetry receiver run on the router inside a container (lxc or docker) so that applications running locally inside the container can take actions based on Telemetry data.This may be done for different reasons#      Users may choose to simplify their server environment and not run external services (like  Kafka, influxDB stack or prometheus/Grafana etc.). Typically, somebackground in devops engineering is often important to understand how to scale out these services and process large amounts of data coming from all routers at the same time.        The alerts or the remediation actions that a user intends to perform based on the Telemetry data received may be fairly simplistic and can be done on box.  Bear in mind that running onbox does come with its own concerns. Network devices typically have limited compute capacity (CPU/RAM) and limited disk capacity. While CPU/RAM isolation can be achieved using Containers on box, managing the disk space on each individual router does require special care when dealing with Streaming Telemetry applications.Docker container to host Pipeline + KafkaIn this tutorial, we look at using a Docker container to host Pipeline and Kafka (with zookeper) as a Telemetry receiver. Further a simple Kafka consumer is written in python to interact with Kafka and take some sample action on a Telemetry data point.If you haven\u2019t had a chance to learn how we enable hosting for Docker containers on IOS-XR platforms and how we set up routing capabilities within the container, take a look at the following section of our detailed Docker guide for IOS-XR#  Understanding Docker Setup on IOS-XR platformsAs shown in the platform specific sections below, the pipeline-kafka combination runs as a Docker container onbox. Some specifics on the setup#            In IOS-XR 6.2.1 (before 6.3.1) only global-vrf is supported in the linux kernel.              The docker container is launched with the global-vrf network namespace mounted inside the container.              The pipeline and kafka instances are launched inside the global-vrf network namespace and listen on all visible XR IP addresses in the kernel (Data ports in global-vrf, Management port in Global-vrf, loopback interfaces in global-vrf).              The ports and listening IP selected by pipeline can be changed by the user during docker bringup itself by mounting a custom pipeline.conf (shown in subsequent sections).              The XR telemetry process is configured to send Telemetry data to pipeline over              Transport = UDP (only UDP is supported for onbox telemetry) and        Destination address = listening IP address (some local XR IP) for pipeline.            NCS5500/Vagrant On-Box Telemetry SetupThe docker daemon on NCS5500, NCS5000, XRv9k and Vagrant XR (IOS-XRv64) platforms runs on the Host layer at the bottom. The onbox telemetry setup will thus look something like#ASR9k On-Box Telemetry SetupOn ASR9k, the setup is the same from the user perspective. But for accuracy, the Docker daemon runs inside the XR VM in this case, as is shown below.It is recommended to host onbox daemons (in this case Kafka, pipeline, zookeeper) on either the all IP address (0.0.0.0)  or on XR loopback IP addresses. This makes sure that these daemons stay up and available even when a physical interface goes down.Docker image for Pipeline+KafkaWhile a user is welcome to build their own custom Docker images, we have a base image that can take care of installation of pipeline and Kafka+zookeeper for you and is already available on Docker hub#  https#//hub.docker.com/r/akshshar/pipeline-kafka/This image is built out automatically from the following github repo#  https#//github.com/ios-xr/pipeline-kafkaWe will utilize this image and build our own custom variant to run on an IOS-XR box for onbox telemetry.Building a Pipeline-kafka Docker image for IOS-XRTo build our own Docker image, you need a development environment with Docker engine installed.This is basically the devbox environment that we have setup in earlier tutorials. To understand how to do this, follow the steps below (in order) from the Docker guide for IOS-XR#      Pre-requisites#  Setup your Vagrant environment and/or physical boxes (ASR9k, NCS5500 etc.)      **Important#** If you're using the Vagrant setup for this tutorial, bear in mind that the   default Vagrant image runs in 4G RAM. Since the docker image we host on the router is   relatively resource intensive, we will need to increase the memory for our Vagrant IOS-XR   instance to atleast 5G (5120 MB). This can be done easily by modifying the `Vagrantfile` in   your directory and adding the following#                   config.vm.define ~rtr~ do |node|         ##############  SNIP  #############        node.vm.provider ~virtualbox~ do |v|           v.memory = 5120         end      end                 config.vm.define ~devbox~ do |node|        node.vm.box =  ~ubuntu/trusty64~          ##############  SNIP  ##############                  Set up your topology# Understand the Topology        Set up the Devbox environment# Install docker-engine on the devbox  Clone Github repoNow that you have a running devbox environment, let\u2019s clone the github-repo for the pipeline-kafka project#we use \u2013recursive to make sure all the submodules get pulled as well. The submodules are actual github repos for the standalone pipeline and docker-kafka projects.vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ git clone --recursive https#//github.com/ios-xr/pipeline-kafkaCloning into 'pipeline-kafka'...remote# Counting objects# 38, done.remote# Compressing objects# 100% (30/30), done.remote# Total 38 (delta 15), reused 20 (delta 4), pack-reused 0Unpacking objects# 100% (38/38), done.Checking connectivity... done.Submodule 'bigmuddy-network-telemetry-pipeline' (https#//github.com/cisco/bigmuddy-network-telemetry-pipeline) registered for path 'bigmuddy-network-telemetry-pipeline'Submodule 'docker-kafka' (https#//github.com/spotify/docker-kafka) registered for path 'docker-kafka'Cloning into 'bigmuddy-network-telemetry-pipeline'...remote# Counting objects# 14615, done.remote# Compressing objects# 100% (8021/8021), done.remote# Total 14615 (delta 3586), reused 0 (delta 0), pack-reused 3349Receiving objects# 100% (14615/14615), 43.97 MiB | 2.02 MiB/s, done.Resolving deltas# 100% (4012/4012), done.Checking connectivity... done.Submodule path 'bigmuddy-network-telemetry-pipeline'# checked out 'a57e87c59ac220ad7725b6b74c3570243e1a4ac3'Cloning into 'docker-kafka'...remote# Counting objects# 98, done.remote# Total 98 (delta 0), reused 0 (delta 0), pack-reused 98Unpacking objects# 100% (98/98), done.Checking connectivity... done.Submodule path 'docker-kafka'# checked out 'fc8cdbd2e23a5cac21e7138d07ea884b4309c59a'vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ cd pipeline-kafka/iosxr_dockerfile/vagrant@vagrant-ubuntu-trusty-64#~/pipeline-kafka/iosxr_dockerfile$ lsDockerfile  kafka_consumer.pyvagrant@vagrant-ubuntu-trusty-64#~/pipeline-kafka/iosxr_dockerfile$ Understand the DockerfileLet\u2019s take a look at the Dockerfile under the iosxr_dockerfile folder#vagrant@vagrant-ubuntu-trusty-64#~/pipeline-kafka/iosxr_dockerfile$ cat Dockerfile FROM akshshar/pipeline-kafka#latestMaintainer akshshar# Specify the ~vrf~ you want to run daemons in during build time# By default, it is global-vrfARG vrf=global-vrf# Set up the ARG for use by Entrypoint or CMD scriptsENV vrf_exec ~ip netns exec $vrf~# Add a sample kafka_consumer.py script. User can provide their ownADD kafka_consumer.py /kafka_consumer.pyCMD $vrf_exec echo ~127.0.0.1 localhost~ &gt;&gt; /etc/hosts &amp;&amp; $vrf_exec supervisord -nLet\u2019s break it down#All the references below to Dockerfile instructions are derived from official Dockerfile Documentation#https#//docs.docker.com/engine/reference/builder/#known-issues-runARG vrf=global-vrfWe setup the script to accept arguments from the user during build time. This will allow us to be flexible in specifying the vrf (network namespace) to spin up the daemons in, in the future. Today in 6.2.1 (before 6.3.1), only global-vrf is supported.ENV vrf_exec ~ip netns exec $vrf~In Dockerfiles, the ARG variables are rejected in the ENTRYPOINT or CMD instructions. So we set up an ENV variable (which is honored) to create a command prefix necessary to execute a command in a given network namespace (vrf).ADD kafka_consumer.py /kafka_consumer.pyWe place the sample application (in this case written in python) inside the image to act as a consumer of the Telemetry data pushed to Kafka. This application can contain custom triggers to initiate alerts or other actions. For this tutorial, we will initiate the script manually post launch of the container. The user can choose to start the application by default as part of the ENTRYPOINT or CMD instructions in the dockerfile.CMD $vrf_exec echo ~127.0.0.1 localhost~ &gt;&gt; /etc/hosts &amp;&amp; $vrf_exec supervisord -nThis specifies the command that will be run inside the container post boot. The first part of the command $vrf_exec echo ~127.0.0.1 localhost~ &gt;&gt; /etc/hosts sets up /etc/hosts with an entry for localhost making it easier for kafka and applications to talk to each other locally. The second part of the command $vrf_exec supervisord -n is used to start all the services in the correct vrf (hence the $vrf_exec).  We use supervisord to easily specify multiple daemons that need to be launched (pipeline, kafka, zookeeper).  You can get more details on supervisord here# http#//supervisord.org/Build the Docker imageIssue a docker build in the same folder and let\u2019s tag it as pipeline-kafka-xr#latestvagrant@vagrant-ubuntu-trusty-64#~/pipeline-kafka/iosxr_dockerfile$ sudo docker build -t pipeline-kafka-xr . Sending build context to Docker daemon  3.584kBStep 1/6 # FROM akshshar/pipeline-kafka#latestlatest# Pulling from akshshar/pipeline-kafka5040bd298390# Pull complete fce5728aad85# Pull complete c42794440453# Pull complete 0c0da797ba48# Pull complete 7c9b17433752# Pull complete 114e02586e63# Pull complete e4c663802e9a# Pull complete efafcf20d522# Pull complete b5a0de42a291# Pull complete e36cca8778db# Pull complete c3626ac93375# Pull complete 3b079f5713c1# Pull complete 2ac62e83a2a3# Pull complete 5fe3b4ab290e# Pull complete 08b6bc2f514b# Pull complete b86ae3d2d58d# Pull complete Digest# sha256#164adfb0da7f5a74d3309ddec4bc7078a81dcd32591cdb72410eccaf1448d88cStatus# Downloaded newer image for akshshar/pipeline-kafka#latest ---&gt; 0f131a6f1d8cStep 2/6 # MAINTAINER akshshar ---&gt; Running in 4da444d1b027 ---&gt; e21b468c12b5Removing intermediate container 4da444d1b027Step 3/6 # ARG vrf=global-vrf ---&gt; Running in 5cdb3d4eecdf ---&gt; e347fe8cd7d9Removing intermediate container 5cdb3d4eecdfStep 4/6 # ENV vrf_exec ~ip netns exec $vrf~ ---&gt; Running in 6601c66ff5fb ---&gt; 6104847fbe17Removing intermediate container 6601c66ff5fbStep 5/6 # ADD kafka_consumer.py /kafka_consumer.py ---&gt; 6cf31ccbf679Removing intermediate container 72d2b0320cf2Step 6/6 # CMD $vrf_exec echo ~127.0.0.1 localhost~ &gt;&gt; /etc/hosts &amp;&amp; $vrf_exec supervisord -n ---&gt; Running in 8c44808a44e6 ---&gt; d9c6ec3671c0Removing intermediate container 8c44808a44e6Successfully built d9c6ec3671c0vagrant@vagrant-ubuntu-trusty-64#~/pipeline-kafka/iosxr_dockerfile$ You should now have the docker image available on the devbox#vagrant@vagrant-ubuntu-trusty-64#~/pipeline-kafka/iosxr_dockerfile$ sudo docker imagesREPOSITORY                TAG                 IMAGE ID            CREATED              SIZEpipeline-kafka-xr         latest              d9c6ec3671c0        About a minute ago   676MBakshshar/pipeline-kafka   latest              0f131a6f1d8c        5 hours ago          676MBvagrant@vagrant-ubuntu-trusty-64#~/pipeline-kafka/iosxr_dockerfile$ Pull Docker image on the routerThere are multiple ways in which the freshly created Docker image could be transferred to the IOS-XR router. These methods are discussed in detail in the Docker Guide for IOS-XR. Choose your poison #) #      Using an insecure registry        Using a self-signed registry        Using Docker save/load  Launch the Docker containerLet\u2019s assume you chose one of the above methods and pulled the docker container onto the router. In the end, you should see on  the router\u2019s linux shell#[xr-vm_node0_RP0_CPU0#~]$ sudo -i[xr-vm_node0_RP0_CPU0#~]$ docker imagesREPOSITORY          TAG                 IMAGE ID            CREATED             SIZEpipeline-kafka-xr   latest              d9c6ec3671c0        34 minutes ago      676.4 MB[xr-vm_node0_RP0_CPU0#~]$ The name of the image may be different based on the \u201cdocker pull\u201d technique you use.Create a custom pipeline.confBefore we spin up the container, let\u2019s create a custom pipeline.conf file.A sample pipeline.conf can be found here# https#//github.com/cisco/bigmuddy-network-telemetry-pipeline/blob/master/pipeline.confOn-box telemetry in 6.2.1 only works over UDP as transport. Support for TCP and GRPC dial-in/dial-out will come soonConsidering the above limitation, we modify pipeline.conf to only enable UDP as an input transport. Further, we\u2019ll point pipeline to Kafka as an output stage. In the end, the relevant lines in my custom pipeline.conf are shown below#[xr-vm_node0_RP0_CPU0#~]$ grep -v ~^#~ /misc/app_host/pipeline.conf [default]id = pipeline[mykafka]stage = xport_outputtype = kafkaencoding = jsonbrokers = localhost#9092topic = telemetrydatachanneldepth = 1000[udpin]type = udp stage = xport_inputlisten = 1.1.1.1#5958 encap = stlogdata = off[xr-vm_node0_RP0_CPU0#~]$ Let me break down the above output#      [udpin] specifies UDP as the input transport for pipeline and forces pipeline to listen on 1.1.1.1#5958. What is 1.1.1.1 # Address of one of the loopbacks in IOS-XR config as shown below#    RP/0/RSP1/CPU0#asr9k#show  running-config  int loopback 0Thu Apr 13 16#21#57.749 UTCinterface Loopback0 ipv4 address 1.1.1.1 255.255.255.255!RP/0/RSP1/CPU0#asr9k#        Be a little careful here. Do not select loopback1 IP address or any explicitly configured east-west interface for TPA. To understand more on TPA east-west IP addresses, see here#https#//xrdocs.github.io/application-hosting/blogs/2016-06-28-xr-app-hosting-architecture-quick-look/        [mykafka] stage describes the output stage of pipeline pointing to Kafka running inside the container. Pipeline is instructed to deliver data in a josn format to Kafka running at localhost#9092  Notice the location in which we create the customer pipeline.conf file#/misc/app_host/pipeline.confThis is important because the docker daemon runs on the underlying host layer in case of NCS5500/NCS5000/XRv9k and Vagrant IOS-XR platforms. /misc/app_host is a shared volume between the host layer and the XR LXC in these platforms.As for ASR9k, there is no issue placing the file anywhere since docker daemon runs inside the XR VM itself. But for consistency we\u2019ll stick to the /misc/app_host location.Finally, launch the docker container by mounting /misc/app_host/pipeline.conf to /data/pipeline.conf inside the container where it will be picked up by the pipeline process.[xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ docker run -itd --name pipeline-kafka -v /var/run/netns/global-vrf#/var/run/netns/global-vrf -v /misc/app_host/pipeline.conf#/data/pipeline.conf --hostname localhost  --cap-add=SYS_ADMIN pipeline-kafka-xr#latest e42e7e2526253e37b28362bf70c98550ca9ac108dc2aaa667da1290e44c2a035[xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ docker ps CONTAINER ID        IMAGE                      COMMAND                  CREATED             STATUS              PORTS               NAMESe42e7e252625        pipeline-kafka-xr#latest   ~/bin/sh -c '$vrf_exe~   2 minutes ago       Up 2 minutes                            pipeline-kafka[xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ [xr-vm_node0_RP0_CPU0#~]$ docker exec -it pipeline-kafka bashroot@localhost#/# root@localhost#/# root@localhost#/# ip netns exec global-vrf bash root@localhost#/# root@localhost#/# root@localhost#/# ps -ef | grep -E ~pipeline|kafka|zookeeper~ root         9     6  0 02#05 ?        00#00#00 /pipeline --config=/data/pipeline.conf --log=/data/pipeline.logroot        10     6  0 02#05 ?        00#00#00 /usr/bin/java -Dzookeeper.log.dir=/var/log/zookeeper -Dzookeeper.root.logger=INFO,ROLLINGFILE -cp /etc/zookeeper/conf#/usr/share/java/jline.jar#/usr/share/java/log4j-1.2.jar#/usr/share/java/xercesImpl.jar#/usr/share/java/xmlParserAPIs.jar#/usr/share/java/netty.jar#/usr/share/java/slf4j-api.jar#/usr/share/java/slf4j-log4j12.jar#/usr/share/java/zookeeper.jar org.apache.zookeeper.server.quorum.QuorumPeerMain /etc/zookeeper/conf/zoo.cfgroot        11     6  0 02#05 ?        00#00#00 /bin/sh /usr/bin/start-kafka.shroot        12    11  3 02#05 ?        00#00#02 /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -Xmx256M -Xms256M -server -XX#+UseG1GC -XX#MaxGCPauseMillis=20 -XX#InitiatingHeapOccupancyPercent=35 -XX#+DisableExplicitGC -Djava.awt.headless=true -Xloggc#/opt/kafka_2.11-0.10.1.0/bin/../logs/kafkaServer-gc.log -verbose#gc -XX#+PrintGCDetails -XX#+PrintGCDateStamps -XX#+PrintGCTimeStamps -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/opt/kafka_2.11-0.10.1.0/bin/../logs -Dlog4j.configuration=file#/opt/kafka_2.11-0.10.1.0/bin/../config/log4j.properties -cp #/opt/kafka_2.11-0.10.1.0/bin/../libs/aopalliance-repackaged-2.4.0-b34.jar#/opt/kafka_2.11-0.10.1.0/bin/../libs/argparse4j-0.5.0.jar#/opt/kafka_2.11-0.10.1.0/bin/../libs/connect-api-0.10.1.0.jar#/opt/kafka_2.11-0.10.1.0/bin/../libs/connect-file-0.10.1.0.jar#/opt/kafka_2.11-0.10.1.0/bin/../libs/connect-json-0.10.1.0.jar#/opt/kafka_2.11-0.10.1.0/bin/../libs/connect-runtime-0.10.1.0.jar#/opt/kafka_2.11-0-########################  SNIP Output #########################################9.2.15.v20160210.jar#/opt/kafka_2.11-0.10.1.0/bin/../libs/jetty-server-9.2.15.v20160210.jar#/opt/kafka_2.11-0.10.1.0/bin/../libs/jetty-servlet-9.2.15.v20160210.jar#/opt/kafka_2.11-0.10.1.0/bin/../libs/jetty-servlets-9.2.15.v20160210.jar#/opt/kafka_2.11-0.10.1.0/bin/../libs/jetty-util-9.2.15.v20160210.jar#/opt/kafka_2.11-0.10.1.0/-locator-1.0.1.jar#/opt/kafka_2.11-0.10.1.0/bin/../libs/reflections-0.9.10.jar#/opt/kafka_2.11-0.10.1.0/bin/../libs/rocksdbjni-4.9.0.jar#/opt/kafka_2.11-0.10.1.0/bin/../libs/scala-library-2.11.8.jar#/opt/kafka_2.11-0.10.1.0/bin/../libs/scala-root       314   312  0 02#06 ?        00#00#00 grep -E pipeline|kafka|zookeeperroot@localhost#/# Perfect! As we can see the required services# Pipeline, Kafka and Zookeeper were started in the correct network namespace ( notice we did an exec into the global-vrf network namespace) before checking if the processes are running.Testing the on-box Telemetry receiverTo test out the setup, let us first configure IOS-XR to send model-driven Telemetry data to the local pipeline receiver.Remember, in our custom pipeline.conf we set up pipeline to listen on UDP port 5958 on IP=1.1.1.1The configuration required on IOS-XR is#RP/0/RSP1/CPU0#asr9k#RP/0/RSP1/CPU0#asr9k#show  running-config  interface  loopback 0Thu Apr 13 18#11#33.729 UTCinterface Loopback0 ipv4 address 1.1.1.1 255.255.255.255!RP/0/RSP1/CPU0#asr9k#show  running-config  telemetry model-driven Thu Apr 13 18#11#39.862 UTCtelemetry model-driven destination-group DGroup1 address family ipv4 1.1.1.1 port 5958    encoding self-describing-gpb protocol udp   ! ! sensor-group SGroup1  sensor-path Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters  ! subscription Sub1  sensor-group-id SGroup1 sample-interval 30000  destination-id DGroup1 !!RP/0/RSP1/CPU0#asr9k#Notice the highlighted configurations#      We configure the destination to be 1.1.1.1#5958 over UDP, where 1.1.1.1 = loopback0 ip address of XR. Could be any Loopback or interface IP (Except any east-west interface IP address under tpa)        We select the following sensor path# Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters. This sensor path is used to export interface stats for all interfaces on the box using the Cisco IOS-XR infra-statsd-oper YANG model.  To learn more about how to configure model-driven telemetry, check out this great tutorial by Shelly#  https#//xrdocs.github.io/telemetry/tutorials/2016-07-21-configuring-model-driven-telemetry-mdt/Query the local Kafka instanceAs soon as you configure Model-Driven Telemetry as shown above, the router will start streaming statistics to the local pipeline instance.Pipeline will then push the stats to Kafka running locally to the topic = \u2018telemetry\u2019 ( We configured this in our custom pipeline.conf file).Finally purely for test purposes, the docker build process includes a sample python script that uses the python-kafka library to act as a kafka consumer.You can find this inside the running docker container under / #[asr9k#~]$ docker exec -it pipeline-kafka bash root@localhost#/# ip netns exec global-vrf bash root@localhost#/# root@localhost#/# pwd/root@localhost#/# ls kafka_consumer.py kafka_consumer.pyThis is what the sample query script looks like#from kafka import KafkaConsumerimport jsonif __name__ == ~__main__~#    consumer = KafkaConsumer('telemetry', bootstrap_servers=[~1.1.1.1#9092~])    for msg in consumer#        telemetry_msg =  msg.value        telemetry_msg_json = json.loads(telemetry_msg)        print ~\\nTelemetry data Received#\\n ~        print json.dumps(telemetry_msg_json, indent=4, sort_keys=True)        if ~Rows~ in telemetry_msg_json#            content_rows = telemetry_msg_json[~Rows~]            for row in content_rows#                if row[~Keys~][~interface-name~] == 'MgmtEth0/RSP1/CPU0/0'#                    pkt_rcvd = row[~Content~][~packets-received~]                                   input_drops = row[~Content~][~input-drops~]                    print(~\\nParsed fields for interface  MgmtEth0/RSP1/CPU0/0#\\                            \\n  Packets Received = %s,\\                            \\n  Input Drops = %s~ %(pkt_rcvd, input_drops))  As you can guess from the output above we\u2019re executing the commands on an ASR9k. The script above has been built to dump the Telemetry stats in json format in realtime and also parse them to based on the interface key = ~MgmtEth0/RSP1/CPU0/0~. If you want this piece of code to work for the Vagrant setup, you will have to use an interface key based on the Vagrant IOS-XR interface naming convention (MgmtEth0/RP0/CPU0/0, GigabitEthernet0/0/0/0 etc.)When we run the script, we get#root@localhost#/# python kafka_consumer.py Telemetry data Received# {    ~Rows~# [        {            ~Content~# {                ~applique~# 0,                 ~availability-flag~# 0,                 ~broadcast-packets-received~# 0,                 ~broadcast-packets-sent~# 0,                 ~bytes-received~# 0,                 ~bytes-sent~# 0,                 ~carrier-transitions~# 0,                 ~crc-errors~# 0,                 ~framing-errors-received~# 0,                 ~giant-packets-received~# 0,                 ~input-aborts~# 0,                 ~input-drops~# 0,                 ~input-errors~# 0,                 ~input-ignored-packets~# 0,                 ~input-overruns~# 0,                 ~input-queue-drops~# 0,                 ~last-data-time~# 1492110984,                 ~last-discontinuity-time~# 1484314261,                 ~multicast-packets-received~# 0,                 ~multicast-packets-sent~# 0,                 ~output-buffer-failures~# 0,                 ~output-buffers-swapped-out~# 0,                 ~output-drops~# 0,                 ~output-errors~# 0,                 ~output-queue-drops~# 0,                 ~output-underruns~# 0,                 ~packets-received~# 0,                 ~packets-sent~# 0,                 ~parity-packets-received~# 0,                 ~resets~# 0,                 ~runt-packets-received~# 0,                 ~seconds-since-last-clear-counters~# 0,                 ~seconds-since-packet-received~# 4294967295,                 ~seconds-since-packet-sent~# 4294967295,                 ~throttled-packets-received~# 0,                 ~unknown-protocol-packets-received~# 0            },             ~Keys~# {                ~interface-name~# ~Null0~            },             ~Timestamp~# 1492110987184        },         {            ~Content~# {                ~applique~# 0,                 ~availability-flag~# 0,                 ~broadcast-packets-received~# 5894231,                 ~broadcast-packets-sent~# 0,                 ~bytes-received~# 2413968971,                 ~bytes-sent~# 830100769,                 ~carrier-transitions~# 15,                 ~crc-errors~# 0,                 ~framing-errors-received~# 0,                 ~giant-packets-received~# 0,                 ~input-aborts~# 0,                 ~input-drops~# 0,                 ~input-errors~# 0,                 ~input-ignored-packets~# 0,                 ~input-overruns~# 0,                 ~input-queue-drops~# 0,                 ~last-data-time~# 1492110987,                 ~last-discontinuity-time~# 1484314243,                 ~multicast-packets-received~# 24,                 ~multicast-packets-sent~# 0,                 ~output-buffer-failures~# 0,                 ~output-buffers-swapped-out~# 0,                 ~output-drops~# 0,                 ~output-errors~# 0,                 ~output-queue-drops~# 0,                 ~output-underruns~# 0,                 ~packets-received~# 8712938,                 ~packets-sent~# 2328185,                 ~parity-packets-received~# 0,                 ~resets~# 0,                 ~runt-packets-received~# 0,                 ~seconds-since-last-clear-counters~# 0,                 ~seconds-since-packet-received~# 0,                 ~seconds-since-packet-sent~# 3,                 ~throttled-packets-received~# 0,                 ~unknown-protocol-packets-received~# 0            },             ~Keys~# {                ~interface-name~# ~MgmtEth0/RSP1/CPU0/0~            },             ~Timestamp~# 1492110987184        }    ],     ~Source~# ~1.1.1.1#18046~,     ~Telemetry~# {        ~collection_end_time~# 0,         ~collection_id~# 12254,         ~collection_start_time~# 1492110987176,         ~encoding_path~# ~Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters~,         ~msg_timestamp~# 1492110987176,         ~node_id_str~# ~asr9k~,         ~subscription_id_str~# ~Sub1~    }}Parsed fields for interface  MgmtEth0/RSP1/CPU0/0#                              Packets Received = 8712938,                              Input Drops = 0Telemetry data Received# {    ~Source~# ~1.1.1.1#18046~,     ~Telemetry~# {        ~collection_end_time~# 1492110987186,         ~collection_id~# 12254,         ~collection_start_time~# 0,         ~encoding_path~# ~Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters~,         ~msg_timestamp~# 1492110987186,         ~node_id_str~# ~asr9k~,         ~subscription_id_str~# ~Sub1~    }}Works Great! Now that you\u2019re able to capture Telemetry messages in realtime through a python script and are able to parse through the fields, you should be able to create your own conditions and actions based on the value of the fields. There you have it! Your own standalone pipeline and Kafka based Telemetry receiver running on the box.", "url": "https://xrdocs.github.io/application-hosting/tutorials/2017-04-12-on-box-telemetry-running-pipeline-and-kafka-on-ios-xr/", "tags": "vagrant, iosxr, cisco, docker, pipeline, telemetry", "title": "On-box Telemetry: Running  Pipeline and Kafka on IOS-XR (6.2.1+)", "author": "Akshat Sharma"}, "tutorials-2017-12-30-full-internet-view-on-base-ncs-5500-systems-s01e04": {"content": "     Understanding NCS5500 Resources  S01E04 Full Internet View on \u201cBase\u201d NCS 5500 Systems          Previously on \u201cUnderstanding NCS5500 Resources\u201d      The demo      Config and CLI        \u201cWet-finger\u201d Internet Growth Projection  S01E04 Full Internet View on \u201cBase\u201d NCS 5500 SystemsPreviously on \u201cUnderstanding NCS5500 Resources\u201dIn previous posts, we presented#  the different routers and line cards in NCS5500 portfolio  we explained how IPv4 prefixes are sorted in LEM, LPM and eTCAM  and how IPv6 prefixes are stored in the same databases.Let\u2019s illustrate how we can handle a full IPv4 and IPv6 Internet view on base systems and line cards (i.e. without external TCAM, only using the LEM and LPM internal to the forwarding ASIC).The demoFollowing YouTube video will demonstrate we can handle multiple internet peers in the global routing table (15 full views on our demo) on base systems with the appropriate optimizatios.We will demo how we can monitor the important resources used to store routing information and finally we will project what could be the internet size if it follows 2017 trends and how long the systems will be handle the full v4/v6 views.https#//www.youtube.com/watch?v=8Tq4nyP2wuAThis video shows NCS5500 using Jericho-based line cards without external TCAM (also valid for fixed-form systems) handling the current internet table with still significant growth margin.Config and CLIOn this line card we have#RP/0/RP0/CPU0#NCS5508#sh route sumRoute Source                     Routes     Backup     Deleted     Memory(bytes)connected                        9          1          0           2400local                            10         0          0           2400static                           2          0          0           480ospf 100                         0          0          0           0bgp 100                          698440     0          0           167625600isis 1                           0          0          0           0dagr                             0          0          0           0Total                            698461     1          0           167630880  RP/0/RP0/CPU0#NCS5508#sh route ipv6 un sum  Route Source                     Routes     Backup     Deleted     Memory(bytes)connected                        5          0          0           1320connected l2tpv3_xconnect        0          0          0           0local                            5          0          0           1320static                           0          0          0           0bgp 100                          61527      0          0           16243128Total                            61537      0          0           16245768RP/0/RP0/CPU0#NCS5508#sh bgp sumBGP router identifier 1.1.1.1, local AS number 100BGP generic scan interval 60 secsNon-stop routing is enabledBGP table state# ActiveTable ID# 0xe0000000   RD version# 1000324BGP main routing table version 1000324BGP NSR Initial initsync version 624605 (Reached)BGP NSR/ISSU Sync-Group versions 1000324/0BGP scan interval 60 secsBGP is operating in STANDALONE mode.Process       RcvTblVer   bRIB/RIB   LabelVer  ImportVer  SendTblVer  StandbyVerSpeaker         1000324    1000324    1000324    1000324     1000324     1000324Neighbor        Spk    AS MsgRcvd MsgSent   TblVer  InQ OutQ  Up/Down  St/PfxRcd192.168.100.151   0  1000  665841  210331  1000324    0    0    6d23h     655487192.168.100.152   0 45896  666232  210331  1000324    0    0    6d23h     656126192.168.100.153   0  7018  664430  210331  1000324    0    0    6d23h     654330192.168.100.154   0  1836  669052  210331  1000324    0    0    6d23h     658948192.168.100.155   0 50300  646305  210331  1000324    0    0    6d23h     636208192.168.100.156   0 50304  667405  210331  1000324    0    0    6d23h     657301192.168.100.157   0 57381  667411  210331  1000324    0    0    6d23h     657307192.168.100.158   0  4608  687673  276201  1000324    0    0    6d23h     677487192.168.100.159   0  4777  676317  210331  1000324    0    0    6d23h     666213192.168.100.160   0 37989  298774  210331  1000324    0    0    6d23h     288706192.168.100.161   0  3549  664480  210331  1000324    0    0    6d23h     654376192.168.100.163   0  8757  642587  210331  1000324    0    0    6d23h     632483192.168.100.164   0  3257 1319462  360784  1000324    0    0    6d22h     654661192.168.100.165   0  3258  664741  262418  1000324    0    0    6d22h     654661192.168.100.166   0  4609  687524  163237  1000324    0    0    6d22h     677487RP/0/RP0/CPU0#NCS5508#sh bgp ipv6 un sumBGP router identifier 1.1.1.1, local AS number 100BGP generic scan interval 60 secsNon-stop routing is enabledBGP table state# ActiveTable ID# 0xe0800000   RD version# 64373BGP main routing table version 64373BGP NSR Initial initsync version 61139 (Reached)BGP NSR/ISSU Sync-Group versions 64373/0BGP scan interval 60 secs BGP is operating in STANDALONE mode. Process       RcvTblVer   bRIB/RIB   LabelVer  ImportVer  SendTblVer  StandbyVerSpeaker           64373      64373      64373      64373       64373       64373 Neighbor        Spk    AS MsgRcvd MsgSent   TblVer  InQ OutQ  Up/Down  St/PfxRcd2001#111##151     0   100   68925   10070    64373    0    0    6d23h      588602001#111##152     0   100   51103   10070    64373    0    0    6d23h      410382001#111##153     0   100   52945  109776    64373    0    0    6d23h      428802001#111##155     0   100   52754   10070    64373    0    0    6d23h      426892001#111##156     0   100   40481   10070    64373    0    0    6d23h      304172001#111##157     0   100   13997   10070    64373    0    0    6d23h       39322001#111##158     0   100   52944   10070    64373    0    0    6d23h      428792001#111##159     0   100   51465   10070    64373    0    0    6d23h      414002001#111##160     0   100   52737   10070    64373    0    0    6d23h      426722001#111##161     0   100   52918   10070    64373    0    0    6d23h      428532001#111##163     0   100   51428   10070    64373    0    0    6d23h      41364 RP/0/RP0/CPU0#NCS5508#sh bgp scale VRF# default Neighbors Configured# 26     Established# 26  Address-Family   Prefixes Paths    PathElem   Prefix     Path       PathElem                                               Memory     Memory     Memory  IPv4 Unicast    698440   9481781  698440     98.58MB    795.74MB   71.27MB  IPv6 Unicast    61527    430984   61527      9.39MB     36.17MB    6.28MB  ------------------------------------------------------------------------------  Total           759967   9912765  759967     107.97MB   831.91MB   77.55MB Total VRFs Configured# 0 RP/0/RP0/CPU0#NCS5508#sh bgpBGP router identifier 1.1.1.1, local AS number 100BGP generic scan interval 60 secsNon-stop routing is enabledBGP table state# ActiveTable ID# 0xe0000000   RD version# 1000324BGP main routing table version 1000324BGP NSR Initial initsync version 624605 (Reached)BGP NSR/ISSU Sync-Group versions 1000324/0BGP scan interval 60 secs Status codes# s suppressed, d damped, h history, * valid, &gt; best              i - internal, r RIB-failure, S stale, N Nexthop-discardOrigin codes# i - IGP, e - EGP, ? - incomplete   Network            Next Hop            Metric LocPrf Weight Path*&gt; 1.0.4.0/22         192.168.100.151                        0 1000 1299 4826 38803 56203 i*                     192.168.100.152                        0 45896 45896 4826 38803 56203 i*                     192.168.100.153                        0 7018 7018 3257 4826 38803 56203 i*                     192.168.100.154                        0 1836 1836 6939 4826 38803 56203 i*                     192.168.100.155                        0 50300 50300 6939 4826 38803 56203 i*                     192.168.100.156                        0 50304 50304 6939 4826 38803 56203 i*                     192.168.100.157                        0 57381 57381 6939 4826 38803 56203 i*                     192.168.100.158                        0 4608 4608 4826 38803 56203 i*                     192.168.100.159                        0 4777 4777 2516 4713 2914 15412 4826 38803 56203 i*                     192.168.100.160                        0 37989 37989 4844 4826 38803 56203 i*                     192.168.100.161       2514             0 3549 3549 3356 1299 4826 38803 56203 i*                     192.168.100.163                        0 8757 8758 6939 4826 38803 56203 i*                     192.168.100.164         10             0 3257 3257 4826 38803 56203 i*                     192.168.100.165         10             0 3258 3257 4826 38803 56203 i*                     192.168.100.166                        0 4609 4608 4826 38803 56203 i*&gt; 1.0.4.0/24         192.168.100.151                        0 1000 1299 4826 38803 56203 i*                     192.168.100.152                        0 45896 45896 4826 38803 56203 i*                     192.168.100.153                        0 7018 7018 3257 4826 38803 56203 i*                     192.168.100.154                        0 1836 1836 6939 4826 38803 56203 i*                     192.168.100.155                        0 50300 50300 6939 4826 38803 56203 i*                     192.168.100.156                        0 50304 50304 6939 4826 38803 56203 i*                     192.168.100.157                        0 57381 57381 6939 4826 38803 56203 i*                     192.168.100.158                        0 4608 4608 4826 38803 56203 i*                     192.168.100.159                        0 4777 4777 2516 4713 2914 15412 4826 38803 56203 i*                     192.168.100.161       2514             0 3549 3549 3356 1299 4826 38803 56203 i*                     192.168.100.163                        0 8757 8758 6939 4826 38803 56203 i*                     192.168.100.164         10             0 3257 3257 4826 38803 56203 i*                     192.168.100.165         10             0 3258 3257 4826 38803 56203 i*                     192.168.100.166                        0 4609 4608 4826 38803 56203 i*&gt; 1.0.5.0/24         192.168.100.151                        0 1000 1299 4826 38803 56203 i*                     192.168.100.152                        0 45896 45896 4826 38803 56203 i*                     192.168.100.153                        0 7018 7018 3257 4826 38803 56203 i*                     192.168.100.154                        0 1836 1836 6939 4826 38803 56203 i*                     192.168.100.155                        0 50300 50300 6939 4826 38803 56203 i*                     192.168.100.156                        0 50304 50304 6939 4826 38803 56203 i*                     192.168.100.157                        0 57381 57381 6939 4826 38803 56203 i*                     192.168.100.158                        0 4608 4608 4826 38803 56203 i*                     192.168.100.159                        0 4777 4777 2516 4713 2914 15412 4826 38803 56203 i*                     192.168.100.161       2514             0 3549 3549 3356 1299 4826 38803 56203 i*                     192.168.100.163                        0 8757 8758 6939 4826 38803 56203 i*                     192.168.100.164         10             0 3257 3257 4826 38803 56203 i*                     192.168.100.165         10             0 3258 3257 4826 38803 56203 i*                     192.168.100.166                        0 4609 4608 4826 38803 56203 i... RP/0/RP0/CPU0#NCS5508#sh bgp ipv6 unBGP router identifier 1.1.1.1, local AS number 100BGP generic scan interval 60 secsNon-stop routing is enabledBGP table state# ActiveTable ID# 0xe0800000   RD version# 64373BGP main routing table version 64373BGP NSR Initial initsync version 61139 (Reached)BGP NSR/ISSU Sync-Group versions 64373/0BGP scan interval 60 secs Status codes# s suppressed, d damped, h history, * valid, &gt; best              i - internal, r RIB-failure, S stale, N Nexthop-discardOrigin codes# i - IGP, e - EGP, ? - incomplete   Network            Next Hop            Metric LocPrf Weight Path*&gt;i##/0               2001#111##151            0    100      0 1299 i* i2001##/32          2001#111##151            0    100      0 286 1103 1101 i*&gt;i                   2001#111##152                 100      0 7018 6939 i* i                   2001#111##155                 100      0 57821 6939 i* i                   2001#111##156                 100      0 8758 6939 i* i                   2001#111##158                 100      0 50304 2603 1103 1101 i* i                   2001#111##159                 100      0 22652 6939 i* i                   2001#111##160                 100      0 6881 6939 i* i                   2001#111##161                 100      0 50300 6939 i* i                   2001#111##163                 100      0 1836 6939 i*&gt;i2001#4#112##/48    2001#111##151            0    100      0 6724 112 i* i                   2001#111##152                 100      0 7018 6939 112 i* i                   2001#111##153                 100      0 57381 42708 112 i* i                   2001#111##155                 100      0 57821 6939 112 i* i                   2001#111##156                 100      0 8758 9002 112 i* i                   2001#111##158                 100      0 50304 2603 1103 112 i* i                   2001#111##159                 100      0 22652 112 i* i                   2001#111##160                 100      0 6881 112 i* i                   2001#111##161                 100      0 50300 112 i* i                   2001#111##163                 100      0 1836 112 i*&gt;i2001#5#5##/48      2001#111##151            0    100      0 174 48260 i* i                   2001#111##152                 100      0 7018 174 48260 i* i                   2001#111##153                 100      0 57381 42708 1299 174 48260 i* i                   2001#111##155                 100      0 57821 12586 3257 174 48260 i* i                   2001#111##158                 100      0 50304 1299 174 48260 i* i                   2001#111##159                 100      0 22652 174 48260 i* i                   2001#111##160                 100      0 6881 25512 174 48260 i* i                   2001#111##161                 100      0 50300 174 48260 i* i                   2001#111##163                 100      0 1836 174 48260 i*&gt;i2001#200##/32      2001#111##151            0    100      0 174 2914 2500 2500 i* i                   2001#111##152                 100      0 7018 2914 2500 2500 i* i                   2001#111##153                 100      0 57381 6939 2914 2500 2500 i* i                   2001#111##155                 100      0 57821 6939 2914 2500 2500 i* i                   2001#111##156                 100      0 8758 174 2914 2500 2500 i* i                   2001#111##158                 100      0 50304 1299 2914 2500 2500 i* i                   2001#111##159                 100      0 22652 3356 2914 2500 2500 i* i                   2001#111##160                 100      0 6881 6939 2914 2500 2500 i* i                   2001#111##161                 100      0 50300 2914 2500 2500 i* i                   2001#111##163                 100      0 1836 174 2914 2500 2500 i... RP/0/RP0/CPU0#NCS5508#sh dpa resources iproute loc 0/2/CPU0~iproute~ DPA Table (Id# 21, Scope# Global)--------------------------------------------------IPv4 Prefix len distributionPrefix   Actual       Prefix   Actual /0       3            /1       0 /2       0            /3       0 /4       3            /5       0 /6       0            /7       0 /8       16           /9       14 /10      37           /11      107 /12      288          /13      557 /14      1071         /15      1909 /16      13546        /17      7986 /18      14000        /19      25861 /20      40214        /21      44565 /22      83070        /23      70129 /24      388562       /25      1522 /26      1338         /27      877 /28      314          /29      510 /30      782          /31      60 /32      1170                          NPU ID# NPU-0           NPU-1           NPU-2           NPU-3           NPU-4           NPU-5                          In Use# 698511          698511          698511          698511          698511          698511                 Create Requests                           Total# 698546          698546          698546          698546          698546          698546                         Success# 698546          698546          698546          698546          698546          698546                 Delete Requests                           Total# 35              35              35              35              35              35                         Success# 35              35              35              35              35              35                 Update Requests                           Total# 141991          141991          141991          141991          141991          141991                         Success# 141991          141991          141991          141991          141991          141991                    EOD Requests                           Total# 0               0               0               0               0               0                         Success# 0               0               0               0               0               0                          Errors                     HW Failures# 0               0               0               0               0               0                Resolve Failures# 0               0               0               0               0               0                 No memory in DB# 0               0               0               0               0               0                 Not found in DB# 0               0               0               0               0               0                    Exists in DB# 0               0               0               0               0               0 RP/0/RP0/CPU0#NCS5508#sh dpa resources ip6route loc 0/2/CPU0 ~ip6route~ DPA Table (Id# 22, Scope# Global)--------------------------------------------------IPv6 Prefix len distributionPrefix   Actual       Prefix   Actual /0       3            /1       0 /2       0            /3       0 /4       0            /5       0 /6       0            /7       0 /8       0            /9       0 /10      3            /11      0 /12      0            /13      0 /14      0            /15      0 /16      10           /17      0 /18      0            /19      2 /20      9            /21      3 /22      4            /23      4 /24      20           /25      6 /26      15           /27      17 /28      79           /29      1899 /30      156          /31      128 /32      9773         /33      640 /34      435          /35      410 /36      1618         /37      284 /38      680          /39      161 /40      2285         /41      212 /42      397          /43      117 /44      2283         /45      180 /46      1465         /47      371 /48      20154        /49      13 /50      12           /51      4 /52      16           /53      0 /54      1            /55      8 /56      11621        /57      16 /58      2            /59      0 /60      3            /61      0 /62      1            /63      0 /64      5177         /65      0 /66      0            /67      0 /68      0            /69      0 /70      0            /71      0 /72      0            /73      0 /74      0            /75      0 /76      0            /77      0 /78      0            /79      0 /80      0            /81      0 /82      0            /83      0 /84      0            /85      0 /86      0            /87      0 /88      0            /89      0 /90      0            /91      0 /92      0            /93      0 /94      0            /95      0 /96      1            /97      0 /98      0            /99      0 /100     0            /101     0 /102     0            /103     0 /104     3            /105     0 /106     0            /107     0 /108     0            /109     0 /110     0            /111     0 /112     0            /113     0 /114     0            /115     4 /116     0            /117     0 /118     0            /119     0 /120     0            /121     0 /122     71           /123     0 /124     15           /125     0 /126     24           /127     18 /128     735                          NPU ID# NPU-0           NPU-1           NPU-2           NPU-3           NPU-4           NPU-5                          In Use# 61568           61568           61568           61568           61568           61568                 Create Requests                           Total# 61572           61572           61572           61572           61572           61572                         Success# 61572           61572           61572           61572           61572           61572                 Delete Requests                           Total# 4               4               4               4               4               4                         Success# 4               4               4               4               4               4                 Update Requests                           Total# 2629            2629            2629            2629            2629            2629                         Success# 2628            2628            2628            2628            2628            2628                    EOD Requests                           Total# 0               0               0               0               0               0                         Success# 0               0               0               0               0               0                          Errors                     HW Failures# 0               0               0               0               0               0                Resolve Failures# 0               0               0               0               0               0                 No memory in DB# 0               0               0               0               0               0                 Not found in DB# 0               0               0               0               0               0                    Exists in DB# 0               0               0               0               0               0 RP/0/RP0/CPU0#NCS5508#sh contr npu resources lem location 0/2/CPU0HW Resource Information    Name                            # lem OOR Information    NPU-0        Estimated Max Entries       # 786432        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green    NPU-1        Estimated Max Entries       # 786432        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green    NPU-2        Estimated Max Entries       # 786432        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green    NPU-3        Estimated Max Entries       # 786432        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green    NPU-4        Estimated Max Entries       # 786432        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green    NPU-5        Estimated Max Entries       # 786432        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Green Current Usage    NPU-0        Total In-Use                # 409888   (52 %)        iproute                     # 389732   (50 %)        ip6route                    # 20154    (3 %)        mplslabel                   # 2        (0 %)    NPU-1        Total In-Use                # 409888   (52 %)        iproute                     # 389732   (50 %)        ip6route                    # 20154    (3 %)        mplslabel                   # 2        (0 %)    NPU-2        Total In-Use                # 409888   (52 %)        iproute                     # 389732   (50 %)        ip6route                    # 20154    (3 %)        mplslabel                   # 2        (0 %)    NPU-3        Total In-Use                # 409888   (52 %)        iproute                     # 389732   (50 %)        ip6route                    # 20154    (3 %)        mplslabel                   # 2        (0 %)    NPU-4        Total In-Use                # 409888   (52 %)        iproute                     # 389732   (50 %)        ip6route                    # 20154    (3 %)        mplslabel                   # 2        (0 %)    NPU-5        Total In-Use                # 409888   (52 %)        iproute                     # 389732   (50 %)        ip6route                    # 20154    (3 %)        mplslabel                   # 2        (0 %) RP/0/RP0/CPU0#NCS5508#sh contr npu resources lpm location 0/2/CPU0HW Resource Information    Name                            # lpm OOR Information    NPU-0        Estimated Max Entries       # 430200        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Yellow        OOR State Change Time       # 2017.Dec.22 09#30#17 PST    NPU-1        Estimated Max Entries       # 430200        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Yellow        OOR State Change Time       # 2017.Dec.22 09#30#17 PST    NPU-2        Estimated Max Entries       # 430200        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Yellow        OOR State Change Time       # 2017.Dec.22 09#30#17 PST    NPU-3        Estimated Max Entries       # 430200        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Yellow        OOR State Change Time       # 2017.Dec.22 09#30#17 PST    NPU-4        Estimated Max Entries       # 430200        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Yellow        OOR State Change Time       # 2017.Dec.22 09#30#17 PST    NPU-5        Estimated Max Entries       # 430200        Red Threshold               # 95        Yellow Threshold            # 80        OOR State                   # Yellow        OOR State Change Time       # 2017.Dec.22 09#30#17 PST Current Usage    NPU-0        Total In-Use                # 350206   (81 %)        iproute                     # 308779   (72 %)        ip6route                    # 41414    (10 %)        ipmcroute                   # 0        (0 %)    NPU-1        Total In-Use                # 350206   (81 %)        iproute                     # 308779   (72 %)        ip6route                    # 41414    (10 %)        ipmcroute                   # 0        (0 %)    NPU-2        Total In-Use                # 350206   (81 %)        iproute                     # 308779   (72 %)        ip6route                    # 41414    (10 %)        ipmcroute                   # 0        (0 %)    NPU-3        Total In-Use                # 350206   (81 %)        iproute                     # 308779   (72 %)        ip6route                    # 41414    (10 %)        ipmcroute                   # 0        (0 %)    NPU-4        Total In-Use                # 350206   (81 %)        iproute                     # 308779   (72 %)        ip6route                    # 41414    (10 %)        ipmcroute                   # 0        (0 %)    NPU-5        Total In-Use                # 350206   (81 %)        iproute                     # 308779   (72 %)        ip6route                    # 41414    (10 %)        ipmcroute                   # 0        (0 %) RP/0/RP0/CPU0#NCS5508#Configuration to enable the internet-optimized mode on non-eTCAM line cards#RP/0/RP0/CPU0#NCS5508#sh run | i hw-Building configuration...hw-module fib ipv4 scale internet-optimizedRP/0/RP0/CPU0#NCS5508#Configuration to enable streaming telemetry for the counters used for this video#RP/0/RP0/CPU0#NCS5508#sh run telemetry model-driven    telemetry model-driven     destination-group DGroup1      vrf default      address-family ipv4 192.168.100.141 port 5432   encoding self-describing-gpb   protocol tcp  ! ! sensor-group fib  sensor-path Cisco-IOS-XR-fib-common-oper#fib/nodes/node/protocols/protocol/vrfs/vrf/summary ! sensor-group brcm  sensor-path Cisco-IOS-XR-fretta-bcm-dpa-hw-resources-oper#dpa/stats/nodes/node/hw-resources-datas/hw-resources-data ! sensor-group routing  sensor-path Cisco-IOS-XR-ipv4-bgp-oper#bgp/instances/instance/instance-active/default-vrf/process-info  sensor-path Cisco-IOS-XR-ip-rib-ipv4-oper#rib/vrfs/vrf/afs/af/safs/saf/ip-rib-route-table-names/ip-rib-route-table-name/protocol/bgp/as/information  sensor-path Cisco-IOS-XR-ip-rib-ipv6-oper#ipv6-rib/vrfs/vrf/afs/af/safs/saf/ip-rib-route-table-names/ip-rib-route-table-name/protocol/bgp/as/information ! subscription fib  sensor-group-id fib strict-timer  sensor-group-id fib sample-interval 1000  destination-id DGroup1 ! subscription brcm  sensor-group-id brcm strict-timer  sensor-group-id brcm sample-interval 1000  destination-id DGroup1 ! subscription routing  sensor-group-id routing strict-timer  sensor-group-id routing sample-interval 1000  destination-id DGroup1 !!RP/0/RP0/CPU0#NCS5508#\u201cWet-finger\u201d Internet Growth ProjectionWe take the data graciously provided by Darren\u2019s (https#//twitter.com/mellowdrifter) twitter pages#  https#//twitter.com/bgp4_table  https#//twitter.com/bgp6_table            Date      %/24      %/23      %/22      %/21-/19      %18-16                  15/12/2016      56,1      10      11,7      16,8      5,4              18/01/2017      56,2      10      11,7      16,7      5,4              15/02/2017      56,4      10,1      11,7      16,5      5,3              15/03/2017      56,4      10      11,8      16,4      5,4              12/04/2017      56,5      10      11,8      16,3      5,4              17/05/2017      56,6      10      11,8      16,2      5,3              14/06/2017      56,5      10,1      11,9      16,2      5,3              12/07/2017      56,5      10,1      11,9      16,1      5,3              16/08/2017      56,6      10,1      12      16,1      5,3              13/09/2017      56,7      10,1      12,1      15,9      5,2              10/10/2017      56,6      10,1      12,1      15,9      5,2              15/11/2017      56,6      10,1      12,1      15,9      5,2      Which can be converted in numbers of prefixes per prefix-length#            Date      Total v4      /24      /23      /22      /21-/19      /18-/16                  15/12/2016      638707      358315      63871      74729      107303      34491              18/01/2017      643504      361650      64351      75290      107466      34750              15/02/2017      650916      367117      65743      76158      107402      34499              15/03/2017      652062      367763      65207      76944      106939      35212              12/04/2017      658828      372238      65883      77742      107389      35577              17/05/2017      663357      375461      66336      78277      107464      35158              14/06/2017      666765      376723      67344      79346      108016      35339              12/07/2017      669699      378380      67640      79695      107822      35495              16/08/2017      673374      381130      68011      80805      108414      35689              13/09/2017      677348      384057      68413      81960      107699      35223              10/10/2017      679210      384433      68601      82185      107995      35319              15/11/2017      684059      387178      69090      82772      108766      35572      Same approach for IPv6#            Date      %/48      %/32      %/44      %/40      %/36      %/29                  15/12/2016      46,9      24      4,6      4,8      3,9      4,1              18/01/2017      46,5      23,8      4,6      4,8      3,8      4,2              15/02/2017      45,8      23,6      4,6      5,4      3,6      4,2              15/03/2017      45,5      23,3      4,8      5,4      3,6      4,2              12/04/2017      45,8      22,7      4,7      5,3      3,6      4,2              17/05/2017      45,8      22,8      4,7      5,3      3,6      4,2              14/06/2017      46,2      22,7      4,7      5,3      3,5      4,3              12/07/2017      45,9      22,8      4,8      5,2      3,6      4,3              16/08/2017      46,5      22,1      4,8      5,3      3,6      4,2              13/09/2017      46,6      21,9      4,8      5,2      3,6      4,2              18/10/2017      46,5      22,1      5      5,1      3,6      4,3              15/11/2017      46,3      22,1      5,2      5,3      3,7      4,3                  Date      Total v6      /48      /32      /44      /40      /36      /29      Rest                  15/12/2016      35118      16471      8429      1616      1686      1370      1440      4144              18/01/2017      35970      16727      8561      1655      1727      1367      1511      4425              15/02/2017      36801      16855      8686      1693      1988      1325      1546      4674              15/03/2017      37826      17211      8814      1816      2043      1362      1589      5031              12/04/2017      39152      17932      8888      1841      2076      1410      1645      5403              17/05/2017      40147      18388      9154      1887      2128      1446      1687      5460              14/06/2017      40737      18821      9248      1915      2160      1426      1752      5459              12/07/2017      40860      18755      9317      1962      2125      1471      1757      5517              16/08/2017      42911      19954      9484      2060      2275      1545      1803      5879              13/09/2017      43540      20290      9536      2090      2265      1568      1829      5965              18/10/2017      43389      20176      9589      2170      2213      1563      1866      5771              15/11/2017      44025      20384      9730      2290      2334      1629      1894      5812      Which gives us the following graphs#We can extrapolate the route count in LEM and LPM now.            Year      LEM      LPM                  2017      545742      274488              2018      592543      296045              2019      639344      317602              2020      686145      339159              2021      732946      360717              2022      779747      382274              2023      826548      403832              2024      873349      425389              2025      920150      446947      It\u2019s certainly a very simplistic approach, feel free to provide other sources or your own growth projection in the comments, we will re-do the math with it.", "url": "https://xrdocs.github.io/cloud-scale-networking/tutorials/2017-12-30-full-internet-view-on-base-ncs-5500-systems-s01e04/", "tags": "ncs5500, ncs 5500, demo, video, youtube, lem, lpm, routes, base, prefixes", "title": "Full Internet View on &quot;Base&quot; NCS 5500 Systems (S01E04)", "author": "Nicolas Fevrier"}, "tutorials-2016-09-28-solenoid-inject-routes-into-cisco-s-rib-table-using-grpc": {"content": "     On This Page  Introduction          How Solenoid Works        Pre-requisites  Understand the Topology  Clone the git repo  Spin up the Ubuntu devbox  Create Solenoid LXC tarball          Install Application dependencies inside LXC      Fetch the Application code from github      Configure Solenoid and exaBGP      Change the SSH port inside the container      Package up the LXC        Launch router topology  Test out Solenoid          Solenoid GUI      Solenoid on the Backend        IntroductionIf you haven\u2019t checked out the XR toolbox Series, then you can do so here#XR Toolbox SeriesThis series is meant to help a beginner get started with application-hosting on IOS-XR.In this tutorial we intend to utilize almost all the techniques learned in the above series to inject third-party BGP routes into Cisco\u2019s RIB table.How Solenoid WorksThis tutorial focuses on hosting the Solenoid application on IOS-XR, but following is a brief description of how Solenoid works.For the demos Solenoid uses exaBGP as a third-party BGP software. exaBGP will be running on an Ubuntu vagrant box as well as in a third-party container on the IOS-XR (see Understand the Topology for more information). The two boxes form a BGP neighbor relationship.When exaBGP in the IOS-XR container hears a neighborhood update (either an announcement of a new route or a withdrawal of an old route), Solenoid works as the glue between exaBGP and the Cisco RIB table. Solenoid hears the exaBGP update, and pulls out the relevant data from the exaBGP udate and models it using the Cisco YANG model for static routes. Then it uses gRPC to send the data to the RIB table.Pre-requisitesMake sure you have Vagrant and Virtualbox installed on your system.The system must have  4.5GB of space available. The topology includes an IOS-XRv router (3.5G RAM) and an Ubuntu instance (501MB RAM).Go through the Vagrant quick-start tutorial, if you haven\u2019t already, to learn how to use Vagrant with IOS-XR# IOS-XR vagrant quick-startIt would be beneficial for the user to go through the XR Toolbox Series. But it is not a hard requirement. Following the steps in this tutorial should work out just fine for this demo.Once you have everything set up, you should be able to see the IOS-XRv vagrant box in the vagrant box list command#lisroach@LISROACH-M-J0AY ~/W/X/S/vagrant&gt; vagrant box listIOS XRv         (virtualbox, 0)Understand the Topology      devbox# The Ubuntu Vagrant box on the right. This is running exaBGP and is peered with the xrv router to its left. exaBGP is sending out 3 BGP neighbor announcements and withdrawals about every 2 seconds.        xrv# The router on the left. This router is running a gRPC server, and is not running any version of Cisco\u2019s BGP. It has an Ubuntu LXC as it\u2019s third-party container instead, which is running exaBGP and the Solenoid application.        solenoid container# The Ubuntu LXC that is running on the xrv. exaBGP is peered with the devbox and hears all of its neighbor\u2019s announcements and withdrawals. Upon receiving a neighborhood update, exaBGP runs Solenoid, which uses a gRPC client and YANG models to send the new route (or withdrawn route) to the RIB table in the IOS-XR.  Clone the git repoThe entire environment can be replicated on any environment running vagrant, provided there is at least 4.5GB of space available.Clone the Solenoid code from here# https#//github.com/ios-xr/Solenoid.gitlisroach@LISROACH-M-J0AY ~/Workspace&gt; git clone https#//github.com/ios-xr/Solenoid.gitCloning into 'Solenoid'...remote# Counting objects# 1539, done.remote# Compressing objects# 100% (623/623), done.remote# Total 1539 (delta 884), reused 1508 (delta 866), pack-reused 0Receiving objects# 100% (1539/1539), 713.76 KiB | 317.00 KiB/s, done.Resolving deltas# 100% (884/884), done.Checking connectivity... done.lisroach@LISROACH-M-J0AY ~/Workspace&gt;Spin up the Ubuntu devboxBefore we spin up the routers, we can create the container tarball for the Solenoid code. The way the launch scripts are setup for xrv, you can launch the vagrant boxes without creating a new Solenoid tarball (since one with the latest release will be downloaded for you automatically). But if you interested in the absolute latest code, or are interested in the process for your own education, follow the steps below to create your own Solenoid tarball. If you are not interested, skip to Launch router topology.Move into the vagrant directory and launch only the devbox node#lisroach@LISROACH-M-J0AY ~/Workspace&gt; cd Solenoid/vagrantlisroach@LISROACH-M-J0AY ~/W/S/vagrant&gt; vagrant up devboxexaBGP is already installed and running on your devbox. If you want to see it running, you can jump into the exabgp screen.vagrant@vagrant-ubuntu-trusty-64#~$ sudo screen -lsThere is a screen on#       \t1762.exabgp    \t(09/27/2016 10#43#34 PM)       \t(Detached)1 Socket in /var/run/screen/S-root.vagrant@vagrant-ubuntu-trusty-64#~$ sudo screen -r exabgpTue, 27 Sep 2016 23#43#25 | INFO     | 1764   | processes     | Command from process add-routes # announce route 2.2.2.0/24 next-hop selfTue, 27 Sep 2016 23#43#25 | INFO     | 1764   | reactor       | Route added to neighbor 11.1.1.10 local-ip 11.1.1.20 local-as 65000 peer-as 65000 router-id 11.1.1.20 family-allowed in-open # 2.2.2.0/24 next-hop 11.1.1.20To detach from the screen, do the following#CTRL+a, dYou do not want to kill the process in the screen or destroy the screen, so be sure you detach properly. You will see the following output#vagrant@vagrant-ubuntu-trusty-64#~$ sudo screen -r exabgp[detached from 1762.exabgp]Create Solenoid LXC tarballEnter the devbox#lisroach@LISROACH-M-J0AY ~/W/S/vagrant&gt; vagrant ssh devboxWelcome to Ubuntu 14.04.4 LTS (GNU/Linux 3.13.0-92-generic x86_64) * Documentation#  https#//help.ubuntu.com/  System information as of Tue Sep 27 23#20#46 UTC 2016  System load#  0.06              Users logged in#       0  Usage of /#   5.4% of 39.34GB   IP address for eth0#   10.0.2.15  Memory usage# 36%               IP address for eth1#   11.1.1.20  Swap usage#   0%                IP address for lxcbr0# 10.0.3.1  Processes#    80  Graph this data and manage this system at#    https#//landscape.canonical.com/  Get cloud support with Ubuntu Advantage Cloud Guest#    http#//www.ubuntu.com/business/services/cloudNew release '16.04.1 LTS' available.Run 'do-release-upgrade' to upgrade to it.Last login# Tue Sep 27 23#20#46 2016 from 10.0.2.2vagrant@vagrant-ubuntu-trusty-64#~$Install LXC#vagrant@vagrant-ubuntu-trusty-64#~$ sudo apt-get updatevagrant@vagrant-ubuntu-trusty-64#~$ sudo apt -y install lxcCreate the Solenoid LXC template#vagrant@vagrant-ubuntu-trusty-64#~$ sudo lxc-create -t ubuntu --name solenoid\t Start the container. You will be dropped into the console once boot is complete.vagrant@vagrant-ubuntu-trusty-64#~$ sudo lxc-start --name solenoidsolenoid login# init# setvtrgb main process (428) terminated with status 1init# plymouth-upstart-bridge main process ended, respawningubuntuPassword#Username# ubuntuPassword# ubuntuInstall Application dependencies inside LXCInstall Solenoid, exaBGP and all of their dependencies inside the container. Initiate the following commands#ubuntu@solenoid#~$ sudo apt-get -y install git curl screen python-dev python-setuptools[sudo] password for ubuntu# ubuntuubuntu@solenoid#~$ sudo easy_install pipubuntu@solenoid#~$ sudo pip install virtualenv exabgpThese dependencies make it possible for us to install the important components of our applications.Fetch the Application code from githubNow, download Solenoid from github. Using the Solenoid directory, we can install most of the remaining dependencies with the setup.py installation script.ubuntu@solenoid#~$ git clone https#//github.com/ios-xr/Solenoid.gitLet\u2019s install the dependencies in a virtualenv. First, navigate into the Solenoid directory and activate the virtualenv.ubuntu@solenoid#~$ cd Solenoidubuntu@solenoid#~$ virtualenv venvubuntu@solenoid#~$ source venv/bin/activateThe (venv) indicates that you have entered your virtualenv. Now you can install the dependencies, and they will only be available in your virtualenv. This means you will have to activate your virtualenv in order to run Solenoid.(venv) ubuntu@solenoid#~$ pip install grpcio(venv) ubuntu@solenoid#~$ python setup.py install Perfect! Now all of our dependencies have been installed.Configure Solenoid and exaBGPSolenoid requires a configuration file to indicate some important metadata. Create a file named solenoid.config with the following data (in the Solenoid/ top-level directory)#[default]\t# Name you choose for the nodetransport# gRPC    # Either gRPC or RESTconfip# 11.1.1.10      # IP address of the destination RIB table (the XR device you intend to control)port# 57777 \t   # Depends on what is configured for your gRPC or RESTconf serversusername# vagrant  # Username for the XR devicepassword# vagrant  # Password for the XR deviceThat is all we need to configure Solenoid for your system. Now we need to add a configuration file for exaBGP. Navigate to your home directory, and add a file named router.ini#group demo {        router-id 11.1.1.10;        process monitor-neighbors {            encoder json;            receive {                parsed;                updates;                neighbor-changes;            }            run /usr/bin/env python /home/ubuntu/Solenoid/solenoid/edit_rib.py -f '/home/ubuntu/Solenoid/filter.txt';        }        neighbor 11.1.1.20 {                local-address 11.1.1.10;                local-as 65000;                peer-as 65000;        }}The most important part of this code is#run /usr/bin/env python /home/ubuntu/Solenoid/solenoid/edit_rib.py -f '/home/ubuntu/Solenoid/filter.txt';This line runs a custom script. The /usr/bin/env python is the path to your python instance. Specifically, it is the path to the first python instance in your PATH, which is important because we are using a virtualenv where the python path might be different than the normal /usr/bin/python./home/ubuntu/Solenoid/solenoid/edit_rib.py is the path to the file that launches Solenoid.The second half of the line, -f '/home/ubuntu/Solenoid/filter.txt' is an optional file argument pointing to the file used for filtering .For more information about the router.ini file, please consult Solenoid\u2019s Wiki and review exaBGP\u2019s documentation.Change the SSH port inside the containerWhen we deploy the container to IOS-XR, we will share XR\u2019s network namespace. Since IOS-XR already uses up port 22 and port 57722 for its own purposes, we need to pick some other port for our container.P.S. If you check the Vagrantfile, we intend to expose port 58822 to the user\u2019s laptop directly, on IOS-XRv.Let\u2019s change the SSH port to 58822#(venv) ubuntu@solenoid#~$ sudo sed -i s/Port\\ 22/Port\\ 58822/ /etc/ssh/sshd_configCheck that your port was updated successfully#(venv) ubuntu@solenoid#~$ cat /etc/ssh/sshd_config | grep PortPort 58822We\u2019re good!Package up the LXCShutdown the container#(venv) ubuntu@solenoid#~$ sudo shutdown -h now(venv) ubuntu@solenoid#~$Broadcast message from ubuntu@solenoid       \t(/dev/lxc/console) at 23#00 ...The system is going down for halt NOW!init# tty4 main process (369) killed by TERM signalinit# tty2 main process (372) killed by TERM signalinit# tty3 main process (373) killed by TERM signalinit# cron main process (383) killed by TERM signal...You\u2019re back on the devbox.Become root and package up your tarball#vagrant@vagrant-ubuntu-trusty-64#~$ sudo -sroot@vagrant-ubuntu-trusty-64#~# cd /var/lib/lxc/solenoid/rootfs/root@vagrant-ubuntu-trusty-64#~# tar -czvf /vagrant/solenoid.tgz *See what we did there? We packaged up the container tarball as solenoid.tgz under /vagrant directory. Why is this important?Well, Vagrant also automatically shares a certain directory with your laptop (for most types of guest operating systems). So the /vagrant is automatically mapped to the directory in which you launched your vagrant instance. To check this, let\u2019s get out of our vagrant instance and issue an ls in your launch directory#root@vagrant-ubuntu-trusty-64#~# exitexitvagrant@vagrant-ubuntu-trusty-64#~$ exitlogoutConnection to 127.0.0.1 closed.lisroach@LISROACH-M-J0AY ~/W/S/vagrant&gt; pwd/Users/lisroach/Workspace/Solenoid/vagrantlisroach@LISROACH-M-J0AY ~/W/S/vagrant&gt; ls -la solenoid.tgz-rw-r--r--  1 lisroach  staff  252417007 Aug 2 11#27 solenoid.tgz&gt;Now you have your solenoid tarball! This will be used to launch the container on your IOS-XRv. If you did not create this tarball, the Vagrantfile is smart enough to grab the container from the internet.Launch router topologyLaunching the router topology is incredibly simple. Just do a vagrant up in the Solenoid/vagrant/ directory.lisroach@LISROACH-M-J0AY ~/W/S/vagrant&gt; pwd/Users/lisroach/Workspace/Solenoid/vagrantlisroach@LISROACH-M-J0AY ~/W/S/vagrant&gt; vagrant upBringing machine 'xrv' up with 'virtualbox' provider...Bringing machine 'devbox' up with 'virtualbox' provider...==&gt; xrv# Importing base box 'IOS XRv'...It will take a few minutes, and you will see a number of ugly looking messages like these#==&gt; xrv# tar# dev/audio2# Cannot mknod# Operation not permitted==&gt; xrv# tar# dev/sequencer# Cannot mknod# Operation not permitted==&gt; xrv# tar# dev/midi3# Cannot mknod# Operation not permitted==&gt; xrv# tar# dev/mixer3# Cannot mknod# Operation not permitted==&gt; xrv# tar# dev/smpte3# Cannot mknod# Operation not permitted==&gt; xrv# tar# dev/mpu401data# Cannot mknod# Operation not permittedBut don\u2019t worry, your vagrant boxes are working perfectly. Once you see the following message you will know you are done#==&gt; xrv# Machine 'xrv' has a post `vagrant up` message. This is a message==&gt; xrv# from the creator of the Vagrantfile, and not from Vagrant itself#==&gt; xrv#==&gt; xrv#==&gt; xrv#     Welcome to the IOS XRv (64-bit) VirtualBox....You can also check the status of your vagrant boxes#lisroach@LISROACH-M-J0AY ~/W/S/vagrant&gt; vagrant statusCurrent machine states#xrv                       running (virtualbox)devbox                    running (virtualbox)This environment represents multiple VMs. The VMs are all listedabove with their current state. For more information about a specificVM, run `vagrant status NAME`.Great! Time to start playing with Solenoid.Test out SolenoidSolenoid GUIAfter completing the initial vagrant up, the application is already up and running. In your browser, navigate to#localhost#57780Here you will see the routes being added and withdrawn from the IOS-XRv\u2019s RIB table.These routes are the routes that are being automatically sent and withdrawn from the exaBGP instance running in your devbox.Currently there is no filtering enabled, but feel free to add prefixes or prefix ranges to the filtering file. This file acts as a whitelist, so by adding a prefix or prefix range, all other prefixes will be dropped. For example, add the prefix range 1.1.1.0/24-2.2.2.0/24 to the filtering. Now watch as the 3.3.3.0/24 network never gets added to the RIB table, because it has been filtered out.To view the application running on the box, reference the instructions below on how to navigate the vagrant environment.Solenoid on the BackendLet\u2019s see what Solenoid looks like on the box. First we\u2019ll check our RIB table on the xrv. In order to do this, we need to SSH into the xrv. First, find out the port that has been forwarded for port 22. Then ssh into that port, and you will find yourself in the CLI. From there, view your RIB table.Password# vagrantlisroach@LISROACH-M-J0AY ~/W/S/vagrant&gt; vagrant port xrvThe forwarded ports for the machine are listed below. Please note thatthese values may differ from values configured in the Vagrantfile if theprovider supports automatic port collision detection and resolution.22 (guest) =&gt; 2223 (host) 57722 (guest) =&gt; 2222 (host) 57780 (guest) =&gt; 57780 (host) 58822 (guest) =&gt; 58822 (host) (venv) lisroach@LISROACH-M-J0AY ~/W/S/vagrant&gt; ssh -p 2223 vagrant@localhostvagrant@localhost's password#RP/0/RP0/CPU0#ios#RP/0/RP0/CPU0#ios#show ip routeWed Sep 28 18#33#18.266 UTCCodes# C - connected, S - static, R - RIP, B - BGP, (&gt;) - Diversion path       D - EIGRP, EX - EIGRP external, O - OSPF, IA - OSPF inter area       N1 - OSPF NSSA external type 1, N2 - OSPF NSSA external type 2       E1 - OSPF external type 1, E2 - OSPF external type 2, E - EGP       i - ISIS, L1 - IS-IS level-1, L2 - IS-IS level-2       ia - IS-IS inter area, su - IS-IS summary null, * - candidate default       U - per-user static route, o - ODR, L - local, G  - DAGR, l - LISP       A - access/subscriber, a - Application route       M - mobile route, r - RPL, (!) - FRR Backup pathGateway of last resort is 10.0.2.2 to network 0.0.0.0S*   0.0.0.0/0 [1/0] via 10.0.2.2, 01#01#34C    10.0.2.0/24 is directly connected, 01#03#27, MgmtEth0/RP0/CPU0/0L    10.0.2.15/32 is directly connected, 01#03#27, MgmtEth0/RP0/CPU0/0L    10.1.1.5/32 is directly connected, 01#01#34, Loopback1C    11.1.1.0/24 is directly connected, 01#01#34, GigabitEthernet0/0/0/0L    11.1.1.10/32 is directly connected, 01#01#34, GigabitEthernet0/0/0/0RP/0/RP0/CPU0#ios#We can see here there are currently no static routes except for 0.0.0.0/0. You may see some routes other than this, as Solenoid is running and adding routes constantly to the RIB.Now leave this screen up, open a new tab in your terminal and jump into the Solenoid container. Remember when we changed the ssh port of the container? Now we will use that port to SSH directly from our CLI into the Solenoid container.Password # ubuntulisroach@LISROACH-M-J0AY ~/W/S/vagrant&gt; vagrant port xrvThe forwarded ports for the machine are listed below. Please note thatthese values may differ from values configured in the Vagrantfile if theprovider supports automatic port collision detection and resolution. 22 (guest) =&gt; 2223 (host) 57722 (guest) =&gt; 2222 (host) 57780 (guest) =&gt; 57780 (host) 58822 (guest) =&gt; 58822 (host)lisroach@LISROACH-M-J0AY ~/W/S/vagrant&gt; ssh -p 58822 ubuntu@localhost The authenticity of host '[localhost]#58822 ([127.0.0.1]#58822)' can't be established.ECDSA key fingerprint is SHA256#Swie3V2VIYDNCACaRLbSjQa7417yIM6hpbeimNwZr1o.Are you sure you want to continue connecting (yes/no)? yesWarning# Permanently added '[localhost]#58822' (ECDSA) to the list of known hosts.ubuntu@localhost's password#Welcome to Ubuntu 14.04.5 LTS (GNU/Linux 3.14.23-WR7.0.0.2_standard x86_64) * Documentation#  https#//help.ubuntu.com/Last login# Thu Sep 22 21#31#13 2016We are now on the Solenoid container that is running on the xrv. Solenoid is currently running in a screen named exaBGP. Resume the screen to see Solenoid running.ubuntu@solenoid#~$ubuntu@solenoid#~$ screen -lsThere are screens on#       \t1423.website   \t(09/28/2016 05#38#22 PM)       \t(Detached)       \t1421.exabgp    \t(09/28/2016 05#38#22 PM)       \t(Detached)2 Sockets in /var/run/screen/S-ubuntu.ubuntu@solenoid#~$ubuntu@solenoid#~$ screen -r exabgpWed, 28 Sep 2016 18#35#04 | INFO     | 1436   | solenoid      | WITHDRAW | OKWed, 28 Sep 2016 18#35#06 | INFO     | 1436   | solenoid      | WITHDRAW | OKWed, 28 Sep 2016 18#35#11 | INFO     | 1436   | solenoid      | ANNOUNCE | OKWed, 28 Sep 2016 18#35#13 | INFO     | 1436   | solenoid      | ANNOUNCE | OKWed, 28 Sep 2016 18#35#17 | INFO     | 1436   | solenoid      | WITHDRAW | OKWed, 28 Sep 2016 18#35#19 | INFO     | 1436   | solenoid      | WITHDRAW | OKWed, 28 Sep 2016 18#35#25 | INFO     | 1436   | solenoid      | ANNOUNCE | OKWed, 28 Sep 2016 18#35#27 | INFO     | 1436   | solenoid      | ANNOUNCE | OKWed, 28 Sep 2016 18#35#37 | INFO     | 1436   | solenoid      | WITHDRAW | OKWed, 28 Sep 2016 18#35#37 | INFO     | 1436   | solenoid      | WITHDRAW | OKWed, 28 Sep 2016 18#35#38 | INFO     | 1436   | solenoid      | ANNOUNCE | OKWed, 28 Sep 2016 18#35#40 | INFO     | 1436   | solenoid      | ANNOUNCE | OKWed, 28 Sep 2016 18#35#44 | INFO     | 1436   | solenoid      | WITHDRAW | OKWed, 28 Sep 2016 18#35#46 | INFO     | 1436   | solenoid      | WITHDRAW | OKThese messages show the output of Solenoid running. All of the OKs show us that it is running properly. If you hop back to your tab running the CLI and run show ip route a few times, you will see the RIB table changing with the messages that Solenoid is sending.RP/0/RP0/CPU0#ios#show ip routeWed Sep 28 18#49#22.165 UTCCodes# C - connected, S - static, R - RIP, B - BGP, (&gt;) - Diversion path       D - EIGRP, EX - EIGRP external, O - OSPF, IA - OSPF inter area       N1 - OSPF NSSA external type 1, N2 - OSPF NSSA external type 2       E1 - OSPF external type 1, E2 - OSPF external type 2, E - EGP       i - ISIS, L1 - IS-IS level-1, L2 - IS-IS level-2       ia - IS-IS inter area, su - IS-IS summary null, * - candidate default       U - per-user static route, o - ODR, L - local, G  - DAGR, l - LISP       A - access/subscriber, a - Application route       M - mobile route, r - RPL, (!) - FRR Backup pathGateway of last resort is 10.0.2.2 to network 0.0.0.0S*   0.0.0.0/0 [1/0] via 10.0.2.2, 01#17#38S    1.1.1.0/24 [1/0] via 11.1.1.20, 00#00#00C    10.0.2.0/24 is directly connected, 01#19#31, MgmtEth0/RP0/CPU0/0L    10.0.2.15/32 is directly connected, 01#19#31, MgmtEth0/RP0/CPU0/0L    10.1.1.5/32 is directly connected, 01#17#38, Loopback1C    11.1.1.0/24 is directly connected, 01#17#38, GigabitEthernet0/0/0/0L    11.1.1.10/32 is directly connected, 01#17#38, GigabitEthernet0/0/0/0RP/0/RP0/CPU0#ios#show ip routeWed Sep 28 18#49#25.660 UTCCodes# C - connected, S - static, R - RIP, B - BGP, (&gt;) - Diversion path       D - EIGRP, EX - EIGRP external, O - OSPF, IA - OSPF inter area       N1 - OSPF NSSA external type 1, N2 - OSPF NSSA external type 2       E1 - OSPF external type 1, E2 - OSPF external type 2, E - EGP       i - ISIS, L1 - IS-IS level-1, L2 - IS-IS level-2       ia - IS-IS inter area, su - IS-IS summary null, * - candidate default       U - per-user static route, o - ODR, L - local, G  - DAGR, l - LISP       A - access/subscriber, a - Application route       M - mobile route, r - RPL, (!) - FRR Backup pathGateway of last resort is 10.0.2.2 to network 0.0.0.0S*   0.0.0.0/0 [1/0] via 10.0.2.2, 01#17#42S    1.1.1.0/24 [1/0] via 11.1.1.20, 00#00#03S    2.2.2.0/24 [1/0] via 11.1.1.20, 00#00#01C    10.0.2.0/24 is directly connected, 01#19#35, MgmtEth0/RP0/CPU0/0L    10.0.2.15/32 is directly connected, 01#19#35, MgmtEth0/RP0/CPU0/0L    10.1.1.5/32 is directly connected, 01#17#42, Loopback1C    11.1.1.0/24 is directly connected, 01#17#42, GigabitEthernet0/0/0/0L    11.1.1.10/32 is directly connected, 01#17#42, GigabitEthernet0/0/0/0RP/0/RP0/CPU0#ios#From this example you can see that we first added 1.1.1.0/24, then in a moment 2.2.2.0/24 was added. 3.3.3.0/24 will never be added, since we added the filtering on the GUI.Hopfully this tutorial was helpful! If you have issues or questions running Solenoid, please visit Solenoid\u2019s Issues page and submit your question.", "url": "https://xrdocs.github.io/application-hosting/tutorials/2016-09-28-solenoid-inject-routes-into-cisco-s-rib-table-using-grpc/", "tags": "vagrant, iosxr", "title": "Solenoid: inject routes into Cisco's RIB table using gRPC", "author": "Lisa Roach"}, "tutorials-iosxr-vagrant-quickstart": {"content": "     IOS-XR Vagrant# Quick Start  Introduction  Pre-requisites#  Single Node Bringup          Download and Add the IOS-XRv vagrant box      Pick the last stable version      Pick the latest (run with scissors)      Initialize a Vagrantfile      Bring up the Vagrant Instance      Access the XR Linux shell      Access XR Console        Multi Node Bringup          Set up the Vagrantfile      Bring up the topology      Access the nodes        IntroductionThis tutorial is meant to be a quick-start guide to get you up and running with an IOS-XRv Vagrant box.If you\u2019re unfamiliar with Vagrant as a tool for development, testing and design, then here\u2019s a quick look at why Vagrant is useful, directly from the folks at Hashicorp#  https#//www.vagrantup.com/intro/index.html  To learn more about how to use IOS-XR + Vagrant to      Test native and container applications on IOS-XR    Use configuration management tools like Chef/Puppet/Ansible/Shell as Vagrant provisioners    Create complicated topologies and a variety of other use cases,    take a look at the rest of the \u201cXR toolbox\u201d series.Pre-requisites#  Vagrant for your Operating System. 1.8+There is currently a bug in vagrant version 1.8.7 causing a failure in vagrant box add on Mac OSX. Either follow the workaround as specified here# https#//github.com/mitchellh/vagrant/issues/7997 or downgrade to Vagrant version 1.8.6  Virtualbox for your Operating System. 5.1+  A laptop with atleast 4-5G free RAM. (Each XR vagrant instance uses upto 4G RAM, so plan ahead based on the number of XR nodes you want to run)Tha above items are applicable to all operating systems - Mac OSX, Linux or Windows.If you\u2019re using Windows, we would urge you to download a utility like Git Bash so that all the commands provided below work as advertised.Single Node BringupDownload and Add the IOS-XRv vagrant box  IOS-XR Vagrant is currently in Private Beta  To download the box, you will need an API-KEY and a CCO-ID  To get the API-KEY and a CCO-ID, browse to the following link and follow the steps#  Steps to Generate API-KEYPick the last stable versionThe last stable version of XR vagrant was 6.1.2.These images have been out for a while, and should work well. Pick this if you want something that works for sure.$ BOXURL=~https#//devhub.cisco.com/artifactory/appdevci-release/XRv64/6.1.2/iosxrv-fullk9-x64.box~$ curl -u your-cco-id#API-KEY $BOXURL --output ~/iosxrv-fullk9-x64.box$ vagrant box add --name IOS-XRv ~/iosxrv-fullk9-x64.boxPick the latest (run with scissors)If you\u2019re feeling adventurous, pick the latest version of the XR vagrant box as shown below.Bear in mind, there may be bugs and you are free to ask us questions and/or raise issues on our github repo#  https#//github.com/xrdocs/application-hosting/issues$ BOXURL=~https#//devhub.cisco.com/artifactory/XRv64-snapshot/latest/iosxrv-fullk9-x64.latest.box~$ curl -u your-cco-id#API-KEY $BOXURL --output ~/iosxrv-fullk9-x64.box$ vagrant box add --name IOS-XRv ~/iosxrv-fullk9-x64.boxOf course, you should replace  your-cco-id with your actual Cisco.com ID and API-KEY with the key you generated and copied using the above link.The curl command will take around 10-15 mins as it downloads the box for you. If it happens pretty quickly then it probably means you still don\u2019t have access and you can check the downloaded box file to see if it is a vagrant box (about 1.8G) or a simple \u201cunauthorized\u201d html document.Once it completes, you should be able to see the box added as \u201cIOS-XRv\u201d in your local vagrant box list#AKSHSHAR-M-K0DS#~ akshshar$ vagrant box listIOS-XRv (virtualbox, 0)AKSHSHAR-M-K0DS#~ akshshar$ Initialize a VagrantfileLet\u2019s create a working directory (any name would do) for our next set of tasks#mkdir ~/iosxrv; cd ~/iosxrvNow, in this directory, let\u2019s initialize a Vagrantfile with the name of the box we added.AKSHSHAR-M-K0DS#iosxrv akshshar$ vagrant init IOS-XRv A `Vagrantfile` has been placed in this directory. You are nowready to `vagrant up` your first virtual environment! Please readthe comments in the Vagrantfile as well as documentation on`vagrantup.com` for more information on using Vagrant.AKSHSHAR-M-K0DS#iosxrv akshshar$Bring up the Vagrant InstanceA simple vagrant up will bring up the XR instancevagrant up This bootup process will take some time, (close to 5 minutes).You might see some ` Warning# Remote connection disconnect. Retrying\u2026` messages. Ignore them. These messages appear because the box takes longer than a normal linux machine to boot.Look for the green \u201cvagrant up\u201d welcome message to confirm the machine has booted#Now we have two options to access the Vagrant instance#Access the XR Linux shellVagrant takes care of key exchange automatically. We\u2019ve set things up to make sure that the XR linux shell (running SSH on port 57722) is the environment a user gets dropped into when using vagrant sshAKSHSHAR-M-K0DS#simple-mixed-topo akshshar$ vagrant ssh xr-vm_node0_RP0_CPU0#~$ xr-vm_node0_RP0_CPU0#~$ xr-vm_node0_RP0_CPU0#~$ The reason we select the XR linux shell as the default environment and not XR CLI, should be obvious to seasoned users of Vagrant. In the future,Vagrantfiles that integrate chef/puppet/Ansible/Shell as Vagrant provisioners would benefit from linux as the default environment.Access XR ConsoleXR SSH runs on port 22 of the guest IOS-XR instance.First, determine the port to which the XR SSH port (port 22) is forwarded by vagrant by using the vagrant port command#AKSHSHAR-M-K0DS#simple-mixed-topo akshshar$  vagrant port The forwarded ports for the machine are listed below. Please note thatthese values may differ from values configured in the Vagrantfile if theprovider supports automatic port collision detection and resolution.    22 (guest) =&gt; 2223 (host)  57722 (guest) =&gt; 2222 (host)As shown above, port 22 of XR is fowarded to port 2223#Use port 2223 to now ssh into XR CLIThe password is \u201cvagrant\u201dAKSHSHAR-M-K0DS#simple-mixed-topo akshshar$ ssh -p 2223 vagrant@localhostThe authenticity of host '[localhost]#2223 ([127.0.0.1]#2223)' can't be established.RSA key fingerprint is 65#d1#b8#f6#68#9c#04#a2#d5#db#17#d8#de#04#cb#22.Are you sure you want to continue connecting (yes/no)? yesWarning# Permanently added '[localhost]#2223' (RSA) to the list of known hosts.vagrant@localhost's password# RP/0/RP0/CPU0#ios#RP/0/RP0/CPU0#ios#RP/0/RP0/CPU0#ios#Multi Node BringupBear in mind the RAM and CPU resource requirements per IOS-XR vagrant instance before you proceed with this section. A 3 node topology as shown below will require 8-9G RAM and can be shared on a 4-core CPU with your laptop\u2019s OS.Let\u2019s try to bring up a multi-node topology as shown below#Set up the VagrantfileFor this purpose, Let\u2019s use a Sample vagrantfile located here#https#//github.com/ios-xr/vagrant-xrdocs/blob/master/simple-mixed-topo/Vagrantfilegit clone https#//github.com/ios-xr/vagrant-xrdocs.gitcd vagrant-xrdocs/simple-mixed-topoShown below is a snippet of the Vagrantfile#Vagrant.configure(2) do |config|    config.vm.define ~rtr1~ do |node|      node.vm.box =  ~IOS-XRv~      # gig0/0/0/0 connected to link2,       # gig0/0/0/1 connected to link1,       # gig0/0/0/2 connected to link3,      # auto-config not supported.      node.vm.network #private_network, virtualbox__intnet# ~link2~, auto_config# false      node.vm.network #private_network, virtualbox__intnet# ~link1~, auto_config# false      node.vm.network #private_network, virtualbox__intnet# ~link3~, auto_config# false     end    config.vm.define ~rtr2~ do |node|      node.vm.box =  ~IOS-XRv~      # gig0/0/0/0 connected to link1,      # gig0/0/0/1 connected to link3,       # auto-config not supported      node.vm.network #private_network, virtualbox__intnet# ~link1~, auto_config# false      node.vm.network #private_network, virtualbox__intnet# ~link3~, auto_config# false    endIf you compare this with the topology above it becomes pretty clear how the interfaces of the XR instances are mapped to individual links.The order of the \u201cprivate_networks\u201d is important.For each XR node, the first \u201cprivate_network\u201d corresponds to gig0/0/0/0, the second \u201cprivate_network\u201d to gig0/0/0/1 and so on.Bring up the topologyAs before, we\u2019ll issue a vagrant up to bring up the topology.vagrant upThis will take some time, possibly over 10 minutes.Look for the green \u201cvagrant up\u201d welcome message to confirm the three machines have booted#Access the nodesThe only point to remember is that in a multinode setup, we \u201cname\u201d each node in the topology.For example, let\u2019s access \u201crtr2\u201d  Access the XR Linux shell#AKSHSHAR-M-K0DS#simple-mixed-topo akshshar$ vagrant ssh rtr2 Last login# Tue May 31 05#43#44 2016 from 10.0.2.2xr-vm_node0_RP0_CPU0#~$ xr-vm_node0_RP0_CPU0#~$   Access XR Console#Determine the forwarded port for port 22 (XR SSH) for rtr2#AKSHSHAR-M-K0DS#simple-mixed-topo akshshar$ vagrant port rtr2 The forwarded ports for the machine are listed below. Please note thatthese values may differ from values configured in the Vagrantfile if theprovider supports automatic port collision detection and resolution.    22 (guest) =&gt; 2201 (host) 57722 (guest) =&gt; 2200 (host)AKSHSHAR-M-K0DS#simple-mixed-topo akshshar$ For rtr2 port 22, the forwarded port is 2201. So, to get into the XR CLI of rtr2, we use#AKSHSHAR-M-K0DS#simple-mixed-topo akshshar$ ssh -p 2201 vagrant@localhost The authenticity of host '[localhost]#2201 ([127.0.0.1]#2201)' can't be established.RSA key fingerprint is 65#d1#b8#f6#68#9c#04#a2#d5#db#17#d8#de#04#cb#22.Are you sure you want to continue connecting (yes/no)? yesWarning# Permanently added '[localhost]#2201' (RSA) to the list of known hosts.vagrant@localhost's password# RP/0/RP0/CPU0#ios#RP/0/RP0/CPU0#ios#That\u2019s it for the quick-start guide on XR vagrant. Launch your very own XR instance using vagrant and let us know your feedback in the comments below!Head over to Part 2 of the XR Toolbox series where we look at bootstrapping a Vagrant XR instance with a user-defined configuration on boot \u2014&gt; Bootstrap XR configuration with Vagrant.", "url": "https://xrdocs.github.io/application-hosting/tutorials/iosxr-vagrant-quickstart", "tags": "vagrant, iosxr, cisco, xr toolbox, apphosting", "title": "XR toolbox, Part 1 : IOS-XR Vagrant Quick Start", "author": "Akshat Sharma"}, "blogs-2017-08-07-multithreading-in-mdt": {"content": "     On This Page  Collections  A big \u201cbag\u201d of data  A big and a small \u201cbag\u201d  Share the workload  Conclusion  CollectionsHave you ever thought what \u201csample-interval\u201d really means? And why is it so important to really understand its operation and properly design your telemetry configuration?In this paper, I will explain how collections work internally. The overall process can be divided into three major parts#  Messaging to a router  Internal operations within MDT process  Collecting data from a requested sensor path (and sending back to a collector)It is not very important for our topic whether you have dial-in or dial-out mode configured on your router, so let\u2019s consider a case with dial-in.At the beginning of the session, our router will get a gRPC request message. The configured sample-interval timer starts and an internal MDT process (aka EMSd or Extensible Manageability Services) starts its operations. EMSd requests the information from an internal data source. The built-in efficiency of the IOS XR architecture means that collection time usually takes tens of milliseconds. After the collection is done, information is sent back to EMSd for fast encoding and transport.For a better understanding, take a look into this schema#As soon as a new sample interval starts, MDT sends a new request to the operational data storage and the system follows steps described above.You can check collection time with the following show command (or in the Cisco-IOS-XR-telemetry-model-driven-oper.yang YANG model)#RP/0/RP0/CPU0#ios#sh telemetry model-driven subscription 1Sat Jul 22 21#04#22.527 UTCSubscription#  1-------------&lt;&lt;&lt; skipped &gt;&gt;&gt;  Collection Groups#  ------------------    Id# 1    Sample Interval#      5000 ms    Encoding#             self-describing-gpb    Num of collection#    6    Collection time#      Min#    16 ms Max#    17 ms    Total time#           Min#    16 ms Avg#    17 ms Max#    18 ms    Total Deferred#       0    Total Send Errors#    0    Total Send Drops#     0    Total Other Errors#   0    Last Collection Start#2017-07-22 21#04#18.1396342587 +0000    Last Collection End#  2017-07-22 21#04#18.1396360587 +0000    Sensor Path#          Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-countersIn the output above, I\u2019ve highlighted the Total time (collection + MDT encoding) and a sample interval values.  This tells you how much time is needed to collect and encode all the data in a given sensor-path. Information is provided for each sensor-path you have configured.A big \u201cbag\u201d of dataSo far so good# we have a well-defined collection time; we have an optimized sample-interval. But what can go wrong?Imagine you have a system with a high number of routes, or with a big number of MPLS-TE tunnels, or a system with a big number of interfaces/sub-interfaces. Even with optimized collection processes, the amount of data is so big that it takes some time is needed to deliver it back to EMSd. Let\u2019s have a look into the picture again#The steps for the system are the same \u2013 we need an initial message request, we need to process information within EMSd, we need to send a request message for the internal data. But because of the amount of data, the collection time will take more than the configured sample-interval.  In this case, IOS XR will continue to collect the original sample and send it as soon as it is complete (which may be after the next sample-interval has expired).  Depending on the sample interval and collection time ratio, it could be even a window after the next sample and so on.EMSd guarantees non-stop operation. So it will request a new sample of data from the storage as soon as it gets current collection back (as a new sample interval has already started).Below is an example of such behavior from a system with a big number of interfaces (just for demo purposes)#RP/0/RP1/CPU0#ios#sh telemetry model-driven subscription 1Sat Jul 22 14#30#29.775 UTCSubscription#  1-------------&lt;&lt;&lt; skipped &gt;&gt;&gt;  Collection Groups#  ------------------    Id# 7    Sample Interval#      5000 ms    Encoding#             self-describing-gpb    Num of collection#    6    Collection time#      Min#    13675 ms Max#    14030 ms    Total time#           Min# 13806 ms Avg# 13940 ms Max# 14067 ms    Total Deferred#       0    Total Send Errors#    0    Total Send Drops#     0    Total Other Errors#   0    No data Instances#    6    Last Collection Start#2017-07-22 14#30#15.3522663588 +0000    Last Collection End#  2017-07-22 14#30#29.3536676588 +0000    Sensor Path#          Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/data-rateAs you see from the outputs, the sample-interval is 5 seconds, but due to the big amount of data, total collection time takes around 14 seconds! That led to the worst-case scenario where several consecutive sample intervals were skipped.A big and a small \u201cbag\u201dThe situation described above doesn\u2019t look good. But is that the worst you can expect?Let\u2019s have a look at what might happen if you have multiple sensor-paths to collect and one sensor-path has a big \u201cbag\u201d of data and another one has a small \u201cbag\u201d#We have the same story as before \u2013 a request is coming, after which our router needs to start processing and pushing out requested operational data. But we have two sensor-paths to be sent out this time. Let\u2019s say that the collection starts with the biggest one. As before, it takes some long time, exceeding configured sample-interval. And all that time, our request for the second, smaller sensor-path has to sit and wait in the queue for the first collection to be finished. As the result, both collections are delayed and sent during one of the next sample-intervals, even if the second sensor-path collection needs just few milliseconds to be collected and sent out.Here is a snapshot from a router with big number of interfaces#RP/0/RP1/CPU0#ios#sh telemetry model-driven subscription 1Sat Jul 22 14#57#23.911 UTCSubscription#  1&lt;&lt;&lt; skipped &gt;&gt;&gt;  Collection Groups#  ------------------    Id# 9    Sample Interval#      5000 ms    Encoding#             self-describing-gpb    Num of collection#    4    Collection time#      Min#    13650 ms Max#    13707 ms    Total time#           Min# 13840 ms Avg# 13894 ms Max# 13933 ms    Total Deferred#       0    Total Send Errors#    0    Total Send Drops#     0    Total Other Errors#   0    No data Instances#    4    Last Collection Start#2017-07-22 14#57#08.841218292 +0000    Last Collection End#  2017-07-22 14#57#22.855108292 +0000    Sensor Path#          Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/data-rate    Id# 10    Sample Interval#      5000 ms    Encoding#             self-describing-gpb    Num of collection#    4    Collection time#      Min#    10 ms Max#    14 ms    Total time#           Min#    10 ms Avg#    12 ms Max#    14 ms    Total Deferred#       0    Total Send Errors#    0    Total Send Drops#     0    Total Other Errors#   0    No data Instances#    0    Last Collection Start#2017-07-22 14#57#22.855108292 +0000    Last Collection End#  2017-07-22 14#57#22.855121292 +0000    Sensor Path#          Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-countersAs you can see, our second path, which only requires around 12ms of collection time, was delayed by 19 seconds because it had to wait for the first path to complete.Share the workloadIOS XR is a real time, modular software architecture based on processes that operate in separate address spaces with memory protection. Each process consists from a number of threads. EMSd is a process that represents core functionality of MDT within IOS XR. And it also contains a big number of different threads, which execute multiple tasks.Starting in the 6.2.x release train, EMSd will deliver improved performance by creating a separate thread within its architecture to process each \u201csubscription\u201d within MDT configuration. In other words, this enhancement will let you interleave small \u201cbag\u201d sensor-paths with large bag sensor-paths. This means you will be able to send \u201cfast\u201d paths according to expected sample-intervals while giving \u201cslow\u201d paths its own processing.Here is a picture of the enhanced functionality#As soon as a sample-interval starts, a separate thread will be allocated for each \u201csubscription\u201d configured (or to each sensor-path in case you have just one path inside each \u201csubscription\u201d configuration). When a given thread has finished the collection for its paths, the data will be sent immediately. Larger, slower sensor paths will continue collecting and an update will be sent out to collector that collection is still in progress.This is how it will look like on the tested router#RP/0/RP1/CPU0#ios#sh telemetry model-driven subscription 1Sat Jul 22 16#08#41.087 UTCSubscription#  1-------------&lt;&lt;&lt; skipped &gt;&gt;&gt;  Collection Groups#  ------------------    Id# 16    Sample Interval#      5000 ms    Encoding#             self-describing-gpb    Num of collection#    1    Collection time#      Min#    13931 ms Max#    13931 ms    Total time#           Min# 14000 ms Avg# 14000 ms Max# 14000 ms    Total Deferred#       0    Total Send Errors#    0    Total Send Drops#     0    Total Other Errors#   0    No data Instances#    1    Last Collection Start#2017-07-22 16#08#23.821224996 +0000    Last Collection End#  2017-07-22 16#08#37.835224996 +0000    Sensor Path#          Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/data-rateRP/0/RP1/CPU0#ios#sh telemetry model-driven subscription 2Sat Jul 22 16#08#42.777 UTCSubscription#  2-------------&lt;&lt;&lt; skipped &gt;&gt;&gt;  Collection Groups#  ------------------    Id# 17    Sample Interval#      5000 ms    Encoding#             self-describing-gpb    Num of collection#    5    Collection time#      Min#    13 ms Max#    16 ms    Total time#           Min#    13 ms Avg#    14 ms Max#    16 ms    Total Deferred#       0    Total Send Errors#    0    Total Send Drops#     0    Total Other Errors#   0    No data Instances#    0    Last Collection Start#2017-07-22 16#08#42.839437996 +0000    Last Collection End#  2017-07-22 16#08#42.839450996 +0000    Sensor Path#          Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-countersAs you can see, the snapshots were taken almost at the same time, but the number of collections done by the second subscription is way ahead compared to the first one. This example demonstrates the behavior of multithreading processing of sensor paths.It is also possible to see threads within a process with this \u201cshow\u201d command#RP/0/RP1/CPU0#ios#sh proc emsdSat Jul 22 16#11#19.938 UTC                  Job Id# 1165                     PID# 27830            Process name# emsd         &lt;&lt;&lt; skipped &gt;&gt;&gt;        Process cpu time# 3081.880 user, 1382.840 kernel, 4464.720 totalJID    TID  Stack  pri  state        NAME             rt_pri1165   27830    0K  20   Sleeping     emsd             0 1165   27831    0K  20   Sleeping     lwm_debug_threa  0 1165   27832    0K  20   Sleeping     emsd             0 &lt;&lt;&lt; skipped &gt;&gt;&gt;1165   9576    0K  20   Sleeping     emsd             0 1165   31769    0K  20   Sleeping     mdt_wkr_1        0 1165   16846    0K  20   Sleeping     mdt_wkr_2        0 ------------------------------------------------------------------------------\u201cmdt_wkr_\u201d is the thread you are looking for. Each one will be created for a separate subscription.ConclusionModel-driven telemetry represents the future of high-speed export of operational data. Before 6.2.x releases, you can configure different sample-intervals for different sensor-paths, but as soon as you have a path with a large amount of data in a processing queue, everything else will have to wait until after that collection is finished. Starting from 6.2.x, IOS XR added threading support for MDT. With this capability, we recommend that you separate your sensor-paths into different subscriptions to increase productivity of the router and your ability to get rich amount of different operational data at scale.", "url": "https://xrdocs.github.io/telemetry/blogs/2017-08-07-multithreading-in-mdt/", "tags": "iosxr, Telemetry, MDT", "title": "Multithreading in MDT", "author": "Viktor Osipchuk"}, "tutorials-2016-06-08-ios-xr-ansible-container-deployment": {"content": "     Ansible LXC deployment  Introduction  Pre-requisite  Boot up the environment  Configure Passwordless Access into XR Linux shell  Create LXC Tar ball in devbox  Create XML file in devbox  Ansible Playbook  Run playbook to deploy LXC          Slow playbook run? XR Gig interfaces are rate limited!        IntroductionThe goal of this tutorial to deploy a container (LXC) on XR using an Ansible playbook.In this tutorial we will use techniques from 2 other tutorials#      IOS-XR# Ansible and Vagrant. enable connectivity between machines and have preinstalled Ansible on devbox instance.        XR Toolbox, Part 2# Bootstrap XR configuration with Vagrant# using the new shell/bash based automation techniques.  The figure below illustrates the basic steps required to launch an lxc container on IOS-XR 6.0+#If you&#8217;ve gone through the tutorial# XR toolbox, Part 4# Bring your own Container (LXC) App, you would have a fair idea about how to accomplish the manual steps illustrated above. In this tutorial, we want to automate all of these steps using an Ansible Playbook.Pre-requisite      Vagrant box added for IOS-XRv# If you don&#8217;t have it, get it using the steps specified here# XR Toolbox, Part 1# IOS XR Vagrant quick start        Clone the following repository before we start#  cd ~/git clone https#//github.com/ios-xr/vagrant-xrdocs.gitcd  vagrant-xrdocs/ansible-tutorials/app_hosting/Boot up the environmentWe are ready to start, boot the boxes by issuing the vagrant up commandbash$ vagrant up Bringing machine 'devbox' up with 'virtualbox' provider...Bringing machine 'rtr' up with 'virtualbox' provider...==&gt; devbox# Importing base box 'ubuntu/trusty64'...---------------------------snip output -----------------------Configure Passwordless Access into XR Linux shellLet&#8217;s copy public part of key from devbox box and allow access without apassword.First,  connect to the devbox instance and copy its public key to XR via SCP#vagrant ssh devbox  scp -P 57722 /home/vagrant/.ssh/id_rsa.pub  vagrant@10.1.1.20#/home/vagrant/id_rsa_ubuntu.pubNow add the copied keys to authorized_keys in XR linuxvagrant ssh rtr  cat /home/vagrant/id_rsa_ubuntu.pub &gt;&gt; /home/vagrant/.ssh/authorized_keysAnsible is ready to work without password.Create LXC Tar ball in devboxThe user is free to bring their own lxc rootfs tar-ball for deployment on IOS-XR. This section is meant to help a user create a rootfs tar ball from scratch.  All the steps required to create a container rootfs are already covered in detail in the tutorial#  XR toolbox, Part 4# Bring your own Container (LXC) App  Specifically, head over to the following section of the tutorial#XR toolbox, Part 4&#8230;/create-a-container-rootfsAt the end of the section, you should have your very own rootfs (xr-lxc-app-rootfs.tar.gz), ready for deployment.Copy and keep the rootfs tar ball in the /home/vagrant/ directory of your devbox. The Ansible playbook will expect the tar ball in this directory, so make sure an ls -l for the tar ball in /home/vagrant returns something like#vagrant@vagrant-ubuntu-trusty-64#~$ ls -l /home/vagrant/xr-lxc-app-rootfs.tar.gz-rw-r--r-- 1 root root 101246853 Jun 20 02#34 /home/vagrant/xr-lxc-app-rootfs.tar.gzvagrant@vagrant-ubuntu-trusty-64#~$ Great! Ansible will copy this tar ball to XR for you.Create XML file in devboxTo create a container, we need an xml file with the specifications for the container. Create the following file in the /home/vagrant directory of your devbox #cat /home/vagrant/xr-lxc-app.xml&lt;domain type='lxc' xmlns#lxc='http#//libvirt.org/schemas/domain/lxc/1.0' &gt;  &lt;name&gt;xr-lxc-app&lt;/name&gt;  &lt;memory&gt;327680&lt;/memory&gt;  &lt;os&gt;    &lt;type&gt;exe&lt;/type&gt;    &lt;init&gt;/sbin/init&lt;/init&gt;  &lt;/os&gt;  &lt;lxc#namespace&gt;    &lt;sharenet type='netns' value='global-vrf'/&gt;  &lt;/lxc#namespace&gt;  &lt;vcpu&gt;1&lt;/vcpu&gt;  &lt;clock offset='utc'/&gt;  &lt;on_poweroff&gt;destroy&lt;/on_poweroff&gt;  &lt;on_reboot&gt;restart&lt;/on_reboot&gt;  &lt;on_crash&gt;destroy&lt;/on_crash&gt;  &lt;devices&gt;    &lt;emulator&gt;/usr/lib64/libvirt/libvirt_lxc&lt;/emulator&gt;    &lt;filesystem type='mount'&gt;      &lt;source dir='/misc/app_host/xr-lxc-app/'/&gt;      &lt;target dir='/'/&gt;    &lt;/filesystem&gt;    &lt;console type='pty'/&gt;  &lt;/devices&gt;&lt;/domain&gt;Ansible PlaybookAnsible playbook contains 7 tasks#cat deploy_container.yml---- hosts# ss-xr  tasks#  - name# Copy XML file    copy# src=/home/vagrant/xr-lxc-app.xml dest=/home/vagrant/xr-lxc-app.xml owner=vagrant force=no  - name# Copy rootfs tar ball    copy# src=/home/vagrant/xr-lxc-app-rootfs.tar.gz dest=/misc/app_host/scratch/xr-lxc-app-rootfs.tar.gz owner=vagrant force=no  - name# Create rootfs directory    file# path=/misc/app_host/xr-lxc-app/rootfs state=directory    become# yes  - command# tar -zxf /misc/app_host/scratch/xr-lxc-app-rootfs.tar.gz -C /misc/app_host/xr-lxc-app/rootfs    become# yes    register# output    ignore_errors# yes  - debug# var=output.stdout_lines  - name# grep    shell# sudo -i virsh list | grep xr-lxc-app    args#      warn# no    register# container_exist    ignore_errors# yes  - debug# var=output.stdout_lines  - name# virsh create    shell# sudo -i virsh  create /home/vagrant/xr-lxc-app.xml    args#      warn# no    register# output    when# ~ container_exist | failed ~  - debug# var=output.stdout_lines  - shell# sudo -i virsh list    args#      warn# no    register# output  - debug# var=output.stdout_linesTasks overview#  Task 1 copies xr-lxc-app.xml to XR ;  Task 2 copies the xr-lxc-app-rootfs.tar.gz tar ball to XR;  Task 3 creates folder &#8220;xr-lxc-app&#8221; at XR, if it does not exist;  Task 4 unpacks archive with container filesystem (Notice the ignore_errors?- we&#8217;re simply avoiding the mknod warnings);  Task 5 getting list of container and checking if &#8216;xr-lxc-app&#8217; in grep output. In case of success variable would be changed and Task 6 would be skipped;  Task 6 creates the container itself using the virsh alias in the XR linux shell (issuecommand &#8220;type virsh&#8221; on XR Linux to check. &#8220;sudo -i&#8221; is important, to load up Aliases for the root user). Triggered only if container not exist;  Task 7 dumps the virsh list output to show that container is up and running.Run playbook to deploy LXCAnsible playbook is ready to use. Issue command in devbox#ansible-playbook deploy_container.yml  Slow playbook run? XR Gig interfaces are rate limited!  The default ansible setup uses the Gig0/0/0/0 XR interface (connected to eth1 of devbox) to transfer the files over port 57722 (ssh to XR linux). This playbook could be directly used for physical devices as well.  But, bear in mind that the IOS-XR Vagrant instance is rate-limited on its Gig interfaces. So the copy process might be quite slow. To speed up the process we could use the Management interface instead. To do this, determine to which port vagrant forwards port 57722 from XR#bash-3.2$ vagrant port rtrThe forwarded ports for the machine are listed below. Please note thatthese values may differ from values configured in the Vagrantfile if theprovider supports automatic port collision detection and resolution. 58822 (guest) =&gt; 58822 (host)    22 (guest) =&gt; 2223 (host)    57722 (guest) =&gt; 2200 (host)bash-3.2$   Based on the above output#      Change the ansible host IP address from 10.1.1.20 (Gig0/0/0/0) address to 10.0.2.2 (gateway/laptop address) in /home/vagrant/iosxr-ansible/remote/ansible_hosts on devbox.    Change the remote_port  from 57722 to 2200 (forwarded port determined above, in your case it may be different) in /home/vagrant/iosxr-ansible/remote/ansible_cfg on devbox    Thus by using 10.0.2.2#2200 to run the playbook over the management port we significantly reduce the runtime of the playbook.Verify container is up from XR Linux shell#xr-vm_node0_RP0_CPU0#/misc/app_host/rootfs$ virsh list Id    Name                           State---------------------------------------------------- 4907  sysadmin                       running 8087  xr-lxc-app                     running 12057 default-sdr--1                 running  Container is up and running. It might take some time to be fully up. Give it about 20-30 seconds and you should be able to SSH to it from your laptop#  ssh -p 58822 ubuntu@127.0.0.1    Congratulations!", "url": "https://xrdocs.github.io/application-hosting/tutorials/2016-06-08-ios-xr-ansible-container-deployment/", "tags": "vagrant, iosxr, cisco", "title": "IOS-XR: Ansible based LXC deployment", "author": "Mike Korshunov"}, "tutorials-2016-06-17-xr-toolbox-part-5-running-a-native-wrl7-app": {"content": "     Running a Native (WRL7) App  Introduction  What\u2019s a native app?  Spin up the build environment          Clone the git repo        Build iperf from source on WRL7 Build Server          Fetch iperf source code      Set up the SPEC file for rpmbuild      Build RPM      Transfer the iperf RPM to router        Install iperf as native WRL7 app  Test the Native app          Set TPA IP (Src-hint) for App Traffic      Start iperf server on router      Install iperf in devbox (ubuntu server)      Set a route to TPA IP on devbox      Run iperf!        Check out Part 4 of the XR toolbox series# Bring your own Container (LXC) App.IntroductionIf you haven\u2019t checked out the earlier parts to the XR toolbox Series, then you can do so here#  XR Toolbox SeriesThe purpose of this series is simple. Get users started with an IOS-XR setup on their laptop and incrementally enable them to try out the application-hosting infrastructure on IOS-XR.In this part, we explore how a user can build and deploy native WRL7 RPMs that they may host in the same process space as XR.What\u2019s a native app?I go into some detail with respect to the IOS-XR application hosting architecture in the following blog#  XR app-hosting infrastructure# Quick LookFor reference, a part of the architecture is shown below. We focus on the green container in the figure from the original blog#This is the XR control plane LXC. XR processes (routing protocols, XR CLI etc.) are all housed in the blue region. We represent XR FIB within the same region to indicate that the XR control plane exclusively handles the data-plane programming and access to the real XR interfaces (Gig, Mgmt etc.)The gray region inside the control plane LXC represents the global-vrf network namespace in the XR linux environment. Today, IOS-XR only supports the mapping of global/default VRF in IOS-XR to the global-vrf network namespace in XR linux.  To get into the XR linux shell (global-vrf network namespace), we have two possible techniques#      From XR CLI#  Issue the bash command to drop into the XR linux shell from the CLI.    Over SSH using port 57722#  Port 22 is used by XR SSH. To enable a user/tool to drop directly into the XR linux shell, we enable SSH over port 57722. Any reachable IP address of XR could be used for this purpose.  Once in the XR linux shell, if we issue an ifconfig we should see all the interfaces (that are up/unshut) in the global/default VRF#   RP/0/RP0/CPU0#rtr1#   RP/0/RP0/CPU0#rtr1#   RP/0/RP0/CPU0#rtr1#show  ip int br   Sun Jul 17 11#52#15.049 UTC      Interface                      IP-Address      Status          Protocol Vrf-Name   Loopback0                      1.1.1.1         Up              Up       default    GigabitEthernet0/0/0/0         10.1.1.10       Up              Up       default    GigabitEthernet0/0/0/1         11.1.1.10       Up              Up       default    GigabitEthernet0/0/0/2         unassigned      Shutdown        Down     default   MgmtEth0/RP0/CPU0/0            10.0.2.15       Up              Up       default    RP/0/RP0/CPU0#rtr1#   RP/0/RP0/CPU0#rtr1#   RP/0/RP0/CPU0#rtr1#bash       Sun Jul 17 11#52#22.904 UTC   [xr-vm_node0_RP0_CPU0#~]$   [xr-vm_node0_RP0_CPU0#~]$ifconfig   Gi0_0_0_0 Link encap#Ethernet  HWaddr 08#00#27#e0#7f#bb               inet addr#10.1.1.10  Mask#255.255.255.0             inet6 addr# fe80##a00#27ff#fee0#7fbb/64 Scope#Link             UP RUNNING NOARP MULTICAST  MTU#1514  Metric#1             RX packets#0 errors#0 dropped#0 overruns#0 frame#0             TX packets#546 errors#0 dropped#3 overruns#0 carrier#1             collisions#0 txqueuelen#1000              RX bytes#0 (0.0 B)  TX bytes#49092 (47.9 KiB)   Gi0_0_0_1 Link encap#Ethernet  HWaddr 08#00#27#26#ca#9c               inet addr#11.1.1.10  Mask#255.255.255.0             inet6 addr# fe80##a00#27ff#fe26#ca9c/64 Scope#Link             UP RUNNING NOARP MULTICAST  MTU#1514  Metric#1             RX packets#0 errors#0 dropped#0 overruns#0 frame#0             TX packets#547 errors#0 dropped#3 overruns#0 carrier#1             collisions#0 txqueuelen#1000              RX bytes#0 (0.0 B)  TX bytes#49182 (48.0 KiB)   Mg0_RP0_CPU0_0 Link encap#Ethernet  HWaddr 08#00#27#ab#bf#0d               inet addr#10.0.2.15  Mask#255.255.255.0             inet6 addr# fe80##a00#27ff#feab#bf0d/64 Scope#Link             UP RUNNING NOARP MULTICAST  MTU#1514  Metric#1             RX packets#210942 errors#0 dropped#0 overruns#0 frame#0             TX packets#84664 errors#0 dropped#0 overruns#0 carrier#1             collisions#0 txqueuelen#1000              RX bytes#313575212 (299.0 MiB)  TX bytes#4784245 (4.5 MiB)   ---------------------------------- snip output -----------------------------------------Any Linux application hosted in this environment shares the process space with XR, and we refer to it as a native application.Spin up the build environmentWe\u2019re going to spin up a topology with 3 vagrant instances as shown below#      WRL7 Build# Since IOS-XR uses a streamlined custom WRL7 distribution, we need to make sure we have the latest WRL7 environment available to build \u201cnative\u201d apps. For this reason we have released the https#//atlas.hashicorp.com/ciscoxr/boxes/appdev-xr6.1.1 vagrant box to match IOS-XR release 6.1.1.  You will simply need to reference \u201cciscoxr/appdev-xr6.1.1\u201d in your Vagrantfile to spin it up.        IOS-XR# This is the 6.1.1 IOS-XR vagrant instance you would have already downloaded and installed as explained in the vagrant quick-start tutorial#          IOS-XR vagrant box download        In the end, vagrant box list must list your IOS-XRv vagrant box#    AKSHSHAR-M-K0DS#~ akshshar$ vagrant box listIOS-XRv (virtualbox, 0)AKSHSHAR-M-K0DS#~ akshshar$             devbox# This is the ubuntu/trusty64 image we have been using in the other tutorials for LXC creation and generic application testing.  IOS-XR and devbox instances talk to each other over Gig0/0/0/0 and eth1 interfaces respectively.Clone the git repoClone the following git repo# https#//github.com/ios-xr/vagrant-xrdocs.git AKSHSHAR-M-K0DS#~ akshshar$ git clone https#//github.com/ios-xr/vagrant-xrdocs.git Cloning into 'vagrant-xrdocs'...remote# Counting objects# 204, done.remote# Compressing objects# 100% (17/17), done.remote# Total 204 (delta 4), reused 0 (delta 0), pack-reused 187Receiving objects# 100% (204/204), 27.84 KiB | 0 bytes/s, done.Resolving deltas# 100% (74/74), done.Checking connectivity... done.AKSHSHAR-M-K0DS#~ akshshar$ AKSHSHAR-M-K0DS#~ akshshar$ AKSHSHAR-M-K0DS#~ akshshar$ cd vagrant-xrdocs/native-app-topo-bootstrap/AKSHSHAR-M-K0DS#native-app-topo-bootstrap akshshar$ pwd/Users/akshshar/vagrant-xrdocs/native-app-topo-bootstrapAKSHSHAR-M-K0DS#native-app-topo-bootstrap akshshar$ lsVagrantfile\tconfigs\t\tscriptsAKSHSHAR-M-K0DS#native-app-topo-bootstrap akshshar$ Once you\u2019re in the right directory, simply issue a vagrant up# AKSHSHAR-M-K0DS#native-app-topo-bootstrap akshshar$ vagrant up Bringing machine 'rtr' up with 'virtualbox' provider...Bringing machine 'devbox' up with 'virtualbox' provider...Bringing machine 'wrl7_build' up with 'virtualbox' provider...--------------------------- snip output ----------------------------Build iperf from source on WRL7 Build ServerAssuming everything came up fine, let\u2019s ssh into the wrl7_build instance#AKSHSHAR-M-K0DS#native-app-topo-bootstrap akshshar$ vagrant ssh wrl7_buildlocalhost#~$ localhost#~$ localhost#~$ localhost#~$ lsb_release -aLSB Version#\tcore-4.1-noarch#core-4.1-x86_64Distributor ID#\twrlinuxDescription#\tWind River Linux 7.0.0.2Release#\t7.0.0.2Codename#\tn/alocalhost#~$ Fetch iperf source codeGreat! Let\u2019s fetch the source code of iperf (iperf2) from its official location#Current latest version is#  iperf-2.0.9Download this tar ball into the wrl7_build vagrant instance# localhost#~$ localhost#~$ wget https#//iperf.fr/download/source/iperf-2.0.9-source.tar.gz --2016-07-17 14#57#13--  https#//iperf.fr/download/source/iperf-2.0.9-source.tar.gzResolving iperf.fr... 194.158.119.186, 2001#860#f70a##2Connecting to iperf.fr|194.158.119.186|#443... connected.HTTP request sent, awaiting response... 200 OKLength# 277702 (271K) [application/x-gzip]Saving to# 'iperf-2.0.9-source.tar.gz'100%[===================================================================================&gt;] 277,702      345KB/s   in 0.8s   2016-07-17 14#57#14 (345 KB/s) - 'iperf-2.0.9-source.tar.gz' saved [277702/277702]localhost#~$ localhost#~$ localhost#~$ lsiperf-2.0.9-source.tar.gz localhost#~$Copy the source code tar ball into the expected location for rpmbuild# /usr/src/rpm/SOURCES/localhost#~$ sudo cp /home/vagrant/iperf-2.0.9-source.tar.gz /usr/src/rpm/SOURCES/localhost#~$ Set up the SPEC file for rpmbuildWe will need a spec file to build the RPM. The spec file we intend to use is shown below. The highlighted sections are important.This file is  already available in /home/vagrant of wrl7_build server, thanks to the \u201cfile\u201d provisioner that run as part of \u201cvagrant up\u201d.  Name# iperf Version# 2.0.9Release# XR_6.1.1License# Copyright (c) 2015 Cisco Systems Inc. All rights reserved.Packager# ciscoSOURCE0 # %{name}-%{version}-source.tar.gzGroup# 3rd party applicationSummary# iperf compiled for WRL7# XR 6.1.1%descriptionThis is a compiled version of iperf-2.0.9 for WRL7# XR 6.1.1%prep%setup -q -n %{name}-%{version}%build./configuremake%installmkdir -p %{buildroot}%{_sbindir}install -m755 src/iperf %{buildroot}%{_sbindir}%files%defattr(-,root,root)%{_sbindir}/iperf%cleanrm -rf %{buildroot}Build RPMIssue the rpmbuild command# localhost#~$ sudo rpmbuild -ba iperf.spec Executing(%prep)# /bin/sh -e /var/tmp/rpm-tmp.59743+ umask 022+ cd /usr/lib64/rpm/../../src/rpm/BUILD+ cd /usr/src/rpm/BUILD+ rm -rf iperf-2.0.9+ /bin/tar -xf ------------------------------ snip output -------------------------------Requires# libc.so.6()(64bit) libc.so.6(GLIBC_2.14)(64bit) libc.so.6(GLIBC_2.2.5)(64bit) libc.so.6(GLIBC_2.3)(64bit) libc.so.6(GLIBC_2.7)(64bit) libgcc_s.so.1()(64bit) libgcc_s.so.1(GCC_3.0)(64bit) libm.so.6()(64bit) libm.so.6(GLIBC_2.2.5)(64bit) libpthread.so.0()(64bit) libpthread.so.0(GLIBC_2.2.5)(64bit) libpthread.so.0(GLIBC_2.3.2)(64bit) librt.so.1()(64bit) librt.so.1(GLIBC_2.2.5)(64bit) libstdc++.so.6()(64bit) libstdc++.so.6(CXXABI_1.3)(64bit) libstdc++.so.6(GLIBCXX_3.4)(64bit) rtld(GNU_HASH)Checking for unpackaged file(s)# /usr/lib64/rpm/check-files /usr/lib64/rpm/../../../var/tmp/iperf-rootWrote# /usr/src/rpm/SRPMS/iperf-2.0.9-XR_6.1.1.src.rpmWrote# /usr/src/rpm/RPMS/x86_64/iperf-2.0.9-XR_6.1.1.x86_64.rpmlocalhost#~$ The final RPM should be available in /usr/src/rpm/RPMS/x86_64#localhost#~$ ls -l /usr/src/rpm/RPMS/x86_64/total 48-rw-r--r-- 1 root root 48119 Jul 17 16#46 iperf-2.0.9-XR_6.1.1.x86_64.rpmlocalhost#~$ Transfer the iperf RPM to routerWe can transfer the iperf RPM to the router directly over the management network.First determine the forwarded port for XR linux shell (port 57722) for the running router#This command must of course be issued from your laptop running the vagrant environment AKSHSHAR-M-K0DS#native-app-topo-bootstrap akshshar$ vagrant port rtr The forwarded ports for the machine are listed below. Please note thatthese values may differ from values configured in the Vagrantfile if theprovider supports automatic port collision detection and resolution.    22 (guest) =&gt; 2223 (host)57722 (guest) =&gt; 2222 (host) AKSHSHAR-M-K0DS#native-app-topo-bootstrap akshshar$ Get back into wrl7_build and use HOST ip address = 10.0.2.2 with port 2222 to transfer the RPM to the router over the management network#The password for user vagrant on the router is \u201cvagrant\u201d.localhost#~$ localhost#~$ scp -P 2222 /usr/src/rpm/RPMS/x86_64/iperf-2.0.9-XR_6.1.1.x86_64.rpm   vagrant@10.0.2.2#/home/vagrant/ vagrant@10.0.2.2's password# iperf-2.0.9-XR_6.1.1.x86_64.rpm                                                                100%   47KB  47.0KB/s   00#00    localhost#~$ Install iperf as native WRL7 appLogin to the router and install the iperf RPM transferred in the previous step using yum#xr-vm_node0_RP0_CPU0#~$ pwd/home/vagrant xr-vm_node0_RP0_CPU0#~$ ls -l iperf-2.0.9-XR_6.1.1.x86_64.rpm -rw-r--r-- 1 vagrant vagrant 48011 Jul 17 21#11 iperf-2.0.9-XR_6.1.1.x86_64.rpm xr-vm_node0_RP0_CPU0#~$ xr-vm_node0_RP0_CPU0#~$ xr-vm_node0_RP0_CPU0#~$  sudo yum install -y  iperf-2.0.9-XR_6.1.1.x86_64.rpm Loaded plugins# downloadonly, protect-packages, rpm-persistenceSetting up Install ProcessExamining iperf-2.0.9-XR_6.1.1.x86_64.rpm# iperf-2.0.9-XR_6.1.1.x86_64Marking iperf-2.0.9-XR_6.1.1.x86_64.rpm to be installedResolving Dependencies--&gt; Running transaction check---&gt; Package iperf.x86_64 0#2.0.9-XR_6.1.1 will be installed--&gt; Finished Dependency ResolutionDependencies Resolved================================================================================================================================= Package               Arch                   Version                         Repository                                    Size=================================================================================================================================Installing# iperf                 x86_64                 2.0.9-XR_6.1.1                  /iperf-2.0.9-XR_6.1.1.x86_64                 103 kTransaction Summary=================================================================================================================================Install       1 PackageTotal size# 103 kInstalled size# 103 kDownloading Packages#Running Transaction CheckRunning Transaction TestTransaction Test SucceededRunning Transaction  Installing # iperf-2.0.9-XR_6.1.1.x86_64                                                                                   1/1 Installed#  iperf.x86_64 0#2.0.9-XR_6.1.1                                                                                                  Complete!xr-vm_node0_RP0_CPU0#~$ Check the installation#xr-vm_node0_RP0_CPU0#~$ iperf -viperf version 2.0.9 (1 June 2016) pthreadsxr-vm_node0_RP0_CPU0#~$ We\u2019re all set!Test the Native appAs we have seen in greater detail in the LXC container app tutorial#Setting the src-hint for application trafficwe need to set the src-hint for applications to ensure reachability in routed networks.Set TPA IP (Src-hint) for App TrafficAKSHSHAR-M-K0DS#native-app-topo-bootstrap akshshar$ vagrant port rtr The forwarded ports for the machine are listed below. Please note thatthese values may differ from values configured in the Vagrantfile if theprovider supports automatic port collision detection and resolution.    22 (guest) =&gt; 2223 (host)57722 (guest) =&gt; 2222 (host) AKSHSHAR-M-K0DS#native-app-topo-bootstrap akshshar$ ssh -p 2223 vagrant@localhost vagrant@localhost's password# RP/0/RP0/CPU0#ios#RP/0/RP0/CPU0#ios#conf tSun Jul 17 21#23#04.140 UTCRP/0/RP0/CPU0#ios(config)#tpa address-family ipv4 update-source loopback 0RP/0/RP0/CPU0#ios(config)#commitSun Jul 17 21#23#23.464 UTCRP/0/RP0/CPU0#ios(config)#endRP/0/RP0/CPU0#ios#RP/0/RP0/CPU0#ios#bash -c ip routeSun Jul 17 21#23#35.008 UTCdefault dev fwdintf  scope link  src 1.1.1.1 10.0.2.0/24 dev Mg0_RP0_CPU0_0  proto kernel  scope link  src 10.0.2.15 RP/0/RP0/CPU0#ios#Start iperf server on routerAKSHSHAR-M-K0DS#native-app-topo-bootstrap akshshar$vagrant ssh rtrLast login# Sun Jul 17 21#11#44 2016 from 10.0.2.2xr-vm_node0_RP0_CPU0#~$ xr-vm_node0_RP0_CPU0#~$ iperf -s -u ------------------------------------------------------------Server listening on UDP port 5001Receiving 1470 byte datagramsUDP buffer size# 64.0 MByte (default)------------------------------------------------------------Yay! iperf server is running natively in IOS-XR.Install iperf in devbox (ubuntu server)We will use devbox (ubuntu server) in the topology as an iperf clientAKSHSHAR-M-K0DS#native-app-topo-bootstrap akshshar$ vagrant ssh devbox Welcome to Ubuntu 14.04.4 LTS (GNU/Linux 3.13.0-87-generic x86_64) * Documentation#  https#//help.ubuntu.com/  System information as of Sun Jul 17 20#19#54 UTC 2016  System load#  0.0               Processes#           74  Usage of /#   3.5% of 39.34GB   Users logged in#     0  Memory usage# 25%               IP address for eth0# 10.0.2.15  Swap usage#   0%                IP address for eth1# 11.1.1.20  Graph this data and manage this system at#    https#//landscape.canonical.com/  Get cloud support with Ubuntu Advantage Cloud Guest#    http#//www.ubuntu.com/business/services/cloud0 packages can be updated.0 updates are security updates.Last login# Sun Jul 17 20#19#54 2016 from 10.0.2.2vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ sudo apt-get -y install iperfReading package lists... DoneBuilding dependency tree       Reading state information... DoneThe following NEW packages will be installed#  iperf0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.Need to get 0 B/56.3 kB of archives.After this operation, 174 kB of additional disk space will be used.Selecting previously unselected package iperf.(Reading database ... 62989 files and directories currently installed.)Preparing to unpack .../iperf_2.0.5-3_amd64.deb ...Unpacking iperf (2.0.5-3) ...Processing triggers for man-db (2.6.7.1-1ubuntu1) ...Setting up iperf (2.0.5-3) ...vagrant@vagrant-ubuntu-trusty-64#~$ Set a route to TPA IP on devboxLet\u2019s make sure XR\u2019s loopback0 (used as TPA IP) is reachable from the devbox (since we\u2019re not running routing protocols in this topology, this isn\u2019t automatic)#vagrant@vagrant-ubuntu-trusty-64#~$ sudo ip route add 1.1.1.1/32 via 11.1.1.10 vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ ping 1.1.1.1 PING 1.1.1.1 (1.1.1.1) 56(84) bytes of data.64 bytes from 1.1.1.1# icmp_seq=1 ttl=255 time=1.52 ms64 bytes from 1.1.1.1# icmp_seq=2 ttl=255 time=1.94 ms^C--- 1.1.1.1 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1001msrtt min/avg/max/mdev = 1.526/1.734/1.943/0.212 msRun iperf!Initiate the iperf client on the devbox pointing to the router\u2019s loopback0 (TPA IP)#vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ iperf -c 1.1.1.1 -u ------------------------------------------------------------Client connecting to 1.1.1.1, UDP port 5001Sending 1470 byte datagramsUDP buffer size#  208 KByte (default)------------------------------------------------------------[  3] local 11.1.1.20 port 34348 connected with 1.1.1.1 port 5001[ ID] Interval       Transfer     Bandwidth[  3]  0.0-10.0 sec  1.25 MBytes  1.05 Mbits/sec[  3] Sent 893 datagrams[  3] Server Report#[  3]  0.0-10.0 sec  1.25 MBytes  1.05 Mbits/sec   0.256 ms    0/  893 (0%)vagrant@vagrant-ubuntu-trusty-64#~$ We\u2019ve successfully built iperf as a WRL7 RPM, installed it natively inside XR and tested iperf operation over XR\u2019s data port (Gig0/0/0/0 connected to devbox eth1).", "url": "https://xrdocs.github.io/application-hosting/tutorials/2016-06-17-xr-toolbox-part-5-running-a-native-wrl7-app/", "tags": "vagrant, iosxr, cisco, linux, wrl7, rpm, xr toolbox", "title": "XR toolbox, Part 5: Running a native WRL7 app", "author": "Akshat Sharma"}, "blogs-2017-09-21-peering-telemetry": {"content": "     On This Page  Introduction  Telemetry Data Types          Metric Data      Event Data        Peering Metric Data          Peering Metric Data Protocols                  Model-Driven Telemetry          Sampled Netflow / IPFIX          NETCONF          SNMP                    Peering Metric Data Examples                  Peer Physical and Logical Interface Statistics          BGP Operational State                      Peering Event Data          Peering Event Data Protocols                  BGP Monitoring Protocol          Syslog          SNMP Traps                    Peering Related Events                  Peer Interface State          Peer Session State          Max-Prefix Threshold Events          Global and Per-Peer RIB Changes                      Enabling Telemetry          Model Driven Streaming Telemetry      Netflow / IPFIX      BMP      SNMP and SNMP Traps      Syslog        Applications for Peering Telemetry          Enhancing Peering Operations                  Monitor Peering Router Stability and Resources          Monitor Peer Stability          Using Flow Data for Enhanced Troubleshooting          Applicable Metric Telemetry          Applicable Event Telemetry                    Network Visibility                  Peer Traffic Anomaly Detection          Applicable Metric Telemetry          Applicable Event Telemetry                    Capacity Planning                  Peer Targeting          Existing Peer Capacity Planning                    Security                  Attack Detection          BGP Prefix Anomalies          Applicable Metric Telemetry          Applicable Event Telemetry                    Peering Traffic Engineering                  Ingress Peer Engineering                      Appendix A          A.1 Interface Metric SNMP OIDs and YANG Paths                  Relevant YANG Models                    A.2 BGP Operational State YANG Paths                  Relevant YANG Models          Global BGP Protocol State          BGP Neighbor State                          Example Usage                                BGP RIB Data          A.3 Device Resource YANG Paths                      IntroductionTelemetry is the process of measuring the state of the components in a system and transmitting it to a remote location for further processing and analysis. Telemetry is important in any system whether it be a car, water treatment facility, or IP network. The loosely coupled distributed nature of IP networks where the state of a single node can affect an entire set of interconnected elements makes telemetry especially important. Peering adds an additional dimension of a node not under your administrative control, requiring additional telemetry data and analysis to detect network anomalies and provide meaningful insight to network behavior. Analysis of peering telemetry data also enhances operations and network efficiency. In this paper, we\u2019ll explore IP network telemetry data types, how they are used, and their configuration in IOS-XR.Telemetry Data TypesIt\u2019s important to make a distinction between the two major telemetry types we\u2019ll be collecting and analyzing for peering networks. Each data types is important for operations and planning and often combined to fulfill complex use cases.Metric DataMetric data refers to the measurement of quantitative data which normally changes over time. Metric telemetry data is usually found in the form of a counter, Boolean value, gauge, rate, or histogram. A counter is a monotonically increasing measurement, interface received bits is an example of a counter. A Boolean value is used to periodically transmit a state value. These are typically used in the absence of an event data type covering the state change. Gauges are used to record instantaneous values in time, such as the number of prefixes received from a BGP peer. Rate data is the rate of change in a counter or gauge over a period of time. Rate data being received from a remote device requires some processing of data on the device itself since it must record historical values and average them over a time period. Interface bits per second is an example of a typical rate data type. Histograms are an additional more complex data type requiring the most processing on a device. Histograms store the frequency of occurrence over a period of time and typically use ranges to group similar values. Histograms are not widely used in IP networks, but may have more applicability in the future.Event DataEvent data is the recording of data at specific times triggered by a specific monitored state change. The state change could be a boolean value such as an interface being up or down, or an exception triggered by exceeding a limit on a metric like a BGP peer exceeding its received prefix limit. Event data always has a timestamp and then a series of other schema-less data points carrying additional information. Event data often contains metric data to supply context around the event. A prefix limit violation event may include a peer IP, peer ASN, and currently configured limit.Peering Metric DataPeering Metric Data ProtocolsModel-Driven TelemetryIOS-XR on the NCS5500 series supports MDT, or Model-Driven Telemetry over TCP or gRPC as an efficient method to stream statistics to a collector. The MDT fields are accessed by a specific telemetry sensor path defined in native IOS-XR, OpenConfig, or standard IETF YANG models. Multiple MDT groups can be configured to report data at different intervals, for instance to stream interface statistics at higher frequency than BGP protocol statistics. Much more information on Model-Driven Telemetry in IOS-XR can be found at http#//xrdocs.io/telemetry/.Sampled Netflow / IPFIXNetflow was invented by Cisco due to requirements for traffic visibility and accounting. Netflow in its simplest form exports 5-tuple data for each flow traversing a Netflow-enabled interface. Netflow data is further enhanced with the inclusion of BGP information in the exported Netflow data, namely AS_PATH and destination prefix. This inclusion makes it possible to see where traffic originated by ASN and derive the destination for the traffic per BGP prefix. The latest iteration of Cisco Netflow is Netflow v9, with the next-generation IETF standardized version called IPFIX (IP Flow Information Export). IPFIX has expanded on Netflow\u2019s capabilities by introducing hundreds of entities.Netflow is traditionally partially processed telemetry data. The device itself keeps a running cache table of flow entries and counters associated with packets, bytes, and flow duration. At certain time intervals or event triggered, the flow entries are exported to a collector for further processing. The type 315 extension to IPFIX, supported on the NCS5500, does not process flow data on the device, but sends the raw sampled packet header to an external collector for all processing. Due to the high bandwidth, PPS rate, and large number of simultaneous flows on Internet routers, Netflow samples packets at a pre-configured rate for processing. Typical sampling values on peering routers are 1#4000 or 1#8000 packets.NETCONFDefined in RFC 6241, NETCONF can also be used to retrieve metric data from a device over SSH using the operational state paths associated with IETF, Openconfig, and IOS-XR native YANG models. Almost all state data in IOS-XR adheres to a YANG model, allowing one to retrieve state data for protocols, resource utilization, route tables, etc. via simply constructed  NETCONF RPC operations. See Appendix A for several examples of using NETCONF to gather useful peering metric data.SNMPSNMP, the traditional well-supported protocol for pulling data from a device is also supported via native IOS-XR or standard IETF MIBs.Peering Metric Data ExamplesPeer Physical and Logical Interface StatisticsThe most basic information needed on peering connections is interface statistics. Collected via SNMP or newer methods like Model-Driven Telemetry, having insight into both real-time traffic statistics and historical trends is a necessary component for operating and planning peering networks. A list of recommended interface counters, their related MDT sensor paths, and SNMP OIDs can be found in Appendix A.1.BGP Operational StateThere is a variety of BGP operational state data to be mined for information. Doing so can lead to enhanced peering operations. A wealth of information on global and per-peer BGP state is available via OpenConfig and native IOS-XR YANG models. This includes data such as per-AFI and per-neighbor prefix counts, update message counts, and associated configuration data. Using the OpenConfig BGP RIB modesl, you can retrieve the global best-path Loc-RIB and per-neighbor adj-RIB-in and adj-RIB-out pre and post policy along with the reason why a given route was not selected as best-path. This gives additional operational insight through automation which would normally require one to login to various routers, issue show commands, and parse the verbose output. A list of recommended BGP OpState YANG Paths can be found in Appendix A.2Peering Event DataPeering event telemetry data is ideally sent when an event occurs on the device, as opposed to polling the state. The timestamped event is sent to a collection system which may simply log the event or the event may trigger the collection of additional data or remediation action.Peering Event Data ProtocolsBGP Monitoring ProtocolBMP, defined in RFC7854, is a protocol to monitor BGP events as well as BGP related data and statistics. BMP has two primary modes, Route Monitoring mode and Route Mirroring mode. The monitoring mode will initially transmit the adj-rib-in contents per-peer to a monitoring station, and continue to send updates as they occur on the monitored device. Setting the L bits on the RM header to 1 will convey this is a post-policy route, 0 will indicate pre-policy. The mirroring mode simply reflects all received BGP messages to the monitoring host. IOS-XR supports sending pre and post policy routes to a station via the Route Monitoring mode. BMP can additionally send information on peer state change events, including why a peer went down in the case of a BGP event.There are drafts in the IETF process to extend BMP to report additional routing data, such as the loc-RIB and per-peer adj-RIB-out. Local-RIB is the full device RIB including received BGP routes, routes from other protocols, and locally originated routes. Adj-RIB-out will add the ability to monitor routes advertised to peers pre and post policy.SyslogSyslog has long been used as a method for reporting event data from both host servers and network devices, and allows a severity to be transmitted along with a verbose log message. Syslog requires more complex post-processing on the receiver end since all the data is encoded within the text message itself, but in the absence of a standardized schema for certain events can be a useful option. Syslog is not typically encrypted which can be a security concern.SNMP TrapsSNMP traps are event-driven SNMP messages sent by a device following a well-defined SNMP OID schema. SNMP trap receivers can easily decode the message type by the OID and apply the appropriate policy. SNMP trap policies must be defined on the device itself to filter out unwanted messages.Peering Related EventsMonitoring all event data on a router can often overwhelm collectors, so prescriptive monitoring is needed to only ingest applicable events. Applicable SNMP trap OIDs can be found in Appendix A.3.Peer Interface StateThe most basic form of peer monitoring is physical and logical interface state. Whenever an interface goes down, it\u2019s a traffic impacting event needing further investigation. Interface state can be polled at periodic intervals.Peer Session StateMonitoring peer session state can be critical for detecting transient outages, traffic shifts, and performing root cause analysis on historical traffic impacting events. BGP peer sessions can transition from down to up in a short time period and are not always triggered by interface state changes.Max-Prefix Threshold EventsSetting a realistic max-prefix limit on peers is an important security mechanism. Most router operating systems support the ability to trigger an event based on a percentage threshold of this max prefix limit. This is an important event to monitor since reaching the limit generally results in a traffic-affecting session teardown event.Global and Per-Peer RIB ChangesBMP allows one to monitor incoming advertisements on a per-peer basis and record them for historical purposes. Having a record of all changes allows one to playback updates to determine the past impact of peer advertisement changes. BMP is the preferred mechanism to stream BGP updates as they happen, but NETCONF can also be used to retrieve BGP RIB data globally and per-peer on IOS-XR.Enabling TelemetryModel Driven Streaming TelemetryMDT is enabled on the node itself in three steps. 1) Grouping source data YANG paths, called sensors, into a sensor group. 2) Creating a destination group with the destination and data encoding method. 3) Creating a subscription grouping a sensor-group to a destination-group. This method of configuration is known as \u201cdial-out\u201d since the node itself initiates the streaming. Another method, called \u201cdial-in\u201d uses specific models to configure all of the above information from an external management application. The dial-in configuration is ephemeral, meaning it is not stored in the startup configuration. Configuration of MDT for IOS-XR on the NCS5500 can be found here# https#//www.cisco.com/c/en/us/td/docs/iosxr/ncs5500/telemetry/b-telemetry-cg-ncs5500-62x/b-telemetry-cg-ncs5500-62x_chapter_011.htmlAlso, http#//xrdocs.io has a number of telemetry related blogs which go in depth on configuration and use cases for MDT.On the collection side, Pipeline is a Cisco open-source project which can be used to collect streaming data and output it to several popular time-series databases. Pipeline can be located at https#//github.com/cisco/bigmuddy-network-telemetry-pipeline and tutorial on using Pipeline at https#//xrdocs.github.io/telemetry/tutorials/2017-05-08-pipeline-with-grpcNetflow / IPFIXThe Netflow and IPFIX configuration guide for the NCS5500 can be found here#https#//www.cisco.com/c/en/us/td/docs/iosxr/ncs5500/netflow/62x/b-ncs5500-netflow-configuration-guide-62x/b-ncs5500-netflow-configuration-guide-62x_chapter_010.htmlTuning Netflow parameters is critical to extracting the most useful data from Netflow. It is recommended to contact your Cisco SE to work through optimizing Netflow for your platform. As a general guideline, for traffic and security analysis, a sampling interval of 8000#1 or 4000#1 is sufficient.There are a wide range of Netflow collection engines on the market today as well as cloud-based solutions. PMACCT found at http#//www.pmacct.net is a popular open-source Netflow and IPFIX collector.BMPBMP is easily configured in the following steps in IOS-XR. Configure a BMP destination host using the global \u201cbmp server &lt;1-8&gt; command with its associated parameters. The minimum configuration is bmp server &lt;1-8&gt; host &lt;fqdn|ip&gt; port . BMP uses TCP as its transport protocol, and has no standard port so a port must be specified. Additionally, in order to send periodic BGP statistics, a statistics interval must be configured via the bmp server &lt;1-8&gt; stats-reporting-period &lt;1-3600&gt; command. Once a destination BMP host is configured, BMP is activated on a per-peer basis (or all peers via a shared peer-group configuration) using the \u201cbmp-activate server &lt;1-8&gt;\u201d under the neighbor configuration with the BGP routing configuration. The following is an example configuration.!bmp server 1 host 192.168.2.51 port 8500 update-source GigabitEthernet0/0/0/0 stats-reporting-period 60!router bgp 65001 neighbor 192.168.1.1 remote-as 65002  bmp-activate server 1 !! Collecting BMP data is best done using the open source SNAS collector, formally known as OpenBMP. SNAS can be found at http#//snas.io.SNMP and SNMP TrapsThe NCS5500 IOS-XR SNMP configuration guide can be found here# https#//www.cisco.com/c/en/us/td/docs/iosxr/ncs5500/sysman/62x/b-system-management-cg-ncs5500-62x/b-system-management-cg-ncs5500-62x_chapter_0110.html. It is recommended to use SNMPv3 for higher security. SNMP is supported by most traditional EMS/NMS systems.SyslogThe IOS-XR Syslog configuration guide can be found at https#//www.cisco.com/c/en/us/td/docs/iosxr/ncs5500/system-monitoring/62x/b-system-monitoring-cg-ncs5500-62x/b-system-monitoring-cg-ncs5500-62x_chapter_010.htmlApplications for Peering TelemetryEnhancing Peering OperationsSuccessfully operating a peering edge router requires knowledge of a variety of telemetry data. As the connecting device is not under your administrative control, having information on the state of the connection at all times is critical. Mitigating issues like an ingress congestion event on a peering interface can be more difficult to troubleshoot and be in a degraded state longer due to multiple party involvement.Monitor Peering Router Stability and ResourcesGlobal BGP statistics can be used to determine peering router health. Global BGP state values such as overall per-AFI RIB size, established peer session count, overall BGP update counts, and state transitions are used to determine instability either causing network issues or leading to them. When coupled with known resource limits, these values can also be used to monitor devices for exhaustion in resources like FIB or RIB size, and peer session limits.Monitor Peer StabilityJust as we monitor the global BGP state, we can monitor the same statistics on a per-peer basis. Detecting instability on peering edge routers is beneficial since off-net instability can be replicated across your entire network. Tracking per-peer BGP state values such as overall BGP message count, update and withdrawal count, update queue depth, per-AFI adj-RIB-in pre/post policy, and active prefix count can help discover peer stability issues very quickly.Using Flow Data for Enhanced TroubleshootingIt is often difficult to troubleshoot exact network behavior across administrative boundaries. Flow data can assist by giving a view of traffic behavior at an application stream level. Tools like ping and traceroute do not give the same insight into service traffic behavior.Applicable Metric Telemetry      Peer logical and physical interface statistics        Peering router general health data (CPU, Memory, FIB resources, etc.)        BGP protocol statistics                  Global BGP session count                    Global BGP RIB size                    Global BGP table version (update count)                    Per-peer session state                    Per-peer prefix counts                    Per-peer message update counts                    Per-peer message queue depth                    Current dampened paths            Applicable Event Telemetry      Peer logical and physical interface state        Per-peer BGP session state  Network VisibilityPeer Traffic Anomaly DetectionSimple interface stats are again the starting point for peering network visibility. Having accurate and timely logical and physical interface stats can quickly alert you to service-affecting anomalies for both ingress and egress traffic. Using the faster sampling frequency of MDT on IOS-XR decreases the time to catch events from what was typically 5+ minutes using SNMP to 30 seconds or less.Historical flow data from peers can be used to store a network baseline used with real-time information to determine anomalous behavior. Examples include DNS-driven content peers shifting traffic sources causing sub-optimal traffic on your network, or peer BGP routes being withdrawn from optimal peer sessions. Some shifts are not detected by interface statistics alone and require the flow-level traffic view to detect. Grouping by constraints such as SRC/DST ASN or BGP prefix can help quickly determine large changes in traffic across an entire network.Analyzing BGP updates on a global and per-peer basis via BMP data can also help detect traffic-affecting routing anomalies and be an important resource for root cause analysis of previous events.Applicable Metric Telemetry      Peer logical and physical interface statistics        BGP protocol statistics                  Global BGP RIB size                    Global BGP table version (update count)                    Per-peer session state                    Per-peer prefix counts                    Per-peer message update counts                    Per-peer message queue depth                  Netflow / IPFIX  Applicable Event Telemetry      Peer logical and physical interface state        Per-peer BGP session state  Capacity PlanningPeer TargetingThe most common use of Netflow data for peering is to determine who you need your network to peer with or where to add additional peer connections. The traffic exchange rate between sources or destinations on your network and remote networks can easily be derived with flow information and the associated BGP ASN data. Analyzing flow data from transit connections or larger service provider peer connections can help determine new organizations to peer with. Analyzing flow data from existing peers helps determine if traffic to/from your network is taking the optimal path. Sub-optimal paths can be remedied by adding additional peer connections.Telemetry data can not only tell you where to augment existing peering, or connect to a new provider in an existing location, but help determine where to add additional peering facilities. Aggregated flow data along with topology data help determine the cost of carrying traffic across an internal network as well as paid peering connections. Eliminating network hops and augmenting paid peering or transit with settlement free peering connections can offset the location and network build costs in a short amount of time.Existing Peer Capacity PlanningInterface bandwidth statistics are necessary for accurate capacity planning. The most basic metric to trigger capacity upgrades is exceeding a traffic utilization threshold. Capacity planning can also be aided by flow data. Knowing the growth rates of specific types of peer traffic will aid in future overall network traffic projections. Flow data can also be used to derive growth rates between specific source/destination pairs, helping better predict growth across a network and not just at the peer interface boundary.SecurityPeering by definition is at the edge of the network, where security is mandatory. Telemetry data is critical to security applications and aids in quickly identifying potential threats and triggering mitigation activity.Attack DetectionDDoS is a threat to all Internet-connected entities. Often times simple interface packet rates can be used to quickly identify that a DDoS attack is in progress. Flow data is then critical in determining the source, destination, volume, packet rate, and type of data associated to a DDoS attack. Coupled with a dynamic remediation system, traffic can be quickly blocked or diverted and alleviate congestion on downstream nodes.Not all attacks have a signature of high packet rates. The attacks can also originate from within your own network, such as open DNS resolvers participating in an Internet-wide attack on a remote destination. Flow data becomes important in these instances, monitoring per-protocol or anomalous behavior on both ingress and egress peering traffic can quickly help identify and mitigate attacks.BGP Prefix AnomaliesThe pre-policy RIB information from BMP can be used for traffic simulation as well as detecting security issues such as prefix hijacking without the prefixes being active in the provider table. In certain cases, analyzing incoming NLRI for malformed attributes or excessive AS_PATH lengths can help mitigate router security vulnerabilities as well.Having historical information can also help troubleshoot traffic issues where a provider may be changing advertisement locations due to instability on their network, causing reachability issues from sources on your network.Applicable Metric Telemetry      Netflow / IPFIX        Peer logical and physical interface statistics  Applicable Event Telemetry      Peer logical and physical interface state        BGP adj-RIB-in information and updates  Peering Traffic EngineeringPeer traffic engineering in this context refers to shifting either ingress or egress traffic between peer connections. Peer TE may be performed on a variety of reasons such as capacity optimization, performance, or maintenance activity. Without more granular flow data to determine traffic per prefix, where a prefix may be recursively split for precision, accurate traffic placement cannot be achieved. Peer TE may be a manual operation, done by an offline planning tool, or a real-time network component.Ingress Peer EngineeringIngress peer engineering generally involves the manipulation of outbound BGP NLRI, either through prefix withdrawal, prefix disaggregation, or augmenting a transitive attribute such as MED or AS_PATH. Targeting specific prefixes to manipulate requires telemetry data. IPE may be employed due to capacity, performance, or operations reasons. Accurate capacity augmentation requires interface statistics, BGP prefix information, and Netflow data to plan for traffic shifts and verify the network behaves as predicted after implementation.Appendix AA.1 Interface Metric SNMP OIDs and YANG PathsRelevant YANG Modelsietf-interfacesopenconfig-interfacesopenconfig-if-ethernetoc-platformCisco-IOS-XR-infra-statsd-operCisco-IOS-XR-drivers-media-eth-oper            \u00a0      \u00a0                  Logical Interface Admin State      Enum              SNMP OID      IF-MIB#ifAdminStatus              OC YANG      oc-if#interfaces/interface/state/admin-status (see OC model, not just up/down)              Native YANG      Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface/state              MDT      Native                  \u00a0      \u00a0                  Logical Interface Operational State      Enum              SNMP OID      IF-MIB#ifOperStatus              OC YANG      oc-if#interfaces/interface/state/oper-status (see OC model, not just up/down)              Native YANG      Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface/state              MDT      Native                  \u00a0      \u00a0                  Logical Last State Change (seconds)      Counter              SNMP OID      IF-MIB#ifLastChange              OC YANG      oc-if#interfaces/interface/state/last-change              Native YANG      Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface/last-state-transition-time              MDT      Native                  \u00a0      \u00a0                  Logical Interface SNMP ifIndex      Integer              SNMP OID      IF-MIB#ifIndex              OC YANG      oc-if#interfaces/interface/state/if-index              Native YANG      Cisco-IOS-XR-snmp-agent-oper#snmp/interface-indexes/if-index              MDT      Native                  \u00a0      \u00a0                  Logical Interface RX Bytes 64-bit      Counter              SNMP OID      IF-MIB#ifHCInOctets              OC YANG      oc-if#/interfaces/interface/state/counters/in-octets              Native YANG      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters/bytes-received              MDT      Native                  \u00a0      \u00a0                  Logical Interface TX Bytes 64-bit      Counter              SNMP OID      IF-MIB#ifHCOutOctets              OC YANG      oc-if#/interfaces/interface/state/counters/out-octets              Native YANG      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters/bytes-sent              MDT      Native                  \u00a0      \u00a0                  Logical Interface RX Errors      Counter              SNMP OID      IF-MIB#ifInErrors              OC YANG      oc-if#/interfaces/interface/state/counters/in-errors              Native YANG      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters/input-errors              MDT      Native                  \u00a0      \u00a0                  Logical Interface TX Errors      Counter              SNMP OID      IF-MIB#ifOutErrors              OC YANG      oc-if#/interfaces/interface/state/counters/out-errors              Native YANG      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters/output-errors              MDT      Native                  \u00a0      \u00a0                  Logical Interface Unicast Packets RX      Counter              SNMP OID      IF-MIB#ifHCInUcastPkts              OC YANG      oc-if#/interfaces/interface/state/counters/in-unicast-pkts              Native YANG      Not explicitly supported, subtract multicast/broadcast from total              MDT      Native                  \u00a0      \u00a0                  Logical Interface Unicast Packets TX      Counter              SNMP OID      IF-MIB#ifHCOutUcastPkts              OC YANG      oc-if#/interfaces/interface/state/counters/out-unicast-pkts              Native YANG      Not explicitly supported, subtract multicast/broadcast from total              MDT      Native                  \u00a0      \u00a0                  Logical Interface Input Drops      Counter              SNMP OID      IF-MIB#ifIntDiscards              OC YANG      oc-if#/interfaces/interface/state/counters/in-discards              Native YANG      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters/input-drops              MDT      Native                  \u00a0      \u00a0                  Logical Interface Output Drops      Counter              SNMP OID      IF-MIB#ifOutDiscards              OC YANG      oc-if#/interfaces/interface/state/counters/out-discards              Native YANG      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters/output-drops              MDT      Native                  \u00a0      \u00a0                  Ethernet Layer Stats \u2013 All Interfaces      Counters              SNMP OID      NA              OC YANG      oc-if#interfaces/interface/oc-eth#ethernet/oc-eth#state              Native YANG      Cisco-IOS-XR-drivers-media-eth-oper/ethernet-interface/statistics              MDT      Native                  \u00a0      \u00a0                  Ethernet PHY State \u2013 All Interfaces      Counters              SNMP OID      NA              OC YANG      oc-platform#components/component/oc-transceiver#transceiver              Native YANG      Cisco-IOS-XR-drivers-media-eth-oper/ethernet-interface/interfaces/interface/phy-info              MDT      Native                  \u00a0      \u00a0                  Ethernet Input CRC Errors      Counter              SNMP OID      NA              OC YANG      oc-if#interfaces/interface/oc-eth#ethernet/oc-eth#state/oc-eth#counters/oc-eth#in-crc-errors              Native YANG      Cisco-IOS-XR-drivers-media-eth-oper/ethernet-interface/statistics/statistic/dropped-packets-with-crc-align-errors              MDT      Native      The following transceiver paths retrieve the total power for the transceiver, there are specific per-lane power levels which can be retrieved from both native and OC models, please refer to the model YANG file for additional information            \u00a0      \u00a0                  Ethernet Transceiver RX Power      Counter              SNMP OID      NA              OC YANG      oc-platform#components/component/oc-transceiver#transceiver/oc-transceiver#physical-channels/oc-transceiver#channel/oc-transceiver#state/oc-transceiver#input-power              Native YANG      Cisco-IOS-XR-drivers-media-eth-oper/ethernet-interface/interfaces/interface/phy-info/phy-details/transceiver-rx-power              MDT      Native                  \u00a0      \u00a0                  Ethernet Transceiver TX Power      Counter              SNMP OID      NA              OC YANG      oc-platform#components/component/oc-transceiver#transceiver/oc-transceiver#physical-channels/oc-transceiver#channel/oc-transceiver#state/oc-transceiver#input-power              Native YANG      Cisco-IOS-XR-drivers-media-eth-oper/ethernet-interface/interfaces/interface/phy-info/phy-details/transceiver-tx-power              MDT      Native      A.2 BGP Operational State YANG PathsRelevant YANG Modelsopenconfig-bgp.YANGopenconfig-bgp-rib.YANGCisco-IOS-XR-ipv4-bgp-operCisco-IOS-XR-ipv6-bgp-operCisco-IOS-XR-ip-rib-ipv4-operCisco-IOS-XR-ip-rib-ipv6-operGlobal BGP Protocol StateIOS-XR native models do not store route information in the BGP Oper model, they are stored in the IPv4/IPv6 RIB models. These models contain RIB information based on protocol, with a numeric identifier for each protocol with the BGP ProtoID being 5. The protoid must be specified or the YANG path will return data for all configured routing protocols.            \u00a0      \u00a0                  BGP Total Paths (all AFI/SAFI)      Counter              SNMP OID      NA              OC YANG      oc-bgp#bgp/global/state/total-paths              Native YANG      Cisco-IOS-XR-ip-rib-ipv4-oper/rib/rib-table-ids/rib-table-id/summary-protos/summary-proto/proto-route-count/num-active-paths              MDT      Native                  \u00a0      \u00a0                  BGP Total Prefixes (all AFI/SAFI)      Counter              SNMP OID      NA              OC YANG      oc-bgp#bgp/global/state/total-prefixes              Native YANG      Cisco-IOS-XR-ip-rib-ipv4-oper/rib/rib-table-ids/rib-table-id/summary-protos/summary-proto/proto-route-count/active-routes-count              MDT      Native      BGP Neighbor StateExample UsageThe following OC NETCONF RPC returns the BGP session state for all configured peers. The neighbor-address key must be included as a container in all OC BGP state RPCs&lt;rpc message-id=~101~ xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~&gt;  &lt;get&gt;    &lt;filter&gt;      &lt;bgp xmlns=~http#//openconfig.net/YANG/bgp~&gt;        &lt;neighbors&gt;          &lt;neighbor&gt;            &lt;neighbor-address/&gt;            &lt;state&gt;              &lt;session-state/&gt;            &lt;/state&gt;          &lt;/neighbor&gt;        &lt;/neighbors&gt;      &lt;/bgp&gt;    &lt;/filter&gt;  &lt;/get&gt;&lt;/rpc&gt;\t&lt;nc#rpc-reply message-id=~urn#uuid#24db986f-de34-4c97-9b2f-ac99ab2501e3~ xmlns#nc=~urn#ietf#params#xml#ns#netconf#base#1.0~ xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~&gt;  &lt;nc#data&gt;    &lt;bgp xmlns=~http#//openconfig.net/YANG/bgp~&gt;      &lt;neighbors&gt;        &lt;neighbor&gt;          &lt;neighbor-address&gt;172.16.0.2&lt;/neighbor-address&gt;          &lt;state&gt;            &lt;session-state&gt;IDLE&lt;/session-state&gt;          &lt;/state&gt;        &lt;/neighbor&gt;        &lt;neighbor&gt;          &lt;neighbor-address&gt;192.168.2.51&lt;/neighbor-address&gt;          &lt;state&gt;            &lt;session-state&gt;IDLE&lt;/session-state&gt;          &lt;/state&gt;        &lt;/neighbor&gt;      &lt;/neighbors&gt;    &lt;/bgp&gt;  &lt;/nc#data&gt;&lt;/nc#rpc-reply&gt;            \u00a0      \u00a0                  Complete State for all BGP neighbors      Mixed              SNMP OID      NA              OC YANG      oc-bgp#bgp/neighbors/neighbor/state              Native YANG      Cisco-IOS-XR-ipv4-bgp-oper/bgp/instances/instance/instance-active/default-vrf/neighbors              MDT      Native                  \u00a0      \u00a0                  Complete State for all BGP neighbors      Mixed              SNMP OID      NA              OC YANG      oc-bgp#bgp/neighbors/neighbor/state              Native YANG      Cisco-IOS-XR-ipv4-bgp-oper/bgp/instances/instance/instance-active/default-vrf/neighbors              MDT      Native                  \u00a0      \u00a0                  Session State for all BGP neighbors      Enum              SNMP OID      NA              OC YANG      oc-bgp#bgp/neighbors/neighbor/state/session-state              Native YANG      Cisco-IOS-XR-ipv4-bgp-oper/bgp/instances/instance/instance-active/default-vrf/neighbors/neighbor/connection-state              MDT      Native                  \u00a0      \u00a0                  Message counters for all BGP neighbors      Counter              SNMP OID      NA              OC YANG      /oc-bgp#bgp/neighbors/neighbor/state/messages              Native YANG      Cisco-IOS-XR-ipv4-bgp-oper/bgp/instances/instance/instance-active/default-vrf/neighbors/neighbor/message-statistics              MDT      Native                  \u00a0      \u00a0                  Current queue depth for all BGP neighbors      Counter              SNMP OID      NA              OC YANG      /oc-bgp#bgp/neighbors/neighbor/state/queues              Native YANG      Cisco-IOS-XR-ipv4-bgp-oper/bgp/instances/instance/instance-active/default-vrf/sessions/session/messages-queued-out Cisco-IOS-XR-ipv4-bgp-oper/bgp/instances/instance/instance-active/default-vrf/sessions/session/messages-queued-in              MDT      Native      BGP RIB DataRIB data is retrieved per AFI/SAFI. To retrieve IPv6 unicast routes using OC models, replace \u201cipv4-unicast\u201d with \u201cipv6-unicast\u201dIOS-XR native models do not have a BGP specific RIB, but a protocol of \u2018bgp\u2019 can be specified in the  field to filter out prefixes to those learned via BGP. The following OC YANG NETCONF RPC retrieves a list of best-path IPv4 prefixes without attributes from the loc-RIB&lt;rpc message-id=~101~ xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~&gt;  &lt;get&gt;    &lt;filter&gt;      &lt;bgp-rib xmlns=~http#//openconfig.net/YANG/rib/bgp~&gt;        &lt;afi-safis&gt;          &lt;afi-safi&gt;            &lt;ipv4-unicast&gt;              &lt;loc-rib&gt;                &lt;routes&gt;                  &lt;route&gt;                    &lt;prefix/&gt;                    &lt;best-path&gt;true&lt;/best-path&gt;                  &lt;/route&gt;                &lt;/routes&gt;              &lt;/loc-rib&gt;            &lt;/ipv4-unicast&gt;          &lt;/afi-safi&gt;        &lt;/afi-safis&gt;      &lt;/bgp-rib&gt;    &lt;/filter&gt;  &lt;/get&gt;&lt;/rpc&gt;   The following native XR NETCONF RPC retrieves a list of BGP prefixes in its global (vrf default) IPv4 RIB, with only the prefix,prefix-length, source (route-path), and active attributes. Replacing &lt;active/&gt; with &lt;active&gt;true&lt;/active&gt; would only return active prefixes, removing the prefix,prefix-length-xr, and active leaf attributes under route will return all attributes for each route&lt;rpc message-id=~101~ xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~&gt;  &lt;get&gt;    &lt;filter&gt;      &lt;rib xmlns=~http#//cisco.com/ns/YANG/Cisco-IOS-XR-ip-rib-ipv4-oper~&gt;        &lt;vrfs&gt;          &lt;vrf&gt;            &lt;afs&gt;              &lt;af&gt;                &lt;safs&gt;                  &lt;saf&gt;                    &lt;ip-rib-route-table-names&gt;                      &lt;ip-rib-route-table-name&gt;                        &lt;routes&gt;                          &lt;route&gt;                            &lt;route-path&gt;                                &lt;ipv4-rib-edm-path&gt;                                    &lt;address/&gt;                                &lt;/ipv4-rib-edm-path&gt;                            &lt;/route-path&gt;                            &lt;prefix/&gt;                            &lt;prefix-length-xr/&gt;                            &lt;protocol-name&gt;bgp&lt;/protocol-name&gt;                            &lt;active/&gt;                          &lt;/route&gt;                        &lt;/routes&gt;                      &lt;/ip-rib-route-table-name&gt;                    &lt;/ip-rib-route-table-names&gt;                  &lt;/saf&gt;                &lt;/safs&gt;              &lt;/af&gt;            &lt;/afs&gt;            &lt;vrf-name&gt;default&lt;/vrf-name&gt;          &lt;/vrf&gt;        &lt;/vrfs&gt;      &lt;/rib&gt;    &lt;/filter&gt;  &lt;/get&gt;&lt;/rpc&gt;            \u00a0      \u00a0                  IPv4 RIB \u2013 Prefix Count      Counter              SNMP OID      NA              OC YANG      oc-bgprib#bgp-rib/afi-safis/afi-safi/ipv4-unicast/loc-rib/num-routes              Native YANG      Cisco-IOS-XR-ip-rib-ipv4-oper/rib/vrfs/vrf/afs/af/safs/saf/ip-rib-route-table-names/ip-rib-route-table-name/routes/route              MDT      Native                  \u00a0      \u00a0                  IPv4 RIB \u2013 IPv4 Prefixes w/o Attributes      List              SNMP OID      NA              OC YANG      oc-bgprib#bgp-rib/afi-safis/afi-safi/ipv4-unicast/loc-rib/routes/route/prefix              Native YANG      Cisco-IOS-XR-ip-rib-ipv4-oper/rib/vrfs/vrf/afs/af/safs/saf/ip-rib-route-table-names/ip-rib-route-table-name/routes/route (see example RPC)              MDT      Native                  \u00a0      \u00a0                  IPv4 Local RIB \u2013 IPv4 Prefixes w/Attributes      List              SNMP OID      NA              OC YANG      oc-bgprib#bgp-rib/afi-safis/afi-safi/ipv4-unicast/loc-rib/routes              Native YANG      Cisco-IOS-XR-ip-rib-ipv4-oper/rib/vrfs/vrf/afs/af/safs/saf/ip-rib-route-table-names/ip-rib-route-table-name/routes/route (see example RPC)              MDT      Native      The following per-neighbor RIB paths can be qualified with a specific neighbor address to retrieve RIB data for a specific peer. Below is an example of a NETCONF RPC to retrieve the number of post-policy routes from the 192.168.2.51 peer and the returned output.  Native IOS-XR models do not support per-neighbor RIBs, but using the above example with the route-path address leaf set to the neighbor address will filter prefixes to a specific neighbor&lt;rpc message-id=~101~ xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~&gt;  &lt;get&gt;    &lt;filter&gt;      &lt;bgp-rib xmlns=~http#//openconfig.net/YANG/rib/bgp~&gt;        &lt;afi-safis&gt;          &lt;afi-safi&gt;            &lt;ipv4-unicast&gt;              &lt;neighbors&gt;                &lt;neighbor&gt;                  &lt;neighbor-address&gt;192.168.2.51&lt;/neighbor-address&gt;                  &lt;adj-rib-in-post&gt;                    &lt;num-routes/&gt;                  &lt;/adj-rib-in-post&gt;                &lt;/neighbor&gt;              &lt;/neighbors&gt;            &lt;/ipv4-unicast&gt;          &lt;/afi-safi&gt;        &lt;/afi-safis&gt;      &lt;/bgp-rib&gt;    &lt;/filter&gt;  &lt;/get&gt;&lt;/rpc&gt;&lt;nc#rpc-reply message-id=~urn#uuid#7d9a0468-4d8d-4008-972b-8e703241a8e9~ xmlns#nc=~urn#ietf#params#xml#ns#netconf#base#1.0~ xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~&gt;  &lt;nc#data&gt;    &lt;bgp-rib xmlns=~http#//openconfig.net/YANG/rib/bgp~&gt;      &lt;afi-safis&gt;        &lt;afi-safi&gt;          &lt;afi-safi-name xmlns#idx=~http#//openconfig.net/YANG/rib/bgp-types~&gt;idx#IPV4_UNICAST&lt;/afi-safi-name&gt;          &lt;ipv4-unicast&gt;            &lt;neighbors&gt;              &lt;neighbor&gt;                &lt;neighbor-address&gt;192.168.2.51&lt;/neighbor-address&gt;                &lt;adj-rib-in-post&gt;                  &lt;num-routes&gt;3&lt;/num-routes&gt;                &lt;/adj-rib-in-post&gt;              &lt;/neighbor&gt;            &lt;/neighbors&gt;          &lt;/ipv4-unicast&gt;        &lt;/afi-safi&gt;      &lt;/afi-safis&gt;    &lt;/bgp-rib&gt;  &lt;/nc#data&gt;&lt;/nc#rpc-reply&gt;            \u00a0      \u00a0                  IPv4 Neighbor adj-rib-in pre-policy      List              SNMP OID      NA              OC YANG      oc-bgprib#bgp-rib/afi-safis/afi-safi/ipv4-unicast/neighbors/neighbor/adj-rib-in-re              MDT      NA                  \u00a0      \u00a0                  IPv4 Neighbor adj-rib-in post-policy      List              SNMP OID      NA              OC YANG      oc-bgprib#bgp-rib/afi-safis/afi-safi/ipv4-unicast/neighbors/neighbor/adj-rib-in-post              MDT      NA                  \u00a0      \u00a0                  IPv4 Neighbor adj-rib-out pre-policy      List              SNMP OID      NA              OC YANG      oc-bgprib#bgp-rib/afi-safis/afi-safi/ipv4-unicast/neighbors/neighbor/adj-rib-out-pre              MDT      NA                  \u00a0      \u00a0                  IPv4 Neighbor adj-rib-out post-policy      List              SNMP OID      NA              OC YANG      oc-bgprib#bgp-rib/afi-safis/afi-safi/ipv4-unicast/neighbors/neighbor/adj-rib-out-pre              MDT      NA      A.3 Device Resource YANG PathsCisco-IOS-XR-fretta-bcm-dpa-hw-resources-oper.YANGopenconfig-platform            \u00a0      \u00a0                  Device Inventory      List              SNMP OID      ENTITY-MIB#entityMIBObjects.entityPhysical.entPhysicalTable              OC YANG      oc-platform#components              MDT      NA                  \u00a0      \u00a0                  NCS5500 Dataplane Resources      List              SNMP OID      NA              OC YANG      NA              Native YANG      Cisco-IOS-XR-fretta-bcm-dpa-hw-resources-oper/dpa/stats/nodes/node/hw-resources-datas/hw-resources-data              MDT      Native      ", "url": "https://xrdocs.github.io/design/blogs/2017-09-21-peering-telemetry/", "tags": "iosxr, Peering, Design", "title": "Peering Telemetry", "author": "Phil Bedard"}, "tutorials-2017-05-08-pipeline-with-grpc": {"content": "     Pipeline with gRPC  Introduction  gRPC Dialout          gRPC Dialout Without TLS                  Router Config# no-tls          Pipeline.conf# tls = false                    gRPC Dialout With TLS                  Certificates for TLS Dialout          Configuring the Router for gRPC Dialout with TLS          Configuring Pipeline for tls=true                      gRPC Dialin          Common Router Config for gRPC DialIn      Common Dialin Credentials                  gRPC Dialin Without TLS          gRPC Dialin With TLS          Appendix# Secure Password Storage for Dialin                      IntroductionIn previous tutorials, I\u2019ve shown how to use Pipeline to dump Model Driven Telemetry (MDT) data into a text file and into InfluxDB.  In each case, I configured the router to transport MDT data to Pipeline using TCP.  In this tutorial, I\u2019ll cover a few additional steps that are required to use Pipeline with gRPC.  I\u2019ll focus on only the changes needed in the router and Pipeline input stage configs here, so be sure to consult the other Pipeline tutorials for important info about install, output stage, etc.If you\u2019re going to use gRPC, the first thing to decide is whether you\u2019re going to dial out from the router or dial in to the router.If you don\u2019t know the difference between dialin and dialout or need help chosing, check out my blog for some guidance.Once you\u2019ve made that decision, go the appropriate section of this tutorial# gRPC Dialout or gRPC Dialin.  For each section, there will be some \u201ccommon\u201d router and Pipeline config setps and well as some specific steps you need depending on whether or not you enable TLS.gRPC DialoutFor gRPC Dialout, the subscription and sensor-group config are the same whether you use TLS or not, so I\u2019ll re-use those parts of the MDT router config from the gRPC dialout example.  It will look like this#telemetry model-driven sensor-group SGroup2  sensor-path Cisco-IOS-XR-nto-misc-oper#memory-summary/nodes/node/summary ! subscription Sub2  sensor-group-id SGroup2 sample-interval 30000  destination-id DGroup2Now the big decision is whether to use TLS or not. This impacts the destination-group in the router config and the ingress stage of the Pipeline input stage as you\u2019ll see below.gRPC Dialout Without TLSIf you don\u2019t use TLS, your MDT data won\u2019t be encrypted.  On the other hand, it\u2019s easy to configure. So if you\u2019re new to MDT and gRPC, this might be a good starting place.Router Config# no-tlsThe gRPC config for the router is contained in the MDT destination-group.  Here is a destination-group for gRPC dialout without TLS#telemetry model-driven destination-group DGroup2  address family ipv4 172.30.8.4 port 57500   encoding self-describing-gpb   protocol grpc no-tlsAdd that to the subscription and sensor-path configuration in the commmon router config above and your router config for gRPC dialout without TLS is done.Pipeline.conf# tls = falseYou can use the [gRPCDIalout] input stage in the default pipeline.conf from github.  Just uncomment the 6 lines shown below.$ grep -A25 ~gRPCDialout~ pipeline.conf | grep -v -e '^#' -e '^$'[gRPCDialout] stage = xport_input type = grpc encap = gpb listen = #57500 tls = falseIf you now run pipeline with the debug option, you should see these lines when Pipeline starts and the router (at 172.30.8.53) connects#$ bin/pipeline -config pipeline.conf -log= -debug | grep gRPCINFO[2017-05-08 11#25#50.046573] gRPC starting block                           encap=gpb name=grpcdialout server=#57500 tag=pipeline type=~pipeline is SERVER~INFO[2017-05-08 11#25#50.046902] gRPC# Start accepting dialout sessions        encap=gpb name=grpcdialout server=#57500 tag=pipeline type=~pipeline is SERVER~INFO[2017-05-08 11#26#03.572534] gRPC# Receiving dialout stream                encap=gpb name=grpcdialout peer=~172.30.8.53#61857~ server=#57500 tag=pipeline type=~pipeline is SERVER~And that\u2019s it.  You\u2019re done.  Telemetry data is streaming into pipeline and you can do with it what you want.  You can stop reading now unless you want to experiment with TLS.gRPC Dialout With TLSIn a dialout scenario, the router is the \u201cclient\u201d and Pipeline is the \u201cserver.\u201d  Therefore, in the TLS handshake, Pipeline will need to send a certificate to authenticate itself to the router.  The router validates Pipeline\u2019s certificate using the public certificate of the Root Certificate Authority (CA) that signed it and then generates sesssion keys to encrypt the session.To make this all work, you need the following#  A Root CA certificate  A Pipeline certificate signed by the Root CA  A copy of the Root CA certificate on the routerFor the purpose of this tutorial, I will use openssl (an open-source TLS toolkit) for the root CA and Pipeline certificate.  If your organization has an existing PKI, you can skip the first two steps and just copy the Root CA certificate to the router.Certificates for TLS Dialout1. The rootCA Key and CertificateFor simplicity, I\u2019ll generate the rootCA on the same server that I am running Pipeline.  First, create a rootCA key-pair (may require sudo)#scadora@darcy#/etc/ssl/certs$ openssl genrsa -out rootCA.key 2048Generating RSA private key, 2048 bit long modulus...........+++................................+++e is 65537 (0x10001)scadora@darcy#/etc/ssl/certs$Now use that key to self-sign the rootCA certificate.  It will ask you a bunch of questions that you can fill out as you want (I just used all defaults)#scadora@darcy#/etc/ssl/certs$ sudo openssl req -x509 -new -nodes -key rootCA.key -sha256 -days 1024 -extensions v3_ca -config ../openssl.cnf -out rootCA.pem You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter '.', the field will be left blank.-----Country Name (2 letter code) [AU]#State or Province Name (full name) [Some-State]#Locality Name (eg, city) []#Organization Name (eg, company) [Internet Widgits Pty Ltd]#Organizational Unit Name (eg, section) []#Common Name (e.g. server FQDN or YOUR name) []#Email Address []#scadora@darcy#/etc/ssl/certs$You should now have a rootCA certificate called rootCA.pem.2. The Pipeline CertificateFirst, create a key pair for Pipeline.  In this case, I\u2019ve called it \u201cdarcy.key\u201d since darcy is the name of the server on which I am running Pipeline.scadora@darcy#/etc/ssl/certs$  sudo openssl genrsa -out darcy.key 2048Generating RSA private key, 2048 bit long modulus................+++..+++e is 65537 (0x10001)scadora@darcy#/etc/ssl/certs$Next, create a Certificate Signing Request (CSR) using the key you just generated.  In the following, I use all the defaults except for the Common Name, which I set as darcy.cisco.com#scadora@darcy#/etc/ssl/certs$ openssl req -new -key darcy.key -out darcy.csrYou are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter '.', the field will be left blank.-----Country Name (2 letter code) [AU]#State or Province Name (full name) [Some-State]#Locality Name (eg, city) []#Organization Name (eg, company) [Internet Widgits Pty Ltd]#Organizational Unit Name (eg, section) []#Common Name (e.g. server FQDN or YOUR name) []#darcy.cisco.exampleEmail Address []#Please enter the following 'extra' attributesto be sent with your certificate requestA challenge password []#An optional company name []#scadora@darcy#/etc/ssl/certs$Finally, use your rootCA certificate to sign the CSR (\u201cdarcy.csr\u201d) you just generated and create a certificate for Pipeline (\u201cdarcy.pem\u201d)#scadora@darcy#/etc/ssl/certs$ openssl x509 -req -in darcy.csr -CA rootCA.pem -CAkey rootCA.key -CAcreateserial -out darcy.pem -days 500 -sha256Signature oksubject=/C=AU/ST=Some-State/O=Internet Widgits Pty Ltd/CN=darcy.cisco.exampleGetting CA Private Keyscadora@darcy#/etc/ssl/certs$Note# Some people issue certificates with a Common Name set to the IP address of the server instead of a FQDN.  Should you do this for the Pipeline certificate, bear in mind that the certificate will also need to have a Subject Alternative Name section that explicitly lists all valid IP addresses.  If you see the following message in your grpc trace, this could be your problem.RP/0/RP0/CPU0#SunC#show grpc trace emsTue May 16 19#35#44.792 UTC3 wrapping entries (141632 possible, 320 allocated, 0 filtered, 3 total)May 16 19#35#40.240 ems/grpc 0/RP0/CPU0 t26842 EMS-GRPC# grpc# Conn.resetTransport failed to create client transport# connection error# desc = ~transport# x509# cannot validate certificate for 172.30.8.4 because it doesn't contain any IP SANs~For more info on certificates with IP Addresses, take a look at this discussion.3. Copy rootCA Certificate to the routerFor the router to validate Pipeline\u2019s certificate, it needs to have a copy of the rootCA certificate in /misc/config/grpc/dialout/dialout.pem (the filename is important!).  Here is how to scp the rootCA.pem to the appropriate file and directory#RP/0/RP0/CPU0#SunC#bashTue May 16 18#06#04.592 UTC[xr-vm_node0_RP0_CPU0#~]$ scp scadora@172.30.8.4#//etc/ssl/certs/rootCA.pem /misc/config/grpc/dialout/dialout.pemrootCA.pem                                    100% 1204     1.2KB/s   00#00[xr-vm_node0_RP0_CPU0#~]$Configuring the Router for gRPC Dialout with TLSIn addition to the common sensor-group and subscription configuration that we configured on the router at the beginning of the Dialout section, we also need a destination-group. TLS is the default for MDT for gRPC, so the destination-group config just looks like this#telemetry model-driven destination-group DGroup2  address family ipv4 172.30.8.4 port 57500   encoding self-describing-gpb   protocol grpc tls-hostname darcy.cisco.exampleIn that last line, the tls-hostname (darcy.cisco.example) must match the Common Name (CN) in Pipeline\u2019s certificate.Configuring Pipeline for tls=trueWe can use the [gRPCDIalout] input stage in the default pipeline.conf.  The only change is the last 4 lines where we enable tls and set the pem, key and servername to the values corresponding to the Pipeline certificate we generated earlier.scadora@darcy#~/bigmuddy-network-telemetry-pipeline$ grep -A30 ~gRPCDialout~ pipeline.conf | grep -v -e '^#' -e '^$'[gRPCDialout] stage = xport_input type = grpc encap = gpb listen = #57500 tls = true tls_pem = /etc/ssl/certs/darcy.pem tls_key = /etc/ssl/certs/darcy.key tls_servername = darcy.cisco.exampleAnd that\u2019s it.  Run pipeline as usual and you\u2019ll see the router connect#scadora@darcy#~/bigmuddy-network-telemetry-pipeline$ sudo bin/pipeline -config pipeline.conf -log= -debug | grep gRPCINFO[2017-05-16 13#00#40.976896] gRPC starting block                           encap=gpb name=grpcdialout server=#57500 tag=pipeline type=~pipeline is SERVER~INFO[2017-05-16 13#00#40.977505] gRPC# Start accepting dialout sessions        encap=gpb name=grpcdialout server=#57500 tag=pipeline type=~pipeline is SERVER~INFO[2017-05-16 13#01#09.775514] gRPC# Receiving dialout stream                encap=gpb name=grpcdialout peer=~172.30.8.53#59865~ server=#57500 tag=pipeline type=~pipeline is SERVER~On the router, the grpc trace will show you the server name (darcy.cisco.example) of the received certificate.RP/0/RP0/CPU0#SunC#show grpc trace emsTue May 16 20#01#15.059 UTC2 wrapping entries (141632 possible, 320 allocated, 0 filtered, 2 total)May 16 20#01#06.757 ems/conf 0/RP0/CPU0 t26859 EMS-CONF#emsd_is_active_role get proc role (1)May 16 20#01#06.759 ems/info 0/RP0/CPU0 t26843 EMS_INFO# nsDialerCheckAddTLSOption#322 mdtDialout# TLS pem# /misc/config/grpc/dialout/dialout.pem, Server host# darcy.cisco.exampleRP/0/RP0/CPU0#SunC#That\u2019s it.  You\u2019re done with gRPC Dialout with TLS.  No need to read further.gRPC DialinIn a dialin scenario, Pipeline sends the TCP SYN packet and acts as the \u201cclient\u201d in the gRPC session and TLS handshake (if you\u2019re configuring TLS).Common Router Config for gRPC DialInFor this part of the tutorial, I\u2019ll re-use the MDT router config from the gRPC dialin example  It should look like this#grpc port 57500!telemetry model-driven sensor-group SGroup3  sensor-path openconfig-interfaces#interfaces/interface ! subscription Sub3  sensor-group-id SGroup3 sample-interval 30000Note that there is no destination-group for dialin.Common Dialin CredentialsRegardless of whether you use TLS or not, Pipeline will have to provide a username and password when it first connects to the router.On the router side, you need to configure a username and password that Pipeline can use when it dials in.  If you\u2019re just doing a quick test in the lab, assign the user to one of these default usergroups# sysadmin, netadmin, or root-lr.  For example#username mdt group sysadmin secret 5 $1$kAbv$xNk9KA.mIC7K2wfdpGjzk1If you want to be more restrictive, here is the minimal taskgroup that you will need to support telemetry for gRPC dialin#taskgroup mdt-grpc task read li task read acl task read cdp task read eem task read boot task read diag task read ipv4 task read ipv6 task read snmp task read vpdn task read crypto task read system task read logging task read fault-mgr task read interface task read ext-access task read filesystem task read tty-access task read config-mgmt task read ip-services task read host-services task read basic-services task read config-services!usergroup mdt-grpc taskgroup mdt-grpc!username mdt group mdt-grpc secret 5 $1$kAbv$xNk9KA.mIC7K2wfdpGjzk1Next, you get to decide if you want to use TLS or not.gRPC Dialin Without TLSIf you don\u2019t use TLS, your MDT data won\u2019t be encrypted.  On the other hand, there\u2019s less fiddling with certificates. So if you\u2019re trying to get gRPC dialin to work for the first time, this might be a good starting place. There\u2019s nothing you need to add to the router config for this beyond the common router config and credentials we did above. You just need to configure and run Pipeline as shown below.You can use the [mymdtrouter] input stage in the default pipeline.conf.  Just uncomment the 8 lines shown below, changing the server line to match your router\u2019s IP address and configured gRPC port#$ grep -A48 ~mymdtrouter~ pipeline.conf | grep -v -e '^#' -e '^$' [mymdtrouter] stage = xport_input type = grpc encoding = gpbkv encap = gpb server = 172.30.8.53#57500 subscriptions = Sub3 tls = falseNote that the subscription is \u201cSub3\u201d, which matches the subscription in the router configuration above.  Pipeline will request the pre-configured subscription from the router when it connects.When you run pipeline, you will be prompted for a username and password.  This is the username and password that you configured on the router above.$ bin/pipeline -config pipeline.confStartup pipelineLoad config from [pipeline.conf], logging in [pipeline.log]CRYPT Client [mymdtrouter],[172.30.8.53#57500] Enter username# mdt Enter password#Wait for ^C to shutdownIf you don\u2019t want to have to manually enter the username and password each time you run Pipeline, check out the section below on secure password storage in pipeline.To verify that the connection is established, check that the subscription Destination Group State is Active. Also note that the Destination Group Id has been dynamically created (since we don\u2019t configure a destination-group on the router for dialin) and begins with \u201cDialIn_.\u201dRP/0/RP0/CPU0#SunC#show telemetry model sub Sub3Thu May 18 20#46#38.658 UTCSubscription#  Sub3-------------  State#       ACTIVE  Sensor groups#  Id# SGroup3    Sample Interval#      30000 ms    Sensor Path#          openconfig-interfaces#interfaces/interface    Sensor Path State#    Resolved  Destination Groups#  Group Id# DialIn_1019    Destination IP#       172.30.8.4    Destination Port#     48667    Encoding#             self-describing-gpb    Transport#            dialin    State#                Active    No TLS    Total bytes sent#     5723    Total packets sent#   4    Last Sent time#       2017-05-18 20#46#28.2143492698 +0000That\u2019s it, you\u2019re done.  No need to read the next section unless you want to do TLS.gRPC Dialin With TLSIn a dialin scenario, Pipeline acts as the \u201cclient\u201d in the TLS handshake.  Therefore, the router will need to send a certificate to authenticate itself to Pipeline.There are a couple ways to go about creating the router certificate. If you already have a root CA, you can issue a certificate for the router.  However, because this tutorial is far too long already, I\u2019m going to take the easy way out and use a self-signed certificate.Router Certificate and Config for gRPC TLS DialInThe first thing we have to do is enable the gRPC service on the router for TLS by adding \u201ctls\u201d to the grpc config on the router#grpc port 57500 tlsOnce you do this, the router automatically generates a self-signed cert called \u201cems.pem\u201d#RP/0/RP0/CPU0#SunC#bashThu May 18 23#05#51.266 UTC[xr-vm_node0_RP0_CPU0#~]$cd /misc/config/grpc[xr-vm_node0_RP0_CPU0#/misc/config/grpc]$lsdialout  ems.key  ems.pem[xr-vm_node0_RP0_CPU0#/misc/config/grpc]$You can use standard openssl commands to view the cert#[xr-vm_node0_RP0_CPU0#/misc/config/grpc]$openssl x509 -noout -text -in ems.pemCertificate#    Data#        Version# 3 (0x2)        Serial Number# 1789 (0x6fd)    Signature Algorithm# sha512WithRSAEncryption        Issuer# C=US, ST=CA, L=San Jose/street=3700 Cisco Way/postalCode=95134, O=Cisco Systems, Inc., OU=CSG, CN=ems.cisco.com/serialNumber=949DF85F746        Validity            Not Before# May 18 22#49#51 2017 GMT            Not After # May 18 22#49#51 2037 GMT        Subject# C=US, ST=CA, L=San Jose/street=3700 Cisco Way/postalCode=95134, O=Cisco Systems, Inc., OU=CSG, CN=ems.cisco.com/serialNumber=949DF85F746        Subject Public Key Info#            Public Key Algorithm# rsaEncryption                Public-Key# (2048 bit)                Modulus#                    00#cf#89#9e#7a#14#5f#6a#f4#8a#75#ce#69#07#00#                    38#2d#5d#1f#71#f5#cb#69#37#3b#6d#9b#20#ab#47#                    9e#2b#b6#4b#be#30#1e#54#81#76#4f#61#91#de#4e#                    47#80#b2#6d#0c#f3#2a#69#be#85#67#ca#a3#80#7f#                    bc#40#2e#63#5d#c9#ec#a4#fc#60#ae#b2#10#2a#f9#                    de#02#11#50#5a#1e#43#c9#3a#95#6b#9f#fa#3d#f4#                    db#1f#a9#6d#bd#7b#0b#d8#87#64#08#26#2b#54#82#                    42#2f#a2#7e#36#64#9b#42#9a#ff#bf#19#25#2f#42#                    3e#9d#94#af#fc#ea#62#ef#ec#57#20#57#d9#39#c5#                    bd#77#5c#a9#01#76#e1#2c#69#67#6f#b7#30#f8#f8#                    2c#d1#2c#25#de#66#46#fb#49#30#a7#c9#9c#14#b0#                    70#f4#3f#b2#62#8c#5c#c6#8f#a2#e3#de#75#c3#c3#                    e5#72#1f#4e#40#d4#bd#1b#2a#27#19#e7#80#b3#c9#                    cb#56#4e#5c#99#42#d6#97#23#04#6d#9c#9e#f0#d2#                    0e#8b#5c#02#09#d1#c8#31#04#23#b4#f1#b4#41#a2#                    44#b5#16#fd#c3#80#a5#3d#39#26#de#94#2b#db#22#                    d0#0b#07#92#2d#6a#24#37#d4#db#b2#29#23#f3#00#                    88#13                Exponent# 65537 (0x10001)        X509v3 extensions#            X509v3 Basic Constraints# critical            CA#TRUE            X509v3 Subject Key Identifier#                1C#B6#98#EF#7F#A4#1D#07#0B#6F#73#01#08#E6#0C#8C#97#AC#E0#A2            X509v3 Authority Key Identifier#                keyid#1C#B6#98#EF#7F#A4#1D#07#0B#6F#73#01#08#E6#0C#8C#97#AC#E0#A2    Signature Algorithm# sha512WithRSAEncryption         60#97#b9#e2#cb#d5#1d#b0#48#d5#68#fa#aa#a6#36#de#e3#64#         1f#6a#7f#4b#3e#9c#42#e8#59#23#26#14#c1#b1#0e#f3#17#d5#         34#71#4c#79#6f#f7#62#94#21#a2#d7#d4#99#cc#9c#f2#29#2a#         38#79#19#83#fd#a9#16#df#0e#35#55#5e#11#b5#b7#3f#e6#10#         0d#71#c7#3d#2d#9b#41#44#09#9b#b3#98#64#ab#9e#33#f3#08#         a9#f0#6b#62#93#18#7e#ff#14#a7#ea#c2#c3#3b#ed#a6#b3#69#         25#07#04#41#23#82#c6#12#23#6d#e0#14#80#7c#10#dd#ea#06#         8e#e6#78#f5#42#a0#3e#21#81#7d#48#29#18#29#0a#ef#ce#a1#         7c#38#7b#e8#17#44#db#24#37#ba#1c#53#6d#9d#6f#d2#5c#2a#         69#b5#11#13#4d#7c#cc#3d#44#d2#96#fa#71#41#3a#b6#ab#6e#         e7#b1#ff#53#db#e8#95#5c#67#68#51#80#ab#24#e0#7e#8e#fe#         e1#af#36#8c#bc#b2#3a#69#3f#33#bc#b6#36#25#ad#78#49#d1#         2e#43#6f#f8#80#c3#1c#21#89#cd#da#9f#3d#62#ec#79#1b#b0#         77#0d#96#c8#c8#26#25#0b#94#ae#21#14#d1#1b#e0#f7#11#af#         61#ce#13#74[xr-vm_node0_RP0_CPU0#/misc/config/grpc]$As you can see, this certificate has been issued for a CN=ems.cisco.com and is a CA certificate.Since this is also the CA cert (it\u2019s self-signed), we\u2019ll transfer it to the server running Pipeline.[xr-vm_node0_RP0_CPU0#/misc/config/grpc]$ scp ems.pem scadora@172.30.8.4#scadora@172.30.8.4's password#ems.pem                                       100% 1513     1.5KB/s   00#00    [xr-vm_node0_RP0_CPU0#/misc/config/grpc]$Pipeline for gRPC Dialin with TLSAll that\u2019s left is to configure pipeline.conf for TLS.You can use the [mymdtrouter] input stage in the default pipeline.conf.  Uncomment the 10 lines shown below and do the following#  change the server line to match your router\u2019s IP address and configured gRPC port.  set tls to \u201ctrue\u201d  set tls_pem to the full path and filename of the ems.pem file you copied from the router above.  set tls_pem to the CN of the router\u2019s certificate (\u201cems.cisco.com\u201d)$ grep -A48 ~mymdtrouter~ pipeline.conf | grep -v -e '^#' -e '^$'[mymdtrouter] stage = xport_input type = grpc encoding = gpbkv encap = gpb server = 172.30.8.53#57500 subscriptions = Sub3 tls = true tls_pem = /home/scadora/ems.pem tls_servername = ems.cisco.comNote that the subscription is \u201cSub3\u201d, which matches the subscription in the router configuration above.  Pipeline will request the pre-configured subscription from the router when it connects.When you run pipeline, you will be prompted for a username and password.  This is the username and password that you configured on the router above.$ bin/pipeline -config pipeline.confStartup pipelineLoad config from [pipeline.conf], logging in [pipeline.log]CRYPT Client [mymdtrouter],[172.30.8.53#57500] Enter username# mdt Enter password#Wait for ^C to shutdownIf you don\u2019t want to have to manually enter the username and password each time you run Pipeline, check out the section below on secure password storage in pipeline.To verify that the connection is established, check that the subscription Destination Group State is Active. Also note that the Destination Group Id has been dynamically created (since we don\u2019t configure a destination-group on the router for dialin) and beings with \u201cDialIn_.\u201dRP/0/RP0/CPU0#SunC#show telemetry model-driven subscription Sub3Fri May 19 16#48#22.396 UTCSubscription#  Sub3-------------  State#       ACTIVE  Sensor groups#  Id# SGroup3    Sample Interval#      30000 ms    Sensor Path#          openconfig-interfaces#interfaces/interface    Sensor Path State#    Resolved  Destination Groups#  Group Id# DialIn_1030    Destination IP#       172.30.8.4    Destination Port#     57590    Encoding#             self-describing-gpb    Transport#            dialin    State#                Active    TLS #                 True    Total bytes sent#     11446    Total packets sent#   8    Last Sent time#       2017-05-19 16#48#12.1233215666 +0000That\u2019s it, you\u2019re done.  Have fun with your telemetry data!Appendix# Secure Password Storage for DialinBecause Pipeline cares about your security, it won\u2019t let you store unencrypted router passwords in pipeline.conf.  If you dislike being prompted for a password every time you run it or you want to run pipeline in the background, you can have pipeline encrypt the password using the -pem option and store it in a new file as follows#$ bin/pipeline -config pipeline.conf -pem ~/.ssh/id_rsaStartup pipelineLoad config from [pipeline.conf], logging in [pipeline.log]CRYPT Client [mymdtrouter],[172.30.8.53#57500] Enter username# mdt Enter password#Generating sample config...A new configuration file [pipeline.conf_REWRITTEN] has been written including user name and encrypted password.In future, you can run pipeline non-interactively.Do remember to run pipeline with '-pem /home/scadora/.ssh/id_rsa -config pipeline.conf_REWRITTEN' options.Wait for ^C to shutdownIf you take a look at the [mymdtrouter] stage in pipeline.conf_REWRITTEN, you\u2019ll see that the username and encrypted password are included#$ grep -A10 ~mymdtrouter~ pipeline.conf_REWRITTEN | grep -v -e '^#' -e '^$'[mymdtrouter]subscriptions=Sub3password=PZbS/IG4O+2lsok3xxBjQZwJ5CFyraixl//qdNy67IRMM1YMLlWqbbGHUXVGM1pX0HfKf7JU1beRivkOcwyANPff4hVmF5b7Ne1SBxnKS4VqSU+AMCN/e+FFHFrCA24m0ywTYB/Dt2PJZaUCQmYzxTwa71+Vxc7lHe2dtovH/DGutQfvRa2On6aHeqiQfMbBcEeKqwya4jtmexS11Dt1ai1QXqWgn2WiggvWTGcldANO4Nfkl4vICguVlrVEfNv16qNoPB/HerTNCuGLlBR0EBhxGPxCJteexAxadt68whG4UP/teTiD2qFZ2UFXCRnpnPvpic9LIZIaF4PgNg9AGw==server=172.30.8.53#57500type=grpcencoding=gpbkvencap=gpbtls=falseusername=mdtstage=xport_inputNow you can run pipeline with the rewritten .conf file and it won\u2019t prompt you for the username again#$ sudo bin/pipeline -config pipeline.conf_REWRITTEN -pem ~/.ssh/id_rsaStartup pipelineLoad config from [pipeline.conf_REWRITTEN], logging in [pipeline.log]Wait for ^C to shutdown", "url": "https://xrdocs.github.io/telemetry/tutorials/2017-05-08-pipeline-with-grpc/", "tags": "iosxr, telemetry, gRPC, MDT, pipeline", "title": "Pipeline with gRPC", "author": "Shelly Cadora"}, "blogs-2016-10-17-ios-xr-users-and-groups-inside-linux": {"content": "     IOS-XR# Linux users and groups  XR and Linux Users  Gaining Root Privilege  XR and Linux UsersBy default, any user created inside XR is automatically replicated including that user\u2019s password inside Linux using a unique UID and GID.This allows basic access into the Linux shell for all XR configured user, the administrator can create multiple users directly from the XR console if desired.Inside Linux, nine special groups are created by default, each of these groups maps to one of the default XR groups. When the administrator creates a user belonging to one of the default XR group, that user get replicated inside Linux and added to that special Linux group. In addition, XR users that are member of certain default group are granted root access to Linux when they issue the \u201cbash\u201d or \u201crun\u201d command (see table below).            XR Group      Linux Group      GID      Role      Access Linux from XR              cisco-support      cisco-support      1000      Cisco support personnel tasks      n/a (add-on group for root-lr users)              maintenance      maintenance      1001      \u00a0      Yes              netadmin      netadmin      1002      Network administrator tasks      No              provisioning      provisioning      1003      \u00a0      Yes              retrieve      retrieval      1004      \u00a0      No              root-lr      root-lr      1005      Secure domain router administrator tasks      Yes              n/a      root-system      1006      System-wide administrator tasks      Compatibility with previous IOS-XR              serviceadmin      serviceadmin      1007      Service administration tasks      No              sysadmin      sysadmin      1008      System administrator tasks      No              operator      operator      37      Operator day-to-day tasks (demo)      No      In the following example, the administrator creates a user \u201ctest10\u201d member of the maintenance group, which allow the user to enter the Linux shell as root (uid/gid# 0) via the run command, the user \u201ctest10\u201d (uid# 1010) is member of the group \u201ctest10\u201d (gid#1019) and secondary group maintenance (gid#1001)RP/0/RP0/CPU0#pod-rtr(config)#username test10 group maintenanceRP/0/RP0/CPU0#pod-rtr(config)#username test10 password test10RP/0/RP0/CPU0#pod-rtr(config)#commitRP/0/RP0/CPU0#pod-rtr(config)#endRP/0/RP0/CPU0#pod-rtr#exit...Username# test10Password#RP/0/RP0/CPU0#pod-rtr#bashTue Mar 29 03#06#41.759 UTC[xr-vm_node0_RP0_CPU0#~]$iduid=0(root) gid=0(root) groups=0(root)[xr-vm_node0_RP0_CPU0#~]$id test10uid=1010(test10) gid=1019(test10) groups=1019(test10),1001(maintenance)Gaining Root PrivilegeInside Linux the file /etc/sudoers only allows root to do everything on any machine as any user ~root ALL=(ALL) ALL~. No other user can gain root privilege by default, The administrator will have to modify the /etc/sudoers as root to allow other users to gain root access via the sudo command.These measures ensure that only the users with access to the \u201crun\u201d or \u201cbash\u201d command can create initial users in the Linux shell and provide sudo access.A common practice is to allow all members of the sudo group (GID# 27) root privileges. This is done by un-commenting the line ~#%sudo ALL=(ALL) ALL~ as root in the \u201c/etc/sudoers\u201d file and add users to the sudo group.[xr-vm_node0_RP0_CPU0#~]$usermod -a -G sudo test10[xr-vm_node0_RP0_CPU0#~]$id test10uid=1010(test10) gid=1019(test10) groups=1019(test10),27(sudo),1001(maintenance)After the line has been modified any user member of the sudo group can gain root privilege using the sudo command. Sudo logs each command, providing a clear audit trail of who did what, Sudo uses timestamp files to implement a \u201cticketing\u201d system. When a user invokes sudo and enters their password, they are granted a ticket for 5 minutes. for more information on sudoers visit sudo main pageUpdate# Since 6.1.1 All members of the the sudo group can gain root privilege using \u201csudo\u201d by default.", "url": "https://xrdocs.github.io/software-management/blogs/2016-10-17-ios-xr-users-and-groups-inside-linux/", "tags": "iosxr, cisco, linux", "title": "IOS-XR users and groups inside Linux", "author": "Patrick Warichet"}, "tutorials-2016-08-15-netmiko-and-napalm-with-ios-xr-quick-look": {"content": "     IOS-XR# Ansible and Vagrant  Introduction          Module installation      Example using Netmiko      Example using NAPALM        IntroductionTo begin with, let\u2019s take a look the tools we intend to use#Netmiko - multi-vendor ssh tool for device configurationNAPALM- python based automation tool, which provides a common API for different vendor platforms.We will use old setup, which consist of devbox (Ubuntu instance) and rtr (IOS-XRv)  link.We are interested in our interaction with IOS-XRv in particular.Module installationLet\u2019s install python modules on devbox#sudo pip install netmikosudo pip install napalmTo start off, we should verify that the setup was successful. Run python interpreter#vagrant@vagrant-ubuntu-trusty-64#~$ pythonPython 2.7.6 (default, Jun 22 2015, 17#58#13)[GCC 4.8.2] on linux2Type ~help~, ~copyright~, ~credits~ or ~license~ for more information.&gt;&gt;&gt; import netmiko&gt;&gt;&gt; import napalm&gt;&gt;&gt;Example using NetmikoCreate the first file and try to connect to the device.from netmiko import ConnectHandlercisco_ios_xrv = {    'device_type'# 'cisco_xr',    'ip'#   '10.1.1.20',    'username'# 'vagrant',    'password'# 'vagrant',    'port' # 22,          # optional, defaults to 22    'secret'# 'secret',     # optional, defaults to ''    'verbose'# False,       # optional, defaults to False}net_connect = ConnectHandler(**cisco_ios_xrv)output = net_connect.send_command('show ip int brief')print(output)output = net_connect.send_config_set(['hostname my_sweet_rtr', 'commit'])print(output)output = net_connect.send_command('show run | b hostname')print(output)Script output#vagrant@vagrant-ubuntu-trusty-64#~$ python netmiko_tut.pyFri Jul 15 12#29#07.691 UTCInterface                      IP-Address      Status          Protocol Vrf-NameGigabitEthernet0/0/0/0         10.1.1.20       Up              Up       defaultMgmtEth0/RP0/CPU0/0            10.0.2.15       Up              Up       defaultconfig termFri Jul 15 12#29#09.739 UTCRP/0/RP0/CPU0#my_sweetest_rtr(config)#hostname my_sweetest_rtrRP/0/RP0/CPU0#my_sweetest_rtr(config)#commitFri Jul 15 12#29#10.332 UTCendconfig termFri Jul 15 12#29#12.475 UTCRP/0/RP0/CPU0#my_sweetest_rtr(config)#show run | include hostnameFri Jul 15 12#29#13.052 UTCBuilding configuration...hostname my_sweetest_rtrRP/0/RP0/CPU0#my_sweetest_rtr(config)#Now we can proceed with a more serious example. We will use a separate file with the router configuration. Open this file in python, read the lines individually and make a list of commands from it.vagrant@vagrant-ubuntu-trusty-64#~$ cat tel_conftelemetry encoder json  policy group FirstGroup   policy test    transport tcp    !   destination ipv4 10.1.1.10 port 2103commitPython piece of code to split lines into list with commands#with open('tel_conf') as f#    lines = f.read().splitlines()print linestel_out =  net_connect.send_config_set(lines)print tel_outRun python file#vagrant@vagrant-ubuntu-trusty-64#~$ python netmiko_tut.pyconfig termThu Jul 14 23#49#25.447 UTCRP/0/RP0/CPU0#xr(config)#telemetryRP/0/RP0/CPU0#xr(config-telemetry)# encoder jsonRP/0/RP0/CPU0#xr(config-telemetry-json)#  policy group FirstGroupRP/0/RP0/CPU0#xr(config-policy-group)#   policy testRP/0/RP0/CPU0#xr(config-policy-group)#    transport tcpRP/0/RP0/CPU0#xr(config-telemetry-json)#    !RP/0/RP0/CPU0#xr(config-telemetry-json)#   destination ipv4 10.1.1.10 port 2103RP/0/RP0/CPU0#xr(config-policy-group)#commitThu Jul 14 23#49#26.400 UTCRP/0/RP0/CPU0#xr(config-policy-group)#Verify that config is here#RP/0/RP0/CPU0#my_sweet_rtr#show run | begin telemetryThu Jul 14 20#58#19.116 UTCBuilding configuration...xml agent ssl!xml agent tty!telemetry encoder json  policy group FirstGroup   policy test   transport tcp   !   destination ipv4 10.1.1.10 port 2103  ! !!endUseful commands#device.send_command('show ip int brief')Example using NAPALMFile for telemetry configuration will be used. We can change destination port from 2103 to 2109 to try diff command.At current moment commands related to configuration management doesn\u2019t respond correctly, but informative commands work fine#vagrant@vagrant-ubuntu-trusty-64#~$ cat napalus.pyfrom napalm import get_network_driverdriver = get_network_driver('iosxr')device = driver('10.1.1.20', 'vagrant', 'vagrant')device.open()# print device.get_facts() ## doesn't workprint device.get_interfaces()print ''print device.get_interfaces_counters()print ''print device.get_users()device.close()Output will look like#{    'GigabitEthernet0/0/0/0'# {        'is_enabled'# True,        'description'# u '',        'last_flapped'# -1.0,        'is_up'# True,        'mac_address'# u '0800.27b2.5406',        'speed'# 1000    }}{    'GigabitEthernet0/0/0/0'# {        'tx_multicast_packets'# 0,        'tx_discards'# 0,        'tx_octets'# 6929839,        'tx_errors'# 0,        'rx_octets'# 586788,        'tx_unicast_packets'# 10799,        'rx_errors'# 0,        'tx_broadcast_packets'# 0,        'rx_multicast_packets'# 0,        'rx_broadcast_packets'# 3,        'rx_discards'# 0,        'rx_unicast_packets'# 9421    }}{    u 'vagrant'# {        'password'# '',        'sshkeys'# [],        'level'# 15    }}For more details and list of available methods#Netmiko githubNAPALM libraryNAPALM list of commandsGood luck with further automation!", "url": "https://xrdocs.github.io/application-hosting/tutorials/2016-08-15-netmiko-and-napalm-with-ios-xr-quick-look/", "tags": "vagrant, iosxr, Python", "title": "Netmiko and Napalm with IOS-XR: Quick Look", "author": "Mike Korshunov"}, "blogs-2018-04-30-metro-fabric-hld": {"content": "     On This Page  Value Proposition          Summary        Technical Overview  Transport \u2013 Design          Use Cases      Intra-Domain                  Intra-Domain Routing and Forwarding          Intra-Domain Forwarding - Fast Re-Route                    Inter-Domain                  Inter-Domain Forwarding          Area Border Routers \u2013 Prefix-SID vs Anycast-SID          Inter-Domain Forwarding - Label Stack Optimization          Inter-Domain Forwarding - High Availability and Fast Re-Route                    Transport Programmability      Transport Controller Path Computation Engine (PCE)                  Segment Routing Path Computation Element (SR-PCE)          WAN Automation Engine (WAE)          PCE Controller Summary \u2013 SR-PCE &amp; WAE          Path Computation Engine \u2013 Workflow                          Delegated Computation to SR-PCE              WAE Instantiated LSP              Delegated Computation to WAE                                            Transport \u2013 Segment Routing IPv6 Data Plane (SRv6)          Best-Effort Path      Low-Latency Path      SRv6 \u2013 Inter-Domain Forwarding      SRv6 Conclusion        Services \u2013 Design          Overview      Ethernet VPN (EVPN)                  Multi-Homed &amp; All-Active Ethernet Access          Service Provider Network - Integration with Central Office or with Data Center                    End-To-End (Flat) \u2013 Services      Hierarchical \u2013 Services                  Hierarchical L2 Multipoint Multi-Homed/All-Active          Hierarchical L2/L3 Multi/Single-Home, All/Single-Active Service (H-EVPN) and Anycast-IRB          Hierarchical L2/L3 Multipoint Multi-Homed/Single-Active (H-EVPN) and PWHE                    Services \u2013 Router-Reflector (S-RR)      Network Services Orchestrator (NSO)        Transport and Services Integration  The Compass Metro Fabric Design \u2013 Phase 1          Transport - Phase 1      Transport Programmability \u2013 Phase 1      Services \u2013 Phase 1      Transport and Services Integration \u2013 Phase 1        The Compass Metro Fabric Design - Summary  Value PropositionService Providers are facing the challenge to provide next generationservices that can quickly adapt to market needs. New paradigms such as5G introduction, video traffic continuous growth, IoT proliferation andcloud services model require unprecedented flexibility, elasticity andscale from the network. Increasing bandwidth demands and decreasing ARPUput pressure on reducing network cost. At the same time, services needto be deployed faster and more cost effectively to stay competitive.Metro Access and Aggregation solutions have evolved from nativeEthernet/Layer 2 based, to Unified MPLS to address the above challenges.The Unified MPLS architecture provides a single converged networkinfrastructure with a common operational model. It has great advantagesin terms of network convergence, high scalability, high availability,and optimized forwarding. However, that architectural model is stillquite challenging to manage, especially on large-scale networks, becauseof the large number of distributed network protocols involved whichincreases operational complexity.Compass Metro Fabric (CMF) design introduces an SDN-ready architecturewhich evolves traditional Metro network design towards an SDN enabled,programmable network capable of delivering all services (Residential,Business, 5G Mobile Backhauling, Video, IoT) on the premise ofsimplicity, full programmability, and cloud integration, with guaranteedservice level agreements (SLAs).The Compass Metro Fabric design brings tremendous value to the ServiceProviders#      Fast service deployment and rapid time to market throughfully automated service provisioning and end-to-end networkprogrammability        Operational simplicity with less protocols to operate and manage        Smooth migration towards an SDN-ready architecture thanks tobackward-compatibility with existing network protocols and services        Next generation services creation leveraging guaranteed SLAs        Enhanced and optimized operations using telemetry/analytics inconjunction with automation tools  The Compass Metro Fabric design is targeted at Service Providercustomers who#      Want to evolve their existing Unified MPLS Network        Are looking for an SDN ready solution        Need a simple, scalable design that can support future growth        Want an industry\u2013leading or future proof technology and architecture  SummaryThe Compass Metro Fabric design meets the criteria identified forcompass designs#      Simple# based on Segment Routing as unified forwarding plane andEVPN and L3VPN as a common BGP based control plane        Programmable# it uses SR-PCE to program end-to-end paths across thenetwork with guaranteed SLAs        Automatable# service provisioning is fully automated using NSOand Yang models; analytics with model driven telemetry inconjunction with automation tools will be used in the future toenhance operations and network and services optimization        Repeatable# it\u2019s an evolution of the Unified MPLS architectureand based on standard protocols  Technical OverviewThe Compass Metro Fabric design evolves from the successful CiscoEvolved Programmable Network (EPN) 5.0 architecture framework, to bringgreater programmability and automation.In the Compass Metro Fabric design, the transport and service are builton-demand when the customer service is requested. The end-to-endinter-domain network path is programmed through controllers and selectedbased on the customer SLA, such as the need for a low latency path.The Compass Metro Fabric is made of the following main buildingblocks#      IOS-XR as a common Operating System proved in Service ProviderNetworks        Transport Layer based on Segment Routing as UnifiedForwarding Plane        SDN - Segment Routing Path Computation Element (SR-PCE) as Cisco Path ComputationEngine (PCE) coupled with Segment Routing to provide simple andscalable inter-domain transport connectivity and TrafficEngineering and Path control        Service Layer for Layer 2 (EVPN) and Layer 3 VPN services basedon BGP as Unified Control Plane        Automation and Analytics                  NSO for service provisioning                    Netconf/YANG data models                    Telemetry to enhance and simplify operations                    Zero Touch Provisioning and Deployment (ZTP/ZTD)            By leveraging analytics collected through model driven telemetry on IOS-XR platforms, in conjunction with automation tools, Compass Metro Fabric provides Service Providers with enhancements in network and services operations experience.Transport \u2013 DesignUse CasesService Provider networks must adopt a very flexible design that satisfyany to any connectivity requirements, without compromising in stabilityand availability. Moreover, transport programmability is essential tobring SLA awareness into the network,The goals of the Compass Metro Fabric is to provide a flexible networkblueprint that can be easily customized to meet customer specificrequirements.To provide unlimited network scale, the Compass Metro Fabric isstructured into multiple IGP Domains# Access, Aggregation, and Core.Refer to the network topology in Figure 1.Figure 1# Distributed Central OfficeThe network diagram in Figure 2 shows how a Service Provider network canbe simplified by decreasing the number of IGP domains. In this scenariothe Core domain is extended over the Aggregation domain, thus increasingthe number of nodes in theCore.Figure 2# Distributed Central Office with Core domain extensionA similar approach is shown in Figure 3. In this scenario the Coredomain remains unaltered and the Access domain is extended over theAggregation domain, thus increasing the number of nodes in the Accessdomain.Figure 3# Distributed Central Office with Access domain extensionThe Compass Metro Fabric transport design supports all three networkoptions, while remaining easily customizable.The first phase of the Compass Metro Fabric, discussed later in thisdocument, will cover in depth the scenario described in Figure 3.Intra-DomainIntra-Domain Routing and ForwardingThe Compass Metro Fabric is based on a fully programmable transport thatsatisfies the requirements described earlier. The foundation technologyused in the transport design is Segment Routing (SR) with a MPLS basedData Plane in Phase 1 and a IPv6 based Data Plane (SRv6) in future.Segment Routing dramatically reduces the amount of protocols needed in aService Provider Network. Simple extensions to traditional IGP protocolslike ISIS or OSPF provide full Intra-Domain Routing and ForwardingInformation over a label switched infrastructure, along with HighAvailability (HA) and Fast Re-Route (FRR) capabilities.Segment Routing defines the following routing related concepts#      Prefix-SID \u2013 A node identifier that must be unique for each node ina IGP Domain. Prefix-SID is statically allocated by th3 networkoperator.        Adjacency-SID \u2013 A node\u2019s link identifier that must be unique foreach link belonging to the same node. Adjacency-SID is typicallydynamically allocated by the node, but can also be staticallyallocated.  In the case of Segment Routing with a MPLS Data Plane, both Prefix-SIDand Adjacency-SID are represented by the MPLS label and both areadvertised by the IGP protocol. This IGP extension eliminates the needto use LDP or RSVP protocol to exchange MPLS labels.The Compass Metro Fabric design uses ISIS as the IGP protocol.Intra-Domain Forwarding - Fast Re-RouteSegment-Routing embeds a simple Fast Re-Route (FRR) mechanism known asTopology Independent Loop Free Alternate (TI-LFA).TI-LFA provides sub 50ms convergence for link and node protection.TI-LFA is completely Stateless and does not require any additionalsignaling mechanism as each node in the IGP Domain calculates a primaryand a backup path automatically and independently based on the IGPtopology. After the TI-LFA feature is enabled, no further care isexpected from the network operator to ensure fast network recovery fromfailures. This is in stark contrast with traditional MPLS-FRR, whichrequires RSVP and RSVP-TE and therefore adds complexity in the transportdesign.Please refer also to the Area Border Router Fast Re-Route covered inSection# \u201cInter-Domain Forwarding - High Availability and Fast Re-Route\u201d for additional details.Inter-DomainInter-Domain ForwardingThe Compass Metro Fabric achieves network scale by IGP domainseparation. Each IGP domain is represented by separate IGP process onthe Area Border Routers (ABRs).Section# \u201cIntra-Domain Routing and Forwarding\u201d described basic Segment Routing concepts# Prefix-SID andAdjacency-SID. This section introduces the concept of Anycast SID.Segment Routing allows multiple nodes to share the same Prefix-SID,which is then called a \u201cAnycast\u201d Prefix-SID or Anycast-SID. Additionalsignaling protocols are not required, as the network operator simplyallocates the same Prefix SID (thus a Anycast-SID) to a pair of nodestypically acting as ABRs.Figure 4 shows two sets of ABRs#      Aggregation ABRs \u2013 AG        Provider Edge ABRs \u2013 PE  Figure 4# IGP Domains - ABRs Anycast-SIDFigure 5 shows the End-To-End Stack of SIDs for packets traveling fromleft to right through thenetwork.Figure 5# Inter-Domain LSP \u2013 SRTE PolicyThe End-To-End Inter-Domain Label Switched Path (LSP) was computed viaSegment Routing Traffic Engineering (SRTE) Policies.On the Access router \u201cA\u201d the SRTE Policy imposes#      Local Aggregation Area Border Routers Anycast-SID# Local-AGAnycast-SID        Local Provider Edge Area Border Routers Anycast-SID# Local-PEAnycast SID        Remote Provider Edge Area Border Routers Anycast-SID# Remote-PEAnycast-SID        Remote Aggregation Area Border Routers Anycast-SID# Remote-AGAnycast-SID        Remote/Destination Access Router# Destination-A Prefix-SID#Destination-A Prefix-SID  The SRTE Policy is programmed on the Access device on-demand by anexternal Controller and does not require any state to be signaledthroughout the rest of the network. The SRTE Policy provides, by simpleSID stacking (SID-List), an elegant and robust way to programInter-Domain LSPs without requiring additional protocols such as BGP-LU(RFC3107).Please refer to Section# \u201cTransport Programmability\u201d for additional details.Area Border Routers \u2013 Prefix-SID vs Anycast-SIDSection# \u201cInter-Domain Forwarding\u201d showed the use of Anycast-SID at the ABRs for theprovisioning of an Access to Access End-To-End LSP. When the LSP is setup between the Access Router and the AG/PE ABRs, there are two options#      ABRs are represented by Anycast-SID; or        Each ABR is represented by a unique Prefix-SID.  Choosing between Anycast-SID or Prefix-SID depends on the requestedservice. Please refer to Section# \u201cServices - Design\u201d.Note that both options can be combined on the same network.Inter-Domain Forwarding - Label Stack OptimizationSection# \u201cInter-Domain Forwarding\u201d described how SRTE Policy uses SID stacking (SID-List) to define the Inter-Domain End-To-End LSP. The SID-List has to be optimized to be able to support different HW capabilities on different service termination platforms, while retaining all the benefits of a clear, simple and robust design.Figure 6 shows the optimization indetail.Figure 6# Label Stack OptimizationThe Anycast-SIDs and the Anycast Loopback IP address of all PE ABRs inthe network are redistributed into the Aggregation IGP Domain by the local PE ABRs. By doing this, all nodes in a Aggregation IGP Domainknow, via IGP, the Anycast-SID of all PE ABRs in the network. Local AGABRs then redistribute the Anycast-SIDs and Anycast Loopback IP addressof all PE ABRs into the Access IGP Domain. By doing this, all nodes in aAccess IGP Domain also know, via IGP, the Anycast-SID of all PE ABRs inthe network.It is very important to note that this redistribution is asymmetric,thus it won\u2019t cause any L3 routing loop in the network.Another important fact to consider is that there is only a limitedamount of PEs in a Service Provider Network, therefore theredistribution does not affect scalability in the Access IGP Domain.After Label Stack Optimization, the SRTE Policy on the Access routerimposes#      Remote Provider Edge Area Border Routers Anycast-SID# Remote-PEAnycast-SID        Remote Aggregation Are Border Routers Anycast-SID# Remote-AGAnycast-SID        Remote/Destination Access Router# Destination-A Prefix-SID#Destination-A Prefix-SID  Because of the Label Stack Optimization, the total amount of SIDsrequired for the Inter-Domain LSP is reduced to 3 instead of theoriginal 5.The Label Stack Optimization mechanism is very similar when an ABR isrepresented by a Prefix-SID instead of an Anycast-SID. The Prefix-SIDand the unicast Loopback IP address are redistributed into theAggregation IGP Domain by Local PE ABRs. By doing this, all nodes in theAggregation IGP Domain know, via IGP, the Prefix-SID of all PE ABRs inthe network. Local AG ABRs then redistribute the learned Prefix-SIDs andunicast Loopback IP address of all PE ABRs to the Access IGP Domain. Bydoing this, all nodes in a Access IGP Domain know, via IGP, thePrefix-SID of all PE ABRs in the network.Both Anycast-SID and Prefix-SID can be combined in the same network withor without Label Stack Optimization.Inter-Domain Forwarding - High Availability and Fast Re-RouteAG/PE ABRs redundancy enables high availability for Inter-DomainForwarding.Figure 7# IGP Domains - ABRs Anycast-SIDWhen Anycast-SID is used to represent AG or PE ABRs, no other mechanismis needed for Fast Re-Route (FRR). Each IGP Domain provides FRRindependently by TI-LFA as described in Section# \u201cIntra-Domain Forwarding - Fast Re-Route\u201d.Figure 8 shows how FRR is achieved for a Inter-DomainLSP.Figure 8# Inter-Domain - FRRThe access router on the left imposes the Anycast-SID of the ABRs andthe Prefix-SID of the destination access router. For FRR, any router inIGP1, including the Access router, looks at the top label# \u201cABRAnycast-SID\u201d. For this label, each device maintains a primary and backuppath preprogrammed in the HW. In IGP2, the top label is \u201cDestination-A\u201d.For this label, each node in IGP2 has primary and backup pathspreprogrammed in the HW. The backup paths are computed by TI-LFA.As Inter-Domain forwarding is achieved via SRTE Policies, FRR iscompletely self-contained and does not require any additional protocol.Note that when traditional BGP-LU is used for Inter-Domain forwarding,BGP-PIC is also required for FRR.Inter-Domain LSPs provisioned by SRTE Policy are protected by FRR alsoin case of ABR failure (because of Anycast-SID). This is not possiblewith BGP-LU/BGP-PIC, since BGP-LU/BGP-PIC have to wait for the IGP toconverge first.Transport ProgrammabilityFigure 9 and Figure 10 show the design of Router-Reflectors (RR), Segment Routing Path Computation Element (SR-PCE) and WAN Automation Engines (WAE).High-Availability is achieved by device redundancy in the Aggregationand Core networks.Figure 9# Transport Programmability \u2013 PCEPRRs collect network topology from ABRs through BGP Link State (BGP-LS).Each ABR has a BGP-LS session with the two Domain RRs.Aggregation Domain RRs collect network topology information from theAccess and the Aggregation IGP Domain (Aggregation ABRs are part of theAccess and the Aggregation IGP Domain). Core Domain RRs collect networktopology information from the Core IGP Domain.Aggregation Domain RRs have BGP-LS sessions with Core RRs.Through the Core RRs, the Aggregation Domains RRs advertise localAggregation and Access IGP topologies and receive the network topologiesof the remote Access and Aggregation IGP Domains as well as the networktopology of the Core IGP Domain. Hence, each RR maintains the overallnetwork topology in BGP-LS.Redundant Domain SR-PCEs have BGP-LS sessions with the local Domain RRsthrough which they receive the overall network topology. Refer toSection# \u201cSegment Routing Path Computation Element (SR-PCE)\u201d for more details about SR-PCE.SR-PCE is then capable of computing the Inter-Domain LSP path on-demand andto instantiate it. The computed path (SID-List) is then advertised viathe Path Computation Element Protocol (PCEP), as shown in Figure 9, orBGP-SRTE, as shown in Figure 10, to the Service End Points. In the caseof PCEP, SR-PCEs and Service End Points communicate directly, while forBGP-SRTE, they communicate via RRs. Phase 1 uses PCEP only.The Service End Points program the SID-List via SRTE Policy.Service End Points can be co-located with the Access Routers for FlatServices or at the ABRs for Hierarchical Services. The SRTE Policy DataPlane in the case of Service End Point co-located with the Access routerwas described in Figure 5.The WAN Automation Engine (WAE) provides bandwidthoptimization.Figure 10# Transport Programmability \u2013 BGP-SRTEThe proposed design is very scalable and can be easily extended tosupport even higher numbers of BGP-SRTE/PCEP sessions by addingadditional RRs and SR-PCEs into the Access Domain.Figure 11 shows the Compass Metro Fabric physical topology with examplesof productplacement.Figure 11# Compass Metro Fabric \u2013 Physical Topology with transportprogrammabilityNote that the design of the Central Office is not covered by thisdocument.###Traffic Engineering (Tactical Steering) \u2013 SRTE PolicyOperators want to fully monetize their network infrastructure byoffering differentiated services. Traffic engineering is used to providedifferent paths (optimized based on diverse constraints, such aslow-latency or disjoined paths) for different applications. Thetraditional RSVP-TE mechanism requires signaling along the path fortunnel setup or tear down, and all nodes in the path need to maintainstates. This approach doesn\u2019t work well for cloud applications, whichhave hyper scale and elasticity requirements.Segment Routing provides a simple and scalable way of defining anend-to-end application-aware traffic engineering path computed onceagain through SRTE Policy.In the Compass Metro Fabric design, the Service End Point uses PCEP orBGP-SRTE (Phase 1 uses PCEP only) along with Segment Routing On-DemandNext-hop (SR-ODN) capability, to request from the controller a path thatsatisfies specific constraints (such as low latency). This is done byassociating an SLA tag/attribute to the path request. Upon receiving therequest, the SR-PCE controller calculates the path based on the requestedSLA, and uses PCEP or BGP-SRTE to dynamically program the ingress nodewith a specific SRTE Policy.The Compass Metro Fabric design also uses MPLS Performance Management tomonitor link delay/jitter/drop (RFC6374).Transport Controller Path Computation Engine (PCE)Segment Routing Path Computation Element (SR-PCE)Segment Routing Path Computation Element, or SR-PCE, is a Cisco Path Computation Engine(PCE) and it is implemented as a feature included as part of CiscoIOS-XR operating system. The function is typically deployed on a CiscoIOS-XR cloud appliance XRv9000, as it involves control plane operationsonly. The SR-PCE gains network topology awareness from BGP-LSadvertisements received from the underlying network. Such knowledge isleveraged by the embedded multi-domain computation engine to provideoptimal path to Path Computation Element Clients (PCCs) using the PathComputation Element Protocol (PCEP) or BGP-SRTE.The PCC is the device where the service originates and therefore itrequires end-to-end connectivity over the segment routing enabledmulti-domain network.The SR-PCE provides a path based on constraints such as#      Shortest path (IGP metrics).        Traffic-Engineering metrics.        Disjoint path.\u2028  Figure 12# XR Transport Controller \u2013 ComponentsWAN Automation Engine (WAE)WAE Automation combines the smart data collection, modeling, andpredictive analytics of Cisco WAE Planning with an extensible,API-driven configuration platform. The use of open APIs and standardizedprotocols provides a means for intelligent interaction betweenapplications and the network. Applications have visibility into theglobal network and can make requests for specific service levels.Section# \u201cPCE Controller Summary - SR-PCE &amp; WAE\u201d compares SR-PCE and WAE.PCE Controller Summary \u2013 SR-PCE &amp; WAESegment Routing Path Computation Element (SR-PCE)#      Runs as a features in a IOS-XR node        Collects topology from BGP, ISIS, OSPF and BGP Link State        Deploys tunnel# PCEP SR/RSVP, BGP SR-TE        Computes Shortest, Disjoint, Low Latency, and Avoidance paths        North Bound interface with applications via REST API  WAN Automation Engine (WAE)#      Runs as a SR-PCE application        Collects topology# via SR-PCE        Collects BW utilization# Flexible NetFlow (FNF), StreamingTelemetry, SNMP        Deploys tunnel via SR-PCE (preferred# stateful) or NSO (optional#stateless)        Computes# Bandwidth Optimization, On demand BW.  Path Computation Engine \u2013 WorkflowThere are three models available to program transport LSPs#      Delegated Computation to SR-PCE        WAE Instantiated LSP        Delegated Computation to WAE  All models assume SR-PCE has acquired full network topology throughBGP-LS.Figure 13# PCE Path ComputationDelegated Computation to SR-PCE      NSO provisions the service. Alternatively, the service can beprovisioned via CLI        Access Router requests a path        SR-PCE computes the path        SR-PCE provides the path to Access Router        Access Router acknowledges        (Optional) When WAE is deployed for LSP visibility, SR-PCE updates WAEwith the newer LSP  WAE Instantiated LSP      WAE computes the path        WAE sends computed path to SR-PCE        SR-PCE provides the path to Access Router        Access Router confirms        SR-PCE updates WAE with newer LSP  Delegated Computation to WAE      NSO provisions the service \u2013 Service can also be provisioned via CLI        Access Router requests a path        SR-PCE delegates computation to WAE        WAE computes the path        WAE sends computed path to SR-PCE        SR-PCE provides the path to Access Router        Access Router confirms        SR-PCE updates WAE with newer LSP  Transport \u2013 Segment Routing IPv6 Data Plane (SRv6)The Compass Metro Fabric design will use Segment Routing IPv6 Data Plane(SRv6) in later phases.SRv6 brings another level of simplification with IPv6 data plane andwith network programming concept.Network programming concept is the capability to encode a networkprogram in the header of the packet. The program is expressed as a listof segments included in the SRv6 extension header, also called SRH. Eachsegment is a 128-bit entity where the first bits identify a router inthe network, we call them the locator part of the segment, and theremaining bits identify a function to be executed at that router.The SRv6 network programming IETF draft(draft-filsfils-spring-srv6-network-programming) provides thepseudo-code for various functions that allow the implementation ofnetwork services such as TILFA FRR, TE for latency or disjointness, VPN,NFV and many other applications.The following diagram# \u201cSRv6 Network Topology\u201d shows customer\u2019s IPv6traffic with destination IPv6 address 6001##1 (same can be done for IPv4traffic) encapsulated in SRv6 on router 1, then forwarded via SRv6 coreto router 4 via router 2 or via router 3. Router 4 decapsulates SRv6 andperforms IPv6 destination address lookup in customer VRF. In our usecase, VRF 100.All the links in the topology except the link between routers 3 and 4are equal. the Link between 3 and 4 is high cost, but has lowlatencyFigure 14# SRv6 Network TopologyBest-Effort PathThe following diagram# \u201cSRv6 Best-Effort Path\u201d shows best-effort path.Router 1 encapsulates the received IPv6 packets from the customer siteof Entreprise100 in an outer IPv6 header. Router 1 sets the destinationaddress of the outer header to the segment of Router 4 which implementsthe egress PE function related to the VPN of Entreprise100 at Router 4.In this example, this segment is 2001##4#E100. The bits \u201c2001##4\u201d locatethe router where the function will be executed.In this example, we assume that Router 4 would advertise 2001##4/112 inthe IGP (no new IETF extension is required for this). The bits \u201cE100\u201didentify a specific function to be executed at the router identified bythe locator bits, in our example, Router 4.We assume here that Router 4 has instantiated the local function \u201cE100\u201dfor the behavior \u201cdecap the packet, lookup the inner destination addressin the VRF of Entreprise 100 and forward accordingly\u201d.We also assume that Router 4 has signaled the availability of thatfunction to Router 1 either via BGP or via an SDNcontroller.Figure 15# SRv6 Best-Effort PathRouter 1 receives packets from Entreprise100, then encapsulates thesepackets in an outer header with DA leading to Router 4 where thefunction \u201cdecap and lookup in VRF 100\u201d is executed.By the process above, we have eliminated any encapsulation protocol suchas LISP, VXLAN, L2TPv3, GRE etc. This is an important simplification.We have not used an SRH in this case because the network program can beencoded with one single segment and hence we just need the outer IPv6header.The example above shows IPv6 VPN over IPv6. The same is applicable forIPv4 overlay (IPv4 VPN) and L2VPN construct. More details can be foundin draft-filsfils-spring-srv6-network-programming.Low-Latency PathThe following diagram# \u201cSRv6 Low-Latency Path\u201d shows low-latency path.Router 1 encapsulates the customer traffic in an outer IPv6 header withan SRH. In this example, the network program needs two SID\u2019s. The firstSID is placed in the DA and implements the low-latency underlay service.The second SID is programmed in the SRH and implements the overlayservice.The first SID is 2001##3#C34.2001##3 is the locator part and leads the packet to Router 3. OnceRouter 3 gets this packet, it executes the function C34. The functionC34 means \u201cupdate the DA with the next-segment and cross-connect theresulting packet to the neighboring Router 4.\u201dWe assume here that Router 3 has instantiated the local function \u201cC34\u201dfor the behavior \u201cupdate DA, cross-connect to neighbor 4\u201d.We also assume that Router 4 has signaled the availability of thatfunction to Router 1 via the IGP.With one single SID, the ingress PE encodes in the packet header theunderlay SLA service for low-latency. The packets will use the northpath despite that it is not the preferred one from an IGP viewpoint.This is achieved by using the explicit routing capability of SR.State is created in the fabric to create this underlay SLA.The second SID implements the overlay service# this is 2001##4#E100 likewe sawpreviously.Figure 16# SRv6 Low-Latency PathThe following diagram# \u201dSRv6 Cross-Connect Function\u201d shows thecross-connect function 2001##3#C34 instantiated by Router 3 as thisexplicit routing function provides a nice and easy way to enforcerequested SRTE Policy without any stateful information as the networkprogram is in the packetheader.Figure 17# SRv6 Cross-Connect Function\u201cCross-connect\u201d means the function 2001##3#C34 is bound specifically tothe red link between Routers 3 and 4, but before Router 3 cancross-connect the packets, the IPv6 header needs to be updated.SRH can carry multiple segments stored in the segment list, so there isalso index represented by segment left value in SRH, which points to theright segment in the segment list. In our example, we have just onesegment in SRH which is the segment of Router 4.First, Router 3 decreases segment left value by one.In the next step, Router 3 will use segment left value as index in thesegment list to read the next segment. Router 3 sets the new destinationaddress of outer header to this segment which is the segment of Router4.This is completely the same segment of Router 4 like in the first usecase which implements the egress PE function related to VPN ofEnterprise 100 at Router 4.In our example, SRH doesn\u2019t carry other segments, therefor Router 3 canpop this SRH header. We call this operation Penultimate Segment Pop.Finally, Router 3 cross-connects the packet to Router 4 via the redlink.Router 4 decapsulates the packet, lookups the inner destination addressin the VRF Enterprise 100 and forwards accordingly.The following diagram# \u201dSRv6 Low-Latency Detail\u201d shows end-to-endlow-latency traffic data-path described in the previousparagraph.Figure 18# SRv6 Low-Latency DetailSRv6 \u2013 Inter-Domain ForwardingNext network diagram# \u201cSRv6 Inter-Domain Forwarding\u201d shows how SRv6benefits can be used in Service Provider network for Inter-Domainforwarding. End-To-End forwarding reachability can be easily provided bysummary or default route in the Access IGP Domain pointing to AG ABRs.Similarly, the Aggregation IGP Domain has summary or default routepointing to PE ABRs. The Core IGP domain also has summary routes of theAggregation/Access IGP Domains pointing to particular PEABRs.Figure 19# SRv6 Inter-Domain ForwardingNext network diagram# \u201cSRv6 Inter-Domain Forwarding with SRH\u201d shows howSRH can also be used to get Inter-Domain with Traffic Engineering(Low-LatencyPath).Figure 20# SRv6 Inter-Domain Forwarding with SRHNote that there is SDN controller to fulfill SLAs required byprovisioned services and SRTE Policy is programmed to network based onthe SLAs.Segment Routing basic elements are the same for MPLS as well as forIPv6(SRv6) data plane.SRv6 ConclusionSRv6 brings the following benefits to an SP network      Simplicity        Removal of any encapsulation protocol such as GRE, L2TPv3, LISP.        Stateless and Scalable        The network program is in the packet header not as a state in thefabric  Services \u2013 DesignOverviewThe Compass Metro Fabric Design aims to enable simplification across alllayers of a Service Provider network. Thus, the Compass Metro Fabricservices layer focuses on a converged Control Plane based on BGP.BGP based Services include EVPNs and Traditional L3VPNs (VPNv4/VPNv6).EVPN is a technology initially designed for Ethernet multipoint servicesto provide advanced multi-homing capabilities. By using BGP fordistributing MAC address reachability information over the MPLS network,EVPN brought the same operational and scale characteristics of IP basedVPNs to L2VPNs. Today, beyond DCI and E-LAN applications, the EVPNsolution family provides a common foundation for all Ethernet servicetypes; including E-LINE, E-TREE, as well as data center routing andbridging scenarios. EVPN also provides options to combine L2 and L3services into the same instance.To simplify service deployment, provisioning of all services is fullyautomated using Cisco Network Services Orchestrator (NSO) using (YANG)models and NETCONF. Refer to Section# \u201cNetwork Services Orchestrator (NSO)\u201d.There are two types of services# End-To-End and Hierarchical. The nexttwo sections describe these two types of services in more detail.Ethernet VPN (EVPN)EVPNs solve two long standing limitations for Ethernet Services inService Provider Networks#      Multi-Homed &amp; All-Active Ethernet Access        Service Provider Network - Integration with Central Office or withData Center  Multi-Homed &amp; All-Active Ethernet AccessFigure 21 demonstrates the greatest limitation of traditional L2Multipoint solutions likeVPLS.Figure 21# EVPN All-Active AccessWhen VPLS runs in the core, loop avoidance requires that PE1/PE2 andPE3/PE4 only provide Single-Active redundancy toward their respectiveCEs. Traditionally, techniques such mLACP or Legacy L2 protocols likeMST, REP, G.8032, etc. were used to provide Single-Active accessredundancy.The same situation occurs with Hierarchical-VPLS (H-VPLS), where theaccess node is responsible for providing Single-Active H-VPLS access byactive and backup spoke pseudowire (PW).All-Active access redundancy models are not deployable as VPLStechnology lacks the capability of preventing L2 loops that derive fromthe forwarding mechanisms employed in the Core for certain categories oftraffic. Broadcast, Unknown-Unicast and Multicast (BUM) traffic sourcedfrom the CE is flooded throughout the VPLS Core and is received by allPEs, which in turn flood it to all attached CEs. In our example PE1would flood BUM traffic from CE1 to the Core, and PE2 would sends itback toward CE1 upon receiving it.EVPN uses BGP-based Control Plane techniques to address this issue andenables Active-Active access redundancy models for either Ethernet orH-EVPN access.Figure 22 shows another issue related to BUM traffic addressed byEVPN.Figure 22# EVPN BUM DuplicationIn the previous example, we described how BUM is flooded by PEs over theVPLS Core causing local L2 loops for traffic returning from the core.Another issue is related to BUM flooding over VPLS Core on remote PEs.In our example either PE3 or PE4 receive and send the BUM traffic totheir attached CEs, causing CE2 to receive duplicated BUM traffic.EVPN also addresses this second issue, since the BGP Control Planeallows just one PE to send BUM traffic to an All-Active EVPN access.Figure 23 describes the last important EVPNenhancement.Figure 23# EVPN MAC Flip-FloppingIn the case of All-Active access, traffic is load-balanced (per-flow)over the access PEs (CE uses LACP to bundle multiple physical ethernetports and uses hash algorithm to achieve per flow load-balancing).Remote PEs, PE3 and PE4, receive the same flow from different neighbors.With a VPLS core, PE3 and PE4 would rewrite the MAC address tablecontinuously, each time the same mac address is seen from a differentneighbor.EVPN solves this by mean of \u201cAliasing\u201d, which is also signaled via theBGP Control Plane.Service Provider Network - Integration with Central Office or with Data CenterAnother very important EVPN benefit is the simple integration withCentral Office (CO) or with Data Center (DC). Note that Metro CentralOffice design is not covered by this document.The adoption of EVPNs provides huge benefits on how L2 Multipointtechnologies can be deployed in CO/DC. One such benefit is the convergedControl Plane (BGP) and converged data plane (SR MPLS/SRv6) over SP WANand CO/DC network.Moreover, EVPNs can replace existing proprietary EthernetMulti-Homed/All-Active solutions with a standard BGP-based ControlPlane.End-To-End (Flat) \u2013 ServicesThe End-To-End Services use cases are summarized in the table in Figure24 and shown in the network diagram in Figure 25.Figure 24# End-To-End \u2013 Services tableFigure 25# End-To-End \u2013 ServicesAll services use cases are based on BGP Control Plane.Refer also to Section# \u201cTransport and Services Integration\u201d.Hierarchical \u2013 ServicesHierarchical Services Use Cases are summarized in the table of Figure 26and shown in the network diagram of Figure 27.Figure 26# Hierarchical \u2013 Services tableFigure 27# Hierarchical - ServicesHierarchical services designs are critical for Service Providers lookingfor limiting requirements on the access platforms and deploying morecentralized provisioning models that leverage very rich features sets ona limited number of touch points.Hierarchical Services can also be required by Service Providers who wantto integrate their SP-WAN with the Central Office/Data Center networkusing well-established designs based on Data Central Interconnect (DCI).Figure 27 shows hierarchical services deployed on PE routers, but thesame design applies when services are deployed on AG or DCI routers.The Compass Metro Design offers scalable hierarchical services withsimplified provisioning. The three most important use cases aredescribed in the following sections#      Hierarchical L2 Multipoint Multi-Homed/All-Active        Hierarchical L2/L3 Multi/Single-Home, All/Single-Active Service(H-EVPN) and Anycast-IRB        Hierarchical L2/L3 Multipoint Multi-Homed/Single-Active (H-EVPN) andPWHE  Hierarchical L2 Multipoint Multi-Homed/All-ActiveFigure 28 shows a very elegant way to take advantage of the benefits ofSegment-Routing Anycast-SID and EVPN. This use case providesHierarchical L2 Multipoint Multi-Homed/All-Active (Single-Homed Ethernetaccess) service with traditional access routerintegration.Figure 28# Hierarchical \u2013 Services (Anycast-PW)Access Router A1 establishes a Single-Active static pseudowire(Anycast-Static-PW) to the Anycast IP address of PE1/PE2. PEs anycast IPaddress is represented by Anycast-SID.Access Router A1 doesn\u2019t need to establish active/backup PWs as in atraditional H-VPLS design and doesn\u2019t need any enhancement on top of theestablished spoke pseudowire design.PE1 and PE2 use BGP EVPN Control Plane to provide Multi-Homed/All-Activeaccess, protecting from L2 loop, and providing efficient per-flowload-balancing (with aliasing) toward the remote PEs (PE3/PE4).A3, PE3 and PE4 do the same, respectively.Hierarchical L2/L3 Multi/Single-Home, All/Single-Active Service (H-EVPN) and Anycast-IRBFigure 29 shows how EVPNs can completely replace the traditional H-VPLSsolution. This use case provides the greatest flexibility asHierarchical L2 Multi/Single-Home, All/Single-Active modes are availableat each layer of the servicehierarchy.Figure 29# Hierarchical \u2013 Services (H-EVPN)Optionally, Anycast-IRB can be used to enable Hierarchical L2/L3Multi/Single-Home, All/Single-Active service and to provide optimal L3routing.Hierarchical L2/L3 Multipoint Multi-Homed/Single-Active (H-EVPN) and PWHEFigure 30 shows how the previous H-EVPN can be extended by takingadvantage of Pseudowire Headend (PWHE). PWHE with the combination ofMulti-Homed, Single-Active EVPN provides an Hierarchical L2/L3Multi-Homed/Single-Active (H-EVPN) solution that supports QoS.It completely replaces traditional H-VPLS based solutions. This use caseprovides Hierarchical L2 Multi/Single-Home, All/Single-Activeservice.Figure 30# Hierarchical \u2013 Services (H-EVPN and PWHE)Refer also to the section# \u201cTransport and Services Integration\u201d.Services \u2013 Router-Reflector (S-RR)Figure 31 shows the design of Services Router-Reflectors(S-RRs).Figure 31# Services \u2013 Router-ReflectorsThe Compass Metro Fabric Design focuses mainly on BGP-based services,therefore it is important to provide a robust and scalable ServicesRoute-Reflector (S-RR) design.For Redundancy reasons, there are at least 2 S-RRs in any given IGPDomain, although Access and Aggregation are supported by the same pairof S-RRs.Each node participating in BGP-based service termination has two BGPsessions with Domain Specific S-RRs and supports multipleaddress-Families# VPNv4, VPNv6, EVPN.Core Domain S-RRs cover the core Domain. Aggregation Domain S-RRs coverAccess and Aggregation Domains. Aggregation Domain S-RRs and Core S-RRshave BGP sessions among each other.The described solution is very scalable and can be easily extended toscale to higher numbers of BGP sessions by adding another pair of S-RRsin the Access Domain.Network Services Orchestrator (NSO)The NSO is a management and orchestration (MANO) solution for networkservices and Network Functions Virtualization (NFV). The NSO includescapabilities for describing, deploying, configuring, and managingnetwork services and VNFs, as well as configuring the multi-vendorphysical underlay network elements with the help of standard open APIssuch as NETCONF/YANG or a vendor-specific CLI using Network ElementDrivers (NED).In the Compass Metro Fabric design, the NSO is used for ServicesManagement, Service Provisioning, and Service Orchestration.The NSO provides several options for service designing as shown inFigure 32      Service model with service template        Service model with mapping logic        Service model with mapping logic and servicetemplates  Figure 32# NSO \u2013 ComponentsA service model is a way of defining a service in a template format.Once the service is defined, the service model accepts user inputs forthe actual provisioning of the service. For example, a E-Line servicerequires two endpoints and a unique virtual circuit ID to enable theservice. The end devices, attachment circuit UNI interfaces, and acircuit ID are required parameters that should be provided by the userto bring up the E-Line service. The service model uses the YANG modelinglanguage (RFC 6020) inside NSO to define a service.Once the service characteristics are defined based on the requirements,the next step is to build the mapping logic in NSO to extract the userinputs. The mapping logic can be implemented using Python or Java. Thepurpose of the mapping logic is to transform the service models todevice models. It includes mechanisms of how service related operationsare reflected on the actual devices. This involves mapping a serviceoperation to available operations on the devices.Finally, service templates need to be created in XML for each devicetype. In NSO, the service templates are required to translate theservice logic into final device configuration through CLI NED. The NSOcan also directly use the device YANG models using NETCONF for deviceconfiguration. These service templates enable NSO to operate in amulti-vendor environment.Transport and Services IntegrationSection# \u201cTransport - Design\u201d described how Segment Routing provides flexible End-To-End andAny-To-Any Highly-Available transport together with Fast Re-Route. Aconverged BGP Control Plane provides a scalable and flexible solutionalso at the services layer.Figure 33 shows a consolidated view of the Compass Metro Fabric networkfrom a Control-Plane standpoint. Note that while network operators coulduse both PCEP and BGR-SRTE at the same time, it is nottypical.Figure 33# Compass Metro Fabric \u2013 Control-PlaneAs mentioned, service provisioning is independent of the transportlayer. However, transport is responsible for providing the path based onservice requirements (SLA). The component that enables such integrationis On-Demand Next Hop (ODN). ODN is the capability of requesting to acontroller a path that satisfies specific constraints (such as lowlatency). This is achieved by associating an SLA tag/attribute to thepath request. Upon receiving the request, the SR-PCE controller calculatesthe path based on the requested SLA and use PCEP or BGP-SRTE todynamically program the Service End Point with a specific SRTE Policy.The Compass Metro Fabric design also use MPLS Performance Management tomonitor link delay/jitter/drop (RFC6374) to be able to create a LowLatency topology dynamically.Figure 34 shows a consolidated view of Compass Metro Fabric network froma Data Planestandpoint.Figure 34# Compass Metro Fabric \u2013 Data-PlaneThe Compass Metro Fabric Design \u2013 Phase 1Transport - Phase 1This section describes in detail Phase 1 of the Compass Metro Fabricdesign. This Phase focuses on transport programmability and BGP-basedservices adoption.Figure 35 and Figure 36 show the network topology and transport DataPlane details for Phase 1. Refer also to the Access domain extension usecase in Section# \u201cUse Cases\u201d.The network is split into Access and Core IGP domains. Each IGP domainis represented by separate IGP processes. The Compass Metro Fabricdesign uses ISIS IGP protocol for validation.Validation will be done on two types of access platforms, IOS-XR andIOS-XE, to proveinteroperability.Figure 35# Access Domain Extension \u2013 End-To-End TransportFor the End-To-End LSP shown in Figure 35, the Access Router imposes 3transport labels (SID-list) An additional label, the TI-LFA label, canbe also added for FRR (node and link protection). In the Core and in theremote Access IGP Domain, 2 additional TI-LFA labels can be used for FRR(node and link protection). In Phase 1 PE ABRs are represented byPrefix-SID. Refer also to Section# \u201cTransport Programmability - Phase 1\u201d.Figure 36# Access Domain Extension \u2013 Hierarchical TransportFigure 36 shows how the Access Router imposes a single transport labelto reach local PE ABRs, where the hierarchical service is terminated.Similarly, in the Core and in the remote Access IGP domain, thetransport LSP is contained within the same IGP domain (Intra-DomainLSP). Routers in each IGP domain can also impose two additional TI-LFAlabels for FRR (to provide node and link protection).In the Hierarchical transport use case, PE ABRs are represented byAnycast-SID or Prefix-SID. Depending on the type of service, Anycast-SIDor Prefix-SID is used for the transport LSP.Transport Programmability \u2013 Phase 1The Compass Metro Fabric employs a distributed and highly available SR-PCEdesign as described in Section# \u201cTransport Programmability\u201d. Transport programmability is basedon PCEP. Figure 37 shows the design when SR-PCE uses PCEP.Figure 37# SR-PCE \u2013 PCEPSR-PCE in the Access domain is responsible for Inter-Domain LSPs andprovides the SID-list. PE ABRs are represented by Prefix-SID.SR-PCE in the Core domain is responsible for On-Demand Nexthop (ODN) forhierarchical services. Refer to the table in Figure 41 to see whatservices use ODN. Refer to Section# \u201cTransport Controller - Path Computation Engine (PCE)\u201d to see more details about XRTransport Controller (SR-PCE). Note that Phase 1 uses the \u201cDelegatedComputation to SR-PCE\u201d mode described in Section# \u201cPath Computation Engine - Workflow\u201d without WAE as shownin Figure38.Figure 38# PCE Path Computation \u2013 Phase 1Delegated Computation to SR-PCE      NSO provisions the service \u2013 Service can also be provisioned via CLI        Access Router requests a path        SR-PCE computes the path        SR-PCE provides the path to Access Router        Access Router confirms  Services \u2013 Phase 1This section describes the Services used in the Compass Metro FabricPhase 1.The table in Figure 39 describes the End-To-End services, while thenetwork diagram in Figure 40 shows how services are deployed in thenetwork. Refer also to Section# \u201cServices - Design\u201d of this document.Figure 39# End-To-End Services tableFigure 40# End-To-End ServicesThe table in Figure 41 describes the hierarchical services, while thenetwork diagram in Figure 42 shows how services are deployed in thenetwork. Refer also to Section# \u201cServices - Design\u201d of this document.In addition, the table in Figure 41 shows where PE ABRs Anycast-SID isrequired and where ODN in the Core IGP domain is used.Figure 41# Hierarchical Services tableFigure 42# Hierarchical ServicesThe Compass Metro Fabric uses the hierarchical Services Route-Reflectors(S-RRs) design described in Section# \u201cServices - Router-Reflector (S-RR)\u201d. Figure 43 shows in detail the S-RRs design used for Phase 1.Figure 43# Services Route-Reflectors (S-RRs)Network Services Orchestrator (NSO) is used for service provisioning.Refer to Section# \u201cNetwork Services Orchestrator (NSO)\u201d.Transport and Services Integration \u2013 Phase 1Transport and Services integration is described in Section# \u201cTransport and Services Integration\u201d of this document. Figure 44 shows an example of End-To-End LSP and servicesintegration in Phase 1.Figure 44# Transport and Services Data-PlaneFigure 45 shows a consolidated view of the Transport and ServicesControl-Plane.Figure 45# Transport and Services Control-PlaneFigure 46 shows the physical topology of the testbed used for Phase 1validation.Figure 46# Testbed \u2013 Phase 1The Compass Metro Fabric Design - SummaryThe Compass Metro Fabric brings huge simplification at the Transport aswell as at the Services layers of a Service Provider network.Simplification is a key factor for real Software Defined Networking(SDN). Cisco continuously improves Service Provider network designs tosatisfy market needs for scalability and flexibility.From a very well established and robust Unified MPLS design, Cisco hasembarked on a journey toward transport simplification andprogrammability, which started with the Transport Control Planeunification in Evolved Programmable Network 5.0 (EPN5.0). The CiscoMetro Fabric provides another huge leap forward in simplification andprogrammability adding Services Control Plane unification andcentralized path computation.Figure 47# Compass Metro Fabric \u2013 EvolutionThe transport layer requires only IGP protocols with Segment Routingextensions for Intra and Inter Domain forwarding. Fast recovery for nodeand link failures leverages Fast Re-Route (FRR) by Topology IndependentLoop Free Alternate (TI-LFA), which is a built-in function of SegmentRouting. End to End LSPs are built using Traffic Engineering by SegmentRouting, which does not require additional signaling protocols. Insteadit solely relies on SDN controllers, thus increasing overall networkscalability. The controller layer is based on standard industryprotocols like BGP-LS, PCEP, BGP-SRTE, etc., for path computation andNETCONF/YANG for service provisioning, thus providing a on openstandards based solution.For all those reasons, the Cisco Metro Fabric design really brings anexciting evolution in Service Provider Networking.", "url": "https://xrdocs.github.io/design/blogs/2018-04-30-metro-fabric-hld/", "tags": "iosxr, Metro, Design", "title": "Metro Fabric High Level Design", "author": "Jiri Chaloupka"}, "blogs-2016-10-20-using-ztp-to-install-puppet": {"content": "     Using ZTP to install Puppet  Introduction  Puppet in IOS-XR  Script Example  IntroductionPuppet is a configuration management tool for information technology (IT) professionals. Puppet can potentically manage any resource defined on a node. Puppet can manage complex and distributed components to ensure service consistency and availability. In short, Puppet uses a configuration policy referred to as a \u201crecipe\u201d to bring systems into compliance.Puppet enables you to make a lot of changes both quickly and consistently. Unlike scripts, you don\u2019t have to write out every step, you only have to define how it should be. You are not required to write out the process for evaluating and verifying different conditions. Instead, you utilize the Puppet configuration language to declare the final state of the resources. This is why Puppet is often described as a declarative language.The difference between a declarative language and a procedural language is# You tell Puppet the desired end results, but not the steps to get there.If you choose to use Puppet as your configuration platform, it is important to have the agent installed on the devices early on in the deployment process, and not use any scripting beyond the installation procedure of the agent.Puppet in IOS-XRPuppetlabs have created a puppet agent for the IOS-XR Yocto based Linux. You can follow their installation instructions here#Installing Cisco IOS-XR agents. Make sure you download the file which has \u201ccisco-wrlinux-7\u201d in the filename, since this is the version that works in the IOS-XR Yocto Linux environment.If you are interested in using Puppet in conjunction with YANG data models, take a look at the tutorial on Puppet and ciscoyang Using Puppet with IOS-XR 6.1.1. You will have to modify the example below to include the installation of the GRPC GEM file.Script ExampleHere is a small example on how to use ZTP to download and install the Puppet package from a local repository, configure the device hostname and enable DNS resolution. The Puppet agent package is secured with a SHA-1 (GPG) key, and you will need to download it to a secure location or access the key directly from Puppetlabs. In the example below, I simply placed the key in the same directory as the RPM package.Puppet requires all hostnames to be resolved. The script relies on a DNS server to resolve the hostname and include the modifications to IOS-XR Linux. The script also assumes that communication between the Puppet master and the agent will happen over the management interface.#!/bin/bashYUM_REPO=~http#//172.30.0.22/packages/puppet~YUM_PUPPET=~/etc/yum/repos.d/puppet.repo~PUPPET_SRV=~puppet-master.cisco.local~PUPPET_CONF=~/etc/puppetlabs/puppet/puppet.conf~DOMAIN=~cisco.local~DOMAIN_SRV=172.30.0.25HOSTNAME=~ncs-5001-c~MGMT_IP=~172.30.12.54 255.255.255.0~source ztp_helper.shfunction create_repo(){   # Create local repository file for puppet   echo ~### created by ztp $(date +~%b %d %H#%M#%S~) ###~ &gt; $YUM_PUPPET   echo -ne ~[puppetlabs]\\nname=puppetlabs\\nenabled=1\\ngpgcheck=1\\n~ &gt;&gt; $YUM_PUPPET   echo ~baseurl=$YUM_REPO~ &gt;&gt; $YUM_PUPPET   echo ~gpgkey=$YUM_REPO/RPM-GPG-KEY-puppetlabs~ &gt;&gt; $YUM_PUPPET }function install_puppet(){   # Install puppet    /usr/bin/yum clean all &gt; /dev/null   /usr/bin/yum update &gt; /dev/null   /usr/bin/yum install -y puppet &gt; /dev/null}function config_puppet(){  echo ~### created by ztp $(date +~%b %d %H#%M#%S~) ###~ &gt; $PUPPET_CONF  echo -ne ~[main]\\nserver = $PUPPET_SRV\\n~ &gt;&gt; $PUPPET_CONF}function setup_resolver(){  local resolver=/etc/resolv.conf  echo ~### created by ztp $(date +~%b %d %H#%M#%S~) ###~ &gt; $resolver  echo ~domain $DOMAIN~ &gt;&gt; $resolver  echo ~search $DOMAIN~ &gt;&gt; $resolver  echo ~nameserver $DOMAIN_SRV~ &gt;&gt; $resolver  }function set_hostname(){  xrapply_string_with_reason ~ztp puppet install~ ~hostname $HOSTNAME\\n interface mgmtEth 0/RP0/CPU0/0\\n ipv4 address $MGMT_IP \\n~  /bin/hostname -f $HOSTNAME.$DOMAIN  echo $HOSTNAME &gt; /etc/hostname  }function start_services(){  /etc/init.d/sshd_operns start  /etc/init.d/puppet start}### script startset_hostname;setup_resolver;create_repo;install_puppet;config_puppet;start_services;exit 0", "url": "https://xrdocs.github.io/software-management/blogs/2016-10-20-using-ztp-to-install-puppet/", "tags": "iosxr, linux, puppet, ZTP", "title": "Using ZTP to install Puppet", "author": "Patrick Warichet"}, "blogs-2016-10-14-ios-xr-packages-and-security": {"content": "     IOS-XR Packages and Security  Introduction          Packages Verification      Package Signature                  Example for the puppet client                      IntroductionWith the Introduction of IOX XR 6.0, the complete IOS XR software architecture has migrated to a open source infrastructure centered around the Linux Operating System. With the Adoption of Linux and Linux Containers (LXCs) some major change have been introduce in several areas; The monolithic set of XR features has been dis-aggregated in a collection of RPM packages that can be upgraded trough local or remote repositories. The Linux environment comes with its own authentication mechanism and user privileges. With XR and Linux processes residing side-by-side inside the same namespace, it is important to control the installation and execution of these processes.Packages VerificationPackages and ISOs are delivered in a tar file. included in that tar file is a readme file that contain a MD5 sum for all the files. MD5 sum are a good way to verify the integrity of the file using the md5sum utility on Unix.  md5sum generate a 128-bit value known as the \u201cdigital fingerprint.\u201d If two files have different MD5 sums, the files are definitely different whereas if two files have the same MD5 sum, it is highly likely the files are exactly alike. MD5 is technically a cryptography hash function which essentially means that the risk of producing collisions is really low but possible.Example of verifying md5sum from the Linux shell using unnamed pipes.cisco@galaxy-42#~$ diff -awsy &lt;(grep mgbl README-ncs5k-k9sec-6.0.0 | cut -d' ' -f1) &lt;(md5sum ncs5k-mgbl-2.0.0.0-r600.x86_64.rpm-6.0.0 | cut -d' ' -f1)7a0e22ea86622dfc2293179d6fb52721               7a0e22ea86622dfc2293179d6fb52721Files /dev/fd/63 and /dev/fd/62 are identicalor using a simple script#!/bin/bashif [ -z $3 ]; then\techo ~file + readme + feature needed~\techo ~usage# 0? ~\texitfiexport csum=$(grep $3 $2 | cut -d' ' -f1)export fsum=$(md5sum $1 | cut -d' ' -f1)echo $csumecho $fsumif [ ~$csum~ = ~$fsum~ ]; then\techo ~MD5sum are identical~else\techo ~MD5sum are different~ficisco@galaxy-42#~$ chkmd5.sh ncs5k-mgbl-2.0.0.0-r600.x86_64.rpm-6.0.0 README-ncs5k-k9sec-6.0.0 mgbl7a0e22ea86622dfc2293179d6fb527217a0e22ea86622dfc2293179d6fb52721MD5sum are identicalPackage SignatureIOS XR 6.0.0 and above use the RPM format for all its packages, the RPM format include the capability to digitally sign packages using a SHA-1 key. At this time none of the IOS XR packages are signed, this feature will be available in a future release.Some third party packages embed a RSA/SHA-1signature, to install these packages, the public key of the provider can be verified before and during package installation.Example for the puppet client1) Key PresenceOn the local repository server, you can verify if the package has been signed by the provider.cisco@galaxy-42#~$ rpm -qpi  puppet-agent-1.4.1-1.cisco_wrlinux7.x86_64.rpm | grep Signaturewarning# puppet-agent-1.4.1-1.cisco_wrlinux7.x86_64.rpm# Header V4 RSA/SHA1 Signature, key ID 4bd6ec30# NOKEYSignature   # RSA/SHA1, Thu 24 Mar 2016 03#05#33 PM PDT, Key ID 1054b7a24bd6ec302) Key VerificationOn the local repository download and import the public key from the package provider, this step can be performed multiple time to verify the integrity of all packages in the local repository.cisco@galaxy-42#~$ wget http#//yum.puppetlabs.com/RPM-GPG-KEY-puppetlabscisco@galaxy-42#~$ rpm --import RPM-GPG-KEY-puppetlabcisco@galaxy-42#~$ rpm -Kv  puppet-agent-1.4.1-1.cisco_wrlinux7.x86_64.rpmpuppet-agent-1.4.1-1.cisco_wrlinux7.x86_64.rpm#     Header V4 RSA/SHA1 Signature, key ID 4bd6ec30# OK     Header SHA1 digest# OK (fd954ea78e24ea32fdbaf3be045087ffe4c277ae)     V4 RSA/SHA1 Signature, key ID 4bd6ec30# OK     MD5 digest# OK (5eb0292058ba82449b7fb6eaa62fc102)3) Create a Repository PointerOn the Router, create a .repo file in /etc/yum/repos.d that enable key verification of packages, keys can also be copied on a local repository if this repository is secure.[puppetlabs]name=puppetlabsbaseurl=http#//galaxy-42.cisco.com/Packagesgpgcheck=1gpgkey=http#//yum.puppetlabs.com/RPM-GPG-KEY-puppetlabsenabled=14) Package Installation from local repositoryxr-vm_node0_RP0_CPU0#~# yum install puppet-agentLoaded plugins# app_plugin, downloadonly, protect-packages    puppetlabs                                                                     | 2.9 kB     00#00    Setting up Install Process    Resolving Dependencies    --&gt; Running transaction check    ---&gt; Package puppet-agent.x86_64 0#1.4.1-1.cisco_wrlinux7 will be installed    --&gt; Finished Dependency Resolution    Dependencies Resolved    ======================================================================================================    Package                Arch             Version                           Repository            Size    ======================================================================================================    Installing#    puppet-agent           x86_64           1.4.1-1.cisco_wrlinux7            puppetlabs            41 M    Transaction Summary    ======================================================================================================    Install       1 Package    Total download size# 41 M    Installed size# 143 M    Is this ok [y/N]# y    Retrieving key from http#//yum.puppetlabs.com//RPM-GPG-KEY-puppetlabs    Importing GPG key 0x4BD6EC30#    Userid# ~Puppet Labs Release Key (Puppet Labs Release Key) &lt;info@puppetlabs.com&gt;~    From  # http#//yum.puppetlabs.com//RPM-GPG-KEY-puppetlabs    Is this ok [y/N]# y    Downloading Packages#    puppet-agent-1.4.1-1.cisco_wrlinux7.x86_64.rpm                                 |  41 MB     00#01    Running Transaction Check    Running Transaction Test    Transaction Test Succeeded    Running Transaction      Installing # puppet-agent-1.4.1-1.cisco_wrlinux7.x86_64                                         1/1    Installed#      puppet-agent.x86_64 0#1.4.1-1.cisco_wrlinux7    Complete!", "url": "https://xrdocs.github.io/software-management/blogs/2016-10-14-ios-xr-packages-and-security/", "tags": "iosxr, cisco, linux, RPM", "title": "IOS-XR Packages and Security", "author": "Patrick Warichet"}, "tutorials-2017-08-03-using-dcloud-to-access-the-wan-automation-engine-demos": {"content": "     On This Page  Overview  Prerequisites  Switch to the Appropriate Datacenter  Search for the Specified WAE Demo  Schedule and Launch the WAE Demo  Access the WAE Demo  Launch WAE Design and Open a Network Model  OverviewThe WAN Automation Engine (WAE) is a software platform that provides multivendor and multilayer visibility and analysis for service provider and large enterprise networks. It plays a critical role in answering key questions of network resource availability by simulating an abstracted model of the network, and when appropriate can automate and simplify Traffic Engineering mechanisms such as RSVP-TE and Segment Routing.Here on XR Docs, we are aiming to provide tutorials, blogs and other technical resources in order to help customers and partners understand how to effectively use WAE. Given that WAE is a product that requires a license, these tutorials will be using Cisco dCloud which provides a private demo environment.This tutorial will show you how to launch a WAE demo on dCloud.Note# There are several WAE demos on dCloud, the tutorial will tell you which demo to launch and what plan file to use.Prerequisites  Make sure you have an account on cisco.com.  Using your cisco.com account try logging in to dcloud.cisco.com.Switch to the Appropriate Datacenter  Select your user profile icon in the top right of the page.  Change the datacenter option to the datacenter outlined in the tutorial.Search for the Specified WAE Demo  Select the Catalog tab on the top  Search for the demo outlined in the tutorial.Schedule and Launch the WAE Demo  Follow the steps to schedule and start the WAE demo.Note# It may take up to 20 minutes after the scheduled start time before the demo is ready to use.Access the WAE Demo  Select the My Dashboard tab on the top.  Select My Sessions, then select View for the demo.There are two methods to access the demos.  Option 1 (suggested)# Identify and select the workstation and open the link that says \u201cRemote Desktop\u201d to launch a VNC session to the workstation within your browser.  Option 2# Use cisco anyconnect to connect to the demo. Then use your remote desktop client to connect to the workstation. To connect via anyconnect use the credentials specified under Session Details.Launch WAE Design and Open a Network Model  On the workstation desktop, open the WAE Design application.  Select File -&gt; Open  Browse to the samples directory and select us_wan_l1.txt  In the web browser of the workstation you may also navigtae to the tutorial on XR docs and download the plan file from the tutorial if specified.", "url": "https://xrdocs.github.io/automation/tutorials/2017-08-03-using-dcloud-to-access-the-wan-automation-engine-demos/", "tags": "cisco, WAE, Automation, Capacity Planning", "title": "Using dCloud to Access the WAN Automation Engine Demos", "author": "Josh Peters"}, "blogs-2017-09-25-service-layer-intro": {"content": "Service Layer APIIn IOS-XR, routing protocols make use of services provided by the Routing Information Base (RIB), the MPLS label manager, BFD, and other modules, in order to program the forwarding plane. Such programming is exposed through the service layer API, which is very rich in nature.Exposing the service layer API as a Google RPC (or GRPC), over Google protocol buffers (protobuf or GPB), enables customers to write their own applications, routing protocols, controllers, etc., whether on box or off box, in a rich set of languages including cplusplus, python, GO, etc.The Service Layer API is currently organized in a set of files that expose certain verticals e.g. IPv4 RIB functionality, or MPLS functionality, etc.In the initial release, the focus is to provide the following verticals#  Initialization# This mainly handles global initialization, and sets up an event notification channel based on GRPC streaming mechanism.  IPv4, IPv6 Route# This mainly handles any IPv4 or IPv6 route additions into the node based on a certain VRF.  MPLS Incoming Label Maps (ILMs)# This mainly handles any incoming MPLS label mapping to a forwarding function.  IPv4, IPv6 BFD# This mainly handles managing BFD sessions, and getting corresponding BFD session state notifications.  Interfaces# This mainly allows registered clients to get interface state event notifications.  More functions may be added in the future.Each function vertical, e.g. RIB vertical, declares a \u201ctemplate\u201d set of RPCs that is more or less consistently followed throughout other verticals. Some of these template RPCs are explained here#  (Vertical)Get()# This is mainly used to query certain capabilities for that vertical.  (Vertical)GetStats()# This is mainly used to query vertical specific statistics.  (Vertical)RegOp()# This is mainly used to Register/Unregister/EoF, which basically notifies the service layer server about interest in the vertical, no interest, and end of file (EoF), respectively. The EoF marker is especially useful on replay of objects in certain restart scenarios.  (Vertical)(Object)Op()# This is mainly used to add, delete, update objects. The convention used for add and update, is that, object \u2018adds\u2019 may fail if the object already exists, whereas update can create or simply override the object if it exists.  (Vertical)(Object)Get()# This is mainly used to retrieve an object or a set of objects.  Stream()# This is mainly a GRPC \u201cstreaming\u201d version of the non-streaming version of the function.  Notif()# This is mainly a streaming notification function, e.g. asynchronous BFD session state events\u2019 streaming.The Service Layer API allows for GRPC unary functions in most cases, and GRPC streaming in other cases. The former can be rendered in both synchronous and asynchronous modes (depends on the language). The latter is used for continuous transmitting and/or receiving of objects in an asynchronous fashion. This is especially useful to boost performance in certain cases. Please refer to the GRPC website for more information# http#//grpc.ioIn addition, certain RPCs may also allow for batching e.g. creating a number of routes in a single RPC call (in a batch).Each RPC usually takes a GRPC \u201cmessage\u201d or request, typically labeled (Something)Msg, example SLRoutev4Msg, which defines the parameters of the request, and return another \u201cmessage\u201d, typically labeled (Something)MsgRsp as a response to the RPC request, example SLRoutev4MsgRsp.Note# The instructions below assume the user has already cloned the \u201clindt-objmodel\u201d repository that houses the code for the GRPC client creation and testing. All the paths are relative to the root of the \u201clindt-objmodel\u201d repository.Note that all files are annotated with detailed documentation.The user of the API can use doxygen to render his/her own local documentation, refer to instructions under docs directory. The html generated documentation is broken up into sections that describe the messages, verticals, files, etc, and are very useful for quick reference.Finally, please note that the API comes with#  A quick start tutorial written in python. The intent here is to get the user a jump-start on hooking up with the API. The reader is advised to try this next.This can be found here# grpc/python/src/tutorial/  Another similar tutorial written in GO (golang). This tutorial\u2019s code is pre-compiled and committed in the code repo for a quick start on some of the API key features showing batching, etc.This can be found here# grpc/go/src/tutorial/quickstart.goThe executable can be found here# grpc/go/src/tutorial/tutorial  A Python unittest regression suite that covers basic API sanities. It is also very useful and handy if someone wants to get some reference implementation for a certain use case.This can be found here# grpc/python/srcTo run the unit test regression, setup some Environment variables#export SERVER_IP=192.168.122.192export SERVER_PORT=57344Run All tests#python -m unittest -v tests.test_lindtWe hope that the above was useful quick overview about the service layer API. We recommend that the reader goes over the python quick tutorial first and then go over the .proto files under grpc/protos (or look at the generated .html pages, these are not kept in this repo, but can be auto-generated from this repo).", "url": "https://xrdocs.github.io/cisco-service-layer/blogs/2017-09-25-service-layer-intro/", "tags": "iosxr, linux, service, layer", "title": "Service Layer API Introduction", "author": "Reda Haddad"}, "tutorials-2018-01-16-sample-intervals-in-telemetry-configuration": {"content": "     Sample intervals in telemetry configuration  Sample-interval overview  Strict-timer overview  What is a missed collection?          Missed collections with \u201csample-interval\u201d      Missed collections with \u201cstrict-timer\u201d        Conclusion  We\u2019ve got several similar questions recently about sample intervals in MDT configuration on IOS-XR routers. A basic MDT configuration is pretty clear and you can find a number of documents and posts explaining how to do it. But this is a minimum configuration and there are many additional features coming with new releases. The goal is this document is to explain how \u201csample-interval\u201d works internally and options you have today.Sample-interval overviewAs a short reminder, \u201csample-interval\u201d is used inside the subscription level within Model-Driven Telemetry configuration on an IOS-XR router#   \ttelemetry model-driven  subscription SUB1    sensor-group-id SGROUP1 sample-interval 10000    destination-id DGROUP1The general meaning is how fast you want configured sensor-path (the defined data) to be pushed out of the box. But how does this work internally?Here is a simple schematic view of how \u201csample-interval\u201d works#Let\u2019s say that at To your configuration was applied and the first collection just started. The collection by itself needs some time to gather information and put it on the wire. Define this period of time as Tc.  Going this way, at [To + Tc] moment your system will be ready to start counting down your configured \u201csample-interval\u201d [Ts].  Your next collection will start its internal calls right after [To + Tc + Ts], or, speaking more general, instead of having your configured amount of time, you will observe total time of the collection plus the \u201csample-interval\u201d itself.You can feel that behavior analyzing the logs on your collector. In the example below \u201csample-interval\u201d was configured to be 20 seconds (20000 msec)#{'collection_id'# 150, 'node_id_str'# 'R1', 'msg_timestamp'# 1511451973975, 'collection_start_time'# 1511451973975, 'collection_end_time'# 1511451974094, 'encoding_path'# 'Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/protocols/protocol', 'subscription_id_str'# 'sub_testsampleinterval'} {'collection_id'# 151, 'node_id_str'# 'R1', 'msg_timestamp'# 1511451994094, 'collection_start_time'# 1511451994094, 'collection_end_time'# 1511451994209, 'encoding_path'# 'Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/protocols/protocol', 'subscription_id_str'# 'sub_ testsampleinterval'}If you do a simple math with the \u201cmsg_timestamp\u201d values from both entries you will find out, that the difference is 20119 (msec). This number is slightly bigger than the configured \u201csample-interval\u201d, so, let\u2019s find out the time needed for the first collection by subtracting \u201ccollection_start_time\u201d from \u201ccollection_end_time\u201d. The difference is exactly 119 (msec). This simple exercise confirms the behavior explained above.Strict-timer overviewStarting with IOS-XR 6.2.2 you can add a \u201cstrict-timer\u201d command under the subscription#   \ttelemetry model-driven  subscription SUB1    sensor-group-id SGROUP1 sample-interval 10000    sensor-group-id SGROUP1 strict-timer    destination-id DGROUP1This command is not used alone, but together with \u201csample-interval\u201d. The question comes, how does this influence our behavior?Let\u2019s have a look at this picture#The system starts at the same To , when you got your configuration applied. The collection needs the same amount of time, Tc.  But instead of waiting for the [T0 + TC] moment your router will start counting down your configured \u201csample-interval\u201d right at the moment To.  This way, your next collection will start exactly at [To + Ts], or, using other words, the next collection will happen exactly when you expect it to start (according to the configured \u201csample-interval\u201d).Here are the logs from the same system, but running with \u201cstrict-timer\u201d applied this time#{'collection_id'# 365, 'node_id_str'# 'R1', 'msg_timestamp'# 1511551935943, 'collection_start_time'# 1511551935943, 'collection_end_time'# 1511551936062, 'encoding_path'# 'Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/protocols/protocol', 'subscription_id_str'# 'sub_testsampleinterval'} {'collection_id'# 366, 'node_id_str'# 'R1', 'msg_timestamp'# 1511551955943, 'collection_start_time'# 1511551955943, 'collection_end_time'# 1511551956062, 'encoding_path'# 'Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/protocols/protocol', 'subscription_id_str'# 'sub_ testsampleinterval'}Following the same math operations as above, you can see that difference between \u201cmsg_timestamp\u201d values in both entries is exactly 20000 (msec), as it was configured (and each collection takes the same 119msec to complete).What is a missed collection?A question might arise, like, what will happen if the collection time is longer than the configured sample interval? Such a situation is possible when you applied wrong sample interval (a very aggressive one), or when due to some reason collection/encoding/sending took more time than usual. Before going into explanation of behavior, let\u2019s see how one can check missed collections#RP/0/RSP0/CPU0#ASR9k#sh telemetry model-driven subscription xrdocs-test internalTue Jan 15 21#01#00.141 PST Subscription#  xrdocs-testskipped       Sensor Path#          Cisco-IOS-XR-wdsysmon-fd-oper#system-monitoring/cpu-utilization       Sysdb Path#     /oper/wdsysmon_fd/gl/*      Count#          59 Method# DATALIST Min# 19 ms Avg# 21 ms Max# 29 ms      Item Count#     144     Missed Collections#57  send bytes# 2048671 packets# 38 dropped bytes# 0                      success         errors          deferred/drops       Gets            0               0                    List            0               0                    Datalist        39              0                    Finddata        0               0                    GetBulk         0               0                    Encode                          0               0                    Send                            0               0           skippedThe output from \u201cshow telemetry model-driven subscription  internal~ will give you a ton of information, including the number of missed collections. (We will explain each line of the output in one of our next posts!).Missed collections with \u201csample-interval\u201dAs it was described at the very beginning, for the collections without \u201cstrict-timer\u201d configured, as soon as current collection stops, the system will start a new \u201csample-interval\u201d timer countdown.If the collection (includes also encoding and sending) took more time than the \u201csample-interval\u201d configured, then the IOS-XR router will skip sending any information out at this moment (but it will push the data out right when it is ready) and will update its internal \u201cmissed collections\u201d counter (+1 missed collection, based on \u201csample-interval\u201d timer). Right after the collection is done, a new sample interval will start its count down process.Missed collections with \u201cstrict-timer\u201d\u201cStrict-timer\u201d adds more deterministic behavior to the process of pushing data out. And this stays the same with situations where collection time takes longer than the configured \u201csample-interval\u201d#As soon as the configured \u201csample-interval\u201d ends, the router will update its internal counter (+1 missed collection) and will not send anything out (only when information is ready). As with \u201csample-interval\u201d case, it is very important that your router doesn\u2019t send stale information, or even a string of zeros, as it might affect your monitoring and/or automation tools. The difference with \u201csample-interval\u201d case is that here the countdown for the next \u201csample-interval\u201d will start right at the moment when the first timer ends. If you have a consistent behavior with long collection times, you should expect that the \u201cwindow\u201d, between the moment when the previous collection stops and the start of the following collection, will be shrinking over time.ConclusionThere is no \u201cgolden\u201d rule on how to proceed with your configuration of sample intervals. There are telemetry customers that use each way. If you have collections that take several msec to collect the data, encode it and send to your collector, probably there is not much difference. If you have collections with big total time, then make sure your sampling is aligned with that and you don\u2019t have missed collections over time. A good point for \u201cstrict-timer\u201d could be an easier way to implement some kind of automation, as you will have more deterministic behavior of your telemetry.", "url": "https://xrdocs.github.io/telemetry/tutorials/2018-01-16-sample-intervals-in-telemetry-configuration/", "tags": "iosxr, telemetry, MDT, automation", "title": "Sample intervals in telemetry configuration", "author": "Viktor Osipchuk"}, "tutorials-2016-06-06-xr-toolbox-app-development-topology": {"content": "     App Development Topology  Introduction  Pre-requisites  Understand the topology  Bring up the topology          Download and Add the XR Vagrant box      Launch the nodes      Check Reachability        Check out Part 2 of the XR toolbox series# Bootstrap XR configuration with Vagrant.IntroductionWithout diving too deep into the IOS-XR architecture, it might be useful to state that applications on IOS-XR may be deployed in two different ways#  natively (inside the XR process space) OR  as a container (LXC)In this quick start guide we introduce a typical vagrant topology that we intend to use in other quick start guides in the XR Toolbox series. This topology will be used to build and deploy container (LXC) as well as native XR applications and test them on Vagrant IOS-XR.Pre-requisites  Meet the pre-requisites specified in the IOS-XR Vagrant Quick Start guide# Pre-requisites. The topology here will require about 5G RAM and 2 cores on the user&#8217;s laptop.  Clone the following repository# https#//github.com/ios-xr/vagrant-xrdocs, before we start.cd ~/git clone https#//github.com/ios-xr/vagrant-xrdocs.gitcd vagrant-xrdocs/You will notice a few directories. We will utilize the lxc-app-topo-bootstrap directory in this tutorial.AKSHSHAR-M-K0DS#vagrant-xrdocs akshshar$ pwd/Users/akshshar/vagrant-xrdocsAKSHSHAR-M-K0DS#vagrant-xrdocs akshshar$ ls lxc-app-topo-bootstrap/Vagrantfile\tconfigs\t\tscriptsAKSHSHAR-M-K0DS#vagrant-xrdocs akshshar$ Understand the topologyFor this tutorial, we&#8217;ll use a two-node topology# An XR vagrant instance connected to Linux instance (devbox). For illustrative purposes, we use Ubuntu as our devbox OS#The Vagrantfile to bring up this topology is already in your cloned directory#vagrant-xrdocs/lxc-app-topo-bootstrap/VagrantfileVagrant.configure(2) do |config|   config.vm.define ~rtr~ do |node|   node.vm.box =  ~IOS-XRv~   # gig0/0/0 connected to ~link1~   # auto_config is not supported for XR, set to false   node.vm.network #private_network, virtualbox__intnet# ~link1~, auto_config# false   #Source a config file and apply it to XR   node.vm.provision ~file~, source# ~configs/rtr_config~, destination# ~/home/vagrant/rtr_config~   node.vm.provision ~shell~ do |s|     s.path =  ~scripts/apply_config.sh~     s.args = [~/home/vagrant/rtr_config~]   end end  config.vm.define ~devbox~ do |node|   node.vm.box =  ~ubuntu/trusty64~   # eth1 connected to link1   # auto_config is supported for an ubuntu instance   node.vm.network #private_network, virtualbox__intnet# ~link1~, ip# ~11.1.1.20~    endendNotice the   #Source a config file and apply it to XR section of the Vagrantfile? This is derived from the Bootstrap XR configuration with Vagrant tutorial. Check it out if you want to know more about how shell provisioning with XR worksThe configuration we wish to apply to XR on boot is pretty simple. You can find it in the lxc-app-topo-bootstrap/configs directory.We want to configure the XR interface# GigabitEthernet0/0/0/0 with the ip-address# 11.1.1.10AKSHSHAR-M-K0DS#vagrant-xrdocs akshshar$ cat lxc-app-topo-bootstrap/configs/rtr_config !! XR configuration!interface GigabitEthernet0/0/0/0  ip address 11.1.1.10/24  no shutdown!endAKSHSHAR-M-K0DS#vagrant-xrdocs akshshar$ Take a look at the Vagrantfile above, again. We use the Vagrant auto_config capabilities to make sure &#8220;eth1&#8221; interface of the Ubuntu VM (called devbox) is configured in the same subnet (11.1.1.20) as XR gig0/0/0/0.Bring up the topologyDownload and Add the XR Vagrant box  IOS-XR Vagrant is currently in Private Beta  To download the box, you will need an API-KEY and a CCO-ID  To get the API-KEY and a CCO-ID, browse to the following link and follow the steps#  Steps to Generate API-KEY$ BOXURL=~http#//devhub.cisco.com/artifactory/appdevci-release/XRv64/latest/iosxrv-fullk9-x64.box~$ curl -u your-cco-id#API-KEY  $BOXURL --output ~/iosxrv-fullk9-x64.box$ vagrant box add --name IOS-XRv ~/iosxrv-fullk9-x64.boxOf course, you should replace  your-cco-id with your actual Cisco.com ID and API-KEY with the key you generated and copied using the above link.The vagrant box add command will take around 10-15 mins as it downloads the box for you.Once it completes, you should be able to see the box added as &#8220;IOS-XRv&#8221; in your local vagrant box list#AKSHSHAR-M-K0DS#~ akshshar$ vagrant box listIOS-XRv (virtualbox, 0)AKSHSHAR-M-K0DS#~ akshshar$ Launch the nodesMake sure you&#8217;re in the lxc-app-topo-bootstrap/ directory and issue a vagrant upAKSHSHAR-M-K0DS#lxc-app-topo-bootstrap akshshar$pwd/Users/akshshar/vagrant-xrdocs/lxc-app-topo-bootstrapAKSHSHAR-M-K0DS#lxc-app-topo-bootstrap akshshar$ vagrant up Bringing machine 'rtr' up with 'virtualbox' provider...Bringing machine 'devbox' up with 'virtualbox' provider...==&gt; rtr# Importing base box 'IOS-XRv'...==&gt; rtr# Matching MAC address for NAT networking...==&gt; rtr# Setting the name of the VM# lxc-app-topo-bootstrap_rtr_1465208784531_75603==&gt; rtr# Clearing any previously set network interfaces...==&gt; rtr# Preparing network interfaces based on configuration...    rtr# Adapter 1# nat    rtr# Adapter 2# intnet==&gt; rtr# Forwarding ports...    rtr# 57722 (guest) =&gt; 2222 (host) (adapter 1)    rtr# 22 (guest) =&gt; 2223 (host) (adapter 1)==&gt; rtr# Running 'pre-boot' VM customizations...==&gt; rtr# Booting VM...==&gt; rtr# Waiting for machine to boot. This may take a few minutes...    rtr# SSH address# 127.0.0.1#2222    rtr# SSH username# vagrant    rtr# SSH auth method# private key    rtr# Warning# Remote connection disconnect. Retrying...    rtr# Warning# Remote connection disconnect. Retrying...       Once it completes, you should be able to see both the VMs running by using the vagrant status command inside the lxc-app-topo-bootstrap/ directory#Check ReachabilityTo get into the Ubuntu &#8220;devbox&#8221;, issue a vagrant ssh devbox#AKSHSHAR-M-K0DS#lxc-app-topo-bootstrap akshshar$ vagrant ssh devboxWelcome to Ubuntu 14.04.4 LTS (GNU/Linux 3.13.0-87-generic x86_64) * Documentation#  https#//help.ubuntu.com/  System information as of Mon Jun  6 11#20#37 UTC 2016  System load#  0.0               Processes#           74  Usage of /#   3.5% of 39.34GB   Users logged in#     0  Memory usage# 25%               IP address for eth0# 10.0.2.15  Swap usage#   0%                IP address for eth1# 11.1.1.20  Graph this data and manage this system at#    https#//landscape.canonical.com/  Get cloud support with Ubuntu Advantage Cloud Guest#    http#//www.ubuntu.com/business/services/cloud0 packages can be updated.0 updates are security updates.vagrant@vagrant-ubuntu-trusty-64#~$ From &#8220;devbox&#8221;, you should be able to ping the XR Gig0/0/0/0 interface#vagrant@vagrant-ubuntu-trusty-64#~$ ping 11.1.1.10 -c 2PING 11.1.1.10 (11.1.1.10) 56(84) bytes of data.64 bytes from 11.1.1.10# icmp_seq=1 ttl=255 time=1.56 ms64 bytes from 11.1.1.10# icmp_seq=2 ttl=255 time=1.44 ms--- 11.1.1.10 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1003msrtt min/avg/max/mdev = 1.447/1.504/1.562/0.069 msvagrant@vagrant-ubuntu-trusty-64#~$ To get into XR linux shell, issue vagrant ssh rtrAKSHSHAR-M-K0DS#lxc-app-topo-bootstrap akshshar$ vagrant ssh rtrLast login# Mon Jun  6 11#20#58 2016 from 10.0.2.2xr-vm_node0_RP0_CPU0#~$ xr-vm_node0_RP0_CPU0#~$ifconfig Gi0_0_0_0Gi0_0_0_0 Link encap#Ethernet  HWaddr 08#00#27#46#1f#b2            inet addr#11.1.1.10  Mask#255.255.255.0          inet6 addr# fe80##a00#27ff#fe46#1fb2/64 Scope#Link          UP RUNNING NOARP MULTICAST  MTU#1514  Metric#1          RX packets#0 errors#0 dropped#0 overruns#0 frame#0          TX packets#1 errors#0 dropped#3 overruns#0 carrier#1          collisions#0 txqueuelen#1000           RX bytes#0 (0.0 B)  TX bytes#42 (42.0 B)xr-vm_node0_RP0_CPU0#~$ xr-vm_node0_RP0_CPU0#~$ xr-vm_node0_RP0_CPU0#~$ To get into XR CLI, remember that XR SSH runs on port 22 of the guest IOS-XR instance.First, determine the port to which the XR SSH port (port 22) is forwarded by vagrant by using the vagrant port command#AKSHSHAR-M-K0DS#lxc-app-topo-bootstrap akshshar$ vagrant port rtr The forwarded ports for the machine are listed below. Please note thatthese values may differ from values configured in the Vagrantfile if theprovider supports automatic port collision detection and resolution.    22 (guest) =&gt; 2223 (host) 57722 (guest) =&gt; 2222 (host)As shown above, port 22 of XR is fowarded to port 2223#Use port 2223 to now ssh into XR CLIThe password is &#8220;vagrant&#8221;AKSHSHAR-M-K0DS#lxc-app-topo-bootstrap akshshar$ ssh -p 2223 vagrant@localhostThe authenticity of host '[localhost]#2223 ([127.0.0.1]#2223)' can't be established.RSA key fingerprint is 7f#1a#56#e1#3c#7f#cf#a4#ee#ac#20#3a#e6#cf#ad#f5.Are you sure you want to continue connecting (yes/no)? yesWarning# Permanently added '[localhost]#2223' (RSA) to the list of known hosts.vagrant@localhost's password# RP/0/RP0/CPU0#ios#RP/0/RP0/CPU0#ios#show ipv4 interface gigabitEthernet 0/0/0/0 brief Tue Jun  7 03#23#31.324 UTCInterface                      IP-Address      Status                ProtocolGigabitEthernet0/0/0/0         11.1.1.10       Up                    Up      RP/0/RP0/CPU0#ios#You&#8217;re all set! You can now use this topology to build applications (native-WRL7 or LXC containers) on the &#8220;devbox&#8221; and test them out on the IOS-XR vagrant node. We will explore these scenarios in the next set of tutorials in the XR Toolbox series.Head over to Part 4 of the XR Toolbox series where we create and bring up a container (LXC) app on IOS-XR &#8212;&gt; Bring your own Container (LXC) App.", "url": "https://xrdocs.github.io/application-hosting/tutorials/2016-06-06-xr-toolbox-app-development-topology", "tags": "vagrant, iosxr, cisco, linux, xr toolbox, apphosting, topology", "title": "XR Toolbox, Part 3 : App Development Topology ", "author": "Akshat Sharma"}, "tutorials-xr-global-config-replace": {"content": "     IOS XR Pattern Config Replace  Introduction  Interface-based Replace operation          Sub-Interface considerations      Example 1      Example 2#        Pattern-based Replace operation          REGEX string matching considerations        Example 3#  Example 4#    In IOS XR 5.3.1, a customer favorite feature was implemented - Pattern Configuration Replace  This feature allows convenient manipulation of router configuration. Consider the following use cases#      Ever wanted to conveniently move configuration from one interface to another?    Or, rather change all repetitions of a given pattern in your router configuration?    If so, keep on reading \u2026IntroductionThe feature allows the user to replace configuration based on an interface identifier or a string patternUnder the global config mode, enter the new replace keyboardRP/0/0/CPU0#PE1#configureRP/0/0/CPU0#PE1(config)#replace ?  interface  replace configuration for an interface  pattern    replace a string pattern in configurationInterface-based Replace operationIn the mode, the user specifies the source and destination interfaces respectivelyThe command also provides a \u201cdry-run\u201d keyboard that allows the user to validate the changes that would be performed by the replace operation without issuing an actual commitRP/0/0/CPU0#PE1(config)#replace interface &lt;ifid_1&gt; with &lt;ifid_2&gt; ?  dry-run  execute the command without loading the replace config  &lt;cr&gt;Sub-Interface considerationsReplacing interface \u201cX\u201d with \u201cY\u201d will also cause all sub-interfaces hosted under \u201cX\u201d (e.g. \u201cX.abc\u201d, \u201cX.def\u201d) to also be replaced with \u201cY\u201dExample# replace interface gigabitEthernet 0/0/0/1 with gigabitEthernet 0/0/0/2 would cause sub-interface gigabitEthernet 0/0/0/1.100 to be replaced to  gigabitEthernet 0/0/0/2.100Example 1In this example, the operator wants to move all configuration located under interface gig 0/0/0/0 to interface gig 0/0/0/2In addition, all other references to the former interface (for example# in routing protocols, mpls lpd, rsvp, etc) also need to be replaced with the new interface (gig 0/0/0/2)Below is the original router configurationRP/0/0/CPU0#iosxrv-1#show run&lt;snip&gt;!interface GigabitEthernet0/0/0/0 description first ipv4 address 10.20.30.40 255.255.255.0!interface GigabitEthernet0/0/0/2 description second ipv4 address 10.20.50.60 255.255.255.0!router ospf 10 area 0  interface GigabitEthernet0/0/0/0   transmit-delay 5  ! !!mpls ldp interface GigabitEthernet0/0/0/0  igp sync delay on-session-up 5 ! &lt;snip&gt; !endBelow the operator runs the replace command using the interface identifiers.In the first attempt, the user decides to give the command a try and specifies the \u201cdry-run\u201d keyword in order to validate the results and without loading any config changesRemember that the goal is to move all configuration and references associated with gig 0/0/0/0 to gig 0/0/0/2RP/0/0/CPU0#iosxrv-1(config)#replace interface gigabitEthernet 0/0/0/0 with gigabitEthernet 0/0/0/2 dry-runno interface GigabitEthernet0/0/0/0interface GigabitEthernet0/0/0/2 description first ipv4 address 10.20.30.40 255.255.255.0router ospf 10 area 0  no interface GigabitEthernet0/0/0/0  interface GigabitEthernet0/0/0/2   transmit-delay 5mpls ldp no interface GigabitEthernet0/0/0/0 interface GigabitEthernet0/0/0/2  igp sync delay on-session-up 5endBy specifying the \u201cdry-run\u201d keyword, we can see below that NO config changes were actually loaded into the candidate config bufferRP/0/0/CPU0#iosxrv-1(config)#RP/0/0/CPU0#iosxrv-1(config)#showThu May 26 05#48#51.519 UTCBuilding configuration...!! IOS XR Configuration 6.1.1.14IendNow, the operator is ready to proceed with the change. The replace operation is run without using the \u201cdry-run\u201d keywordRP/0/0/CPU0#iosxrv-1(config)#replace interface gigabitEthernet 0/0/0/0 with gigabitEthernet 0/0/0/2Loading.365 bytes parsed in 1 sec (357)bytes/secRP/0/0/CPU0#iosxrv-1(config)#RP/0/0/CPU0#iosxrv-1(config)#show commit changes diffThu May 26 07#02#34.026 UTCBuilding configuration...!! IOS XR Configuration 6.1.1.14I-  interface GigabitEthernet0/0/0/0-   description first-   ipv4 address 10.20.30.40 255.255.255.0   !   interface GigabitEthernet0/0/0/2&lt;-  description second+&gt;  description first&lt;-  ipv4 address 10.20.50.60 255.255.255.0+&gt;  ipv4 address 10.20.30.40 255.255.255.0   !   router ospf 10    area 0-    interface GigabitEthernet0/0/0/0-     transmit-delay 5     !+    interface GigabitEthernet0/0/0/2+     transmit-delay 5     !    !   !   mpls ldp-   interface GigabitEthernet0/0/0/0-    igp sync delay on-session-up 5    !+   interface GigabitEthernet0/0/0/2+    igp sync delay on-session-up 5    !   !endRP/0/0/CPU0#iosxrv-1(config)#RP/0/0/CPU0#iosxrv-1(config)#commitThu May 26 07#02#48.775 UTCRP/0/0/CPU0#iosxrv-1(config)#RP/0/0/CPU0#iosxrv-1(config)#exitAfter committing the configuration, we can see the new configuration and updated references to interface gig 0/0/0/2RP/0/0/CPU0#iosxrv-1#show run&lt;snip&gt;!interface GigabitEthernet0/0/0/2 description first ipv4 address 10.20.30.40 255.255.255.0!interface GigabitEthernet0/0/0/3 shutdown!router ospf 10 area 0  interface GigabitEthernet0/0/0/2   transmit-delay 5  ! !!mpls ldp interface GigabitEthernet0/0/0/2  igp sync delay on-session-up 5 !!endExample 2#In the previous example, both interfaces had the same configuration statements (description and IPv4 address). With the replace operation, the config from interface gig 0/0/0/1 was moved and effectively merged with the config under interface gig 0/0/0/2This example will cover the case where the original and new interfaces have \u201cdifferent\u201d configuration statements. This time the user desires to only apply the config from the original interface and not to mergeWe start with an initial config where interface gig 0/0/0/0 and gig 0/0/0/2 have different configuration statements (note the presence of a non-default mtu on gig 0/0/0/2)RP/0/0/CPU0#iosxrv-1#show run&lt;snip&gt;!interface GigabitEthernet0/0/0/0 description first ipv4 address 10.20.30.40 255.255.255.0!interface GigabitEthernet0/0/0/2 description second mtu 9000 ipv4 address 10.20.50.60 255.255.255.0!&lt;snip&gt; !!endTo achieve the goal, the user first deletes the interface gig 0/0/0/2 by using the \u201cno\u201d commandAnd subsequently follow it with the \u201creplace\u201d operationRP/0/0/CPU0#iosxrv-1#conf tThu May 26 06#55#50.674 UTCRP/0/0/CPU0#iosxrv-1(config)#no interface GigabitEthernet0/0/0/2RP/0/0/CPU0#iosxrv-1(config)#RP/0/0/CPU0#iosxrv-1(config)#replace interface gigabitEthernet 0/0/0/0 with gigabitEthernet 0/0/0/2Loading.365 bytes parsed in 1 sec (357)bytes/secRP/0/0/CPU0#iosxrv-1(config)#Observe below the diffs applied on the candidate config buffer. Note that in fact, the target interface gigabitEthernet 0/0/0/2 was not deleted (even though the \u201cno interface\u201d command was issued) but instead the minimal set of changes were automatically applied by the backend; i.e. description and IPv4 addresses were updated and non-default MTU was automatically removed  With a new behavior introduced in IOS XR 5.3.2, a DELETE followed by a RECREATE of an interface translates to a SET of minimal changes between original and target interface configuration. This way the user does not have to one-by-one remove unwanted configurations while avoiding unnecessary interface flaps  Stay tune for an upcoming tutorial detailing this new behavior !!RP/0/0/CPU0#iosxrv-1(config)#show commit changes diffThu May 26 06#56#44.230 UTCBuilding configuration...!! IOS XR Configuration 6.1.1.14I-  interface GigabitEthernet0/0/0/0-   description first-   ipv4 address 10.20.30.40 255.255.255.0   !   interface GigabitEthernet0/0/0/2&lt;-  description second+&gt;  description first-   mtu 9000&lt;-  ipv4 address 10.20.50.60 255.255.255.0+&gt;  ipv4 address 10.20.30.40 255.255.255.0   !   router ospf 10    area 0-    interface GigabitEthernet0/0/0/0-     transmit-delay 5     !+    interface GigabitEthernet0/0/0/2+     transmit-delay 5     !    !   !   mpls ldp-   interface GigabitEthernet0/0/0/0-    igp sync delay on-session-up 5    !+   interface GigabitEthernet0/0/0/2+    igp sync delay on-session-up 5    !   !endRP/0/0/CPU0#iosxrv-1(config)#RP/0/0/CPU0#iosxrv-1(config)#commitThu May 26 06#56#54.169 UTCRP/0/0/CPU0#iosxrv-1(config)#Lastly, below we can see the resulting configuration completely replacing the configuration under interface gigabitEthernet 0/0/0/2 with the one previously found on gigabitEthernet 0/0/0/1RP/0/0/CPU0#iosxrv-1#show run&lt;snip&gt;!interface GigabitEthernet0/0/0/2 description first ipv4 address 10.20.30.40 255.255.255.0!!router ospf 10 area 0  interface GigabitEthernet0/0/0/2   transmit-delay 5  ! !!mpls ldp interface GigabitEthernet0/0/0/2  igp sync delay on-session-up 5 !!endRP/0/0/CPU0#iosxrv-1#Pattern-based Replace operationIn the second mode of operation, the user can provide string patterns with the \u201creplace\u201d commandAs it was the case before, the command provides a \u201cdry-run\u201d keyboard that allows the user to validate the changes that would be performed by the replace operation without issuing an actual commitRP/0/0/CPU0#PE1(config)#replace pattern ?  regex-string  pattern to be replaced within single quotes  RP/0/0/CPU0#PE1(config)#replace pattern 'string_1' with 'string_2' ?  dry-run  execute the command without loading the replace config  &lt;cr&gt;  REGEX string matching considerationsThe input entered in the replace command is considered a regex stringSo for example, if you are trying to replace an IPv4 address (e.g. 1.2.3.4), remember to escape the \u2018.\u2019 as otherwise it would match any characterUsing an IMPROPER input regex string would match undesired statementsFor example, consider a router configuration that includes an interface with ipv4 address 1.2.3.4 and an interface description 10203040The following string pattern will match occurrences of 1.2.3.4 as well as 10203040replace pattern '1.2.3.4' with '25.26.27.28' ---&gt; *** DO NOT USE THIS ***The following string pattern will match ONLY occurrences of 1.2.3.4replace pattern '1\\.2\\.3\\.4' with '25.26.27.28' ---&gt; *** USE THIS INSTEAD ***  Renaming certain configuration objects with replace operation MAY fail to commit due to interdependency checks performed by IOS XR  For example, renaming a class-map that is referenced by a policy-map will not go thru commit due to classmap interdependecy on policy-map; semantic error raised# \u201c% Object is in use# Class-map \u201cCMAP-TEST\u201d of type \u201cqos\u201d is used by policy-map(s). Delete failed.\u201dExample 3#In this example, we will use string pattern replace to move the configuration under Bundle-Ether1000 to a new Bundle-Ether2000 interfaceConfiguring bundle interfaces requires both configuration of the logical interface itself as well as the bundle members. Using the \u201creplace interface\u201d command alone as previous examples, would have achieved the former but not the latter. Therefore, we would turn to \u201creplace pattern\u201d to achieve our goalBelow is the original router configurationRP/0/0/CPU0#iosxrv-1#show run&lt;snip&gt;interface Bundle-Ether1000 bandwidth 1990656 ipv4 address 13.5.6.5 255.255.255.0 load-interval 30!interface GigabitEthernet0/0/0/0 bundle id 1000 mode active shutdown!interface GigabitEthernet0/0/0/1 bundle id 1000 mode active shutdown!&lt;snip&gt;endRepetitions of pattern \u20181000\u2019 are modified to \u20182000\u2019User specifies the \u201cdry-run\u201d keyboard to validate the changes without an actual commitRP/0/0/CPU0#iosxrv-1#conf tRP/0/0/CPU0#iosxrv-1(config)#replace pattern '1000' with '2000' dry-runno interface Bundle-Ether1000interface Bundle-Ether2000 bandwidth 1990656 ipv4 address 13.5.6.5 255.255.255.0 load-interval 30interface GigabitEthernet0/0/0/0 no bundle id 1000 mode active bundle id 2000 mode activeinterface GigabitEthernet0/0/0/1 no bundle id 1000 mode active bundle id 2000 mode activeendReplace command is re-executed without the \u201cdry-run\u201d keyboardRP/0/0/CPU0#iosxrv-1(config)#replace pattern '1000' with '2000'Loading.319 bytes parsed in 1 sec (312)bytes/secBelow observe the changes in the target configuration bufferRP/0/0/CPU0#iosxrv-1(config)#show commit changes diffFri May 27 08#13#38.485 UTCBuilding configuration...!! IOS XR Configuration 6.1.1.14I-  interface Bundle-Ether1000-   bandwidth 1990656-   ipv4 address 13.5.6.5 255.255.255.0-   load-interval 30   !+  interface Bundle-Ether2000+   bandwidth 1990656+   ipv4 address 13.5.6.5 255.255.255.0+   load-interval 30   !   interface GigabitEthernet0/0/0/0&lt;-  bundle id 1000 mode active+&gt;  bundle id 2000 mode active   !   interface GigabitEthernet0/0/0/1&lt;-  bundle id 1000 mode active+&gt;  bundle id 2000 mode active   !endRP/0/0/CPU0#iosxrv-1(config)#RP/0/0/CPU0#iosxrv-1(config)#commitAfter \u201ccommit\u201d, then entire Bundle-Ether1000 config (including bundle members) has been moved to Bundle-Ether2000RP/0/0/CPU0#iosxrv-1#show run&lt;snip&gt;interface Bundle-Ether2000 bandwidth 1990656 ipv4 address 13.5.6.5 255.255.255.0 load-interval 30!interface GigabitEthernet0/0/0/0 bundle id 2000 mode active shutdown!interface GigabitEthernet0/0/0/1 bundle id 2000 mode active shutdown!&lt;snip&gt;endAs an alternative, note that instead of a single operation, this example could have also been achieved with the following two (2) replace operationsRP/0/0/CPU0#iosxrv-1(config)#replace interface Bundle-Ether1000 with Bundle-Ether2000RP/0/0/CPU0#iosxrv-1(config)#replace pattern 'bundle id 1000 mode active' with 'bundle id 2000 mode active'Example 4#In this example, the goal is to move the configuration under interfaces GigabitEthernet 0/0/0/0, 0/0/0/1 and 0/0/0/2 to interface TenGigE 0/3/0/0, 0/3/0/1 and 0/3/0/2Below is the original router configurationRP/0/0/CPU0#iosxrv-1#show run&lt;snip&gt;!interface GigabitEthernet0/0/0/0 bundle id 2000 mode active shutdown!interface GigabitEthernet0/0/0/1 bundle id 2000 mode active shutdown!interface GigabitEthernet0/0/0/2 description first ipv4 address 10.20.30.40 255.255.255.0!&lt;snip&gt;!router ospf 10 area 0  interface GigabitEthernet0/0/0/2   transmit-delay 5  ! !!mpls ldp interface GigabitEthernet0/0/0/2  igp sync delay on-session-up 5 !!endBelow we apply the replace pattern command using regex strings GigabitEthernet0/0/0/([0-2]) and TenGigE0/3/0/\\1RP/0/0/CPU0#iosxrv-1#conf tRP/0/0/CPU0#iosxrv-1(config)#replace pattern 'GigabitEthernet0/0/0/([0-2])' with 'TenGigE0/3/0/\\1' dry-runno interface GigabitEthernet0/0/0/0interface TenGigE0/3/0/0 bundle id 2000 mode active shutdownno interface GigabitEthernet0/0/0/1interface TenGigE0/3/0/1 bundle id 2000 mode active shutdownno interface GigabitEthernet0/0/0/2interface TenGigE0/3/0/2 description first ipv4 address 10.20.30.40 255.255.255.0router ospf 10 area 0  no interface GigabitEthernet0/0/0/2  interface TenGigE0/3/0/2   transmit-delay 5mpls ldp no interface GigabitEthernet0/0/0/2 interface TenGigE0/3/0/2  igp sync delay on-session-up 5And there you have it !!!I hope that you find this posting useful, but more importantly that you benefit from this new IOS-XR functionality", "url": "https://xrdocs.github.io/cloud-scale-networking/tutorials/xr-global-config-replace", "tags": "iosxr, config replace, string replace", "title": "IOS XR Pattern Config Replace", "author": "Jose Liste"}, "blogs-2018-02-22-ztp-integration-with-nso": {"content": "     Using ZTP to integrate IOS-XR with NSO  Introduction          NSO      IOS-XR      ZTP      Flow of Operation      DHCP Configuration      ZTP Script                  Device Profile                      IntroductionNetwork Services Orchestrator is a Cisco tool that provides end-to-end orchestration that spans multiple domains in your network. Using strict, standardized YANG models for both services and devices and a highly efficient abstraction layer between your network services and the underlying infrastructure, the orchestrator lets you automate Cisco and other vendor\u2019s devices.NSOTo automate configuration of physical devices, NSO relies on add-ons packages called Network Element Driver (NED)NSO provides 2 different ways to interact with IOS-XR#  The IOS-XR CLI NED for CLI configuration  The Netconf NED for Netconf/Yang configurationThe IOS-XR CLI NED must be purchased for your version of NSO. Once acquired, it should be installed inside NSO as a package.For the Netconf NED, there are 2 ways to create the package      Download all the models supported by XR on github# Yang models for Cisco IOS-XR and use the ncs-make-package command to create the package, once created you can install the package inside NSO.        Use the NSO pioneer tool available on github# Your Swiss army knife for NETCONF, YANG and NSO NEDs to retrieve all the models from a device and create the package.  The advantage of the second method is that you are certain that the device effectively supports all the models but the retrieve operation can take some time.NSO has a set of REST/RESTCONF northbound API that can be used to provision a devices using simple HTTP GET/PUT/POST request. In short, only three operations are required#  Creating the device and associate it with the correct NED (Netconf/IOS-XR CLI)  Exchange the RSA keys between the device and NSO  synchronize the configuration with NSOThe example in this blog uses REST, if you plan to use RESTCONF, small modifications in the URIs are required.To allow full configuration of device, NSO requires configuring the username and password (encrypted) in an authorization group, devices that belong to a specified authgroup shares the same username and password. In the example below the authgroup ios-xr-default has been created in advance on the NSO server.devices authgroups group ios-xr-default default-map remote-name cisco default-map remote-password &lt;encrypted password&gt;IOS-XRTo allow IOS-XR to communicate with NSO using the CLI NED, it is required to install the K9 (Crypto support) package. If you decide to use the Netconf NED, you will have to also install the MGBL (SNMP/Netconf/telemetry, etc.) in addition to the K9 package.A base configuration that enables these features should also be placed onto the device. The example described in this blog use the management interface to communicate with the NSO server, it is imperative to keep the ip address and device name constant after registering the device with NSO.ZTPZTP has support for both shell and python scripts, IOS-XR comes with an rich environment of shell tools and python libraries. In this example we will use a python based ZTP script and will leverage the python-netclient, python-json and the embedded ztp_helper libraries to provision the device in NSO.The python-netclient package provides us access to the urllib, urllib2 and base64 libraries, the python-json package allows us to manipulate json data efficiently.Flow of OperationDHCP ConfigurationFor ZTP to operate a valid IPv4/IPv6 address is required and the DHCP server must send a pointer to the configuration script via option 67. Here is an example of configuration## DHCP Server Configuration file.#allow bootp;allow booting;ddns-update-style interim;option time-offset -8;ignore client-updates;default-lease-time 300;log-facility local7;authoritative;subnet 192.168.1.0 netmask 255.255.255.0 {  option subnet-mask                  255.255.255.0;  option broadcast-address            192.168.1.255;  option routers                      192.168.1.1;  option domain-name-servers          192.168.1.10;  option domain-name                  ~cisco.local~;}host ncs-5001-1 {  option dhcp-client-identifier    ~FOC2018R1QU~;  fixed-address                    192.168.1.16;  if exists user-class and option user-class = ~iPXE~ {    filename = ~http#//192.168.2.10/ipxe/ncs5k.ipxe~;  } elsif exists user-class and option user-class = ~exr-config~ {    filename = ~http#//192.168.2.10/scripts/ncs-5001_nso_ztp.py~;  }}ZTP ScriptThe ZTP script will do the following operations#  Install the K9SEC and MGBL packages.  Create a general-purpose key.  Apply a basic configuration that allow the netconf agent to communicate with the NSO server.  Push the Device profile to NSO  Push the RSA key to NSO  Synchronize the basic configuration with NSO    Device Profile    The device profile is described in a JSON template with the name and ip address of the device filled during the ZTP execution, the IOS-XR CLI based template looks like this#  myDevice = {    ~device~# {        ~name~# ~XXXX~,        ~address~# ~XXXX~,        ~port~# 22,        ~state~# {            ~admin-state~# ~unlocked~        },        ~authgroup~# ~ios-xr-default~,        ~device-type~# {            ~cli~# {              ~ned-id~# ~tailf-ned-cisco-ios-xr-id#cisco-ios-xr~            }        }    }}If you plan to use Netconf, the profile template will have to be modified#myDevice = {    ~device~# {        ~name~# ~XXXX~,        ~address~# ~XXXX~,        ~port~# 22,        ~state~# {            ~admin-state~# ~unlocked~        },        ~authgroup~# ~ios-xr-default~,        ~device-type~# {            ~netconf~# {              ~ned-id~# ~tailf-ncs-ned#netconf~            }        }    }}A simple function has been created that can handle all REST operation with NSOdef nso_rest(self, ressource=None, operation=None, data=None)#   ~~~   ~~~   if data is not None#      request = urllib2.Request(ressource, data)   else#      request = urllib2.Request(ressource)             request.add_header(~Authorization~, ~Basic %s~ % base64.encodestring('%s#%s' % (NSO_USER, NSO_PASSWD)).replace('\\n', ''))   request.add_header('Content-Type', 'application/vnd.yang.data+json')   request.get_method = lambda# operation   try#      response = urllib2.urlopen(request)   except urllib2.HTTPError,error#      self.syslogger.info(~REST operation error code# ~ + str(error.code()))      self.syslogger.info(~REST response# ~ + error.read())   except URLError, error#      self.syslogger.info(~URL error# ~ + str(error.code()))   else#      self.syslogger.info(~REST operation status# ~ + str(response.code))      self.syslogger.info(~REST return data# ~  + response.read())   return {~status~# response.code, ~output~ # response.read()}This function will be called like thisztp_script.syslogger.info(~###### Pushing Device Profile ######~)ztp_script.nso_rest(BASE_URI + '/devices/device/' + hostname, 'PUT', json.dumps(myDevice))ztp_script.syslogger.info(~###### Pushing RSA key ######~)ztp_script.nso_rest(BASE_URI + '/devices/device/' + hostname + '/ssh/_operations/fetch-host-keys/', 'POST')ztp_script.syslogger.info(~###### Syncing configuration ######~)ztp_script.nso_rest(BASE_URI + '/devices/device/' + hostname + '/_operations/sync-from', 'POST')The complete detail of the ZTP script is available on github integrating IOS-XR with NSO", "url": "https://xrdocs.github.io/software-management/blogs/2018-02-22-ztp-integration-with-nso/", "tags": "iosxr, Orchestration, NSO", "title": "Using ZTP to integrate IOS-XR with NSO", "author": "Patrick Warichet"}, "techdocs-app-hosting-on-iosxr-xr-linux-shell": {"content": "Minimal Mistakes has been developed to be 100% compatible with hosting a site on GitHub Pages. To get up and running with a new GitHub repository quickly, follow these steps or jump ahead to the full installation guide.Fork the ThemeFork the Minimal Mistakes theme, then rename the repo to USERNAME.github.io &#8212; replacing USERNAME with your GitHub username.  Note# Your Jekyll site should be viewable immediately at http#//USERNAME.github.io. If it&#8217;s not, you can force a rebuild by Customizing Your Site (see below for more details).If you&#8217;re hosting several Jekyll based sites under the same GitHub username you will have to use Project Pages instead of User Pages. Essentially you rename the repo to something other than USERNAME.github.io and create a gh-pages branch off of master. For more details on how to set things up check GitHub&#8217;s documentation.  ProTip# Be sure to delete the gh-pages branch if you forked Minimal Mistakes. This branch contains the documentation and demo site for the theme and you probably don&#8217;t want that showing up in your repo.Customize Your SiteOpen up _config.yml found in the root of the repo and edit anything under Site Settings. For a full explanation of every setting be sure to read the Configuration section, but for now let&#8217;s just change the site&#8217;s title.    Edit text files without leaving GitHub.comCommitting a change to _config.yml (or any file in your repository) will force GitHub Pages to rebuild your site with Jekyll. It should then be viewable a few seconds later at https#//USERNAME.github.io.Congratulations! You&#8217;ve successfully forked the theme and are up an running with GitHub Pages. Now you&#8217;re ready to add content and customize the site further.", "url": "https://xrdocs.github.io/application-hosting/techdocs/app_hosting_on_iosxr/xr_linux_shell", "tags": "", "title": "XR Linux Shell"}, "tutorials-2018-02-19-netflow-sampling-interval-and-the-mythical-internet-packet-size": {"content": "     Netflow, Sampling-Interval and the Mythical Internet Packet Size  Introduction  NCS5500 internals  Netflow principles  Netflow processes  Measured packet sizes  Long-lived or short-lived flows?  New flows rate?  Ok, that\u2019s \u201cinteresting\u201d, but what should I configure on my routers?  Conclusion  IntroductionIn this post, we will try to clarify key concepts around Netflow technology and potentially correct some common misconceptions. Particularly we will explain why the \u201cwhat is the sampling-rate you support?\u201d is not the right question.We will describe in extensive details the NCS5500 implementation too.Also, we will share what we measured in different networks in Europe and North America. This information will be helpful to understand the parameters of this equation.We will provide tools to answer questions like#  how many new flows per second?  how long the flows exist and how long a representation of them will stay in cache?  are we dropping samples because of the protection shaper?It\u2019s certainly not meant to be a state-of-the-art but more an invitation to comment with your own findings.To understand the basic of the technology, we invite you to start with Xander\u2019s post on Cisco supportforum.It has been written for ASR9000 five years ago, so multiple differences exist, but it\u2019s still a very good resource to get familiar with Netflow.NCS5500 internalsNCS5500 supports NetFlow v9 and IPFIX (not sFlow or former versions of Netflow).Netflow is used to create a statistical view of the flow matrix from the router or line card perspective.In a chassis, Netflow activities will be performed at the line card level and will involve the NPU (for instance Qumran-MX, Jericho or Jericho+) and the Line Card CPU. Aside from the configuration and show commands, nothing will be performed at the Route Processor level.Before jumping into the Netflow specifics, let\u2019s describe some key internal parts of an NCS5500 line card or system.Two internal \u201cnetworks\u201d exist and interconnect the various elements#  the EOBC network (for \u201cEthernet Out-of-Band Channel\u201d used for inter-process communication  the EPC network (for \u201cEthernet Protocol Channel\u201d) for all the punted packets.Note# the fixed-form systems like NCS5501(-SE), NCS55A1-24H, NCS55A1-36H(-SE)-S, we don\u2019t have similar internal design, you will not be able to use the \u201cadmin show controller switch xxx\u201d CLI. It\u2019s valid for NCS5504, NCS5508 and NCS5516 chassis but also for NCS5502(-SE) systems.sysadmin-vm#0_RP0# show controller switch reachableRack  Card  Switch---------------------0     SC0   SC-SW0     SC0   EPC-SW0     SC0   EOBC-SW0     SC1   SC-SW0     SC1   EPC-SW0     SC1   EOBC-SW0     LC1   LC-SW0     LC2   LC-SW0     LC6   LC-SW0     LC7   LC-SW0     FC0   FC-SW0     FC1   FC-SW0     FC3   FC-SW0     FC5   FC-SWsysadmin-vm#0_RP0#The sampled packets and the netflow records will transit over the EPC network.The number of NPUs and the bandwidth of EPC/EOBC channels will vary between systems.Here is a diagram representing a line card 24x100G w/ eTCAM with 4x Jericho ASICs. Each NPU is connected at 2.5Gbps to the EPC switch and the LC CPU is connected with 3x 2.5 = 7.5Gbps to the same switch#sysadmin-vm#0_RP0# show controller switch summary location 0/LC7/LC-SWRack  Card  Switch  Rack Serial Number--------------------------------------0     LC7   LC-SW   FGE194XXXXX      Phys   Admin  Port      Protocol  ForwardPort  State  State  Speed     State     State       Connects To--------------------------------------------------------------------4     Up     Up     2.5-Gbps  -         Forwarding  LC CPU (EPC 0)5     Up     Up     2.5-Gbps  -         Forwarding  LC CPU (EPC 1)6     Up     Up     2.5-Gbps  -         Forwarding  LC CPU (EPC 2)7     Up     Up     2.5-Gbps  -         Forwarding  LC CPU (EOBC)8     Up     Up     2.5-Gbps  -         Forwarding  NPU29     Up     Up     2.5-Gbps  -         Forwarding  NPU110    Up     Up     2.5-Gbps  -         Forwarding  NPU011    Up     Up     2.5-Gbps  -         Forwarding  NPU312    Down   Down   1-Gbps    -         -           FC013    Up     Up     1-Gbps    -         Forwarding  FC114    Down   Down   1-Gbps    -         -           FC215    Down   Down   1-Gbps    -         -           FC316    Down   Down   1-Gbps    -         -           FC417    Down   Down   1-Gbps    -         -           FC518    Up     Up     1-Gbps    -         Forwarding  SC0 EOBC-SW19    Down   Down   1-Gbps    -         -           SC1 EOBC-SWsysadmin-vm#0_RP0#Here, we are representing a line card 36x100G w/ eTCAM with 4x Jericho+. Each NPU is connected at 2.5Gbps to the EPC switch and the LC CPU is connected at 10Gbps to the same switch#sysadmin-vm#0_RP0# show controller switch summary location 0/LC1/LC-SWRack  Card  Switch  Rack Serial Number--------------------------------------0     LC1   LC-SW   FGE194XXXXX      Phys   Admin  Port      Protocol  ForwardPort  State  State  Speed     State     State       Connects To-------------------------------------------------------------------4     Up     Up     2.5-Gbps  -         Forwarding  NPU05     Up     Up     2.5-Gbps  -         Forwarding  NPU16     Up     Up     2.5-Gbps  -         Forwarding  NPU27     Up     Up     2.5-Gbps  -         Forwarding  NPU38     Up     Up     10-Gbps   -         Forwarding  LC CPU (EPC)9     Up     Up     10-Gbps   -         Forwarding  LC CPU (EOBC)12    Down   Down   1-Gbps    -         -           FC013    Down   Down   1-Gbps    -         -           FC114    Down   Down   1-Gbps    -         -           FC215    Down   Down   1-Gbps    -         -           FC316    Down   Down   1-Gbps    -         -           FC417    Up     Up     1-Gbps    -         Forwarding  FC518    Down   Down   1-Gbps    -         -           SC0 EOBC-SW19    Up     Up     1-Gbps    -         Forwarding  SC1 EOBC-SWsysadmin-vm#0_RP0#Inside the EPC switch, we have multiple VLANs to differentiate the Netflow sampled traffic coming from the various NPUs.sysadmin-vm#0_RP0# show controller switch vlan information location 0/LC1/LC-SWRack  Card  Switch  Rack Serial Number--------------------------------------0     LC1   LC-SW   FGE194XXXXXSDRIdentifier  SDR Name     VLAN           VLAN Use------------------------------------------------------------------------1           sysadmin-vm  1     (0x001)  Platform EMON                         17    (0x011)  Platform HOST                         3073  (0xC01)  Calvados IPC2           default-sdr  1282  (0x502)  SDR 2 Platform Netflow 1                         1298  (0x512)  SDR 2 Platform Netflow 2                         1314  (0x522)  SDR 2 Platform Netflow 3                         1330  (0x532)  SDR 2 Platform Netflow 4                         1346  (0x542)  SDR 2 Platform Netflow 5                         1362  (0x552)  SDR 2 Platform Netflow 6                         1538  (0x602)  SDR 2 Platform SPP                         1554  (0x612)  SDR 2 Platform BFD                         1570  (0x622)  SDR 2 Platform MAC learning                         1794  (0x702)  SDR 2 Third Party Applications                         3074  (0xC02)  SDR 2 IPCsysadmin-vm#0_RP0#To protect the line card CPU, each NPU is shaping the sampled traffic.In chassis line cards, this shaper is configured at 133Mbps while in fixed-form platforms, it\u2019s configured at 200Mbps. This parameter is fixed and not configurable via CLI. This NPU shaper guarantees that CPU is not overloaded while processing the samples. It\u2019s expected to see high CPU utilization in some netflow process threads and it will not reach 100% of a CPU core.RP/0/RP0/CPU0#R1#sh flow platform pse policer-rate location 0/1/CPU0Npu id #0Netflow Platform Pse Policer Rate#Ingress Policer Rate#                     133 MbpsNpu id #1Netflow Platform Pse Policer Rate#Ingress Policer Rate#                     133 MbpsNpu id #2Netflow Platform Pse Policer Rate#Ingress Policer Rate#                     133 MbpsNpu id #3Netflow Platform Pse Policer Rate#Ingress Policer Rate#                     133 MbpsRP/0/RP0/CPU0#R1#We will come back later on this shaper since it will directly influence the netflow performance and capabilities.Netflow principlesNetflow is a technology ratified as an IETF standards in 2004 via the RFC 3954https#//www.ietf.org/rfc/rfc3954.txtIt is used on routing devices to generate flow records from packet streams by extracting fields from sampled packets. A database, or cache, is used to store the current flows and their accounting information. Based on multiple criteria, we decide to \u201cexpire\u201d a cache entry and generate a flow records which will be transmitted to an external collector.The process can be described as such#1- we sample packets (1 packet every x)2- we pick the first 128B of the packet and add internal header (total# 144B per sampled packet)3- this sampled packet is passed to the LC CPU via the EPC switch4- we extract information for the IP header5- we create cache entries representing flow accounting6- every time a sampled packet of the same flow is received, we update the cache entry7- we maintain multiple timers and when one expires, a NF record is generated8- we send the record to the external collector(s)This concept of timers is very important since it will dictate how fast we flush the cache content, and inform the remote collector of the existence of a flow. In the case of DDoS attack detection, it\u2019s key to speed up the process#  Inactive timer represents the time without receiving a sampled packet matching a particular cache entry.  Active timer, in the other hand, represents the maximum time of existence of a particular cache entry, even if we still receive sampled packets matching it.The basic configuration for Netflow#flow monitor-map monitor1 record ipv4 exporter export1 cache entries 1000000 cache timeout active 15 cache timeout inactive 2 cache timeout rate-limit 2000!flow exporter-map export1 version v9  options interface-table  options sampler-table ! transport udp 9951 source Loopback0 destination 1.3.5.7!sampler-map sampler1 random 1 out-of 4000!interface HundredGigE0/7/0/0 flow ipv4 monitor monitor1 sampler sampler1 ingressSeveral potential bottlenecks need to be understood when using Netflow in your networks.  133 Mbps or 200 Mbps shaper (not configurable)This shaper will have a direct impact on the amount of sampled packets we can pass to the LC CPU#133-200Mbps / [ ( packet size up to 101B + 43B ) * 8]Ex# packets larger than 101 Bytes @ Layer2 will represent 133Mbps / (144*8) = 115,451 PPS per NPU  Flow table sizeDefault 64k, configurable up to 1M per monitor-map  Export rate-limiterDefault 2000 records / sec, configurableNote# the export \u201crate-limiter\u201d name is often creating confusion in operator\u2019s mind because we will not \u201cdrop\u201d records if we exceed this limit, but instead we will keep the entry longer in the cache despite the timer expiration. At the potential risk of reaching the maximum size of this cache.Netflow processesSeveral processes are involved in the Netflow operation and configuration. They are present in both Route Processor and Line Card.RP/0/RP0/CPU0#NCS5508#show processes cpu location 0/RP0/CPU0 | include~ nf~4599     0%      0%       0% nfmgr4890     0%      0%       0% nfmaRP/0/RP0/CPU0#NCS5508#RP/0/RP0/CPU0#NCS5508#show processes cpu location 0/7/CPU0 | include~ nf~4036     0%      0%       0% nfma4776     0%      0%       0% nfea4790    12%     12%      12% nfsvr4810     2%      2%       2% nf_producerRP/0/RP0/CPU0#NCS5508#1- NetFlow Manager (nfmgr) accepts configuration and maintains global objects .i.e. sampler, flow monitor, and flow exporter2- NetFlow MA (nfma) accepts the interface level configuration3- NetFlow EA (nfea) sends config to NF Server and ASIC4- NetFlow Producer receives NF packets from ASIC and adds them to the shared memory data ring for passing data to the NetFlow Server process5- NetFlow Server (nfsvr)  receives NF record packets from nf_producer,  creates a new flow cache if not already created,  or update a existing flow cache (packet / byte count) for the flow monitor,  periodically ages entries form the NF cache into NF export packets  sends the NF export packets to the NF collector using UDP6- show commands are polling information for nfsvr7- netio is used to transport the recordsMeasured packet sizes\u201cAverage Internet packet size\u201d or \u201cIMIX packet sizes\u201d\u2026 Those are concepts very frequently mentioned in the networking industry. It\u2019s an important parameter when considering the forwarding performance of a device.Indeed, the forwarding ASICs or Network Processing Units (NPUs) are often characterized by their port density or bandwidth but also by their forwarding performance expressed in PPS (packets per second).It represents the numbers of packets we can route, filter, encapsulate or decapsulate, count, police, remark, \u2026 every second.In the same vein, you may have heard about NDR (Non-Drop Rate) to express the minimal packet size a system can forward at line rate on all ports simultaneously.Packet size, NDR, bandwidth and performance in PPS are of course directly linked to each others.The average packet size parameter is very important to qualify the Netflow/IPFIX capability of a device and how far we can push in term of sampling-interval. It will be covered in the next part of this blog post.So, understanding the traffic profiles and the average packet size per link and per ASIC is mandatory to qualify your network. Also it will be necessary to know precisely the port allocation to each ASIC, something we documented in this post.You will find a large variety of answers in the litterature or when using your favorite search engine# commonly from 350 bytes to 500 bytes per packet. But the real answer should be, as usual# it depends.Let\u2019s take routers facing the internet and list the different types of interfaces#  core facing  internet# peering and PNI  internet# transit providing a full internet view  internet or local cache engines from various CDNIt\u2019s fairly easy to measure it, just collect the output of a \u201cshow interface\u201d from the router, and devide the byte counter by the packet counter.We collected numbers from multiple ISP in the US and Western Europe, here are some numbers (expressed in Bytes)            Peering/Transit      Ingress Avg      Egress Avg                  Cust 1 Transit 1      1136      328              Cust 1 Transit 2      927      526              Cust 1 Transit 3      1138      346              Cust 2 Transit      1192      237              Cust 3 Transit      999      238              Cust 4 Transit      1249      202              Cable Cust 1 Peering      714      413              Cable Cust 2 Peering      603      285              Cust 1 Peering      496      643              Cust 2 Peering      706      516              Cust 3 Peering      594      560              Peering GIX      819      426      It seems difficult to derive a \u201crule\u201d from these numbers but we can say#  transit traffic is usually more important in ingress from 900B to 1200B average while the egress is usually shorter from 250B to 500B  peering traffic is more balanced between ingress and egress, with an average packet size from 400B to 700BBut other type of interfaces will present more \u201cextreme\u201d numbers, like the CDNs (and they compose the largest and fastest growing amount of traffic in networks today).            CDN / Content Providers      Ingress Avg      Egress Avg                  Cust 1 Google GGC      1277      329              Cust 2 Google GGC      1370      350              Cust 3 Google GGC      1393      284              Cust 1 Netflix      1495      73              Cust 2 Netflix      1470      74              Cust 1 Level3 CDN      1110      274              Cust 2 Level3 CDN      1378      176              Facebook      1314      158              Apple      1080      679              EdgeCast      1475      72              Fastly      1407      140              Twitter      1416      232              Yahoo      964      197              Cust 1 Akamai      1471      72              Cust 2 Akamai      1443      82              Cust 1 Twitch      1490      121              Cust 2 Twitch      1490      116              Cust 3 Twitch      1328      395      It\u2019s showing very clearly that we have a very asymmetrical traffic distribution. Something totally expected considering the type of service they deliver (content). But also it\u2019s showing that ingress traffic is very often \u201cas large as your MTU\u201d. It will be a key parameter when discussing the sampling-interval we have to configure on our interfaces.I hope it convinced you that you can not simply take 350B or 500B as your average packet size. In reality, it will depend on the type on service you are connected to and the port allocation to NPUs.Long-lived or short-lived flows?Now that we understand the average packet size profiles for each type of services, it could be also interesting to study how long the flows last. Or to put it differently, how many packets will represent a normal / average flows before it ends.Indeed, if we have very long streams, the cache entry will stay present for a long time and it will require the expiration of the active timer to generate a record and clear the entry. In the other hand, if we have just very short streams, very likely they will be represented by a single packet cache entry which will be flushed when we will reach the inactive timer limit.The stress on the LC CPU will be higher if we have a larger proportion of 1-packet flows because it will imply we have to create new entries in the cache (with all the appropriate fields) instead of just updating an existing entries.We can take a statistical approach, simply by checking the number of packets we have for each flow entry present in the cache of some real production routers.Quick example#RP/0/RP0/CPU0#R1#show flow monitor fmm cache match counters packets eq 1 include interface ingress location 0/1/cpu0 | utility wc -l  65308RP/0/RP0/CPU0#R1#show flow monitor fmm cache match counters packets neq 1 include interface ingress location 0/1/cpu0 | utility wc -l  12498RP/0/RP0/CPU0#R1#sh run formal | i randomBuilding configuration...sampler-map SM random 1 out-of 2048RP/0/RP0/CPU0#R1#This output with \u201ceq\u201d represents the number of entries with just one packet. With \u201cneq\u201d, we count flows with more than one packet.Let\u2019s check a couple of routers using sampling-interval of 1#2048            Router with 1#2048      eq 1      neq 1      Ratio (%)                  R1 0/0      43680      11122      75/25              R2 0/0      39723      11421      71/29              R2 0/1      31907      8628      73/27              R2 0/2      35110      9168      74/26              R3 0/3      21563      6541      70/30      Some other routers with a sampling-interval of 1#4000            Router with 1#4000      eq 1      neq 1      Ratio (%)                  R1      11312      1725      85/15              R2      56321      15177      73/27      We will let you run the test on your own devices, but it looks like the proportion of \u201c1-packet flow\u201d is more important than the others.It appears with 1#2000 but it\u2019s even clearer with 1#4000.It only proves that statistically, streams are less than 2000- or 4000-packets long for the most part.And that a large majority of the samples will generate new entries in the cache table instead of updating existing entries.The flow entries will be cleared out of the cache (and will generate a NF record) when reaching the inactive timer.New flows rate?Another interesting question# how can I check the number of new flows per second?With the following show command, we can monitor the Cache Hits and Cache Misses.  Hits# every time we sample a packet and it matches an existing entry in the cache, we update the counters  Misses# no entry in the cache for this sample, we create a new flow entryRP/0/RP0/CPU0#R1#sh flow monitor FM cache internal loc 0/0/CPU0 | i CacheFri Feb  9 15#08#14.611 CETCache summary for Flow Monitor #Cache size#                        1000000Cache Hits#                           9797770256Cache Misses#                        22580788616Cache Overflows#                               0Cache above hi water#                          0RP/0/RP0/CPU0#R1#sh flow monitor FM cache internal loc 0/0/CPU0 | i CacheFri Feb  9 15#09#55.314 CET Cache summary for Flow Monitor #Cache size#                        1000000Cache Hits#                           9798220473Cache Misses#                        22581844681Cache Overflows#                               0Cache above hi water#                          0RP/0/RP0/CPU0#R1#Simple math now between the two measurements#  Between the two show commands# 15#09#55.314-15#08#14.611 = (60+55)x1000+314-(14x1000+611) = 100,703 ms  ROUND [ (22581844681-22580788616) / (100.703) ] = 10487 samples creating new flow entries / second  ROUND [ (9798220473-9797770256) / (100.703) ]   = 4471 samples with existing entries / secondOk, that\u2019s \u201cinteresting\u201d, but what should I configure on my routers?We explained the netflow principles, we detailed the internals of NCS5500 routers, reviewed the potential bottlenecks and we provided couple of data points to redefine what is an internet packet average size, the proportion of 1-packet flows in the cache, etc.Indeed that was a lot of concepts, but what can I do more practically?It\u2019s time to address a common misconception and recenter the discussion. A frequent question is \u201cwhat is the sampling-rate you support?\u201d.Since it\u2019s the only parameter you can configure with CLI, network operators wonder what they should use but it\u2019s inherently the wrong question.Because the answer \u201c1#1\u201d could be valid.But it doesn\u2019t mean we can sample every single packet at every speed, on every interface, with every average packet size.It\u2019s capital to understand that the only relevant parameter is the number of sampled packets we can send from the NPU to the line card CPU.This information can be easily derived from following parameters#  average packet size (depends on the charts presented above)  are we using ingress only or both ingress and egress (currently egress NF is not supported in NCS5500)  how the ports configured for netflow are connected to the forwarding ASIC  sum of bandwidth for all the ports connected to the NPU (an estimation can be taken from peak hour traffic, or the projection of growth, or even the biggest DDoS attack)  and finally, the sampling-interval we configuredIf we take the assumption that sampled packets will be mostly larger than 101B, we will transport 144B packets to the CPU.This traffic will be rate-limited by the shaper we mentioned above# 133Mbps or 200Mbps depending on the platform#Something we can not really anticipate is the ratio of sampled packets that will be &lt;101B. But this number will not represent much, except in case of specific DDoS attack.Let\u2019s take a couple of examples to illustrate the formulas above#  you have 6 ports on the Jericho NPU but only 4 are used with Netflow  the average packet size on this ports connected to CDN is 1400B  the load is heavy and the ports are used at 70% total, at peak hour  but the customer would like to anticipate the worst case if all ports are transmitting line rateSo the math will be#Most aggressive sampling-interval = Total-BW / ( Avg-Pkt-Size x 133Mbps ) x ( 144 x 8 )                                  = 400,000,000,000 / ( 1400 x 8 x 133,000,000 ) x ( 144 x 8 )                                  = 309\u2013&gt; in this example, it will be possible to use an 1#309 sampling-interval before reaching the limit of the 133Mbps shaper.Another example#  you have 9 ports on the Jericho NPU+ all configured for NFv9  the average packet size on this ports connected to peering partners is 800B  the load not huge and the ports are used at a total of 40%  at peak hour  but the customer takes some margin of growth (and error) and pick 70%That gives us#Most aggressive sampling-interval = Total-BW / ( Avg-Pkt-Size x 133Mbps ) x ( 144 x 8 )                                  = 900,000,000,000 x 0.7 / ( 800 x 8 x 133,000,000 ) x ( 144 x 8 )                                  = 852\u2013&gt; in this example, it will be possible to use an 1#852 sampling-interval before reaching the limit of the 133Mbps shaper.To check if your sampling is too aggressive and you are hitting the shaper limit, you need to look at the droppedPkts count of the VOQ24 / COS2 in the following show command#RP/0/RP0/CPU0#5508-6.3.2#sh controllers npu stats voq base 24 instance 0 location 0/7/CPU0Asic Instance     =            0VOQ Base          =           24       ReceivedPkts    ReceivedBytes   DroppedPkts     DroppedBytes-------------------------------------------------------------------COS0 = 0               0               0               0COS1 = 0               0               0               0COS2 = 904365472       90918812004     3070488403      308867834524COS3 = 14              1668            0               0COS4 = 1955            201438          0               0COS5 = 0               0               0               0COS6 = 0               0               0               0COS7 = 0               0               0               0RP/0/RP0/CPU0#5508-6.3.2#Having this COS 2 DroppedPkts counter increasing is the proof we are exceeding the shaper and you need to reduce the sampling-interval. The \u201cinstance\u201d here represents the NPU ASIC.Note# In releases before 6.3.x, Netflow was transported over VOQ 32 / COS3 so the CLI to use was \u201csh controllers npu stats voq base 32 instance 0 location 0/7/CPU0\u201dConclusionWe hope this article helped provided useful information on the nature of packets and streams in Internet.Also, we hope we clarified some key concepts related to netflow v9 on NCS5500.Particularly, the notion of \u201cinterval-rate\u201d should be considered irrelevant if we don\u2019t specify the traffic more precisely.In a follow up post, we will perform stress and performance testing on Netflow to illustrate all this. Stay tuned.Acknowledgements# Thanks a lot to the following engineers who helped preparing this article.Benoit Mercier des Rochettes, Thierry Quiniou, Serge Krier, Frederic Cuiller, Hari Baskar Sivasamy, Jisu Bhattacharya", "url": "https://xrdocs.github.io/cloud-scale-networking/tutorials/2018-02-19-netflow-sampling-interval-and-the-mythical-internet-packet-size/", "tags": "ncs5500, ncs 5500, netflow, nf, NFv9", "title": "Netflow, Sampling-Interval and the Mythical Internet Packet Size", "author": "Nicolas Fevrier"}, "blogs-2016-09-12-model-driven-programmability": {"content": "In 2015, one of the most exciting enhancements we introduced to Cisco IOS XR was a much improved programmability framework based on data models.  While you have had access to a diverse number of management interfaces in the past, they did not always provide a cohesive framework to manage the device and treat it as a programmable platform.  Quite often, the command line interface acted as the grand unifying interface.  With the growing support for data models, a rich stack opens the door for new ways to manage and program devices making the most of software automation. What are the benefits of model-driven programmability?  Numerous and all pretty valuable#  Model based, structured, computer friendly  Multiple model types (native, OpenConfig, IETF, etc.)  Models decoupled from transport, protocol end encoding  Your choice of transport, protocol and encoding  Model-driven APIs for abstraction and simplification  Wide standard support while leveraging open sourceIn future posts, we will look at each of the components in that stack and elaborate further on its benefits.  For now, you can get some details on the previous blog post Model-driven Programmability# The Rise of Network Automation", "url": "https://xrdocs.github.io/programmability/blogs/2016-09-12-model-driven-programmability/", "tags": "iosxr, programmability", "title": "Model-driven Programmability", "author": "Santiago Alvarez"}, "tutorials-2017-08-22-ncs1002-configuration-automation-overview": {"content": "     NCS1002 Configuration Automation Overview  Slice configuration overview  Slice mappings within NCS1002          1.OpenConfig configuration for 2x100GE \u2192 2x100G slice mode      2.OpenConfig configuration for 4x100GE \u2192 2x200G slice mode      3.OpenConfig configuration for 5x100GE \u2192 2x250G slice mode      4.OpenConfig configuration for 10G client ports        Conclusion  This tutorial will be the first in a series of posts related to the automation of configuration for Cisco Optical products. In this tutorial, I will explain how to use OpenConfig models to configure an optical device.Cisco Optical products include NCS1002 (terminal device) and NCS1001 (line amplifier). NCS1002 and NCS1001 are complementary to each other and essential elements of Cisco highly scaled and reliable multi-terabit DCI solution. NCS1002 configuration automation will be covered first, following with details for NCS1001 in later posts.There are several ways to make repetitive work easier for you#  One way is to implement CLI automation with different scripts using programming languages like Python or Go. Going down this path will help with automation of configuration, but it results in more complex and less portable automation code.  Another way is to automate configuration using data models. Data models provide a clear representation of the capabilities of a networking device with a definition that is structured, well defined and computer friendly. Usually, data models come in two forms# native or open.          Native data models are defined by a vendor for its products and cover the widest range of possible configurations.      Open data models are usually defined by a group of companies and/or standards bodies (OpenConfig, IETF, etc). Open models cover limited range of configurations, but are vendor neutral. Support for OpenConfig models on Cisco platforms is increasing with each new XR release.      Cisco publishes supported Native and OpenConfig models for each XR release on GitHub. Models for other Cisco operating systems can be found in the parent directory.Slice configuration overviewThe NCS1002 has 4 slices and each slice has 5 client ports and 2 line (or trunk) ports. Slice configuration depends on client speed (10G/40G/100G) and line port mode (100G/200G/250G). You need to configure a slice with proper mapping between client and line ports. OpenConfig models use the same approach, but more layers of mapping are used to support universality across vendors.Here is a high-level scheme of OpenConfig mappings#  Client port corresponds to a physical client transceiver (e.g. SFP+, QSFP, QSFP28)  Physical channels correspond to a mapping between client ports and physical channels (e.g. 40G \u2212&gt; 4x10G mode will have one client port and 4 physical channels)  Logical channels define a nested structure to ensure proper mapping between client and line (trunk) facing ports  Optical channels correspond to a single optical carrier, wavelength and power  Line ports represent a container for optical channels that corresponds to a physical port.There are three OpenConfig models that are needed to configure a slice in NCS1002#  openconfig-interfaces  openconfig-terminal-device  openconfig-platformAll three models are required to fully configure a slice.Slice mappings within NCS1002OpenConfig models give you many levels of hierarchy, but how does this apply to NCS1002? In the figures below, you can find logical representations of five slice modes implemented on NCS1002 using OpenConfig models (Slice0 is used as an example).1.OpenConfig configuration for 2x100GE \u2192 2x100G slice modeThis is the simplest mode supported in NCS1002. The speed of each line port equals the speed of any client port. In this mode, you have direct 1-to-1 mappings between client ports and line (trunk) ports. Because of this, the OpenConfig configuration is very straightforward and transparent.2.OpenConfig configuration for 4x100GE \u2192 2x200G slice modeIn this mode, the line port 16-QAM modulation allows you to have two client ports mapped to a single line port. In other words, 2x100GE client ports go to a single 200G line port and a slice has two groups in total. OpenConfig configuration is also simple; you just need to make sure that each pair of client ports is mapped to the same line port.3.OpenConfig configuration for 5x100GE \u2192 2x250G slice modeThe 5x100GE \u2192 2x250G mode gives you possibility to fill the spectrum in the densest way, as you can put all five clients into two standard-grid wavelengths. OpenConfig configuration is a bit trickier here. As in the previous mode, you need to map channels equally across both line ports. Mapping of \u201cborder\u201d client ports (first, second, forth and fifth) is transparent. You just need to map each group into a single line port as explained in the second slide mode described above. However, the third channel needs to be mapped into both line ports in a 50/50 ratio.4.OpenConfig configuration for 10G client portsIn addition to 100G client ports, 10G client ports are also very popular. NCS1002 supports two different modes for mapping 10G clients into line ports#  20x10GE \u2192 2x100G  20x10GE \u2192 1x200GHere is a logical view of the 20x10GE \u2192 2x100G mode#This mode is similar to the 5x100GE \u2192 2x250G mode, as you need to map groups of client ports into line ports. The first group of ports goes into the first line port and the last group of ports goes into the second line port. As in previous example, the middle group of ports is distributed equally between both line ports.And the final mode is 20x10GE \u2192 1x200G#The modulation scheme allows a line port to hold all 20x10GE client ports. That\u2019s why the entire mapping is simple; you just need to map all client ports into a single available line port.ConclusionNCS1002 is based on IOS XR and gives amazing capabilities for you to bring automation and programmability at full scale. These tools can dramatically save you time to bring platforms up during your installations. In our next post we will give an example of how to configure those defined mappings. Stay tuned!", "url": "https://xrdocs.github.io/programmability/tutorials/2017-08-22-ncs1002-configuration-automation-overview/", "tags": "iosxr, OpenConfig, OC, Rosco, NCS1002, XR optical", "title": "NCS1002 Configuration Automation Overview", "author": "Viktor Osipchuk"}, "blogs-2018-05-08-peering-fabric-hld": {"content": "     On This Page  Key Drivers          Traffic Growth      Network Simplification      Network Efficiency        High-Level Design          Peering Strategy      Topology and Peer Distribution      Platforms      Control-Plane      Telemetry      Automation      Validated Design        Peering Fabric Use Cases          Traditional IXP Peering Migration to  Peering Fabric      Peering Fabric Extension      Localized Metro Peering and Content Delivery      Express Peering Fabric      Datacenter Edge Peering      Peer Traffic Engineering with Segment Routing        Low-Level Design          Integrated Peering Fabric Reference Diagram      Distributed Peering Fabric Reference Diagram      Peering Fabric Hardware Detail                  NCS-5501-SE          NCS-55A1-36H-SE          NCS-55A1-24H          NCS 5504 and 5508 Modular Chassis and NC55-36X100G-A-SE line card                    Peer Termination Strategy      Distributed Fabric Device Roles                  PFL \u2013 Peering Fabric Leaf          PFS \u2013 Peering Fabric Spine                    Device Interconnection      Capacity Scaling      Peering Fabric Control Plane                  PFL to Peer          PFL to PFS          PFS to Core                    SR Peer Traffic Engineering                  Summary          Nodal EPE          Peer Interface EPE          Abstract Peering                      Peering Fabric Telemetry          Telemetry Diagram      Model-Driven Telemetry      BGP Monitoring Protocol      Netflow / IPFIX        Automation and Programmability          Netconf      YANG Model Support      Cisco NSO Modules      3rd Party Hosted Applications      XR Service Layer API        Recommended Device and Protocol Configuration          Overview      Common Node Configuration                  Enable LLDP Globally                    PFS Nodes                  IGP Configuration          Segment Routing Traffic Engineering          BGP Global Configuration          Model-Driven Telemetry Configuration                    PFL Nodes                  Peer QoS Policy          Peer Infrastructure ACL          Peer Interface Configuration          IS-IS IGP Configuration          BGP Add-Path Route Policy          BGP Global Configuration          EBGP Peer Configuration          PFL to PFS IBGP Configuration          Netflow/IPFIX Configuration                    Model-Driven Telemetry Configuration      Abstract Peering Configuration                  PFS Configuration                      Security          Infrastructure ACLs      BCP Implementation      BGP Attribute and CoS Scrubbing      Per-Peer Control Plane Policers      BGP Prefix Security                  RPKI Origin Validation          BGPSEC          BGP Flowspec                      Appendix          Applicable YANG Models      NETCONF YANG Paths      BGP Operational State                  Global BGP Protocol State          BGP Neighbor State                          Example Usage                                BGP RIB Data                          Example Usage                                Device Resource YANG Paths                    Validated Model-Driven Telemetry Sensor Paths        Key DriversTraffic GrowthInternet traffic has seen a compounded annual growth rate of 30% orhigher over the last five years, as more devices are connected and morecontent is consumed, fueled by the demand for video. Traffic willcontinue to grow as more content sources are added and Internetconnections speeds increase. Service and content providers must designtheir peering networks to scale for a future of more connected deviceswith traffic sources and destinations spanning the globe. Efficientpeering is required to deliver traffic to consumers.Network SimplificationSimple networks are easier to build and easier to operate. As networksscale to handle traffic growth, the level of network complexity mustremain flat. A prescriptive design using standard discrete componentsmakes it easier for providers to scale from networks handling a smallamount of traffic to 10s of Tbps without complete network forklifts.Fabrics with reduced control-plane elements and feature sets enhancestability and availability. Dedicating nodes to specific functions ofthe network also helps isolate the rest of the network from maliciousbehavior, defects, or instability.Network EfficiencyNetwork efficiency refers not only to maximizing network resources butalso optimizing the environmental impact of the deployed network. Muchof Internet peering today is done in 3rd party facilitieswhere space, power, and cooling are at a premium. High-density, lowerenvironmental footprint devices are critical to handling more trafficwithout exceeding the capabilities of a facility. In cases wheremultiple facilities must be connected, a simple and efficient way toextend networks must exist.High-Level DesignThe  Peering design incorporates high-density environmentallyefficient edge routers, a prescriptive topology and peer terminationstrategy, and features delivered through IOS-XR to solve the needs ofservice and content providers. Also included as part of the Peeringdesign are ways to monitor the health and operational status of thepeering edge and through Cisco NSO integration assist providers inautomating peer configuration and validation. All  designs areboth feature tested and validated as a complete design to ensurestability once implemented.Peering Strategyproposes a localized peering strategy to reduce network cost for\u201ceyeball\u201d service providers by placing peering or content provider cachenodes closer to traffic consumers. This reduces not only reducescapacity on long-haul backbone networks carrying traffic from IXPs toend users but also improves the quality of experience for users byreducing latency to content sources. The same design can also be usedfor content provider networks wishing to deploy a smaller footprintsolution in a SP location or 3rd party peering facility.Topology and Peer DistributionThe Cisco Peering Fabric introduces two options for fabric topology andpeer termination. The first, similar to more traditional peeringdeployments, collapses the Peer Termination and Core Connectivitynetwork functions into a single physical device using the device\u2019sinternal fabric to connect each function. The second option utilizes afabric separating the network functions into separate physical layers,connected via an external fabric running over standard Ethernet.In many typical SP peering deployments, a traditional two-node setup isused where providers vertically upgrade nodes to support the highercapacity needs of the network. Some may employ technologies such as backto back or multi-chassis clusters in order to support more connectionswhile keeping what seems like the operational footprint low. However,failures and operational issues occurring in these types of systems aretypically difficult to troubleshoot and repair. They also requirelengthy planning and timeframes for performing system upgrades. Weintroduce a horizontally scalable distributed peering fabric, the endresult being more deterministic interface or node failures.Minimizing the loss of peering capacity is very important for bothingress-heavy SPs and egress-heavy content providers. The loss of localpeering capacity means traffic must ingress or egress a sub-optimalnetwork port. Making a conscious design decision to spread peerconnections, even to the same peer, across multiple edge nodes helpsincrease resiliency and limit traffic-affecting network events.PlatformsThe Cisco NCS5500 platform is ideal for edge peer termination, given itshigh-density, large RIB and FIB scale, buffering capability, and IOS-XRsoftware feature set. The NCS5500 is also space and power efficient with36x100GE supporting up to 7.5M IPv4 routes in a 1RU fixed form factor orsingle modular line card. A minimal  The Peering fabric can provide36x100GE, 144x10GE, or a mix of non-blocking peering connections withfull resiliency in 4RU. The fabric can also scale to support 10s ofterabits of capacity in a single rack for large peering deployments.Fixed chassis are ideal for incrementally building a peering edgefabric, the NCS NC55-36X100GE-A-SE and NC55A1-24H are efficient highdensity building blocks which can be rapidly deployed as needed withoutinstalling a large footprint of devices day one. Deployments needingmore capacity or interface flexibility such as IPoDWDM to extend peeringcan utilize the NCS5504 4-slot or NCS5508 8-slot modular chassis. If thepeering location has a need for services termination the ASR9000 familyor XRv-9000 virtual edge node can be incorporated into the fabric.All NCS5500 routers also contain powerful Route Processors to unlockpowerful telemetry and programmability. The  Peering Fabric fixedchassis contain 1.6Ghz 8-core processors and 32GB of RAM. The latestNC55-RP-E for the modular NCS5500 chassis has a 1.9Ghz 6-core processorand 32G of RAM.Control-PlaneThe peering fabric design introduces a simplified control-plane builtupon IPv4/IPv6 with Segment Routing. In the collapsed design, eachpeering node is connected to EBGP peers and upstream to the core viastandard IS-IS, OSPF, and TE protocols, acting as a PE or LER in aprovider network.In the distributed design, network functions are separated. PeerTermination happens on Peering Fabric Leaf nodes. Peering Fabric Spineaggregation nodes are responsible for Core Connectivity and perform moreadvanced LER functions. The PFS routers use ECMP to balance trafficbetween PFL routers and are responsible for forwarding within the fabricand to the rest of the provider network. Each PFS acts as an LER,incorporated into the control-plane of the core network. The PFS, oralternatively vRRs, reflect learned peer routes from the PFL to the restof the network. The SR control-plane supports several trafficengineering capabilities. EPE to a specific peer interface, PFL node, orPFS is supported. We also introduce the abstract peering concept wherePFS nodes utilize a next-hop address bound to an anycast SR SID to allowtraffic engineering on a per-peering center basis.TelemetryThe Peering fabric design uses the rich telemetry available in IOS-XRand the NCS5500 platform to enable an unprecedented level of insightinto network and device behavior. The Peering Fabric leverages Model-DrivenTelemetry and NETCONF along with both standard and native YANG modelsfor metric statistics collection. Telemetry configuration and applicablesensor paths have been identified to assist providers in knowing what tomonitor and how to monitor it.AutomationNETCONF and YANG using OpenConfig and native IOS-XR models are used tohelp automate peer configuration and validation. Cisco has developed specific Peering Fabric NSO service models to help automate common tasks suchas peer interface configuration, peer BGP configuration, and addingphysical interfaces to an existing peer bundle.Validated DesignThe  Design control, management, and forwarding planes haveundergone validation testing to ensure individual design features workas intended and the peering fabric as a whole performs without fault.Validation is done exceeding real-world scaling requirements to ensurethe design fulfills its rule in existing networks with room for futuregrowth.Peering Fabric Use CasesTraditional IXP Peering Migration to  Peering FabricA traditional SP IXP design traditionally uses one or two large modularsystems terminating all peering connections. In many cases, sinceproviders are constrained on space and power they use a collapsed designwhere the minimal set of peering nodes not only terminates peerconnections but also provides services and core connectivity to thelocation. The Peering Fabric uses best of breed high density,low footprint hardware requiring much less space than older generationmodular systems. Many older systems provide densities at approximately4x100GE per rack unit, while Peering Fabric PFL nodes start at 24x100GEor 36x100GE per 1RU with high FIB capability. Due to the superior spaceefficiency, there is no longer a limitation of using just a pair ofnodes for these functions. In either a collapsed function or distributedfunction design, peers can be distributed across a number of devices toincrease resiliency and lessen collateral impact when failures occur.The diagram below shows a fully distributed fabric, where peers are nowdistributed across three PFL nodes, each with full connectivity toupstream PFS nodes.Peering Fabric ExtensionIn some cases, there may be peering facilities within close geographicproximity which need to integrate into a single fabric. This may happenif there are multiple 3rd party facilities in a closegeographic area, each with unique peers you want to connect to. Theremay also be multiple independent peering facilities within a smallgeographic area you do not wish to install a complete peering fabricinto. In those cases, connecting remote PFL nodes to a larger peeringfabric can be done using optical transport or longer range gray optics.Localized Metro Peering and Content DeliveryIn order to drive greater network efficiency, content sources should beplaces as close to the end destination as possible. Traditional wirelineand wireless service providers have heavy inbound traffic from contentproviders delivering OTT video. Providers may also be providing theirown IP video services to on-net and off-net destinations via a SP CDN.Peering and internal CDN equipment can be placed within a localized peeror content delivery center, connected via a common peering fabric. Inthese cases the PFS nodes connect directly to the metro core to enabledelivery across the region or metro.Express Peering FabricAn evolution to localized metro peering is to interconnect the PFSpeering nodes directly or a metro-wide peering core. The main driver fordirect interconnection is minimizing the number of router and transportnetwork interfaces traffic must pass through. High density opticalmuxponders such as the NCS1002 along with flexible photonic ROADMarchitectures enabled by the NCS2000 can help make the most efficientuse of metro fiber assets.Datacenter Edge PeeringIn order to serve traffic as close to consumer endpoints as possible aprovider may construct a peering edge attached to an edge or centraldatacenter. As gateway functions in the network become virtualized forapplications such as vPE, vCPE, and mobile 5G, the need to attachInternet peering to the SP DC becomes more important. The Peering Fabric supports interconnected to the DC via the SP core or withthe PFS nodes as leafs to the DC spine. These would act as traditionalborder routers in the DC design.Peer Traffic Engineering with Segment RoutingSegment Routing performs efficient source routing of traffic across aprovider network. Traffic engineering is particular applicable topeering as content providers look for ways to optimize egress networkports and eyeball providers work to reduce network hops between ingressand subscriber. There are also a number of advanced use cases based onusing constraints to place traffic on optimal paths, such as latency. AnSRTE Policy represents a forwarding entity within the SR domain mappingtraffic to a specific network path, defined statically on the node orcomputed by an external PCE. An additional benefit of SR is the abilityto source route traffic based on a node SID or an anycast SIDrepresenting a set of nodes. ECMP behavior is preserved at each point inthe network, redundancy is simplified, and traffic protection issupplied using TI-LFA.In the Low-Level Design we explore common peer engineering use cases.Much more information on Segment Routing technology and its futureevolution can be found at http#//segment-routing.netLow-Level DesignIntegrated Peering Fabric Reference DiagramDistributed Peering Fabric Reference DiagramPeering Fabric Hardware DetailThe NCS5500 family of routers provide high density, high routing scale,idea buffer sizes, and environmental efficiency to help providerssatisfy any peering fabric use case. Due to high FIB scale, largebuffers, and broad XR feature set, all prescribed hardware can serve ineither a collapsed or distributed fabric. Further detailed informationon each platform can be found athttps#//www.cisco.com/c/en/us/products/routers/network-convergence-system-5500-series/index.html.NCS-5501-SEThe NCS 5501 is a 1RU fixed router with 40X10GE SFP+ and 4X100GE QSFP28interfaces. The 5501 has IPv4 FIB scale of at least 2M routes. The5501-SE is ideal as a peering leaf node when providers need 10GEinterface flexibility such as ER, ZR, or DWDM.NCS-55A1-36H-SEThe 55A1-36H-SE is a second generation 1RU NCS5500 fixed platform with36 100GE QSFP28 ports operating at line rate. The \u2013SE model contains anexternal TCAM increasing route scale to a minimum of 3M IPv4/512K IPv6routes in its FIB. It also contains a powerful multi-core routeprocessor with 64GB of RAM and an on-board 64GB SSD. Its high density,efficiency, and buffering capability make it ideal in 10GE or 100GEdeployments. Peering fabrics can scale to much higher capacity 1RU at atime by simply adding additional 55A1-36H-SE spine nodes.NCS-55A1-24HThe NCS-55A1-24H is a second generation 1RU NCS5500 fixed platform with24 100GE QSFP28 ports. The device uses two 900GB NPUs, with 12X100GEports connected to each NPU. The 55A1-24H uses a high scale NPU with aminimum of 1.3M IPv4/256K IPv6 routes. At just 675W it is ideal for 10GEpeering fabric deployments with a migration path to 100GE connectivity.The 55A1-24H also has a powerful multi-core processor and 32GB of RAM.NCS 5504 and 5508 Modular Chassis and NC55-36X100G-A-SE line card Very large peering fabric deployments or those needing interfaceflexibility such as IPoDWDM connectivity can use the modular NCS5500series chassis. Large deployments can utilize the second-generation36X100G-A-SE line card with external TCAM, supporting a minimum of 3MIPv4 routes.Peer Termination StrategyOften overlooked when connecting to Internet peers is determining astrategy to maximize efficiency and resiliency within a local peeringinstance. Often times a peer is connected to a single peering node evenwhen two nodes exist for ease of configuration and coordination with thepeering or transit partner. However, with minimal additionalconfiguration and administration assisted by automation, even singlepeers can be spread across multiple edge peering nodes. Ideally, withina peering fabric, a peer is connected to each leaf in the fabric. Incases where this cannot be done, the provider should use capacityplanning processes to balance peers and transit connections acrossmultiple leafs in the fabric. The added resiliency leads to greaterefficiency when failures do happen, with less reliance on peeringcapacity further away from the traffic destination.Distributed Fabric Device RolesPFL \u2013 Peering Fabric LeafThe Peering Fabric Leaf is the node physically connected to externalpeers. Peers could be aggregation routers or 3rd party CDNnodes. In a deconstructed design the PFL is analogous to a line card ina modular chassis solution. PFL nodes can be added as capacity needsgrow.PFS \u2013 Peering Fabric SpineThe Peering Fabric Spine acts as an aggregation node for the PFLs and isalso physical connected to the rest of the provider network. Theprovider network could refer to a metro core in the case of localizedpeering, a backbone core in relation to IXP peering, a DC spine layer inthe case of DC peering.Device InterconnectionIn order to maximize resiliency in the fabric, each PFL node isconnected to each PFS. While the design shown includes three PFLs andtwo PFS nodes, there could be any number of PFL and PFS nodes, scalinghorizontally to keep up with traffic and interface growth. PFL nodes arenot connected to each other, the PFS nodes provide the capacity for anytraffic between those nodes. The PFS nodes are also not interconnectedto each other, as no end device should terminate on the PFL, only otherrouters.Capacity ScalingCapacity of the peering fabric is scaled horizontally. The uplinkcapacity from PFL to PFS will be determine by an appropriateoversubscription factor determined by the service provider\u2019s capacityplanning exercises. The leaf/spine architecture of the fabric connectseach PFL to each PFS with equal capacity. In steady-state operationtraffic is balanced between the PFS and PFL in both directions,maximizing the total capacity. The entropy in peering traffic generallyensures equal distribution between either ECMP paths or bundle interfacemember links in the egress direction. More information can be found inthe forwarding plane section of the document. An example deployment mayhave two NC55-36X100G-A-SE spine nodes and two NC55A1-24H leaf nodes. Ina 100GE peer deployment scenario each leaf would support 14x100GE clientconnections and 5x100GE to each spine node. A 10GE deployment wouldsupport 72x10GE client ports and 3x100GE to each spine, at a 1.2#1oversubscription ratio.Peering Fabric Control PlanePFL to PeerThe Peering Fabric Leaf is connected directly to peers via traditionalEBGP. BFD may additionally be used for fault detection if agreed to bythe peer. Each EBGP peer will utilize SR EPE to enable TE to the peerfrom elsewhere on the provider network.PFL to PFSPFL to Peering Fabric Spine uses widely deployed standard routingprotocols. IS-IS is the prescribed IGP protocol within the peeringfabric. Each PFS is configured with the same IS-IS L1 area. In the casewhere OSPF is being used as an IGP, the PFL nodes will reside in an OSPFNSSA area. The peering fabric IGP is SR-enabled with the loopback ofeach PFL assigned a globally unique SR Node SID. Each PFL also has anIBGP session to each PFR to distribute its learned EBGP routes upstreamand learn routes from elsewhere on the provider network. If a provideris distributing routes from PFL to PFL or from another peering locationto local PFLs it is important to enable the BGP \u201cbest-path-external\u201dfeature to ensure the PFS has the routing information to acceleratere-convergence if it loses the more preferred path.Egress peer engineering will be enabled for EBGP peering connections, sothat each peer or peer interface connected to a PFL is directlyaddressable by its AdJ-Peer-SID from anywhere on the SP network.Adj-Peer-SID information is currently not carried in the IGP of thenetwork. If utilized it is recommended to distribute this informationusing BGP-LS to all controllers creating paths to the PFL EPEdestinations.Each PFS node will be configured with IBGP multipath so traffic is loadbalanced to PFL nodes and increase resiliency in the case of peerfailure. On reception of a BGP withdraw update for a multipath route,traffic loss is minimized as the existing valid route is stillprogrammed into the FIB.PFS to CoreThe PFS nodes will participate in the global Core control plane and actas the gateway between the peering fabric and the rest of the SPnetwork. In order to create a more scalable and programmatic fabric, itis prescribed to use Segment Routing across the core infrastructure.IS-IS is the preferred protocol for transmitting SR SID information fromthe peering fabric to the rest of the core network and beyond. Indeployments where it may be difficult to transition quickly to an all-SRinfrastructure, the PFS nodes will also support OSPF and RSVP-TE forinterconnection to the core. The PFS acts as an ABR or ASBR between thepeering fabric and the larger metro or backbone core network.SR Peer Traffic EngineeringSummarySR allows a provider to create engineered paths to egress peeringdestinations or egress traffic destinations within the SP network. Astack of globally addressable labels is created at the traffic entrypoint, requiring no additional protocol state at midpoints in thenetwork and preserving qualities of normal IGP routing such as ECMP ateach hop. The  Peering Fabric proposes end-to-end visibility fromthe PFL nodes to the destinations and vice-versa. This will allow arange of TE capabilities targeting a peering location, peering exitnode, or as granular as a specific peering interface on a particularnode. The use of anycast SIDs within a group of PFS nodes increasesresiliency and load balancing capability.Segment Routing Policy ConfigurationNeed to add detailNodal EPENode EPE directs traffic to a specific peering node within the fabric.The node is targeted using first the PFS cluster anycast IP along withthe specific PFL node SID.Peer Interface EPEThis example uses an Egress Peer Engineering peer-adj-SID value assignedto a single peer interface. The result is traffic sent along this SRpath will use only the prescribed interface for egress traffic.Abstract PeeringAbstract peering allows a provider to simply address a Peering Fabric bythe anycast SIDs of its cluster of PFS nodes. In this case PHP is usedfor the anycast SIDs and traffic is simply forwarded as IP to the finaldestination across the fabric.Peering Fabric TelemetryOnce a peering fabric is deployed, it is extremely important to monitorthe health of the fabric as well as harness the wealth of data providedby the enhanced telemetry on the NCS5500 platform and IOS-XR. Throughstreaming data mechanisms such as Model-Driven Telemetry, BMP, andNetflow, providers can extract data useful for operations, capacityplanning, security, and many other use cases. In the diagram below, thetelemetry collection hosts could be a single system or distributedsystems used for collection. The distributed design of the peeringfabric enhances the ability to collect telemetry data from the fabric bydistributing resources across the fabric. Each PFL or PFS contains amodern multi-core CPU and at least 32GB of RAM (64GB in NC55A1-36H-SE)to support not only built in telemetry operation but also 3rdparty applications a service or content provider may want to deploy tothe node for additional telemetry. Examples of 3rd partytelemetry applications include those storing temporary data forroot-cause analysis if a node is isolated from the rest of the networkor performance measurement applications.The peering fabric also fully supports traditional collections methodssuch as SNMP, and NETCONF using YANG models to integrate with legacysystems.Telemetry DiagramModel-Driven TelemetryMDT uses standards-based or native IOS-XR YANG data models to streamoperational state data from deployed devices. The ability to pushstatistics and state data from the device adds capabilities andefficiency not found using traditional SNMP. Sensors and collectionhosts can be configured statically on the host (dial-out) or the set ofsensors, collection hosts, and their attributes can be managed off-boxusing OpenConfig or native IOS-XR YANG models. Pipeline is Cisco\u2019s opensource collector, which can take MDT data as an input and output it viaa plugin architecture supporting scalable messages buses such as Kafka,or directly to a TSDB such as InfluxDB or Prometheus. The appendixcontains information about MDT YANG paths relevant to the peering fabricand their applicability to PFS and PFL nodes.BGP Monitoring ProtocolBMP, defined in RFC7854, is a protocol to monitor BGP RIB information,updates, and protocol statistics. BMP was created to alleviate theburden of collecting BGP routing information using inefficientmechanisms like screen scraping. BMP has two primary modes, RouteMonitoring mode and Route Mirroring mode. The monitoring mode willinitially transmit the adj-rib-in contents per-peer to a monitoringstation, and continue to send updates as they occur on the monitoreddevice. Setting the L bits on the RM header to 1 will convey this is apost-policy route, 0 will indicate pre-policy. The mirroring mode simplyreflects all received BGP messages to the monitoring host. IOS-XRsupports sending pre and post policy routing information and updates toa station via the Route Monitoring mode. BMP can additionally sendinformation on peer state change events, including why a peer went downin the case of a BGP event.There are drafts in the IETF process led by Cisco to extend BMP toreport additional routing data, such as the loc-RIB and per-peeradj-RIB-out. Local-RIB is the full device RIB include ng received BGProutes, routes from other protocols, and locally originated routes.Adj-RIB-out will add the ability to monitor routes advertised to peerspre and post routing policy.Netflow / IPFIXNetflow was invented by Cisco due to requirements for traffic visibilityand accounting. Netflow in its simplest form exports 5-tuple data foreach flow traversing a Netflow-enabled interface. Netflow data isfurther enhanced with the inclusion of BGP information in the exportedNetflow data, namely AS_PATH and destination prefix. This inclusionmakes it possible to see where traffic originated by ASN and derive thedestination for the traffic per BGP prefix. The latest iteration ofCisco Netflow is Netflow v9, with the next-generation IETF standardizedversion called IPFIX (IP Flow Information Export). IPFIX has expanded onNetflow\u2019s capabilities by introducing hundreds of entities.Netflow is traditionally partially processed telemetry data. The deviceitself keeps a running cache table of flow entries and countersassociated with packets, bytes, and flow duration. At certain timeintervals or event triggered, the flow entries are exported to acollector for further processing. The type 315 extension to IPFIX,supported on the NCS5500, does not process flow data on the device, butsends the raw sampled packet header to an external collector for allprocessing. Due to the high bandwidth, PPS rate, and large number ofsimultaneous flows on Internet routers, Netflow samples packets at apre-configured rate for processing. Typical sampling values on peeringrouters are 1 in 8192 packets, however customers implementing Netflow orIPFIX should work with Cisco to fine tune parameters for optimal datafidelity and performance.Automation and ProgrammabilityNetconfNetconf is an industry standard method for configuration networkdevices. Standardized in RFC 6241, Netconf has standard Remote ProcedureCalls (RPCs) to manipulate configuration data and retrieving state data.Netconf on IOS-XR supports the candidate datastore, meaningconfiguration must be explicitly committed for application to therunning configuration.YANG Model SupportWhile Netconf created standard RPCs for managing configuration on adevice, it did not define a language for expressing configuration. Theconfiguration syntax communicated by Netconf followed the typical CLIconfiguration, proprietary for each network vendor XML formatted withoutfollowing any common semantics. YANG or Yet Another Network Grammar, isa modeling language to express configuration using standard elementssuch as containers, groups, lists, and endpoint data called leafs. YANG1.0 was defined in RFC 6020 and updated to version 1.1 in RFC 7950.Vendors cover the majority of device configuration and state usingNative YANG models unique to each vendor, but the industry is headedtowards standardized models where applicable. Groups such as OpenConfigand the IETF are developing standardized YANG models allowing operatorsto write a configuration once across all vendors. Cisco has implementeda number of standard OpenConfig network models relevant to peeringincluding the BGP protocol, BGP RIB, and Interfaces model.The appendix contains information about YANG paths relevant toconfiguring the peering fabric and their applicability to PFS and PFLnodes.Cisco NSO ModulesCisco Network Services Orchestrator is a widely deployed networkautomation and orchestration platform, performing intent-drivenconfiguration and validation of networks from a single source of truthconfiguration database. The  Peering design includes a Cisco NSOmodules to perform specific peering tasks such as peer turn-up, peermodification, deploying routing policy and ACLs to multiple nodes,providing a jumpstart to peering automation.3rd Party Hosted ApplicationsIOS-XR starting in 6.0 runs on an x86 64-bit Linux foundation. The moveto an open and well supported operating system, with XR componentsrunning on top of it, allows network providers to run 3rdparty applications directly on the router. There are a wide variety ofapplications which can run on the XR host, with fast path interfaces inand out of the application. Example applications are telemetrycollection, custom network probes, or tools to manage other portions ofthe network within a location.XR Service Layer APIThe XR service layer API is a gRPC based API to extract data from adevice as well as provide a very fast programmatic path into therouter\u2019s runtime state. One use case of SL API in the peering fabricis to directly program FIB entries on a device, overriding the defaultpath selection. Using telemetry extracted from a peering fabric, anexternal controller can use the data and additional external constraintsto programmatically direct traffic across the fabric. SL API alsosupports transmission of event data via subscriptions.Recommended Device and Protocol ConfigurationOverviewThe following configuration guidelines will step through the majorcomponents of the device and protocol configuration specific to thepeering fabric and highlight non-default configuration recommended foreach device role and the reasons behind those choices. Complete exampleconfigurations for each role can be found in the Appendix of thisdocument. Configuration specific to telemetry is covered in section 4.Common Node ConfigurationThe following configuration is common to both PFL and PFS NCS5500 seriesnodes.Enable LLDP GloballylldpPFS NodesAs the PFS nodes will integrate into the core control-plane, onlyrecommended configuration for connectivity to the PFL nodes is given.IGP Configurationrouter isis pf-internal-core set-overload-bit on-startup wait-for-bgp  is-type level-1-2  net &lt;L2 NET&gt;  net &lt;L1 PF NET&gt;  log adjacency changes log pdu drops lsp-refresh-interval 65000  ;Maximum refresh interval to reduce IS-IS protocol traffic  max-lsp-lifetime 65535 ;Maximum LSP lifetime to reduce IS-IS protocol traffic  lsp-password hmac-md5 &lt;password&gt; ;Set LSP password, enhance security address-family ipv4 unicast    metric-style wide  segment-routing mpls ;Enable segment-routing for IS-IS   maximum-paths 32 ;Set ECMP path limit  address-family ipv6 unicast    metric-style wide  maximum-paths 32 !interface Loopback0  passive  address-family ipv4 unicast   metric 10   prefix-sid index &lt;globally unique index&gt; address-family ipv6 unicast   metric 10! interface HundredGigE0/0/0 point-to-point   circuit-type level-1 hello-password hmac-md5 &lt;password&gt; bfd minimum-interval 100  bfd multiplier 3  bfd fast-detect ipv4  bfd fast-detect ipv6  address-family ipv4 unicast   metric 10   fast-reroute per-prefix ti-lfa ;Enable topology-independent loop-free-alternates on a per-prefix basis address-family ipv6 unicast   metric 10Segment Routing Traffic EngineeringIn IOS-XR there are two mechanisms for configuring SR-TE. Prior to IOS-XR 6.3.2 SR-TE was configured using the MPLS traffic engineering tunnel interface configuration. Starting in 6.3.2 SR-TE can now be configured using the more flexible SR-TE Policy model. The following examples show how to define a static SR-TE path from PFS node to exit PE node using both the legacy tunnel configuration model as well as the new SR Policy model.Paths to PE exit node being load balanced across two static P routers using legacy tunnel configexplicit-path name PFS1-P1-PE1-1 index 1 next-address 192.168.12.1 index 2 next-address 192.168.11.1!explicit-path name PFS1-P2-PE1-1 index 1 next-label 16221  index 2 next-label 16511!interface tunnel-te1 bandwidth 1000 ipv4 unnumbered Loopback0 destination 192.168.11.1 path-option 1 explicit name PFS1-P1-PE1-1 segment-routing!interface tunnel-te2 bandwidth 1000 ipv4 unnumbered Loopback0 destination 192.168.11.2 path-option 1 explicit name PFS1-P2-PE1-1 segment-routingIOS-XR 6.3.2+ SR Policy Configurationsegment-routingtraffic-eng  segment-list PFS1-P1-PE1-SR-1   index 1 mpls label 16211   index 2 mpls label 16511  !  segment-list PFS1-P2-PE1-SR-1   index 1 mpls label 16221   index 2 mpls label 16511  !  policy pfs1_pe1_via_p1   binding-sid mpls 900001   color 1 end-point ipv4 192.168.11.1   candidate-paths    preference 150     explicit segment-list PFS1-P1-PE1-SR-1      weight 1     !    !   !  !  policy pfs1_pe1_via_p2   binding-sid mpls 900002   color 2 end-point ipv4 192.168.11.1   candidate-paths    preference 150     explicit segment-list PFS1-P1-PE1-SR-1      weight 1     !    !   !  !BGP Global Configurationbgp router-id &lt;Lo0 IP&gt;  bgp bestpath aigp ignore ;Ignore AIGP community when sent by peer bgp bestpath med always ;Compare MED values even when AS_PATH doesn\u2019t match bgp bestpath as-path multipath-relax ;Use multipath even if AS_PATH is longer address-family ipv4 unicast  additional-paths receive maximum-paths ibgp 32 ;set maximum retained IBGP paths to 32   maximum-paths ebgp 32 ;set maximum retained EBGP paths to 32 !address-family ipv6 unicast additional-paths receive bgp attribute-download  maximum-paths ibgp 32  maximum-paths ebgp 32!address-family link-state link-state ;Enable BGP-LS AF  Model-Driven Telemetry ConfigurationThe configuration below creates two sensor groups, one for BGP data andone for Interface counters. Each is added to a separate subscription,with the BGP data sent every 60 seconds and the interface data sentevery 30 seconds. A single destination is used, however multipledestinations could be configured. The sensors and timers provided arefor illustration only.telemetry model-driven destination-group mdt-dest-1  vrf default  address-family ipv4 &lt;dest IP&gt; &lt;dest-port&gt;   encoding &lt;gpb | self-describing-gbp&gt;    protocol &lt;tcp | grpc&gt;  ! ! sensor-group peering-pfl-bgp   sensor-path openconfig-bgp#bgp/neighbors !  sensor-group peering-pfl-interface  sensor-path openconfig-platform#components  sensor-path openconfig-interfaces#interfaces  sensor-path Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface  sensor-path Cisco-IOS-XR-drivers-media-eth-oper/ethernet-interface/interfaces/interface/phy-info  sensor-path Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters ! subscription peering-pfl-sub-bgp   sensor-group-id peering-pfl-bgp sample-interval 60000  destination-id mdt-dest-1 ! subscription peering-pfl-sub-interface   sensor-group-id peering-pfl-interface sample-interval 30000  destination-id mdt-dest-1PFL NodesPeer QoS PolicyPolicy applied to edge of the network to rewrite any incoming DSCP valueto 0.policy-map peer-qos-in class class-default  set dscp default ! end-policy-map!Peer Infrastructure ACLSee the Security section of the document for recommended best practicesfor ingress and egress infrastructure ACLs.access-group v4-infra-acl-in access-group v6-infra-acl-in access-group v4-infra-acl-out access-group v6-infra-acl-out Peer Interface Configurationinterface TenGigE0/0/0/0 description \u201cexternal peer\u201d  service-policy input peer-qos-in ;Explicit policy to rewrite DSCP to 0  lldp transmit disable #Do not run LLDP on peer connected interfaces  lldp receive disable #Do not run LLDP on peer connected interfaces  ipv4 access-group v4-infra-acl-in #IPv4 Ingress infrastructure ACL    ipv4 access-group v4-infra-acl-out #IPv4 Egress infrastructure ACL, BCP38 filtering  ipv6 access-group v6-infra-acl-in #IPv6 Ingress infrastructure ACL  ipv6 access-group v6-infra-acl-out #IPv6 Egress infrastructure ACL, BCP38 filtering IS-IS IGP Configurationrouter isis pf-internal set-overload-bit on-startup wait-for-bgp  is-type level-1 net &lt;L1 Area NET&gt; log adjacency changes log pdu drops lsp-refresh-interval 65000  ;Maximum refresh interval to reduce IS-IS protocol traffic  max-lsp-lifetime 65535 ;Maximum LSP lifetime to reduce IS-IS protocol traffic  lsp-password hmac-md5 &lt;password&gt; ;Set LSP password, enhance security address-family ipv4 unicast    metric-style wide  segment-routing mpls ;Enable segment-routing for IS-IS   maximum-paths 32 ;Set ECMP path limit  address-family ipv6 unicast    metric-style wide  maximum-paths 32 !interface Loopback0  passive  address-family ipv4 unicast   metric 10   prefix-sid index &lt;globally unique index&gt; address-family ipv6 unicast   metric 10 ! interface HundredGigE0/0/0 point-to-point   circuit-type level-1 hello-password hmac-md5 &lt;password&gt; bfd minimum-interval 100  bfd multiplier 3  bfd fast-detect ipv4  bfd fast-detect ipv6  address-family ipv4 unicast   metric 10   fast-reroute per-prefix ti-lfa ;Enable topology-independent loop-free-alternates on a per-prefix basis address-family ipv6 unicast   metric 10BGP Add-Path Route Policyroute-policy advertise-all ;Create policy for add-path advertisements   set path-selection all advertiseend-policyBGP Global Configurationbgp router-id &lt;Lo0 IP&gt;  bgp bestpath aigp ignore ;Ignore AIGP community when sent by peer bgp bestpath med always ;Compare MED values even when AS_PATH doesn\u2019t match bgp bestpath as-path multipath-relax ;Use multipath even if AS_PATh is longer address-family ipv4 unicast bgp attribute-download  ;Enable BGP information for Netflow/IPFIX export  additional-paths send  additional-paths selection route-policy advertise-all ;Advertise all equal-cost IPv4 NLRI to PFS  maximum-paths ibgp 32 ;set maximum retained IBGP paths to 32   maximum-paths ebgp 32 ;set maximum retained EBGP paths to 32 !address-family ipv6 unicast additional-paths send  additional-paths receive  additional-paths selection route-policy advertise-all ;Advertise all equal-cost IPv6 NLRI to PFS bgp attribute-download  maximum-paths ibgp 32  maximum-paths ebgp 32!address-family link-state link-state ;Enable BGP-LS AF  EBGP Peer Configurationsession-group peer-session   ignore-connected-check #Allow loopback peering over ECMP w/o EBGP Multihop    egress-engineering #Allocate adj-peer-SID   ttl-security #Enable gTTL security if neighbor supports it     bmp-activate server 1 #Optional send BMP data to receiver 1af-group v4-af-peer address-family ipv4 unicast  soft-reconfiguration inbound always #Store inbound routes for operational purposes  multipath #Store multiple paths if using ECMP to neighbor maximum-prefix 1000 80;Set maximum inbound prefixes, warning at 80% thresholdaf-group v6-af-peer  soft-reconfiguration inbound always #Store inbound routes for operational purposes  multipath #Store multiple paths if using ECMP to neighbor maximum-prefix 100 80 #Set maximum inbound prefixes, warning at 80% thresholdneighbor-group v4-peer   use session-group peer-session   dmz-link-bandwidth ;Propagate external link BW   address-family ipv4 unicast af-group v4-af-peerneighbor-group v6-peer   use session-group peer-session  dmz-link-bandwidth    address-family ipv6 unicast af-group v6-af-peer neighbor 1.1.1.1 description ~ext-peer;12345~ remote-as 12345   use neighbor-group v4-peer address-family ipv4 unicast  route-policy v4-peer-in(12345) in  route-policy v4-peer-out(12345) out  neighbor 2001#dead#b33f#0#1#1#1#1 description ~ext-peer;12345~ remote-as 12345   use neighbor-group v6-peer address-family ipv6 unicast  route-policy v6-peer-in(12345) in  route-policy v6-peer-out(12345) out PFL to PFS IBGP Configurationsession-group pfs-session  ttl-security #Enable gTTL security if neighbor supports it    bmp-activate server 1 #Optional send BMP data to receiver 1 update-source Loopback0 #Set BGP session source address to Loopback0 address  af-group v4-af-pfs address-family ipv4 unicast  next-hop-self #Set next-hop to Loopback0 address soft-reconfiguration inbound always #Store inbound routes for operational purposes  multipath #Store multiple paths if using ECMP to neighbor route-policy v4-pfs-in in  route-policy v4-pfs-out out  af-group v6-af-pfs  next-hop-self #Set next-hop to Loopback0 address soft-reconfiguration inbound always #Store inbound routes for operational purposes  multipath #Store multiple paths if using ECMP to neighbor route-policy v6-pfs-in in route-policy v6-pfs-out out   neighbor-group v4-pfs   !  use session-group pfs-session   address-family ipv4 unicast af-group v4-af-pfsneighbor-group v6-pfs   !  use session-group pfs-session    address-family ipv6 unicast af-group v6-af-pfs neighbor &lt;PFS IP&gt;  description ~PFS #1~ remote-as &lt;local ASN&gt;    use neighbor-group v4-pfsNetflow/IPFIX Configurationflow exporter-map nf-export version v9  options interface-table timeout 60  options sampler-table timeout 60  template timeout 30  ! transport udp &lt;port&gt; source Loopback0 destination &lt;dest&gt;flow monitor-map flow-monitor-ipv4 record ipv4 option bgpattr exporter nf-export cache entries 50000 cache timeout active 60 cache timeout inactive 10!flow monitor-map flow-monitor-ipv6 record ipv6 option bgpattr exporter nf-export cache timeout active 60 cache timeout inactive 10!flow monitor-map flow-monitor-mpls record mpls ipv4-ipv6-fields option bgpattr exporter nf-export cache timeout active 60 cache timeout inactive 10 sampler-map nf-sample-8192 random 1 out-of 8192Peer Interfaceinterface Bundle-Ether100 flow ipv4 monitor flow-monitor-ipv4 sampler nf-sample-8192 ingress flow ipv6 monitor flow-monitor-ipv6 sampler nf-sample-8192 ingress flow mpls monitor flow-monitor-mpls sampler nf-sample-8192 ingressPFS Upstream Interfaceinterface HundredGigE0/0/0/100   flow ipv4 monitor flow-monitor-ipv4 sampler nf-sample-8192 ingress flow ipv6 monitor flow-monitor-ipv6 sampler nf-sample-8192 ingress flow mpls monitor flow-monitor-mpls sampler nf-sample-8192 ingressModel-Driven Telemetry ConfigurationThe configuration below creates two sensor groups, one for BGP data andone for Interface counters. Each is added to a separate subscription,with the BGP data sent every 60 seconds and the interface data sentevery 30 seconds. A single destination is used, however multipledestinations could be configured. The sensors and timers provided arefor illustration only.telemetry model-driven destination-group mdt-dest-1  vrf default  address-family ipv4 &lt;dest IP&gt; &lt;dest-port&gt;   encoding &lt;gpb | self-describing-gbp&gt;    protocol &lt;tcp | grpc&gt;  ! ! sensor-group peering-pfl-bgp   sensor-path openconfig-bgp#bgp/neighbors !  sensor-group peering-pfl-interface  sensor-path openconfig-platform#components  sensor-path openconfig-interfaces#interfaces  sensor-path Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface  sensor-path Cisco-IOS-XR-drivers-media-eth-oper/ethernet-interface/interfaces/interface/phy-info  sensor-path Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters ! subscription peering-pfl-sub-bgp   sensor-group-id peering-pfl-bgp sample-interval 60000  destination-id mdt-dest-1 ! subscription peering-pfl-sub-interface   sensor-group-id peering-pfl-interface sample-interval 30000  destination-id mdt-dest-1Abstract Peering ConfigurationAbstract peering uses qualities of Segment Routing anycast addresses toallow a provider to steer traffic to a specific peering fabric by simplyaddressing a node SID assigned to all PFS members of the peeringcluster. All of the qualities of SR such as midpoint ECMP and TI-LFAfast protection are preserved for the end to end BGP path, improvingconvergence across the network to the peering fabric. Additionally,through the use of SR-TE Policy, source routed engineered paths can beconfigured to the peering fabric based on business logic and additionalpath constraints.PFS ConfigurationOnly the PFS nodes require specific configuration to perform abstractpeering. Configuration shown is for example only with IS-IS configuredas the IGP carrying SR information. The routing policy setting thenext-hop to the AP anycast SID should be incorporated into standard IBGPoutbound routing policy.interface Loopback1  ipv4 address x.x.x.x/32  ipv6 address x#x#x#x##x/128  router isis &lt;ID&gt;   passive  address-family ipv4 unicast   prefix-sid absolute &lt;Global IPv4 AP Node SID&gt;  address-family ipv6 unicast   prefix-sid absolute &lt;Global IPv6 AP Node SID&gt; route-policy v4-abstract-ibgp-out  set next-hop &lt;Loopback1 IPv4 address&gt;  route-policy v6-abstract-ibgp-out  set next-hop &lt;Loopback1 IPv6 address&gt; router bgp &lt;ASN&gt;  ibgp policy out enforce-modifications ;Enables a PFS node to set a next-hop address on routes reflected to IBGP peersrouter bgp &lt;ASN&gt;  neighbor x.x.x.x   address-family ipv4 unicast route-policy v4-abstract-ibgp-out  neighbor x#x#x#x##x   address-family ipv6 unicast route-policy v6-abstract-ibgp-out SecurityPeering by definition is at the edge of the network, where security ismandatory. While not exclusive to peering, there are a number of bestpractices and software features when implemented will protect your ownnetwork as well as others from malicious sources within your network.Infrastructure ACLsInfrastructure ACLs and their associated ACEs (Access Control Entries)are the perimeter protection for a network. The recommended PFL deviceconfiguration uses IPv4 and IPv6 infrastructure ACLs on all edgeinterfaces. These ACLs are specific to each provider\u2019s security needs,but should include the following sections.  Filter IPv4 and IPv6 BOGON space ingress and egress  Drop ingress packets with a source address matching your own aggregate IPv4/IPv6 prefixes.  Rate-limit ingress traffic to Unix services typically used in DDoSattacks, such as chargen (TCP/19).  On ingress and egress, allow specific ICMP types and rate-limit toappropriate values, filter out ones not needed on your network. ICMPttl-exceeded, host unreachable, port unreachable, echo-reply,echo-request, and fragmentation needed should always be allowed in somecapacity.BCP ImplementationBest Current Practices are informational documents published by the IETFto give guidelines on operational practices. This document will notoutline the contents of the recommended BCPs, but two in particular areof interest to Internet peering. BCP38 explains the need to filterunused address space at the edges of the network, minimizing the chancesof spoofed traffic from DDoS sources reaching their intended target.BCP38 is applicable for ingress traffic and especially egress traffic,as it stops spoofed traffic before it reaches outside your network.BCP194, BGP Operations and Security, covers a number of BGP operationalpractices, many of which are used in Internet peering. IOS-XR supportsall of the mechanisms recommended in BCP38, BCP84, and BCP194, includingsoftware features such as GTTL, BGP dampening, and prefix limits.BGP Attribute and CoS ScrubbingScrubbing of data on ingress and egress of your network is an importantsecurity measure. Scrubbing falls into two categories, control-plane anddataplane. The control-plane for Internet peering is BGP and there are afew BGP transitive attributes one should take care to normalize. Yourinternal BGP communities should be deleted from outbound BGP NLRI viaegress policy. Most often you are setting communities on inboundprefixes, make sure you are replacing existing communities from the peerand not adding communities. Unless you have an agreement with the peer,normalize the MED attribute to zero or another standard value on allinbound prefixes.In the dataplane, it\u2019s important to treat the peering edge as untrustedand clear any CoS markings on inbound packets, assuming a prioragreement hasn\u2019t been reached with the peer to carry them across thenetwork boundary. It\u2019s an overlooked aspect which could lead to peertraffic being prioritized on your network, leading to unexpected networkbehavior. An example PFL infrastructure ACL is given resetting incomingIPv4/IPv6 DSCP values to 0.Per-Peer Control Plane PolicersBGP protocol packets are handled at the RP level, meaning each packet ishandled by the router CPU with limited bandwidth and processingresources. In the case of a malicious or misconfigured peer this couldexhaust the processing power of the CPU impacting other important tasks.IOS-XR enforces protocol policers and BGP peer policers by default.BGP Prefix SecurityRPKI Origin ValidationPrefix hijacking has been prevalent throughout the last decade as theInternet became more integrated into our lives. This led to the creationof RPKI origin validation, a mechanism to validate a prefix was beingoriginated by its rightful owner by checking the originating ASN vs. asecure database. IOS-XR fully supports RPKI for origin validation.BGPSECRPKI origin validation works to validate the source of a prefix, butdoes not validate the entire path of the prefix. Origin validation alsodoes not use cryptographic signatures to ensure the originator is whothey say they are, so spoofing the ASN as well does not stop someoneform hijacking a prefix. BGPSEC is an evolution where a BGP prefix iscryptographically signed with the key of its valid originator, and eachBGP router receiving the path checks to ensure the prefix originatedfrom the valid owner. BGPSEC standards are being worked on in the SIDRworking group.BGP FlowspecBGP Flowspec was standardized in RFC 5575 and defines additional BGPNLRI to inject traffic manipulation policy information to be dynamicallyimplemented by a receiving router. BGP acts as the control-plane fordisseminating the policy information while it is up to the BGP Flowspecreceiver to implement the dataplane rules specified in the NLRI. At theInternet peering edge, DDoS protection has become extremely important,and automating the remediation of an incoming DDoS attack has becomevery important. Automated DDoS protection is only one BGP Flowspec usecase, any application needing a programmatic way to create interfacepacket filters can make se use of its capabilities.AppendixApplicable YANG ModelsModelDataopenconfig-interfacesCisco-IOS-XR-infra-statsd-operCisco-IOS-XR-pfi-im-cmd-operInterface config and state Common counters found in SNMP IF-MIB openconfig-if-ethernet Cisco-IOS-XR-drivers-media-eth-operEthernet layer config and stateXR native transceiver monitoringopenconfig-platformInventory, transceiver monitoring openconfig-bgpCisco-IOS-XR-ipv4-bgp-oper Cisco-IOS-XR-ipv6-bgp-operBGP config and state Includes neighbor session state, message counts, etc.openconfig-bgp-rib Cisco-IOS-XR-ip-rib-ipv4-oper Cisco-IOS-XR-ip-rib-ipv6-operBGP RIB information. Note# Cisco native includes all protocols openconfig-routing-policyConfigure routing policy elements and combined policyopenconfig-telemetryConfigure telemetry sensors and destinations Cisco-IOS-XR-ip-bfd-cfg Cisco-IOS-XR-ip-bfd-operBFD config and state Cisco-IOS-XR-ethernet-lldp-cfg Cisco-IOS-XR-ethernet-lldp-operLLDP config and state openconfig-mplsMPLS config and state, including Segment RoutingCisco-IOS-XR-clns-isis-cfgCisco-IOS-XR-clns-isis-operIS-IS config and state Cisco-IOS-XR-fretta-bcm-dpa-hw-resources-operNCS 5500 HW resources NETCONF YANG PathsNote that while paths are given to retrieve data from a specific leafnode, it is sometimes more efficient to retrieve all the data under aspecific heading and let a management station filter unwanted data thanperform operations on the router. Additionally, Model Driven Telemetrymay not work at a leaf level, requiring retrieval of an entire subset ofdata.The data is also available via NETCONF, which does allow subtree filtersand retrieval of specific data. However, this is a more resourceintensive operation on the router.MetricData            \u00a0      \u00a0                  Logical Interface Admin State      Enum              SNMP OID      IF-MIB#ifAdminStatus              OC YANG      openconfig-interfaces#interfaces/interface/state/admin-status (see OC model, not just up/down)              Native YANG      Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface/state                  \u00a0      \u00a0                  Logical Interface Operational State      Enum              SNMP OID      IF-MIB#ifOperStatus              OC YANG      openconfig-interfaces#interfaces/interface/state/oper-status (see OC model, not just up/down)              Native YANG      Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface/state                  \u00a0      \u00a0                  Logical Last State Change (seconds)      Counter              SNMP OID      IF-MIB#ifLastChange              OC YANG      openconfig-interfaces#interfaces/interface/state/last-change              Native YANG      Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface/last-state-transition-time                  \u00a0      \u00a0                  Logical Interface SNMP ifIndex      Integer              SNMP OID      IF-MIB#ifIndex              OC YANG      openconfig-interfaces#interfaces/interface/state/if-index              Native YANG      Cisco-IOS-XR-snmp-agent-oper#snmp/interface-indexes/if-index                  \u00a0      \u00a0                  Logical Interface RX Bytes 64-bit      Counter              SNMP OID      IF-MIB#ifHCInOctets              OC YANG      openconfig-interfaces#/interfaces/interface/state/counters/in-octets              Native YANG      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters/bytes-received                  \u00a0      \u00a0                  Logical Interface TX Bytes 64-bit      Counter              SNMP OID      IF-MIB#ifHCOutOctets              OC YANG      openconfig-interfaces#/interfaces/interface/state/counters/out-octets              Native YANG      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters/bytes-sent                  \u00a0      \u00a0                  Logical Interface RX Errors      Counter              SNMP OID      IF-MIB#ifInErrors              OC YANG      openconfig-interfaces#/interfaces/interface/state/counters/in-errors              Native YANG      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters/input-errors              MDT      Native                  \u00a0      \u00a0                  Logical Interface TX Errors      Counter              SNMP OID      IF-MIB#ifOutErrors              OC YANG      openconfig-interfaces#/interfaces/interface/state/counters/out-errors              Native YANG      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters/output-errors                  \u00a0      \u00a0                  Logical Interface Unicast Packets RX      Counter              SNMP OID      IF-MIB#ifHCInUcastPkts              OC YANG      openconfig-interfaces#/interfaces/interface/state/counters/in-unicast-pkts              Native YANG      Not explicitly supported, subtract multicast/broadcast from total                  \u00a0      \u00a0                  Logical Interface Unicast Packets TX      Counter              SNMP OID      IF-MIB#ifHCOutUcastPkts              OC YANG      openconfig-interfaces#/interfaces/interface/state/counters/out-unicast-pkts              Native YANG      Not explicitly supported, subtract multicast/broadcast from total                  \u00a0      \u00a0                  Logical Interface Input Drops      Counter              SNMP OID      IF-MIB#ifIntDiscards              OC YANG      openconfig-interfaces#/interfaces/interface/state/counters/in-discards              Native YANG      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters/input-drops                  \u00a0      \u00a0                  Logical Interface Output Drops      Counter              SNMP OID      IF-MIB#ifOutDiscards              OC YANG      openconfig-interfaces#/interfaces/interface/state/counters/out-discards              Native YANG      Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters/output-drops                  \u00a0      \u00a0                  Ethernet Layer Stats \u2013 All Interfaces      Counters              SNMP OID      NA              OC YANG      openconfig-interfaces#interfaces/interface/oc-eth#ethernet/oc-eth#state              Native YANG      Cisco-IOS-XR-drivers-media-eth-oper/ethernet-interface/statistics                  \u00a0      \u00a0                  Ethernet PHY State \u2013 All Interfaces      Counters              SNMP OID      NA              OC YANG      oc-platform#components/component/oc-transceiver#transceiver              Native YANG      Cisco-IOS-XR-drivers-media-eth-oper/ethernet-interface/interfaces/interface/phy-info                  \u00a0      \u00a0                  Ethernet Input CRC Errors      Counter              SNMP OID      NA              OC YANG      openconfig-interfaces#interfaces/interface/oc-eth#ethernet/oc-eth#state/oc-eth#counters/oc-eth#in-crc-errors              Native YANG      Cisco-IOS-XR-drivers-media-eth-oper/ethernet-interface/statistics/statistic/dropped-packets-with-crc-align-errors      The following transceiver paths retrieve the total power for thetransceiver, there are specific per-lane power levels which can beretrieved from both native and OC models, please refer to the model YANGfile for additionalinformation.            \u00a0      \u00a0                  Ethernet Transceiver RX Power      Counter              SNMP OID      NA              OC YANG      oc-platform#components/component/oc-transceiver#transceiver/oc-transceiver#physical-channels/oc-transceiver#channel/oc-transceiver#state/oc-transceiver#input-power              Native YANG      Cisco-IOS-XR-drivers-media-eth-oper/ethernet-interface/interfaces/interface/phy-info/phy-details/transceiver-rx-power                  \u00a0      \u00a0                  Ethernet Transceiver TX Power      Counter              SNMP OID      NA              OC YANG      oc-platform#components/component/oc-transceiver#transceiver/oc-transceiver#physical-channels/oc-transceiver#channel/oc-transceiver#state/oc-transceiver#input-power              Native YANG      Cisco-IOS-XR-drivers-media-eth-oper/ethernet-interface/interfaces/interface/phy-info/phy-details/transceiver-tx-power      BGP Operational StateGlobal BGP Protocol StateIOS-XR native models do not store route information in the BGP Opermodel, they are stored in the IPv4/IPv6 RIB models. These models containRIB information based on protocol, with a numeric identifier for eachprotocol with the BGP ProtoID being 5. The protoid must be specified orthe YANG path will return data for all configured routingprotocols.            \u00a0      \u00a0                  BGP Total Paths (all AFI/SAFI)      Counter              SNMP OID      NA              OC YANG      openconfig-bgp#bgp/global/state/total-paths              Native YANG      Cisco-IOS-XR-ip-rib-ipv4-oper/rib/rib-table-ids/rib-table-id/summary-protos/summary-proto/proto-route-count/num-active-paths              MDT      Native                  \u00a0      \u00a0                  BGP Total Prefixes (all AFI/SAFI)      Counter              SNMP OID      NA              OC YANG      openconfig-bgp#bgp/global/state/total-prefixes              Native YANG      Cisco-IOS-XR-ip-rib-ipv4-oper/rib/rib-table-ids/rib-table-id/summary-protos/summary-proto/proto-route-count/active-routes-count              MDT      Native      BGP Neighbor StateExample UsageDue the construction of the YANG model, the neighbor-address key must beincluded as a container in all OC BGP state RPCs. The following RPC getsthe session state for all configured peers#&lt;rpc message-id=~101~ xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~&gt;  &lt;get&gt;    &lt;filter&gt;      &lt;bgp xmlns=~http#//openconfig.net/yang/bgp~&gt;        &lt;neighbors&gt;          &lt;neighbor&gt;            &lt;neighbor-address/&gt;            &lt;state&gt;              &lt;session-state/&gt;            &lt;/state&gt;          &lt;/neighbor&gt;        &lt;/neighbors&gt;      &lt;/bgp&gt;    &lt;/filter&gt;  &lt;/get&gt;&lt;/rpc&gt;\t&lt;nc#rpc-reply message-id=~urn#uuid#24db986f-de34-4c97-9b2f-ac99ab2501e3~ xmlns#nc=~urn#ietf#params#xml#ns#netconf#base#1.0~ xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~&gt;  &lt;nc#data&gt;    &lt;bgp xmlns=~http#//openconfig.net/yang/bgp~&gt;      &lt;neighbors&gt;        &lt;neighbor&gt;          &lt;neighbor-address&gt;172.16.0.2&lt;/neighbor-address&gt;          &lt;state&gt;            &lt;session-state&gt;IDLE&lt;/session-state&gt;          &lt;/state&gt;        &lt;/neighbor&gt;        &lt;neighbor&gt;          &lt;neighbor-address&gt;192.168.2.51&lt;/neighbor-address&gt;          &lt;state&gt;            &lt;session-state&gt;IDLE&lt;/session-state&gt;          &lt;/state&gt;        &lt;/neighbor&gt;      &lt;/neighbors&gt;    &lt;/bgp&gt;  &lt;/nc#data&gt;&lt;/nc#rpc-reply&gt;            \u00a0      \u00a0                  Complete State for all BGP neighbors      Mixed              SNMP OID      NA              OC YANG      openconfig-bgp#bgp/neighbors/neighbor/state              Native YANG      Cisco-IOS-XR-ipv4-bgp-oper/bgp/instances/instance/instance-active/default-vrf/neighbors                  \u00a0      \u00a0                  Complete State for all BGP neighbors      Mixed              SNMP OID      NA              OC YANG      openconfig-bgp#bgp/neighbors/neighbor/state              Native YANG      Cisco-IOS-XR-ipv4-bgp-oper/bgp/instances/instance/instance-active/default-vrf/neighbors                  \u00a0      \u00a0                  Session State for all BGP neighbors      Enum              SNMP OID      NA              OC YANG      openconfig-bgp#bgp/neighbors/neighbor/state/session-state              Native YANG      Cisco-IOS-XR-ipv4-bgp-oper/bgp/instances/instance/instance-active/default-vrf/neighbors/neighbor/connection-state                  \u00a0      \u00a0                  Message counters for all BGP neighbors      Counter              SNMP OID      NA              OC YANG      openconfig-bgp#bgp/neighbors/neighbor/state/messages              Native YANG      Cisco-IOS-XR-ipv4-bgp-oper/bgp/instances/instance/instance-active/default-vrf/neighbors/neighbor/message-statistics      Current queue depth for all BGP neighborsCounterSNMP OIDNAOC YANG/openconfig-bgp#bgp/neighbors/neighbor/state/queuesNative YANGCisco-IOS-XR-ipv4-bgp-oper/bgp/instances/instance/instance-active/default-vrf/sessions/session/messages-queued-outCisco-IOS-XR-ipv4-bgp-oper/bgp/instances/instance/instance-active/default-vrf/sessions/session/messages-queued-inBGP RIB DataRIB data is retrieved per AFI/SAFI. To retrieve IPv6 unicast routesusing OC models, replace \u201cipv4-unicast\u201d with \u201cipv6-unicast\u201dIOS-XR native models do not have a BGP specific RIB, only RIB dataper-AFI/SAFI for all protocols. Retrieving RIB information from thesepaths will include this data.While this data is available via both NETCONF and MDT, it is recommendedto use BMP as the mechanism to retrieve RIB table data.Example UsageThe following retrieves a list of best-path IPv4 prefixes withoutattributes from the loc-RIB#&lt;rpc message-id=~101~ xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~&gt;  &lt;get&gt;    &lt;filter&gt;      &lt;bgp-rib xmlns=~http#//openconfig.net/yang/rib/bgp~&gt;        &lt;afi-safis&gt;          &lt;afi-safi&gt;            &lt;ipv4-unicast&gt;              &lt;loc-rib&gt;                &lt;routes&gt;                  &lt;route&gt;                    &lt;prefix/&gt;                    &lt;best-path&gt;true&lt;/best-path&gt;                  &lt;/route&gt;                &lt;/routes&gt;              &lt;/loc-rib&gt;            &lt;/ipv4-unicast&gt;          &lt;/afi-safi&gt;        &lt;/afi-safis&gt;      &lt;/bgp-rib&gt;    &lt;/filter&gt;  &lt;/get&gt;&lt;/rpc&gt;               \u00a0      \u00a0                  IPv4 Local RIB \u2013 Prefix Count      Counter              OC YANG      openconfig-bgp-rib#bgp-rib/afi-safis/afi-safi/ipv4-unicast/loc-rib/num-routes              Native YANG      \u00a0                  \u00a0      \u00a0                  IPv4 Local RIB \u2013 IPv4 Prefixes w/o Attributes      List              OC YANG      openconfig-bgp-rib#bgp-rib/afi-safis/afi-safi/ipv4-unicast/loc-rib/routes/route/prefix                  \u00a0      \u00a0                  IPv4 Local RIB \u2013 IPv4 Prefixes w/Attributes      List              OC YANG      openconfig-bgp-rib#bgp-rib/afi-safis/afi-safi/ipv4-unicast/loc-rib/routes              Native YANG      \u00a0      The following per-neighbor RIB paths can be qualified with a specificneighbor address to retrieve RIB data for a specific peer. Below is anexample of a NETCONF RPC to retrieve the number of post-policy routesfrom the 192.168.2.51 peer and the returned output.&lt;rpc message-id=~101~ xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~&gt;  &lt;get&gt;    &lt;filter&gt;      &lt;bgp-rib xmlns=~http#//openconfig.net/yang/rib/bgp~&gt;        &lt;afi-safis&gt;          &lt;afi-safi&gt;            &lt;ipv4-unicast&gt;              &lt;neighbors&gt;                &lt;neighbor&gt;                  &lt;neighbor-address&gt;192.168.2.51&lt;/neighbor-address&gt;                  &lt;adj-rib-in-post&gt;                    &lt;num-routes/&gt;                  &lt;/adj-rib-in-post&gt;                &lt;/neighbor&gt;              &lt;/neighbors&gt;            &lt;/ipv4-unicast&gt;          &lt;/afi-safi&gt;        &lt;/afi-safis&gt;      &lt;/bgp-rib&gt;    &lt;/filter&gt;  &lt;/get&gt;&lt;/rpc&gt;&lt;nc#rpc-reply message-id=~urn#uuid#7d9a0468-4d8d-4008-972b-8e703241a8e9~ xmlns#nc=~urn#ietf#params#xml#ns#netconf#base#1.0~ xmlns=~urn#ietf#params#xml#ns#netconf#base#1.0~&gt;  &lt;nc#data&gt;    &lt;bgp-rib xmlns=~http#//openconfig.net/yang/rib/bgp~&gt;      &lt;afi-safis&gt;        &lt;afi-safi&gt;          &lt;afi-safi-name xmlns#idx=~http#//openconfig.net/yang/rib/bgp-types~&gt;idx#IPV4_UNICAST&lt;/afi-safi-name&gt;          &lt;ipv4-unicast&gt;            &lt;neighbors&gt;              &lt;neighbor&gt;                &lt;neighbor-address&gt;192.168.2.51&lt;/neighbor-address&gt;                &lt;adj-rib-in-post&gt;                  &lt;num-routes&gt;3&lt;/num-routes&gt;                &lt;/adj-rib-in-post&gt;              &lt;/neighbor&gt;            &lt;/neighbors&gt;          &lt;/ipv4-unicast&gt;        &lt;/afi-safi&gt;      &lt;/afi-safis&gt;    &lt;/bgp-rib&gt;  &lt;/nc#data&gt;&lt;/nc#rpc-reply&gt;            \u00a0      \u00a0                  IPv4 Neighbor adj-rib-in pre-policy      List              OC YANG      openconfig-bgp-rib#bgp-rib/afi-safis/afi-safi/ipv4-unicast/neighbors/neighbor/adj-rib-in-re                  \u00a0      \u00a0                  IPv4 Neighbor adj-rib-in post-policy      List              OC YANG      openconfig-bgp-rib#bgp-rib/afi-safis/afi-safi/ipv4-unicast/neighbors/neighbor/adj-rib-in-post                  \u00a0      \u00a0                  IPv4 Neighbor adj-rib-out pre-policy      List              OC YANG      openconfig-bgp-rib#bgp-rib/afi-safis/afi-safi/ipv4-unicast/neighbors/neighbor/adj-rib-out-pre                  \u00a0      \u00a0                  IPv4 Neighbor adj-rib-out post-policy      List              OC YANG      openconfig-bgp-rib#bgp-rib/afi-safis/afi-safi/ipv4-unicast/neighbors/neighbor/adj-rib-out-pre      Device Resource YANG Paths            \u00a0      \u00a0                  Device Inventory      List              OC YANG      oc-platform#components                  \u00a0      \u00a0                  NCS5500 Dataplane Resources      List              OC YANG      NA              Native YANG      Cisco-IOS-XR-fretta-bcm-dpa-hw-resources-oper/dpa/stats/nodes/node/hw-resources-datas/hw-resources-data      Validated Model-Driven Telemetry Sensor PathsThe following represents a list of validated sensor paths useful formonitoring the Peering Fabric and the data which can be gathered byconfiguring these sensorpaths.            \u00a0                  openconfig-bgp#bgp              openconfig-acl#acl              openconfig-lacp#lacp              openconfig-mpls#mpls              openconfig-rib-bgp#bgp-rib              openconfig-bgp#bgp/neighbors              openconfig-platform#components              openconfig-interfaces#interfaces              openconfig-if-aggregate#aggregate              *openconfig-if-aggregate#aggregate/state              openconfig-interfaces#interfaces/interface              openconfig-interfaces#interfaces/interface/state              openconfig-interfaces#interfaces/interface/state/counters              openconfig-interfaces#interfaces/interface/subinterfaces/subinterface/state/counters              *openconfig-if-ip#ipv4              *openconfig-if-ip#ipv6              Cisco-IOS-XR-bundlemgr-oper#bundles              Cisco-IOS-XR-bundlemgr-oper#bundle-information/bfd-counters              Cisco-IOS-XR-bundlemgr-oper#lacp-bundles              Cisco-IOS-XR-ethernet-lldp-oper#lldp              Cisco-IOS-XR-ethernet-lldp-oper#lldp/nodes/node/neighbors              Cisco-IOS-XR-shellutil-oper#system-time/uptime              Cisco-IOS-XR-wdsysmon-fd-oper#system-monitoring/cpu-utilization              Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface              Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface/interface-statistics              Cisco-IOS-XR-pfi-im-cmd-oper#interfaces/interface-xr/interface/interface-statistics/basic-interface-stats              Cisco-IOS-XR-controller-optics-oper#optics-oper/optics-ports/optics-port/optics-info              Cisco-IOS-XR-infra-statsd-oper#infra-statistics/interfaces/interface/latest/generic-counters              Cisco-IOS-XR-qos-ma-oper#qos/nodes/node/policy-map/interface-table/interface/input/statistics/              Cisco-IOS-XR-qos-ma-oper#qos/nodes/node/policy-map/interface-table/interface/input/statistics/class-stats/general-stats              Cisco-IOS-XR-qos-ma-oper#qos/nodes/node/policy-map/interface-table/interface/input/statistics/class-stats/queue-stats-array              Cisco-IOS-XR-clns-isis-oper#isis/instances/instance/neighbors              Cisco-IOS-XR-clns-isis-oper#isis/instances/instance/levels/interfaces              Cisco-IOS-XR-clns-isis-oper#isis/instances/instance/levels/adjacencies              Cisco-IOS-XR-ipv4-bgp-oper#bgp/instances/instance/instance-active/default-vrf/bmp              Cisco-IOS-XR-ipv4-bgp-oper/bgp/instances/instance/instance-active/default-vrf/neighbors              Cisco-IOS-XR-ipv4-bgp-oper#bgp/instances/instance/instance-active/default-vrf/process-info/vrf              Cisco-IOS-XR-ipv4-bgp-oper#bgp/instances/instance/instance-active/default-vrf/neighbors/neighbor              Cisco-IOS-XR-ipv4-bgp-oper#bgp/instances/instance/instance-active/default-vrf/process-info/global              Cisco-IOS-XR-ipv4-bgp-oper#bgp/instances/instance/instance-active/default-vrf/process-info/performance-statistics              **Cisco-IOS-XR-ipv6-bgp-oper/bgp/instances/instance/instance-active/default-vrf/neighbors              **Cisco-IOS-XR-ipv6-bgp-oper#bgp/instances/instance/instance-active/default-vrf/process-info/vrf              **Cisco-IOS-XR-ipv6-bgp-oper#bgp/instances/instance/instance-active/default-vrf/neighbors/neighbor              **Cisco-IOS-XR-ipv6-bgp-oper#bgp/instances/instance/instance-active/default-vrf/process-info/global              **Cisco-IOS-XR-ipv6-bgp-oper#bgp/instances/instance/instance-active/default-vrf/bmp              **Cisco-IOS-XR-ipv6-bgp-oper#bgp/instances/instance/instance-active/default-vrf/process-info/performance-statistics              Cisco-IOS-XR-ip-rib-ipv4-oper#rib/rib-table-ids/rib-table-id/summary-protos/summary-proto/rtype-bgp-ext              Cisco-IOS-XR-ip-rib-ipv4-oper#rib/rib-table-ids/rib-table-id/summary-protos/summary-proto/rtype-bgp-int              Cisco-IOS-XR-ip-rib-ipv4-oper#rib/rib-table-ids/rib-table-id/summary-protos/summary-proto/rtype-isis-l1              Cisco-IOS-XR-ip-rib-ipv4-oper#rib/rib-table-ids/rib-table-id/summary-protos/summary-proto/rtype-isis-l2              Cisco-IOS-XR-ip-rib-ipv4-oper#rib/rib-table-ids/rib-table-id/summary-protos/summary-proto/rtype-isis-sum              Cisco-IOS-XR-ip-rib-ipv4-oper#rib/rib-table-ids/rib-table-id/summary-protos/summary-proto/proto-route-count              Cisco-IOS-XR-ip-rib-ipv6-oper#rib/rib-table-ids/rib-table-id/summary-protos/summary-proto/rtype-bgp-ext              Cisco-IOS-XR-ip-rib-ipv6-oper#rib/rib-table-ids/rib-table-id/summary-protos/summary-proto/rtype-bgp-int              Cisco-IOS-XR-ip-rib-ipv6-oper#rib/rib-table-ids/rib-table-id/summary-protos/summary-proto/rtype-isis-l1              Cisco-IOS-XR-ip-rib-ipv6-oper#rib/rib-table-ids/rib-table-id/summary-protos/summary-proto/rtype-isis-l2              Cisco-IOS-XR-ip-rib-ipv6-oper#rib/rib-table-ids/rib-table-id/summary-protos/summary-proto/rtype-isis-sum              Cisco-IOS-XR-ip-rib-ipv6-oper#rib/rib-table-ids/rib-table-id/summary-protos/summary-proto/proto-route-count              Cisco-IOS-XR-fretta-bcm-dpa-hw-resources-oper/dpa/stats/nodes/node/hw-resources-datas/hw-resources-data              \u00a0      ", "url": "https://xrdocs.github.io/design/blogs/2018-05-08-peering-fabric-hld/", "tags": "iosxr, Peering, Design", "title": "Peering Fabric Design", "author": "Phil Bedard"}, "tutorials-2016-06-16-xr-toolbox-part-4-bring-your-own-container-lxc-app": {"content": "     Launching a Container App  Introduction  Pre-requisites  Create a container rootfs          Install lxc tools on devbox      Launch an LXC container on the devbox      Create/Install your app      Change SSH port inside your container      Shutdown and package your container        Create LXC SPEC XML File  Transfer rootfs and XML file to XR  Untar rootfs under /misc/app_host/  Use virsh to launch container  Test your app!          Set the src-hint for Application traffic      See if things work!        Check out Part 3 of the XR toolbox series# App Development Topology.IntroductionIf you haven\u2019t checked out the earlier parts to the XR toolbox Series, then you can do so here#  XR Toolbox SeriesThe purpose of this series is simple. Get users started with an IOS-XR setup on their laptop and incrementally enable them to try out the application-hosting infrastructure on IOS-XR.In this part, we explore how a user can build and deploy their own container (LXC) based applications on IOS-XR.Pre-requisitesBefore we begin, let\u2019s make sure you\u2019ve set up your development environment.If you haven\u2019t checked it out, go through the \u201cApp-Development Topology\u201d tutorial here#  XR Toolbox, Part 3# App Development TopologyFollow the instructions to get your topology up and running as shown below#If you\u2019ve reached the end of the above tutorial, you should be able to issue a vagrant status in the vagrant-xrdocs/lxc-app-topo-bootstrap directory to see a rtr (IOS-XR) and a devbox (Ubuntu/trusty) instance running.AKSHSHAR-M-K0DS#lxc-app-topo-bootstrap akshshar$ pwd/Users/akshshar/vagrant-xrdocs/lxc-app-topo-bootstrap AKSHSHAR-M-K0DS#lxc-app-topo-bootstrap akshshar$ AKSHSHAR-M-K0DS#lxc-app-topo-bootstrap akshshar$ vagrant status Current machine states#rtr                       running (virtualbox)devbox                    running (virtualbox)This environment represents multiple VMs. The VMs are all listedabove with their current state. For more information about a specificVM, run `vagrant status NAME`.AKSHSHAR-M-K0DS#lxc-app-topo-bootstrap akshshar$ All good? Perfect. Let\u2019s start building our container application tar ball.    The figure on the right illustrates the basic steps to undertake to launch an lxc container on IOS-XR 6.0+#      We will build the container rootfs tar ball on our devbox (see topology above)    The rootfs tar ball will then be transferred to IOS-XR    The rootfs will  be launched on the underlying hypervisor using the virsh command in XR shell.  Create a container rootfs  Using a custom rootfs tar ballThe technique presented here focuses on the creation of a container from scratch (using a base ubuntu template) followed by the installation of an application for first-time users.A user can easily use their own pre-built rootfs tar ball and ignore this section altogether.The only point to remember is that if you expect to use SSH access into the container after deployment to XR, then change the default SSH port in /etc/ssh/sshd_config in your rootfs to something other than 22/57722 (or any other port you expect XR to use based on your config).This is showcased in the following section below#Change SSH port inside your containerTo launch an LXC container we need two things#  A container rootfs tar ball  An XML file to launch the container using virsh/libvirtTo create them, we\u2019ll hop onto our devbox (Ubuntu/trusty) VM in the topology and install lxc-tools. lxc-tools will be used to create a container rootfs tar ball.Install lxc tools on devboxSSH into the devbox#AKSHSHAR-M-K0DS#lxc-app-topo-bootstrap akshshar$ vagrant ssh devboxWelcome to Ubuntu 14.04.4 LTS (GNU/Linux 3.13.0-87-generic x86_64) * Documentation#  https#//help.ubuntu.com/  System information as of Thu Jun 16 14#27#47 UTC 2016  System load#  0.0               Processes#           74  Usage of /#   3.5% of 39.34GB   Users logged in#     0  Memory usage# 25%               IP address for eth0# 10.0.2.15  Swap usage#   0%                IP address for eth1# 11.1.1.20  Graph this data and manage this system at#    https#//landscape.canonical.com/  Get cloud support with Ubuntu Advantage Cloud Guest#    http#//www.ubuntu.com/business/services/cloud0 packages can be updated.0 updates are security updates.Last login# Thu Jun 16 14#27#47 2016 from 10.0.2.2vagrant@vagrant-ubuntu-trusty-64#~$ Install lxc tools inside the devboxsudo apt-get updatesudo apt-get -y install lxcCheck that lxc was properly installed#vagrant@vagrant-ubuntu-trusty-64#~$ sudo lxc-start --version1.0.8vagrant@vagrant-ubuntu-trusty-64#~$ Launch an LXC container on the devboxUsing the standard ubuntu template available with lxc, let\u2019s create and start the ubuntu container inside devbox#vagrant@vagrant-ubuntu-trusty-64#~$ sudo lxc-create -t ubuntu --name xr-lxc-appChecking cache download in /var/cache/lxc/trusty/rootfs-amd64 ... Installing packages in template# ssh,vim,language-pack-enDownloading ubuntu trusty minimal ...I# Retrieving Release I# Retrieving Release.gpg I# Checking Release signatureI# Valid Release signature (key id 790BC7277767219C42C86F933B4FE6ACC0B21F32)I# Retrieving Packages ------------------------------ snip output ------------------------------------This process will take some time as the ubuntu rootfs template is downloaded for you by the lxc tools.Once the container template is installed successfully, it should show up in the lxc-ls output#vagrant@vagrant-ubuntu-trusty-64#~$ sudo lxc-ls --fancy NAME        STATE    IPV4  IPV6  AUTOSTART  ------------------------------------------xr-lxc-app  STOPPED  -     -     NO         vagrant@vagrant-ubuntu-trusty-64#~$ Now let\u2019s start the container#vagrant@vagrant-ubuntu-trusty-64#~$ sudo lxc-start --name xr-lxc-app &lt;4&gt;init# plymouth-upstart-bridge main process (5) terminated with status 1&lt;4&gt;init# plymouth-upstart-bridge main process ended, respawning&lt;4&gt;&gt;init# hwclock main process (7) terminated with status 77&lt;4&gt;&gt;init# plymouth-upstart-bridge main process (15) terminated with status 1&lt;4&gt;&gt;init# plymouth-upstart-bridge main process ended, respawning------------------------------ snip output ------------------------------------You will be taken to the login prompt.The Default credentials are#Username#  ubuntuPassword#  ubuntuUbuntu 14.04.4 LTS xr-lxc-app consolexr-lxc-app login# &lt;4&gt;init# setvtrgb main process (428) terminated with status 1&lt;4&gt;init# plymouth-upstart-bridge main process (23) killed by TERM signalUbuntu 14.04.4 LTS xr-lxc-app consolexr-lxc-app login# ubuntuPassword# Welcome to Ubuntu 14.04.4 LTS (GNU/Linux 3.13.0-87-generic x86_64) * Documentation#  https#//help.ubuntu.com/The programs included with the Ubuntu system are free software;the exact distribution terms for each program are described in theindividual files in /usr/share/doc/*/copyright.Ubuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted byapplicable law.ubuntu@xr-lxc-app#~$ Perfect! You\u2019ve launched an ubuntu container on your devbox.Create/Install your appIn this example we\u2019ll install iperf as a sample application.You may choose to skip this step if you have another app in mind.sudo password#  ubuntuubuntu@xr-lxc-app#~$ sudo apt-get -y install iperf[sudo] password for ubuntu# Reading package lists... DoneBuilding dependency tree       Reading state information... DoneThe following NEW packages will be installed#  iperf0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.Need to get 56.3 kB of archives.After this operation, 174 kB of additional disk space will be used.Get#1 http#//archive.ubuntu.com/ubuntu/ trusty/universe iperf amd64 2.0.5-3 [56.3 kB]Fetched 56.3 kB in 2s (23.5 kB/s)Selecting previously unselected package iperf.(Reading database ... 14629 files and directories currently installed.)Preparing to unpack .../iperf_2.0.5-3_amd64.deb ...Unpacking iperf (2.0.5-3) ...Setting up iperf (2.0.5-3) ...ubuntu@xr-lxc-app#~$ ubuntu@xr-lxc-app#~$ ubuntu@xr-lxc-app#~$ ubuntu@xr-lxc-app#~$ iperf -viperf version 2.0.5 (08 Jul 2010) pthreadsubuntu@xr-lxc-app#~$ Change SSH port inside your containerWhen we deploy the container to IOS-XR, we will share XR\u2019s network namespace. Since IOS-XR already uses up port 22 and port 57722 for its own purposes, we need to pick some other port for our container.Our recommendation? - Pick some port in the 58xxx range.Let\u2019s change the SSH port to 58822#ubuntu@xr-lxc-app#~$ sudo sed -i s/Port\\ 22/Port\\ 58822/ /etc/ssh/sshd_config ubuntu@xr-lxc-app#~$ Check that your port was updated successfully#ubuntu@xr-lxc-app#~$ cat /etc/ssh/sshd_config | grep PortPort 58822ubuntu@xr-lxc-app#~$ We\u2019re good!Shutdown and package your containerIssue a shutdown to escapeubuntu@xr-lxc-app#~$ sudo shutdown -h nowubuntu@xr-lxc-app#~$ Broadcast message from ubuntu@xr-lxc-app\t(/dev/lxc/console) at 19#37 ...The system is going down for halt NOW!------------------------------ snip output ------------------------------------mount# cannot mount block device /dev/sda1 read-only * Will now haltvagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ We\u2019re back on our devbox.Now hop over to the directory /var/lib/lxc/xr-lxc-app and package the rootfs into a tar ball.In the end we transfer the tar ball to the home directory (~/ or /home/vagrant)You will need to be root for this operationvagrant@vagrant-ubuntu-trusty-64#~$ sudo -s root@vagrant-ubuntu-trusty-64#~# root@vagrant-ubuntu-trusty-64#~# whoami rootroot@vagrant-ubuntu-trusty-64#~# cd /var/lib/lxc/xr-lxc-app/ root@vagrant-ubuntu-trusty-64#/var/lib/lxc/xr-lxc-app# lsconfig  fstab  rootfsroot@vagrant-ubuntu-trusty-64#/var/lib/lxc/xr-lxc-app# cd rootfs root@vagrant-ubuntu-trusty-64#/var/lib/lxc/xr-lxc-app/rootfs# root@vagrant-ubuntu-trusty-64#/var/lib/lxc/xr-lxc-app/rootfs# tar -czf xr-lxc-app-rootfs.tar.gz * tar# dev/log# socket ignoredroot@vagrant-ubuntu-trusty-64#/var/lib/lxc/xr-lxc-app/rootfs#root@vagrant-ubuntu-trusty-64#/var/lib/lxc/xr-lxc-app/rootfs#mv *.tar.gz /home/vagrantroot@vagrant-ubuntu-trusty-64#/var/lib/lxc/xr-lxc-app/rootfs#ls -l /home/vagranttotal 119984-rw-r--r-- 1 root root 122863332 Jun 16 19#41 xr-lxc-app-rootfs.tar.gzCreate LXC SPEC XML FileWe need to create an XML file that will define different parameters (cpu, mem, rootfs location etc.) for the container launch on IOS-XR (which uses libvirt).On the devbox, use your favorite editor (vi, nano, pico etc.) to create a new file called xr-lxc-app.xml under /home/vagrant of the devbox with the following content#&lt;domain type='lxc' xmlns#lxc='http#//libvirt.org/schemas/domain/lxc/1.0' &gt;&lt;name&gt;xr-lxc-app&lt;/name&gt;&lt;memory&gt;327680&lt;/memory&gt;&lt;os&gt;&lt;type&gt;exe&lt;/type&gt;&lt;init&gt;/sbin/init&lt;/init&gt;&lt;/os&gt;&lt;lxc#namespace&gt;&lt;sharenet type='netns' value='global-vrf'/&gt;&lt;/lxc#namespace&gt;&lt;vcpu&gt;1&lt;/vcpu&gt;&lt;clock offset='utc'/&gt;&lt;on_poweroff&gt;destroy&lt;/on_poweroff&gt;&lt;on_reboot&gt;restart&lt;/on_reboot&gt;&lt;on_crash&gt;destroy&lt;/on_crash&gt;&lt;devices&gt;&lt;emulator&gt;/usr/lib64/libvirt/libvirt_lxc&lt;/emulator&gt;&lt;filesystem type='mount'&gt;&lt;source dir='/misc/app_host/xr-lxc-app/'/&gt;&lt;target dir='/'/&gt;&lt;/filesystem&gt;&lt;console type='pty'/&gt;&lt;/devices&gt;&lt;/domain&gt;  A couple of configuration knobs seem interesting in the above XML file#            The netns (network namespace) setting#      `&lt;sharenet type='netns' value='global-vrf'/&gt;`;            In IOS-XR the \u2018global-vrf\u2019 network namespace houses all the XR Gig/Mgmt interfaces that are in the global/default VRF. The sharenet setting above makes sure that the container on launch will also have access to all of XR\u2019s interfaces natively              The rootfs mount volume#      `&lt;source dir='/misc/app_host/xr-lxc-app/'/&gt;`;            /misc/app_host/ in IOS-XR is a special mount volume that is designed to provide nearly 3.9G of Disk space on IOS-XRv and varying amounts on other platforms (NCS5508, ASR9k) etc. This mount volume may be used to host custom container rootfs and other large files without using up XR\u2019s disk space. In this case we expect the rootfs to be untarred in the /misc/app_host/xr-lxc-app/ directory      Your LXC app is now ready to be deployed! You should have the following two components in the home directory of the devbox#root@vagrant-ubuntu-trusty-64#~# pwd/home/vagrantroot@vagrant-ubuntu-trusty-64#~# ls -ltotal 119988-rw-r--r-- 1 root root 122863332 Jun 16 19#41 xr-lxc-app-rootfs.tar.gz-rw-r--r-- 1 root root       590 Jun 16 23#29 xr-lxc-app.xmlroot@vagrant-ubuntu-trusty-64#~# Transfer rootfs and XML file to XRWe can either use the XR Gig or Mgmt interface to transfer the files.IOS-XR runs openssh in the linux environment on port 57722.  We need to transfer the files to the /misc/app_host volume on IOS-XR.However, /misc/app_host is owned by root and root access over SSH is not allowed, for obvious security reasons.  Hence, to enable the transfer of custom files to IOS-XR, we provide a /misc/app_host/scratch directory which is owned by the app_host group. Any user transferring files over SSH to this directory must be part of the app_host group to have access.The user vagrant is already part of the app_host group.Transfer using the Gig interface#The password for the vagrant user is vagrantscp -P 57722 /home/vagrant/xr-lxc-app-rootfs.tar.gz vagrant@11.1.1.10#/misc/app_host/scratch/scp -P 57722 /home/vagrant/xr-lxc-app.xml vagrant@11.1.1.10#/misc/app_host/scratch/Where 11.1.1.10 is the directly connected Gig0/0/0/0 interface of IOS-XR instance (this config was explained in the XR Toolbox, Part 3# App Development Topology tutorial).But this process might be slow since Gig interfaces in the Vagrant IOS-XR image are rate-limited.Transfer using the Mgmt interfaceVagrant forwards the port 57722 to some host port for IOS-XR over the management port. In Virtualbox, the IP address of the host (your laptop) is always 10.0.2.2 for the NAT\u2019ed port.So determine the forwarded port for port 57722 for XR on your laptop shell (in a separate window)#AKSHSHAR-M-K0DS#lxc-app-topo-bootstrap akshshar$ vagrant port rtrThe forwarded ports for the machine are listed below. Please note thatthese values may differ from values configured in the Vagrantfile if theprovider supports automatic port collision detection and resolution.    22 (guest) =&gt; 2223 (host) 57722 (guest) =&gt; 2222 (host)AKSHSHAR-M-K0DS#lxc-app-topo-bootstrap akshshar$ Now use port 2222 to transfer the files over the management port using the host IP = 10.0.2.2 from your devboxvagrant@vagrant-ubuntu-trusty-64#~$ scp -P 2222 /home/vagrant/*.* vagrant@10.0.2.2#/misc/app_host/scratchThe authenticity of host '[10.0.2.2]#2222 ([10.0.2.2]#2222)' can't be established.ECDSA key fingerprint is db#25#e2#27#49#2a#7b#27#e1#76#a6#7a#e4#70#f5#f7.Are you sure you want to continue connecting (yes/no)? yesWarning# Permanently added '[10.0.2.2]#2222' (ECDSA) to the list of known hosts.vagrant@10.0.2.2's password# xr-lxc-app-rootfs.tar.gz                                   100%  117MB  16.7MB/s   00#07    xr-lxc-app.xml                                             100%  590     0.6KB/s   00#00    vagrant@vagrant-ubuntu-trusty-64#~$ Untar rootfs under /misc/app_host/Let\u2019s hop onto the IOS-XR instance.AKSHSHAR-M-K0DS#lxc-app-topo-bootstrap akshshar$ vagrant ssh rtrLast login# Thu Jun 16 19#45#33 2016 from 10.0.2.2xr-vm_node0_RP0_CPU0#~$ xr-vm_node0_RP0_CPU0#~$ Create a directory xr-lxc-app/(remember the source dir in the XML file?) under /misc/app_host#You need to be sudo to perform the next set of tasks.sudo mkdir /misc/app_host/xr-lxc-app/Now untar the rootfs tar-ball that we transferred to the /misc/app_host/scratch directory into the newly created /misc/app_host/xr-lxc-app/ directory.xr-vm_node0_RP0_CPU0#~$cd /misc/app_host/xr-lxc-app/ xr-vm_node0_RP0_CPU0#/misc/app_host/xr-lxc-app$ xr-vm_node0_RP0_CPU0#/misc/app_host/xr-lxc-app$sudo tar -zxf ../scratch/xr-lxc-app-rootfs.tar.gztar# dev/mpu401data# Cannot mknod# Operation not permittedtar# dev/rmidi3# Cannot mknod# Operation not permittedtar# dev/rmidi2# Cannot mknod# Operation not permittedtar# dev/smpte1# Cannot mknod# Operation not permittedtar# dev/audio1# Cannot mknod# Operation not permittedtar# dev/smpte0# Cannot mknod# Operation not permittedtar# dev/midi0# Cannot mknod# Operation not permittedtar# dev/mixer1# Cannot mknod# Operation not permittedtar# dev/smpte3# Cannot mknod# Operation not permitted--------------------------- snip output --------------------------Ignore the \u201cOperation not permitted\u201d messages when you untar. These are harmless.Use virsh to launch containerNow we use the XML file that we transferred to /misc/app_host/scratch to launch our container.libvirtd is the daemon running on IOS-XR to help launch LXC containers. The client for libvirtd (virsh) is made available in the XR linux shell to interact with the libvirtd daemon.To perform the virsh client commands, you will need to be root. In order to properly source the right environment variables for the virsh commands to connect to the libvirtd daemon, use the \u201c-i\u201d flag with \u201csudo\u201d when becoming root.Become root#xr-vm_node0_RP0_CPU0#~$ sudo -ixr-vm_node0_RP0_CPU0#~$The \u201cvagrant\u201d user is already a part of the sudoers group, so you won\u2019t be asked for the sudo password. But when you create your own users, expect the password prompt to show up.To list the current running containers#xr-vm_node0_RP0_CPU0#~$ virsh list Id    Name                           State---------------------------------------------------- 4922  sysadmin                       running 12010 default-sdr--1                 runningxr-vm_node0_RP0_CPU0#~$ Now launch the container using virsh create and the XML file we transferred earlier#xr-vm_node0_RP0_CPU0#~$ virsh create /misc/app_host/scratch/xr-lxc-app.xml Domain xr-lxc-app created from /misc/app_host/scratch/xr-lxc-app.xmlxr-vm_node0_RP0_CPU0#~$ xr-vm_node0_RP0_CPU0#~$ xr-vm_node0_RP0_CPU0#~$ virsh list  Id    Name                           State---------------------------------------------------- 4922  sysadmin                       running 7315  xr-lxc-app                     running 12010 default-sdr--1                 runningxr-vm_node0_RP0_CPU0#~$ To get into the container, you have two options#Our credentials for the container were#Username# ubuntuPassword# ubuntu      Use virsh console#      xr-vm_node0_RP0_CPU0#~$ virsh console xr-lxc-appConnected to domain xr-lxc-appEscape character is ^]init# Unable to create device# /dev/kmsg* Stopping Send an event to indicate plymouth is up                     [ OK ]* Starting Mount filesystems on boot                                    [ OK ]* Starting Signal sysvinit that the rootfs is mounted                   [ OK ]* Starting Fix-up sensitive /proc filesystem entries                    [ OK ]-------------------------------- snip output ---------------------------------  Ubuntu 14.04.4 LTS xr-lxc-app tty1xr-lxc-app login# ubuntuPassword# Last login# Thu Jun 16 19#23#10 UTC 2016 on lxc/consoleWelcome to Ubuntu 14.04.4 LTS (GNU/Linux 3.14.23-WR7.0.0.2_standard x86_64)* Documentation#  https#//help.ubuntu.com/ubuntu@xr-lxc-app#~$   ubuntu@xr-lxc-app#~$ ubuntu@xr-lxc-app#~$         To get out of the container console, issue  Ctrl+]        Use SSH to get into the container#    We set the SSH port to 58822 earlier, we can use any of XR\u2019s interface addresses to log in#      xr-vm_node0_RP0_CPU0#~$ ssh -p 58822 ubuntu@11.1.1.10Warning# Permanently added '[11.1.1.10]#58822' (ECDSA) to the list of known hosts.ubuntu@11.1.1.10's password# Welcome to Ubuntu 14.04.4 LTS (GNU/Linux 3.14.23-WR7.0.0.2_standard x86_64)* Documentation#  https#//help.ubuntu.com/Last login# Fri Jun 17 16#42#13 2016ubuntu@xr-lxc-app#~$                  If you\u2019d like to be able to access the container directly from your laptop, then make sure youforward the intended port (in this case 58822) to your laptop (any port of your choice), in theVagrantfile#      node.vm.network ~forwarded_port~, guest# 58822, host# 58822            With the above setting in the Vagrantfile, you can ssh to the container directly from your laptop using#      ssh -p 58822 vagrant@localhost            Perfect! Our container is up and running!Test your app!Now that we have our container up and running, let\u2019s see how we run our app (iperf in our case).Think of the LXC container as your own linux server on the router. Because we share the network namespace between the LXC and XR, all of XR's interfaces (Gig, Mgmt etc.) are available to bind to and run your applications. We can see this by issuing an ifconfig inside the running container#xr-vm_node0_RP0_CPU0#~$ssh -p 58822 ubuntu@11.1.1.10 Warning# Permanently added '[11.1.1.10]#58822' (ECDSA) to the list of known hosts.ubuntu@11.1.1.10's password# Welcome to Ubuntu 14.04.4 LTS (GNU/Linux 3.14.23-WR7.0.0.2_standard x86_64) * Documentation#  https#//help.ubuntu.com/Last login# Fri Jun 17 16#42#13 2016ubuntu@xr-lxc-app#~$ ubuntu@xr-lxc-app#~$ ubuntu@xr-lxc-app#~$ ubuntu@xr-lxc-app#~$ ifconfig Gi0_0_0_0 Link encap#Ethernet  HWaddr 08#00#27#17#f9#a8            inet addr#11.1.1.10  Mask#255.255.255.0          inet6 addr# fe80##a00#27ff#fe17#f9a8/64 Scope#Link          UP RUNNING NOARP MULTICAST  MTU#1514  Metric#1          RX packets#0 errors#0 dropped#0 overruns#0 frame#0          TX packets#1 errors#0 dropped#3 overruns#0 carrier#1          collisions#0 txqueuelen#1000           RX bytes#0 (0.0 B)  TX bytes#42 (42.0 B)Mg0_RP0_CPU0_0 Link encap#Ethernet  HWaddr 08#00#27#13#ad#eb           inet addr#10.0.2.15  Mask#255.255.255.0          inet6 addr# fe80##a00#27ff#fe13#adeb/64 Scope#Link          UP RUNNING NOARP MULTICAST  MTU#1514  Metric#1          RX packets#89658 errors#0 dropped#0 overruns#0 frame#0          TX packets#34130 errors#0 dropped#0 overruns#0 carrier#1          collisions#0 txqueuelen#1000           RX bytes#127933763 (127.9 MB)  TX bytes#2135907 (2.1 MB)------------------------------- snip output -----------------------------------Set the src-hint for Application trafficBy default, your XR Vagrant box is set up to talk to the internet using a default route through your management port.If you want the router to use XR\u2019s routing table and talk to other nodes in the topology, then you need to set the \u201ctpa address\u201d in XR\u2019s configuration. This becomes the \u201csrc-hint\u201d for all linux application traffic. The reason we use something like \u201cloopback 0\u201d is to make sure that the IP for any originating traffic for applications on the router is a reachable IP address across your topology.AKSHSHAR-M-K0DS#lxc-app-topo-bootstrap akshshar$ vagrant port rtr | grep 22     22 (guest) =&gt; 2223 (host) 57722 (guest) =&gt; 2222 (host)AKSHSHAR-M-K0DS#lxc-app-topo-bootstrap akshshar$ AKSHSHAR-M-K0DS#lxc-app-topo-bootstrap akshshar$ AKSHSHAR-M-K0DS#lxc-app-topo-bootstrap akshshar$ ssh -p 2223 vagrant@localhost vagrant@localhost's password# RP/0/RP0/CPU0#ios#RP/0/RP0/CPU0#ios#conf tFri Jun 17 17#34#45.707 UTCRP/0/RP0/CPU0#ios(config)#int loopback 0RP/0/RP0/CPU0#ios(config-if)#ip address 1.1.1.1/32RP/0/RP0/CPU0#ios(config-if)#exit         RP/0/RP0/CPU0#ios(config)#tpa address-family ipv4 update-source loopback 0RP/0/RP0/CPU0#ios(config)#commitFri Jun 17 17#35#19.815 UTCRP/0/RP0/CPU0#ios(config)#RP/0/RP0/CPU0#ios(config)#exitRP/0/RP0/CPU0#ios#Let\u2019s say we\u2019ve set up the TPA address as shown above, you should see the following route in XR\u2019s linux shell#RP/0/RP0/CPU0#ios#bashFri Jun 17 17#39#37.771 UTC[xr-vm_node0_RP0_CPU0#~]$[xr-vm_node0_RP0_CPU0#~]$ip routedefault dev fwdintf  scope link  src 1.1.1.1 10.0.2.0/24 dev Mg0_RP0_CPU0_0  proto kernel  scope link  src 10.0.2.15 [xr-vm_node0_RP0_CPU0#~]$So all you\u2019ve really done using the tpa address-family...  config is to set src address for all application traffic to XR\u2019s loopback0 address.The advantage of this approach is that when you use larger topologies that may include routing protocols like OSPF,BGP or even static routes, all you have to do is make loopback0 reachable and the application will be able to communicate across the entire topology. Also, this significantly reduces the routing table size in the linux environment as you can see in the output above.See if things work!We\u2019re going to use an iperf-server inside our container on XR and an iperf-client running on devbox. You could reverse the client-server setup if you want.Start the iperf server inside the Container on XR#xr-vm_node0_RP0_CPU0#~$ ssh -p 58822 ubuntu@11.1.1.10 ubuntu@11.1.1.10's password# Welcome to Ubuntu 14.04.4 LTS (GNU/Linux 3.14.23-WR7.0.0.2_standard x86_64) * Documentation#  https#//help.ubuntu.com/Last login# Fri Jun 17 18#09#50 2016 from 11.1.1.10ubuntu@xr-lxc-app#~$ ubuntu@xr-lxc-app#~$ iperf -s -u ------------------------------------------------------------Server listening on UDP port 5001Receiving 1470 byte datagramsUDP buffer size# 64.0 MByte (default)------------------------------------------------------------Keep the iperf server (started above) running, as you proceed to initiate the iperf client on the devbox.Let\u2019s make sure XR\u2019s loopback0 is reachable from the devbox (since we\u2019re not running routing protocols in this topology, this isn\u2019t automatic)#AKSHSHAR-M-K0DS#lxc-app-topo-bootstrap akshshar$ vagrant ssh devboxWelcome to Ubuntu 14.04.4 LTS (GNU/Linux 3.13.0-87-generic x86_64) * Documentation#  https#//help.ubuntu.com/---------------------------- snip output -------------------------------vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ sudo ip route add 1.1.1.1/32 via 11.1.1.10 vagrant@vagrant-ubuntu-trusty-64#~$ vagrant@vagrant-ubuntu-trusty-64#~$ ping 1.1.1.1PING 1.1.1.1 (1.1.1.1) 56(84) bytes of data.64 bytes from 1.1.1.1# icmp_seq=1 ttl=255 time=6.53 ms64 bytes from 1.1.1.1# icmp_seq=2 ttl=255 time=1.77 msInstall iperf on devbox and start the iperf client there (to point to XR loopback=1.1.1.1)#vagrant@vagrant-ubuntu-trusty-64#~$ sudo apt-get install iperfReading package lists... DoneBuilding dependency tree       Reading state information... DoneThe following NEW packages will be installed#  iperf---------------------------- snip output -------------------------------vagrant@vagrant-ubuntu-trusty-64#~$ iperf -u -c 1.1.1.1 ------------------------------------------------------------Client connecting to 1.1.1.1, UDP port 5001Sending 1470 byte datagramsUDP buffer size#  208 KByte (default)------------------------------------------------------------[  3] local 11.1.1.20 port 54284 connected with 1.1.1.1 port 5001[ ID] Interval       Transfer     Bandwidth[  3]  0.0-10.0 sec  1.25 MBytes  1.05 Mbits/sec[  3] Sent 893 datagrams[  3] Server Report#[  3]  0.0-10.0 sec  1.25 MBytes  1.05 Mbits/sec   0.275 ms    0/  893 (0%)vagrant@vagrant-ubuntu-trusty-64#~$ There you have it! iperf running inside an Ubuntu Container on IOS-XR. Too many steps to look up? In our next tutorial, we look at automating all of the  steps needed to bring up a container using an Ansible Playbook# IOS-XR# Ansible based LXC deployment", "url": "https://xrdocs.github.io/application-hosting/tutorials/2016-06-16-xr-toolbox-part-4-bring-your-own-container-lxc-app/", "tags": "vagrant, iosxr, cisco, linux, lxc, containers, xr toolbox", "title": "XR toolbox, Part 4: Bring your own Container (LXC) App", "author": "Akshat Sharma"}, "tutorials-2018-03-01-everything-you-need-to-know-about-pipeline": {"content": "     Everything you need to know about Pipeline  A typical basic analytics platform architecture  Pipeline# a brief overview  Pipeline# how to start  Pipeline# metrics.json  Pipeline# internal monitoring  Pipeline# TCP Dial-OUT  Pipeline# UDP Dial-OUT  gRPC# things to know about  Pipeline# gRPC Dial-OUT (no TLS)  Pipeline# gRPC Dial-OUT (TLS)  Pipeline# gRPC Dial-IN (no TLS)  Pipeline# gRPC Dial-IN (TLS)  Pipeline# out to \u201cdump.txt\u201d  Pipeline# out to InfluxDB  Pipeline# out to Prometheus  Pipeline# out to Kafka  So many ways\u2026 what is the best one?  Conclusion  We\u2019ve delivered several great tutorials and blogs about Pipeline and modes of its operations during last year. Hopefully, that gave enough information for your good first impression about that collector! IOS XR Telemetry got new protocols and features recently. Plus, we still get different questions about the end-to-end process of using Pipeline and consuming Telemetry. So, it might be helpful to create a more detailed explanation of the whole process. The goal of this tutorial is to remind you the architecture to consume Telemetry streams from routers and give a detailed explanation of how to use Pipeline in different modes. This document will be long, by intention. The purpose is to have everything in a single place. You will be able to quickly jump to the section, you are interested in. If you think you need to remember the basics of how to configure Model Driven Telemetry on IOS XR routers, have a look at our previous post.A typical basic analytics platform architectureOne of the popular first questions we are still receiving is whether it is possible to re-use the existing SNMP collector to consume and process Streaming Telemetry. The short answer is \u201cNo\u201d. The long answer is that Telemetry is not just much faster comparing to SNMP, but it also has a different format and, hence, processing of that data is different. When it comes to Telemetry consumption, one might think about this high-level architecture#  Collection layer#  the first stop for the data streamed out of the router. The main goal is to collect all the streams and transform them from GPB/JSON into a format that will be supported by the layer above. Filtering might also be configured here.  Storage layer# usually a TSDB (time-series database). The goal is to take the data from the \u201cCollection layer\u201d and store it together with timestamps. You can also have other types of databases here (think of telemetry as a big data solution).  Application layer# this is where you apply your business logic tools for the data stored in the storage layer.You should have a solid picture of the basic three-layer architecture by now. A question might come about mapping this architecture to a real solution.This is an open-source based end-to-end solution for IOS-XR Model Driven Telemetry consumption#All elements in the solution can be downloaded from Github (well, except routers!). Pipeline represents the \u201cCollection layer\u201d. InfluxDB and Prometheus represent the \u201cStorage layer\u201d, or the place to store your data. Grafana is an example of the \u201cApplication layer\u201d. As of today, Grafana is a very popular visualization tool, that can be used for monitoring and alerting. Pipeline can also stream data into Kafka bus. You can connect your own databases to consume data from Kafka bus.Pipeline is the main topic of this tutorial. Storage and Application layers will be explained in  details in the following tutorials.Pipeline# a brief overviewPipeline is a well-written Golang\u2013based code which consumes IOS XR telemetry streams directly from routers or indirectly from a pub/sub bus (Kafka). Once collected, Pipeline performs transformations of the data and forwards the result to the configured consumer.Pipeline supports different input transport formats from routers (please be aware that multiple input modules of any type can run in parallel)#  TCP  gRPC  UDP  Apache KafkaPipeline can support different encodings as well#  (compact) GPB  KV-GPB  JSONPipeline can stream data to several different consumers. Supported downstream consumers include#  InfluxDB (TSDB)  Prometheus (TSDB)  Apache Kafka  dump-to-file (mostly for diagnostics purposes)Pipeline# how to startThere are two ways to install Pipeline on your Linux server#  Clone or download from Github  Install as a Docker container\u201cPipeline.conf\u201d contains everything you need to configure your collector. It contains several input sections (where you can define how you want the collector to interact with routers) and different output sections (to define where you want to send the processed data).\u201cMetrics.json\u201d is the place where you need to define what you want to insert into your TSDB (InfluxDB, Prometheus).pipeline is the binary for the Pipeline collector and can be found in \u201cbigmuddy-network-telemetry-pipeline/bin\u201d directory.To make Pipeline running, one must start the binary file. There are several ways to do it#  The simplest way is just to start the binary as is. To do this, you need to go to the \u201cbigmuddy-network-telemetry-pipeline\u201d directory and send this command  \u201c./bin/pipeline\u201d. After you start Pipeline, the system will check for the \u201cpipeline.conf\u201d file in the current directory (hence, to start Pipeline from the \u201c/bin\u201d directory, you will need to copy the \u201cpipeline.conf\u201d file there. So, probably it is easier to start just from the main directory)  There is an alternative way to start pipeline with another (your own) version of the \u201dpipeline.conf\u201d configuration file. As an example, you want to quickly check your new Pipeline configuration, but don\u2019t want to update the current working config. You can just create a copy of \u201cpipeline.conf\u201d, make all the needed changes and then run your Pipeline specifying that file, using this command# ./bin/pipeline -config=~pipeline_test.conf~  A very good option when you want to see internal logging messages is to start this way# ./bin/pipeline -log= --debug.Option 3 is very helpful for tests, when you want to check how routers connect to the Pipeline (or Pipeline connects to the routers) or when something goes wrong, you can check logging messages, as it will accelerate your troubleshooting activity. When you\u2019re ready to move to a scaled environment, it is better to simplify Pipeline operations as much as possible and start it using option 1 or 2.Pipeline# metrics.jsonIOS XR Model Driven Telemetry is based on YANG models, that\u2019s why telemetry data pushed from a router is also hierarchical. Time-series databases (InfluxDB, Prometheus, etc) typically expect data in a simple, flat format.Pipeline takes the hierarchical YANG-based data and transforms it into a flat format for TSDBs consumption. To perform this transformation, Pipeline uses the \u201cmetrics.json\u201d file. The \u201cmetrics.json\u201d file is a series of JSON objects, one for each configured sensor path. Each object follows corresponding YANG model and you can specify fields (counters) you want to be added.An example of the \u201cmetrics.json\u201d file can be found in the GitHub repo. It contains these models already#  Interface stats (generic-counters).  MPLS-TE tunnels auto-bandwidth.  QoS output stats.  Processes memory info.  RAM/free/system memory info.  CPU utilization.Creation of the content of the \u201cmetrics.json\u201d file might seem difficult initially, but as soon as you start working with it, you will see the logic behind. The header always stays in the same format, you just update your sensor path. Finally, you follow the YANG model and select fields you\u2019re interested in (respecting the hierarchy of the model). As an example, let\u2019s see how a single hop IPv4 BFD YANG model will look like after translation into a \u201cmetrics.json\u201d object. Here is the YANG model and the specific path we are interested in#vosipchu$ pyang -f tree Cisco-IOS-XR-ip-bfd-oper.yang --tree-path bfd/ipv4-single-hop-summarymodule# Cisco-IOS-XR-ip-bfd-oper   +--ro bfd      +--ro ipv4-single-hop-summary         +--ro session-state            +--ro total-count?      uint32            +--ro down-count?       uint32            +--ro up-count?         uint32            +--ro unknown-count?    uint32And this is how you can build the content in the \u201cmetrics.json\u201d file#{\t~basepath~ # ~Cisco-IOS-XR-ip-bfd-oper#bfd/ipv4-single-hop-summary~,\t~spec~ # {\t\t~fields~ # [\t\t\t{~name~#~session-state~,\t\t\t\t~fields~ # [\t\t\t\t\t{~name~#~down-count~},\t\t\t\t\t{~name~#~total-count~},\t\t\t\t\t{~name~#~unknown-count~},\t\t\t\t\t{~name~#~up-count~}\t\t\t\t]\t\t\t}\t\t]\t}},In one of our next tutorials we will share the \u201cmetrics.json\u201d file containing JSON objects for many popular sensor paths, together with use cases for your convenience and faster Telemetry adoption!Pipeline# internal monitoringPipeline comes already with a basic configuration that accepts TCP-based telemetry on port 5432 and the processed data is dumped into a file in the JSON format. (we will go through all configurations later in this tutorial). Above that, exporting of internal state for Pipeline monitoring is active as well. You don\u2019t need to configure anything in addition to this, but this works with Prometheus time series database. It doesn\u2019t mean you have to use just Prometheus for all other sensor paths, but you should have it running. You can also use a script from the Pipeline GitHub repo to start Prometheus for monitoring.Here is a snapshot from Pipeline under load (not all monitored parameters are shown below)#If, for some reason, internal monitoring is disabled, you need to make sure you have these 2 lines under [default] section of the \u201cPipeline.conf\u201d file (you can find it at the beginning of the file)#metamonitoring_prometheus_resource = /metricsmetamonitoring_prometheus_server = 10.1.1.1#8989  ## put the IP address and port of your Prometheus serverPipeline# TCP Dial-OUTAs it was mentioned earlier, Pipeline has several input methods. Let\u2019s start with TCP Dial-OUT mode configuration. This is the case, where you use TCP as the transport protocol for your streaming telemetry data delivery. And this mode is enabled by default!To make sure that Pipeline accepts and processes telemetry data, you need to make sure that configuration on your router corresponds to the configuration on Pipeline.Here is the configuration to be done for TCP Dial-OUT mode#As you can see, the configuration is pretty simple. You can use IPv6 or IPv4 destination address, Pipeline works fine with both. A major requirement for TCP is to have a two-way connectivity, as TCP is a connection-oriented protocol. You need to make sure that destination port on your router is equal to the listen port at Pipeline. If you have several IP addresses / NICs on your server, Pipeline will listen to the specified port on each interface. You can also add IP address in the Pipeline configuration if you want to be specific. The format for IPv4 address is#listen = ipv4_address#portThe format for IPv6 address is#listen = [ipv6_address]#portAs of today, IOS XR supports several encoding protocols#  Compact GPB  Key-Value GPB  JSONYou can proceed with any encoding you like, but from Pipeline side configuration will always stay as#encap = stThis small feature should make your life a bit easier!If you have everything configured correctly, the two-way connectivity is up and you run Pipeline in debug mode, you should get a similar message in stdout#INFO[2017-11-15 14#07#41.898128] TCP server accepted connection                encap=st keepalive=0s local=~[2600##100]#5432~ name=testbed remote=~[2222#beaf#13##3]#55137~ tag=pipelineThis is everything you need to know to have TCP Dial-OUT mode up and running!Pipeline# UDP Dial-OUTUDP Dial-OUT support in IOS XR Model Driven Telemetry was added in IOS XR 6.2.x release and could be a good option to do quick tests with Streaming Telemetry. UDP is a connectionless protocol, so, you need to have just a one-way connection to your collector. The lack of feedback from Pipeline back to your routers and unreliable delivery of packets are two major concerns against using Streaming Telemetry over UDP in your production environment.UDP Dial-OUT mode configuration is similar to TCP Dial-OUT mode. Here is the configuration for UDP Dial-OUT mode#As with TCP Dial-OUT, you can use IPv6 or IPv4 addresses to reach to Pipeline. You can use any available encoding protocol on the router (GPB, KVGPB or JSON), encoding configuration in Pipeline will stay the same (\u201cencap = st\u201d)There is no messaging expected in stdout from Pipeline, as there is no connection establishment with UDP.This is everything you need to know to have UDP Dial-OUT mode up and running!gRPC# things to know aboutBefore going forward with other input modes, let\u2019s make a short stop to talk about gRPC. gRPC is the most popular transport protocol across installations of our customers. The reason is that it is based on HTTP/2 and has a number of benefits#  Dial-IN and Dial-OUT support  Binary mode  Encryption support  Windowing mechanism at the application layer (speed negotiations between the collector and the router)To have gRPC running, you need to have a two-way connectivity between the router and your collector. That sounds reasonable, but you should always remember that gRPC code in IOS XR routers runs as a third-party application (to learn more about application hosting in IOS XR, have a look here) in Linux (hence, that is why there is no gRPC support on 32-bit QNX-based XR!). So, it means that you need to check your connectivity exactly from there!Here are the steps you need to follow to check the connectivity#  In CLI exec mode type \u201cbash\u201d (this will move you to gRPC application)  From there check the routing table with \u201cip route show\u201d Linux command  If there is no route to your destination, you have to add it. Otherwise, try to ping (and hope to get your echo replies!)Here is an example of the steps above#RP/0/RP0/CPU0#NCS5502_bottom#bashWed Feb 21 09#06#47.963 PST[NCS5502_bottom#~]$ ip route showdefault dev fwdintf  scope link  src 172.16.0.310.30.110.32/27 dev Mg0_RP0_CPU0_0  proto kernel  scope link  src 10.30.110.43 [NCS5502_bottom#~]$ ping 10.30.110.38PING 10.30.110.38 (10.30.110.38) 56(84) bytes of data.64 bytes from 10.30.110.38# icmp_seq=1 ttl=64 time=0.751 ms64 bytes from 10.30.110.38# icmp_seq=2 ttl=64 time=0.962 ms^CBefore moving into the explanation how to fix situations with no proper route to your collector, let\u2019s have a look at the routing table output above. That output should be very similar to what you will see after enabling MDT with gRPC.The default route (in blue color) is used for all Telemetry traffic going out through data plane ports. It will be created automatically as soon as you have the first Loopback configured on your router (and it will be not, if you don\u2019t yet have loopbacks!). The route shown in magenta color represents all the traffic flowing through management port, and it is also created automatically for you.Let\u2019s think about two possible scenarios where you might need to make changes to the routing table. The first one is when you have your collector behind the data port, but not reachable via the selected loopback interface. Yet another situation is when you have the collector within your management network, but there is no route to that destination (you have the directly connected network only through the management port and the default route is through data ports). In both cases you will need to update the TPA routing table. The best way to achieve that is to configure the needed source interface under TPA configuration in IOS XR. Here is an example of changing the default route through the management port#tpa vrf default  address-family ipv4   update-source MgmtEth0/RP0/CPU0/0  ! !!And the result of the change is#RP/0/RP0/CPU0#NCS5502_bottom#bashWed Feb 21 11#37#13.271 PST [NCS5502_bottom#~]$ ip route showdefault dev fwdintf  scope link  src 10.30.110.4310.30.110.32/27 dev Mg0_RP0_CPU0_0  proto kernel  scope link  src 10.30.110.43 As you can see, the default route was updated with the IP address of the management port. You can read a bit more about gRPC tricks in our previous post. Worth to mention, you\u2019re working with Linux here and can add a route using Linux commands#route add \u2013net ip_address netmask mask gw your_gw_addressBut in that case, it will be available untill the first reboot (and then you need to configure it again, or automate this process).Everything described in that section is important for both, Dial-IN and Dial-OUT mode. Two-way connectivity means that the router should be able to reach to the collector and, vice versa, your collector will need to have the path to the router.Pipeline# gRPC Dial-OUT (no TLS)The most common mode for Telemetry today is gRPC Dial-OUT without encryption (no TLS option). This option was explained before, so let\u2019s just quickly recap the configuration and point out a couple of updates from the previous version.Here is the configuration to be done for gRPC Dial-OUT (no TLS) mode#There are several moments that need more attention. When you configure \u201cself-describing-gpb\u201d (Key-Value GPB) or \u201cgpb\u201d (Compact GPB) on your router, you always configure \u201cencap = gpb\u201d in the \u201cpipeline.conf\u201d file. If you want to use JSON encoding, you will have to have this line in \u201cpipeline.conf\u201d file#\u201cencap = json\u201dEverything else follows the same logic as in the previous mode. Just be sure to check that you have TLS disabled on your router, as well as in Pipeline.If you have everything configured correctly, the two-way connectivity is up and you run Pipeline in debug mode, you should get a similar message in stdout#INFO[2017-11-15 14#20#26.098695] gRPC# Receiving dialout stream           encap=json name=grpcdialout peer=~[2500##3]#59206~ server=[2600##100]#57500 tag=pipeline type=~pipeline is SERVER~This is everything you need to know to have gRPC Dial-OUT (no TLS) mode up and running!Pipeline# gRPC Dial-OUT (TLS)gRPC has SSL/TLS integration and promotes the use of SSL/TLS to authenticate the server and to encrypt all the data exchanged between the client and the server. It is something similar to SNMPv3 (added security).In Dial-OUT mode, the router is the \u201cclient\u201d and Pipeline is the \u201cserver.\u201d Therefore, in the TLS handshake, Pipeline will need to send a certificate to authenticate itself to the router. The router validates Pipeline\u2019s certificate using the public certificate of the Root Certificate Authority (CA) that signed it and then generates session keys to encrypt the session.Running in this mode requires you to have certificates and have your infra ready. But if you want just to try this mode on, there are two ways available for you#  Follow the steps from this tutorial, or  Follow the steps in this document. Start with downloading an archive with three files from hereAfter you downloaded the archive and extracted files from it, follow these steps#  Put the \u201cdialout.pem\u201d and \u201cdialout.key\u201d files in any folder you like on the server running Pipeline. Remember the path (it will be used later in the \u201cpipeline.conf\u201d file)  Put the \u201cca-chain.cert.pem\u201d file on your router to this directory# \u201c/misc/config/grpc/dialout\u201d folder (use \u201crun\u201d from CLI exec mode to get into Linux and then standard SCP command).  Change the name of the \u201cca-chain.cert.pem\u201d file from step two to \u201cdialout.pem\u201d.After going through all the steps above, make sure you have proper configurations on your router and Pipeline (destination, encoding, and type stay the same as in gRPC Dial-OUT no TLS mode)#You need to specify the full path to your \u201cdialout.pem\u201d and \u201cdialout.key\u201d files, located on the server. That is how Pipeline will know where to find the needed certificates.If you followed the steps, you should see a similar output from Pipeline running in debug mode#INFO[2017-11-17 20#45#54.732520] gRPC# Receiving dialout stream  encap=gpb name=grpcdialout peer=~10.30.110.43#59914~ server=10.30.110.38#57500 tag=pipeline type=~pipeline is SERVER~And here is an indication of the successful connection from the router#The most common issue for gRPC Dial-OUT with TLS mode is a bad certificate. You will see a similar message from Pipeline if that happens#2017/11/17 15#51#20 grpc# Server.Serve failed to complete security handshake from ~10.30.110.43#58954~# remote error# tls# bad certificateThis is everything you need to know to have gRPC Dial-OUT (TLS) mode up and running!Pipeline# gRPC Dial-IN (no TLS)gRPC provides a possibility for a collector to dial-in to a router and to request Telemetry data to be streamed out. This mode could be convenient for you if you want to have a centralized way of making configurations in your network and requesting operational data.There are several changes needed on the router side to support Dial-IN mode.First, you need to make sure that there is a port opened for a gRPC session#grpc port 57500                address-family ipv6     ## this is only needed if you plan to use IPv6The port number specified under gRPC configuration should be equal to the port configured at your collector (Pipeline). Our example is based on IPv6, so, it has to be specified under gRPC configuration as well (skip that line for IPv4 case).When Pipeline connects to a router, it needs to be authenticated. In other words, Pipeline needs to provide a login/password pair that has proper rights within a router. There are a good overview and description about Pipeline authentication in our previous tutorial. To make things simpler and faster, let\u2019s just create a login/password pair and add \u201croot-lr\u201d group#username  group root-lr group cisco-support secret 5 $1$uuqh$Pl5K1G.aaZUtPlV4LouAk/After you committed mentioned configurations, rest of Telemetry configuration is similar to other cases#telemetry model-driven sensor-group health  sensor-path Cisco-IOS-XR-shellutil-oper#system-time/uptime ! subscription health  sensor-group-id health sample-interval 5000As you can see, there is no \u201cDestination Group\u201d part needed. That is correct and expected for Dial-IN mode, as encoding and subscription to use will come within the gRPC call. Here is how the Pipeline configuration for Dial-IN (no-TLS) with KV-GPB encoding mode looks like#[grpc_in_mymdtrouter]stage = xport_inputtype = grpc      \t\t\t## transport is gRPCencoding = gpbkv  \t\t\t## Key-Value GPB encodingencap = gpb\t\t\t\t## use \u201cgpb\u201d for both, compact and key-value GPBserver = [2500##3]#57500   \t\t## IP address and port of the routersubscriptions = health     \t\t## specify the subscription to be used (it has to be configured)tls = false        \t\t\t## no TLSThere are a couple of things worth your attention#  Transport is always \u201cgrpc\u201d (the only protocol that supports Dial-IN).  The port number should be identical to the port number configured on your router. (For IPv4 addresses you don\u2019t need to include square brackets, just type# \u201cserver = IP_address#port\u201d)  You can specify several subscriptions, separate them with comma, e.g. \u201csubscriptions = health1,health2,health2\u201dYou can have different encodings for Dial-IN mode# GPB, KV-GPB and JSON. Here is how you need to configure Pipeline for different encodings in Dial-IN mode#  GPB encoding# \u201cencap = gpb\u201d and \u201cencoding = gpbcompact\u201d  KV-GPB encoding# \u201cencap = gpb\u201d and \u201cencoding = gpbkv\u201d  JSON encoding# \u201cencap = json\u201d and \u201cencoding = json\u201dYour next step is to start Pipeline. After you start it, you will be asked to enter the login/password pair for the router (the same as defined on your router)#$ bin/pipeline -config pipeline.conf Startup pipeline Load config from [pipeline.conf], logging in [pipeline.log] CRYPT Client [grpc_in_mymdtrouter], [[2500##3]#57500] Enter username# cisco Enter password#Wait for ^C to shutdownIf you don\u2019t want to have this step (with manual typing), you can store the login/password pair in the \u201cpipeline.conf\u201d file, but you won\u2019t be able to have passwords stored in clear text. There is a way how to encrypt passwords in the \u201cpipeline.conf\u201d file, the full description is here.If the gRPC call was successful you will see a similar output on the screen (Pipeline should be in debug mode)#INFO[2017-11-15 16#51#09.093983] gRPC#    Connected codec=gpb encap=gpb encodingRequest=gpbkv name=~grpc_in_mymdtrouter~ server=[2500##3]#57500 subscriptions=[health] tag=pipeline type=~pipeline is CLIENT~ username=ciscoAnd you also can additionally check the state on the router#This is everything you need to know to have gRPC Dial-IN (no TLS) mode up and running!Pipeline# gRPC Dial-IN (TLS)In Dial-IN mode, Pipeline acts as the \u201cclient\u201d in the TLS handshake. Therefore, the router will need to send a certificate to authenticate itself to Pipeline.As with the previous mode, you need to configure a gRPC port on the router, but this time you need to add \u201ctls\u201d support#grpc port 57500     tls   After you commit this gRPC with TLS configuration, the router will generate a self-signed certificate that you need to copy to the server running Pipeline#RP/0/RP0/CPU0#NCS5502_bottom#runFri Nov 17 20#54#21.285 PST[xr-vm_node0_RP0_CPU0#~]$cd /misc/config/grpc[xr-vm_node0_RP0_CPU0#/misc/config/grpc]$lsdialout  ems.key  ems.pem   ## copy ems.pem to the server with PipelineTo copy, you can use a standard SCP command from Linux#[xr-vm_node0_RP0_CPU0#/misc/config/grpc]$scp ems.pem your_username@pipeline_server#/some/remote/directoryRest of the configuration stays the same as in previous gRPC dial-IN no TLS mode.Here is how the Pipeline configuration looks like#[grpc_in_mymdtrouter]stage = xport_inputtype = grpc      \t\t\tencoding = gpbkv  \tencap = gpb\t\tserver = 10.30.110.43#57500\t\tsubscriptions = health     \t\ttls = true \t\t\t\t\t## TLS is enabledtls_pem = /somepath/ems.pem\t \t\t## specify the path to the ems.pem certificatetls_servername = ems.cisco.com\t\t\t## specify the nameThis example is based on IPv4 configuration, just to show the difference with previous scenarios. Configuration stays as with gRPC Dial-IN (no TLS) mode, but this time you need to activate TLS mode and define the path for the certificate.After you start Pipeline and enter the login/password pair, you will see similar logging messages#INFO[2017-11-17 21#11#42.987607] setup authentication                          authenticator=~10.30.110.43#57500~ name=grpcdialout pem= tag=pipeline username=ciscoDEBU[2017-11-17 21#11#42.987942] Conductor watching for shutdown...            config=pipeline.conf debug=true logfile= tag=pipelineINFO[2017-11-17 21#11#42.988039] gRPC starting block                           encap=gpb encodingRequest=gpbkv name=grpcdialout server=10.30.110.43#57500 subscriptions=[health] tag=pipeline type=~pipeline is CLIENT~ username=ciscoINFO[2017-11-17 21#11#42.988976] gRPC# Connected                               codec=gpb encap=gpb encodingRequest=gpbkv name=grpcdialout server=10.30.110.43#57500 subscriptions=[health] tag=pipeline type=~pipeline is CLIENT~ username=ciscoINFO[2017-11-17 21#11#43.024879] gRPC# Subscription handler running            encap=gpb encodingRequest=gpbkv name=grpcdialout reqID=7821695275122717908 server=10.30.110.43#57500 subscription=health subscriptions=[health] tag=pipeline type=~pipeline is CLIENT~ username=ciscoAnd you can additionally check the state on the router#This is everything you need to know to have gRPC Dial-IN (TLS) mode up and running!This section concludes information about input modules. Let\u2019s talk now about output modules you can have in Pipeline.Pipeline# out to \u201cdump.txt\u201dThere are several ways how you can configure the data to be pushed out of Pipeline. When you just start exploring Pipeline, dumping to a file might be the best option to start with. You will be able to see the content of the data your router is streaming out and it will be easier for you to move on with a TSDB.Dumping to a file is active by default when you download Pipeline. In that mode every Telemetry packet is transformed by Pipeline and written to the \u201cdump.txt\u201d file. This file needs to be created (manually) before any information will be written there. Here is the Pipeline configuration for the mode#[inspector]stage = xport_outputtype = tap              file = /home/pipeline/bin/dump.txt     \t\t## the full path to the file is neededencoding = json          \t\t           ## countonly = false             As you can see, the configuration is simple. There are several important comments about this mode#  You need to specify the full path to the \u201cdump.txt\u201d file and this file needs to be created before Pipeline is started. Otherwise, you won\u2019t see anything.  There is an option to disable telemetry data transformation, while still keeping the connection with the router in UP mode and just count the number of Telemetry packets coming in. That mode is useful when you want to test Telemetry speed and don\u2019t want to troubleshoot slow processing on the server running Pipeline. To enable this mode, change \u201ccountonly = false\u201d to \u201ccountonly = true\u201d.Here is an example of a successful record in the \u201cdump.txt\u201d file from the syslog sensor path#Summary# GPB(common) Message [10.30.110.41#60914(NCS5501_top)/Cisco-IOS-XR-infra-syslog-oper#syslog/messages/message msg len# 2214]{    ~Source~# ~10.30.110.41#60914~,    ~Telemetry~# {        ~node_id_str~# ~NCS5501_top~,        ~subscription_id_str~# ~test~,        ~encoding_path~# ~Cisco-IOS-XR-infra-syslog-oper#syslog/messages/message~,        ~collection_id~# 72000,        ~collection_start_time~# 0,        ~msg_timestamp~# 1516238643814,        ~collection_end_time~# 1516238643814    },    ~Rows~# [        {            ~Timestamp~# 1516238643811,            ~Keys~# {                ~message-id~# 1600            },            ~Content~# {                ~card-type~# ~RP~,                ~category~# ~SECURITY~,                ~group~# ~SSHD~,                ~message-name~# ~INFO_USER_LOGOUT~,                ~node-name~# ~0/RP0/CPU0~,                ~process-name~# ~SSHD_~,                ~severity~# ~message-severity-informational~,                ~text~# ~SSHD_[68638]# %SECURITY-SSHD-6-INFO_USER_LOGOUT # User 'cisco' from '10.154.161.88' logged out on 'vty20' \\n~,                ~time-of-day~# ~Jan 17 17#24#00.240 # ~,                ~time-stamp~# 1516238640000,                ~time-zone~# ~PST~            }        },Looking through the content of the \u201cdump.txt\u201d file can give you a picture of the counters that your router is streaming out.Please be aware that if you stream a lot of data at very high speed, the \u201cdump.txt\u201d will consume a lot of space (there is no compression involved, as in time series databases, and text is stored as is).This is everything you need to know about pushing data to the \u201cdump.txt\u201d file mode configuration!Pipeline# out to InfluxDBThe most popular option is to stream data into InfluxDB (a time series database or TSDB). It is the place where you will store telemetry data to be retrieved later by other tools, like Grafana. InfluxDB and Grafana configuration explanation will be covered in a separated tutorial later. If you want to get some initial information right now, please have a look here.Pipeline configuration for InfluxDB is pretty straightforward#[metrics_influx]stage = xport_outputtype = metrics   \t\t\t## specify the type of the file to be used to select data to be accepted into the TSDBfile = /home/pipeline/metrics.json  \t## define the location of this filedatachanneldepth = 10000  \t\t## optionally, specify a buffer for the dataoutput = influx  \t\t\t## destination is InfluxDBinflux = http#//10.30.110.38#8086  \t## address and port of InfluxDB (can be IPv6 as well)database = mdt_db    \t\t\t## the database within InfluxDB (you will have to create it)workers = 15    \t\t\t## a number of threads working internally (bigger means more threads to be activated)#dump = metricsdump.txt    \t\t## a local dump file for InfluxDBAs you can see, the configuration of Pipeline for InfluxDB is pretty straightforward. There are several moments that need your attention#  You should specify the full path to the \u201cmetrics.json\u201d file.  Everything not defined in \u201cmetrics.json\u201d will be dropped and not inserted into InfluxDB.  You need to specify a specific database inside InfluxDB. The database is not created by itself, as soon as you get InfluxDB installed, you should create this database.  When you just start testing InfluxDB it might be helpful to enable local logging of all the data inserted into the database (enabling \u201cdump\u201d). You will be able to quickly check that your \u201cmetrics.json\u201d file was correct and all needed information is there (Later on, as you feel more confident, you will be able just to get directly into InfluxDB and check information right there, using InfluxDB Query language that is pretty similar to SQL and easy to use).Please be aware that if you stream a lot of data at very high speed, the \u201cmetricsdump.txt\u201d file will consume a lot of space (there is no compression involved and text is saved as a string, while InfluxDB does an efficient compression data while storing).This is everything you need to know to start pushing data to InfluxDB and have it up and running!Pipeline# out to PrometheusThe second possible time series database is Prometheus.Prometheus, by default, prefers a pull based metrics collection. It means, that Prometheus will periodically collect metrics and store it in its database. Such method is not that aligned with goals of telemetry and, so, you need to add one more tool that will push metrics directly to Prometheus. This tool is PushGW. With that information in mind, we can proceed to the Pipeline configuration#[metrics_influx]stage = xport_outputtype = metrics     \t\t\t\t## specify the type of the file to be used to select data to be accepted into the TSDBfile = /home/pipeline/metrics.json  \t        ## define the location of this filedatachanneldepth = 10000    \t\t\t## optionally, specify a buffer for the dataoutput = prometheus  \t\t\t\t## this is where you specify that the destination is Prometheuspushgw = 10.30.110.38#9091    \t\t\t## address and port of PushGWjobname = telemetry  \t\t\t\t## Specify a jobname to be usedstatsensorcount = 1000    \t\t\t## must be set for any stats to be exportedAs you can see, nothing is so hard here. This is everything you need to know to start pushing data to Prometheus and have it up and running!Pipeline# out to KafkaThe last option for Pipeline that will be covered is how to stream data into Kafka bus. It might be useful if you just want to stream the data somewhere and have several your clients to connect to it. In this case, you push your transformed data to the bus and then consumers subscribe to it.Here is the config of Pipeline to push data to Kafka#[output_kafka] stage = xport_outputtype = kafka           \t\t\t## specify the type of the outputencoding = json  \t\t\t## JSON is used as the encodingbrokers = 10.30.110.38#32768  \t\t## specify a Kafka brokertopic = telemetry\t\t\t## specify a name of the topicThis is everything you need to know to start pushing data to Kafka bus and have it up and running!So many ways\u2026 what is the best one?There are many options in Pipeline available for you. This tutorial was created to help you to understand Pipeline better, its benefits and possibilities. If you feel yourself a bit lost and thinking about the best way to start with, then try to look at this stack#IOSXR-&gt;Pipeline-&gt;InfluxDB-&gt;Grafana.It was proved through many trials and pretty easy to make it up and running.ConclusionPipeline is a lightweight, yet a very powerful tool that you can download and start using today. It gives you the flexibility to explore telemetry, to understand how it works and what are the benefits behind the speed and wide coverage of YANG models. There are still many questions left unanswered and we will do our best to make sure that you have a detailed explanation of everything you might need for this exciting journey into [near] real-time monitoring and automation. In our next tutorials, we will cover what you should expect when you activate Telemetry, how Telemetry works internally and interesting use cases that you will be able to download and try by yourself. Stay with us!", "url": "https://xrdocs.github.io/telemetry/tutorials/2018-03-01-everything-you-need-to-know-about-pipeline/", "tags": "iosxr, telemetry, MDT, Streaming Telemetry, Pipeline", "title": "Everything you need to know about Pipeline", "author": "Viktor Osipchuk"}, "blogs-2018-05-03-cisco-ios-xr-at-mplswc2018-interop": {"content": "     Cisco IOS XR at MPLS WC 2018 interop  Time for another interop  The Big Picture  Cisco Participating Devices  Topology Independent Fast Reroute using Segment Routing  SR Traffic Engineering (SRTE) and Path Computation Element Protocol (PCEP)  SR and LDP Interworking  SR Prefix SID extensions for BGP (BGP-SR)  SR Operations, Administration and Maintenance (OAM)  Ethernet VPN  What is NEXT?  Time for another interopI have represented Cisco for more than 8 years at EANTC-sponsored interoperability events. Going back to 2008, I have experienced more pleasant Berlin winters than I could have ever imagined.But seriously and in retrospective, it is fascinating to have witnessed several technology (and even political) battles and transitions that shaped the networking industry. Many technologies and entire companies have had short and unsuccessful lives. In my opinion, during the late 2000s our industry was deeply distracted and as a result wasted brain / development cycles in fruitless endeavors; remember PBT, PBB-TE, T-MPLS, MPLS-TP, OpenFlow?However, one technology has always remained strong \u2013 and that is MPLS. During the hype days of OpenFlow, several so-called experts questioned the future of MPLS in operator networks.  At that time, Cisco was starting the journey with Segment Routing (SR). In November of 2012, Cisco Fellow Clarence Filsfils first disclosed the SR concept to network operators. And just one year later, a new working group was officially formed at the IETF - Source Packet Routing In Networking (SPRING). And in 2015, EANTC was already conducting the first public SR interop event. Fast-forward to today and this interop provides the latest proof-point of overwhelming multi-vendor support for SR.Another technology with a successful trajectory is Ethernet VPN (EVPN). Initially, it was positioned as the next generation solution for Layer 2 VPNs and in particular for Layer 2 Data Center Interconnection (DCI) and multipoint Ethernet LAN (E-LAN) services. From there, it quickly evolved to accommodate other usecases such as point-to-point Ethernet Line (E-LINE) and point-to-multipoint Ethernet Tree (E-Tree) services. Currently, EVPN usecases cross beyond Carrier Ethernet and are deeply entrenched into the datacenter for both intra-subnet and inter-subnet forwarding. In 2013, I was part of the first public interop test of PBB-EVPN at EANTC. In the last five years, multi-vendor support and sophistication of test scenarios have been growing steadily.But enough of the history lesson!!! Let me move onto the important part of this blogMy goal is to provide a technical overview of Cisco\u2019s participation at this year\u2019s interop showcase with platforms powered by the IOS XR operating system. From a technology perspective, my focus will be on SR and EVPN test areas. Be aware that Cisco was also represented by our Datacenter product line and the Network Services Orchestrator (NSO).First, I strongly recommend the reader to go over EANTC\u2019s official public whitepaper. Complementing the information on their report, I take a step back hoping to provide further context and perspective of the results \u2013 Why should I CARE ABOUT the event? What do these results REALLY represent? Then last, I provide further insight as to what operators should keep in mind when evaluating vendor offerings \u2013 What ELSE to keep in mind beyond the results in the report?The Big PictureWith one of the largest vendor participation ever (21 in total) and over 60 device types, this event had the potential to become very meaningful for network operators. And in my view, the event met such expectations.Interop booth at MPLS WC - \u00a9 Photo by EANTCThe following list summarizes SR related facts pertinent to Cisco\u2019s participation at the showcase#  Cisco was one of a total of ten (10) network and test equipment vendors that validated readiness of their SR implementations. The interop counted with participation from all major networking vendors  By far, SR-MPLS dominated on those test cases using MPLS as a transport.  This included the transport of services such as IP VPN and Ethernet VPN. Use of LDP was kept to a minimum. RSVP-TE was not used at the event  IS-IS was chosen as the main IGP throughout the event. Note that use of OSPF was considered but not prioritized due to time constraints  Baseline IS-IS SR extensions were successfully verified. No interoperability issues were observed among Cisco and vendors that we interconnected with. Verified functionality included#          IPv4 control plane      Prefix Segment ID (Prefix-SID) for host prefixes including both Node and Anycast SIDs      Adjacency Segment IDs (Adj-SIDs) for IS-IS adjacencies      Prefix-to-SID mapping advertisements performed by the SR Mapping Server (SRMS) function        SR Traffic Engineering (SRTE) was another area of focus with validation of the following#          Path Computation Element Protocol (PCEP) - Stateful PCE model      PCEP extensions for Segment Routing      BGP Link-State (BGP-LS) and extensions for Segment Routing        In addition, the following SR-MPLS related topics were tested for the first time at EANTC#          Topology Independent LFA (TI-LFA)      SR Prefix SID extensions for BGP (BGP-SR)      SR Operations, Administration and Maintenance (OAM)        Lastly, SRv6 was validated also for the first time at an EANTC event. Tests covered baseline functions from the SRv6 Network Programming IETF draftI describe EVPN related facts later in the blogCisco Participating DevicesAt this year\u2019s event, Cisco IOS XR product portfolio was represented by the Cisco ASR 9000 and NCS 5500 product families. For the NCS 5500, it was its debut at the showcase.Also another first time, was the participation of Cisco IOS XRv9000 virtual router acting as a virtual SR Path Computation Element.Let\u2019s delve next into the main test categories \u2026Topology Independent Fast Reroute using Segment RoutingIt is critical for operators to provide services with SLA guarantees and to automatically restore connectivity in the case of a network component failure. By relying on Segment Routing, Topology Independent Loop Free Alternate (TI-LFA) provides a local repair mechanism to achieve this goal. With behaviors described in an IETF draft, TI-LFA provides key benefits, including#  Automatic Per-Destination protection \u2013 automatic backup paths are pre-computed by the IGP for each destination (prefix). TI-LFA prepares a data-plane switch-over to be activated upon detection of the failure of a link used to reach a given destination  Topology Independent coverage \u2013 TI-LFA provides sub-50msec link, node and local SRLG protection for ANY topology. TI-LFA provides a loop free backup path irrespective of the topologies prior the failure and after the failure  Optimal routing \u2013 TI-LFA provides optimal routing by enforcing a backup path that is identical to the post-convergence path  Stateless operation \u2013 based on source routing paradigm, there is no need to create additional forwarding state in the network in order to enforce a backup pathAs a result of these benefits and based on our deployment experience, TI-LFA remains one of the main drivers behind SR deployments to-date. TI-LFA has been one of the key areas of execution for Cisco since we started shipping it in 2014.With this in mind, we welcomed the addition, for the first-time, of TI-LFA testcases to EANTC\u2019s interop. Highlights of Cisco\u2019s participation include#  Cisco successfully validated sub-50 msec protection with TI-LFA  Cisco successfully validated TI-LFA with Link protection  Cisco successfully validated TI-LFA with Local SRLG protection. Cisco was the only participating vendor that passed this test case  Note that TI-LFA with Node protection is also supported by Cisco\u2019s implementation but was not part of the test plan. Stay tuned for upcoming announcements of new enhancements to Cisco\u2019s TI-LFA in the 2018 summer timeframe!!!Lastly, here are key aspects NOT COVERED by the report and that MUST always be considered as you evaluate TI-LFA implementations#  Does the vendor implementation provide a backup path computed for each destination? Watch for implementations that may cut corners and not compute an optimum backup path for each destination in the network. Cisco\u2019s TI-LFA implementation was designed to meet this goal  Does the vendor implementation provide prefix-independent convergence? Make sure to validate that the implementation\u2019s performance during activation of backup paths does NOT degrade as the number of protected prefixes increases. Cisco\u2019s TI-LFA implementation was also designed and implemented with this principle in mind  Does the vendor implementation provide protection to traffic that originally is forwarded using other paradigms such as LDP signaling or pure IP-routed traffic? Make sure to validate that the implementation\u2019s coverage includes also non-SR traffic. Cisco\u2019s TI-LFA can also be used to protect LDP and IP trafficFor more information, I suggest reviewing this TI-LFA tutorial and TI-LFA demonstrationSR Traffic Engineering (SRTE) and Path Computation Element Protocol (PCEP)Segment Routing\u2019s ability to address traffic engineering (TE) use cases is one of the most sought-after applications of the technology.The SRTE architecture IETF draft describes in detail the behaviors and mechanisms that allow a headend node to direct traffic along a path in the network using \u201cSR Policies\u201d. Based on the source routing paradigm, all state is encoded at the headend node using an ordered list of segments. As a result, SRTE no longer requires state to be maintained at intermediate nodes as it was the case with legacy TE solutions.The segment routed path of an SR policy can be derived from a number of choices, including computation by a centralized PCE. An IETF draft describes PCEP extensions for SR that allow a stateful PCE to compute and initiate TE paths, as well as a path computation client (PCC) to request a path subject to certain constraint(s) and optimization criteria in SR networks.Overall, this was one of the MOST active areas at the interop and where I personally spent most time on. With one of the largest number of positive results achieved, EANTC reported over 30 successful combinations of different PCE-PCC vendor / products.Cisco\u2019s participation in this test area can be broken into 2 categories \u2013 as a PCC and as a PCE.Highlights of Cisco\u2019s participation as PCC include#  Cisco was one of a group of six (6) vendors (not counting traffic emulator vendors) that participated as PCEP PCC headend nodes  Cisco\u2019s SR PCC implementation was the MOST interoperable PCC at the event considering the number of successful test results against participating PCE vendors  As PCC, Cisco successfully validated the creation, update and deletion of SR policies based on the PCE-initiated model with all participating non-Cisco SR PCEs  As PCC, Cisco successfully validated the creation, update and deletion of SR policies based on the PCC-initiated model with all participating non-Cisco SR PCEsHighlights of Cisco\u2019s participation as PCE include#  Cisco was one of a group of three (3) vendors (not counting traffic emulator vendors) that participated as PCEP PCE nodes  Cisco\u2019s SR PCE was the MOST interoperable PCE at the event considering the number of successful test results across participating PCC vendors  As PCE, Cisco successfully validated the creation, update and deletion of SR policies based on the PCE-initiated model with participating non-Cisco SR PCCs  As PCE, Cisco successfully validated the creation, update and deletion of SR policies using PCC-initiated model with participating non-Cisco SR PCCs  Also, Cisco SR PCE successfully validated single-domain and multi-domain topology learning using BGP-LS feeds originated at non-Cisco nodes  Lastly, Cisco SR PCE was the only PCE at the event to successfully validate path computation on a multi-domain network with Egress Peering Engineering (EPE) SIDs at domain boundariesPresenting at MPLS WC with colleagues from Huawei (left) and Nokia (right) - \u00a9 Photo by EANTCLastly, and beyond protocol interoperability, it is important that operators consider these key aspects NOT COVERED by the report when evaluating SRTE headend and PCE implementations#  Does the PCE implementation provide path computation based on the SR principles \u2013 i.e. maximizing ECMP and minimizing label stack size? Watch for implementations that again may cut corners and simply reuse RSVP-TE algorithms for SR. RSVP-TE is non-ECMP aware and circuit-based and hence requiring many SIDs when coding an SR path. Cisco developed NEW algorithms for SR path computation with recognized innovation by the academic community  Does the vendor implementation allow for path computation at the headend? For the majority of single-domain scenarios, the headend node should be in a position to compute paths. Therefore an operator should not settled for SR-optimized path computation only at the PCE but also at the PCC. Remember that the main difference between a headend node and a PCE node is the scope/size of the topology database. The former is single domain while the later could be multi-domain. A Cisco SRTE headend is provided with the SAME computation algorithms that are present in the PCE  Does the implementation provide maximum scale without requiring a-priori full-mesh connectivity? Triggered by a service route (e.g. IP VPN), Cisco\u2019s SR On-demand Next Hop (SR ODN) provides a LOCAL mechanism at the headend that triggers instantiation of an SR policy enforcing the transport SLA required by the service. Learn more and watch an ODN demonstration here  Does the implementation avoid complex and many times performance-impacting traffic steering techniques? Based on the steering behaviors described in the SRTE architecture IETF draft, Cisco supports an innovative steering technique that we called Automated Steering (AS). AS steers automatically service traffic onto the right SR policy based on the color of the service route. This solution provides simplicity and performance without penalties. The benefits of AS apply to all instantiation methods of an SR policy (e.g. on-demand, pce-initiated, local). Watch a demonstration of AS in the same ODN demonstration highlighted in the previous bulletFor more information, I recommend reviewing this SRTE tutorialSR and LDP InterworkingOne of the key usecases addressed by SR is the support of brownfield deployments. Segment Routing interworking with LDP IETF draft documents several mechanisms through which SR interworks with LDP in a network where a mix of SR and LDP routers co-exist.For scenarios where SR and LDP are available in different parts of the network, a continuous MPLS LSP in the SR-to-LDP direction leverages the so-called SR Mapping Server (SRMS) function. The SRMS is an IGP node advertising mapping between Segment Identifiers (SID) and prefixes advertised by other IGP nodes.Cisco\u2019s SR implementation supports SRMS and SR/LDP data-plane interworking functions since 2014.Highlights of Cisco\u2019s participation on this test case include#  Cisco was successfully validated as an SR-only node receiving IS-IS SRMS advertisements from a non-Cisco SRMS implementation  Cisco was successfully validated as an SRMS node in a domain with non-Cisco SR-only nodes  Cisco was successfully validated as an LDP/SR interconnect \u201cstitching\u201d nodeFor more information, I suggest reviewing this SRMS tutorial and SR / LDP interworking tutorialSR Prefix SID extensions for BGP (BGP-SR)Segment Routing Prefix SID extensions for BGP IETF draft defines a BGP attribute for announcing BGP Prefix Segment Identifiers (BGP Prefix-SID) information.  A BGP Prefix-SID is always a global segment (a global instruction) and it identifies an instruction to forward the packet over the ECMP-aware best-path computed by BGP to the related prefix.Use cases for the BGP Prefix SID are documented in these IETF drafts# BGP-Prefix Segment in large-scale data centers and Interconnecting Millions Of Endpoints With Segment Routing.This test case represented a first-time interop test at EANTC. Highlights of Cisco\u2019s participation on this test case include#  Cisco was successfully validated as a Leaf node in a multi-vendor BGP-SR fabric  Cisco was successfully validated as a Spine node in a multi-vendor BGP-SR fabricSR Operations, Administration and Maintenance (OAM)Network operators require the ability to verify and isolate faults within the SR network. IETF RFC 8287 defines a set of extensions to perform LSP Ping and Traceroute operations for SR IGP-Prefix SIDs and IGP-Adjacency SIDs with an MPLS data plane.This test case also represented a first-time interop test at EANTC. Highlights of Cisco\u2019s participation on this test case include#  Cisco was successfully validated as initiator of SR OAM ping / traceroute operations  - using an MPLS echo request with a target FEC Stack TLV carrying FECs with the new IPv4 IGP-prefix SID sub-TLV  Cisco was successfully validated as target / responder of SR OAM ping / traceroute operationsDuring the event, an interop issue arose among some vendors due to different interpretations of RFC 8287 concerning the IPv4 IGP-prefix SID sub-TLV length. A technical errata was raised by one of the interop participating vendors.Ethernet VPNFrom its inception, Cisco has been leading the definition of EVPN at the IETF. And followed by a strong commitment reflected in our implementation across Service Provider and Datacenter product lines, the technology is deployed by network operators worldwide.Though some may have noticed IOS XR\u2019s absence for the past couple of years at this interop, we returned back with full-strength and showcased the advanced EVPN feature set available in Cisco ASR 9000 and NCS 5500 product families.Highlights of Cisco\u2019s participation on this test area include#  Cisco was one of a group of eight (8) vendors (not counting traffic emulator vendors) that participated in the EVPN test area. This represents an all-time high and included participation from all major networking vendors  Cisco acted as the main BGP route-reflector for EVPN and was leveraged by all participating vendors connected to the SR-MPLS core  For the first time at EANTC, a common SR-MPLS network was used as the main transport for EVPN services across the core  EVPN all-active multi-homing over SR-MPLS test case          All-active multi-homing functionality is one of the main advantages of EVPN over its legacy predecessors such as VPLS      Cisco was successfully validated as a PE in a multi-vendor multi-home Ethernet segment        EVPN VPWS over SR-MPLS test case          Cisco was successfully validated as a PE in a single-home configuration. Participating vendors had agreed to perform multi-home testing, but we ran out of time. There are only so many days that one can run non-stop on high caffeine!!!        EVPN-VXLAN and IP-VPN Interworking test case          Cisco was successfully validated as a Layer 3 DCI interconnecting EVPN datacenter sites across a WAN network based on IP-VPN      What is NEXT?Follow us on Twitter and LinkedIN for the latest announcementsAlso visit our external SR site to stay abreast of the latest presentations, tutorials, demonstrations and much more!!!Interop-wise, I look forward to another successful event in 2019. In particular, I look forward to multi-vendor interest and readiness in a number of important standard-based solutions that Cisco ALREADY proposed for this year\u2019s event; including#  IGP Segment Routing Flexible Algorithms \u2013 Flex Algo, the latest addition to the SRTE toolkit, defines IGP extensions that allow an operator to customize and assign traffic-engineering optimizations to an IGP prefix algorithm. Flex Algo is defined at IETF for both IS-IS and OSPF. Cisco announced this new solution at Cisco Live Barcelona 2018 and further described it in Clarence\u2019s blog and this demonstration  BGP-signaled Segment Routing Policies \u2013 BGP can also be used to signal an SR Policy candidate path to an SRTE headend.  A new BGP SAFI and NLRI are under standardization at IETF  PCEP LSP Disjointness Signaling and Computation \u2013 Path diversity is a very common use case today in IP/MPLS networks especially for Layer 2 transport over MPLS. An IETF draft describes a PCEP extension for signaling LSP diversity constraint. Such request can then be honored by a PCE computing LSP paths of the desired disjointness typeBut above all, I really look forward to yet another pleasant Berlin winter!!!", "url": "https://xrdocs.github.io/cloud-scale-networking/blogs/2018-05-03-cisco-ios-xr-at-mplswc2018-interop/", "tags": "iosxr, cisco", "title": "MPLS + SDN + NFV World @ Paris2018 \u2013 Cisco IOS XR participation at Interoperability Showcase", "author": "Jose Liste"}}